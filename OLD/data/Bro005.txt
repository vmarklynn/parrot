0:00:00	SPEAKER_07
 Hey, Mike, Mike one.

0:00:12	None
 Uh?

0:00:14	None
 Yes, please.

0:00:18	SPEAKER_03
 I mean, we're testing oyster busting, but listen, you get to wait.

0:00:28	SPEAKER_02
 Okay, so, uh, we've got some, uh, Zerax things to pass out.

0:00:34	SPEAKER_07
 Yeah.

0:00:42	SPEAKER_07
 I'm sorry for the table, but...

0:00:44	None
 There's a bruise.

0:00:46	SPEAKER_03
 This one's nice though.

0:00:48	SPEAKER_03
 This is the last column we use for imagination.

0:00:52	None
 Okay.

0:00:54	SPEAKER_03
 Uh, this one's nice though.

0:00:58	SPEAKER_03
 This has nice big font.

0:01:00	SPEAKER_09
 Yeah.

0:01:02	SPEAKER_09
 Yeah.

0:01:06	SPEAKER_03
 Yeah.

0:01:08	SPEAKER_03
 You get older, you have these different perspectives.

0:01:10	SPEAKER_03
 I mean, lowering the word area to spine, but having big font.

0:01:14	SPEAKER_07
 Extending the width.

0:01:16	SPEAKER_07
 Put the cut off for some.

0:01:20	SPEAKER_04
 Yeah, it's a nice little big line.

0:01:28	SPEAKER_07
 Okay.

0:01:30	SPEAKER_07
 Okay.

0:01:32	SPEAKER_07
 So there is kind of summary of what has been done.

0:01:36	SPEAKER_07
 Oh, summary of experiments since, well, since last week and also since the...

0:01:40	SPEAKER_07
 We've started working this.

0:01:44	SPEAKER_07
 So since last week, we've started to fill the column with, uh, features with net strain on PLP with our nine normalization, but with delta also, because the column must not completely, what?

0:02:00	SPEAKER_07
 It's still not completely filled, but we have more results to compare with network using without BLP. And finally, delta seems very important.

0:02:14	SPEAKER_07
 I don't know if you take, um, let's say, anyway, or a 2B.

0:02:22	SPEAKER_07
 So the next, the second part of the table, uh, when we use the large training set using French Spanish and English, you have 106 without delta and 89 with the delta.

0:02:36	SPEAKER_03
 And again, all of these numbers are with 100% being the baseline performance, but with the no cap straw system going straight into the edge.

0:02:48	SPEAKER_07
 So now we see that the gap between the different training set is much, uh, much smaller.

0:03:02	SPEAKER_07
 But actually, for English training on timid is still better than the other languages.

0:03:12	SPEAKER_07
 And, yeah.

0:03:18	SPEAKER_07
 And also for Italian, actually. If you take the second set of experiment for Italian, so the mismatched condition, um, when we use the training on timid, so it's multi-english, we have 91 number, and training with other languages is a little bit worse.

0:03:38	SPEAKER_03
 Oh, I see it down near the bottom of this sheet.

0:03:42	SPEAKER_07
 So, yeah. And, yeah. And here, the gap is still more important between using delta and not using delta.

0:03:52	SPEAKER_07
 If I take the, the large training set, it's, we have 172, and 104 when we use delta.

0:04:00	SPEAKER_07
 Even if the context is quite the same because without delta, we use 17 frames.

0:04:08	SPEAKER_07
 Yeah. So, the second point is that we have no single cross-language experiments that we did not have last week.

0:04:20	SPEAKER_07
 So, this is training the net on French only, or on English only, and testing on Italian.

0:04:28	SPEAKER_07
 And training the net on French only, and Spanish only, and testing on the attitudes.

0:04:36	SPEAKER_07
 And, yeah. What we see is that these nets are not as good, except for the multi-english, which is always one of the best.

0:04:48	SPEAKER_07
 Yeah. Then, we've started to work on a large data base containing sentences from the French, from the Spanish, from the Tibet, from Spain, from English digits, and from Italian digits.

0:05:14	SPEAKER_07
 So, this is another line, another set of lines in the table, and left to the same as what it's fine.

0:05:22	SPEAKER_07
 And, actually, we did this before knowing the result about the delta. So, we have to redo the experiment training the net with PLP, but with delta.

0:05:34	SPEAKER_07
 But, this net performed quite well. It's better than the net using French, Spanish, and English.

0:05:44	SPEAKER_07
 So, we have also started feature combination experiments, mainly experiments using features and net outputs together.

0:06:08	SPEAKER_07
 And, this is the results on the other document.

0:06:16	SPEAKER_07
 We can discuss this after a problem, just to know if we need to.

0:06:20	SPEAKER_07
 Yeah. So, basically, there are four kind of systems. The first one is combine two feature streams using each feature stream as its own MLP, so it's similar to the tandem that was proposed for the first multi-stream tandem for the first proposal.

0:06:42	SPEAKER_07
 The second is using features and PLT transform MLP outputs, and the third one is to use a single PLT transform features as well as MLP outputs.

0:06:58	SPEAKER_07
 Yeah. You can command this result.

0:07:06	SPEAKER_08
 Yes, I would like to say that, for example, if we doesn't use the delta delta, we have an improve when we use some combination.

0:07:24	SPEAKER_07
 But, we... Just to clear the numbers here are recognition accuracy. So, it's another one.

0:07:32	SPEAKER_08
 Again, we switch to another one.

0:07:34	SPEAKER_08
 Yes, and the base line is 82.

0:07:38	SPEAKER_02
 The base line is 82.

0:07:40	SPEAKER_02
 Yeah.

0:07:41	SPEAKER_07
 So, it's experiment only on the Italian mismatched for the moment for this.

0:07:46	SPEAKER_08
 This is Italian mismatched. Okay, I move.

0:07:56	SPEAKER_08
 This is MLP, and it's obviously that the English MLP is dependent. For the rest of the experiment, I use multi-English, only multi-English.

0:08:16	SPEAKER_08
 The result is that the MSG-3 feature doesn't work for the Italian database, because it never helps to increase the algorithms.

0:08:30	SPEAKER_07
 Actually, if we look at the table, the huge table, we see that for TI digits, MLG performs as well as the PLP. But this is not a case for Italian.

0:08:44	SPEAKER_07
 Where the error rate is almost twice the error rate of PLP.

0:08:50	SPEAKER_07
 So, I don't think this is a bug, but this is something in probably the MLG process that...

0:09:03	SPEAKER_07
 I don't know what exactly perhaps the fact that there's no low pass filter, well, or low-prim phase filter, and that there is some VC offset in the Italian.

0:09:15	SPEAKER_07
 Well, something simple like that, but that we need to sort out if we want to get improvement by combining PLP and MSG, because on the moment the MSG doesn't bring much information.

0:09:29	SPEAKER_07
 And as Karman said, if we combine the two, we have the result basically of PLP.

0:09:35	SPEAKER_03
 The baseline system, when you said the baseline system was 82%, that was trained on what and tested on what.

0:09:45	SPEAKER_03
 That was Italian mismatched digits, is the testing, and the training is Italian digits.

0:09:55	SPEAKER_03
 So, the mismatch just refers to the noise and microphone, so forth. So, would that then correspond to the first line here of where the training is?

0:10:13	SPEAKER_03
 Is the Italian digits...

0:10:15	SPEAKER_08
 The training of the HTG?

0:10:19	SPEAKER_08
 Yes.

0:10:20	SPEAKER_03
 Training of the net, yeah. So, what that says is that in a matched condition, we end up with a fair amount worse putting in the PLP.

0:10:32	SPEAKER_03
 Now, do we have a number I suppose for the matched? I don't mean matched, but use of Italian training on Italian digits for PLP only.

0:10:43	SPEAKER_07
 So, basically this is in the table. So, the number is 52%.

0:10:55	SPEAKER_07
 52% of 82% of 18%. So, it's error rate.

0:11:03	SPEAKER_07
 So, this is accuracy. So, we have 90%.

0:11:13	SPEAKER_07
 Which is what we have also if we use PLP and MSG together, 89.7%.

0:11:22	SPEAKER_03
 Okay, so, even just PLP, it is not in the matched condition. I wonder if it's the difference between PLP and Mellkebstra or whether it's that the net of some reason is...

0:11:42	SPEAKER_07
...it's not PLP and Mellkebstra give the same result. Well, we have this result. It's not...

0:11:52	SPEAKER_07
 So, PLP is a result with PLP alone feeling HTK. That's what you mean. Just PLP.

0:11:59	SPEAKER_03
 So, PLP. So, adding MSG, well, but that's without the neural net, right?

0:12:15	SPEAKER_07
 Yeah, that's without the neural net. And that's the result, basically, that OGI as well. So, with the MFCC with online normalization.

0:12:22	SPEAKER_03
 But, she had said 82%.

0:12:25	SPEAKER_07
 But, this is without online normalization.

0:12:29	SPEAKER_07
 Oh, this is the 82.

0:12:31	SPEAKER_07
 82 is the Aurora baseline. So, MFCC, then we can use...

0:12:35	SPEAKER_07
 Well, OGI, they use MFCC, the baseline MFCC plus online normalization.

0:12:40	SPEAKER_03
 I keep getting confused because this is accuracy.

0:12:44	SPEAKER_03
 Alright, alright. So, this is... I was thinking, this was worse. Okay, so, this is all better because...

0:12:49	SPEAKER_03
 I'm bigger than 82. Okay, I'm all better now. Okay.

0:12:55	SPEAKER_07
 So, what happens is that when we apply online normalization, we jump to almost 90%.

0:13:04	SPEAKER_07
 When we apply a neural network is the same. We jump to 90%.

0:13:10	SPEAKER_07
 And whatever the normalization actually, if we use a neural network, even if the features are not correctly normalized, we jump to 90%.

0:13:21	SPEAKER_03
 So, we go from 88.6 to 290.

0:13:25	SPEAKER_07
 No, I mean 90, it's around 89.

0:13:28	SPEAKER_07
 89.

0:13:29	SPEAKER_03
 And then, adding MFCC does nothing, basically.

0:13:33	SPEAKER_07
 No.

0:13:34	SPEAKER_07
 Okay.

0:13:36	SPEAKER_07
 For Italian.

0:13:38	SPEAKER_07
 For this case, right?

0:13:41	SPEAKER_03
 Alright. So, actually, the answer for experiments with one is that adding MSG, if you does not help in that case...

0:13:59	SPEAKER_06
 But don't, it's really good.

0:14:05	SPEAKER_03
 And the multi-English does...

0:14:11	SPEAKER_03
 So, if we think of this as an error rate, we start off with 18% error rate, roughly.

0:14:19	SPEAKER_03
 And we almost cut that in half by putting in the online normalization and the neural net.

0:14:32	SPEAKER_03
 And the MSG doesn't, however, particularly affect things.

0:14:37	SPEAKER_03
 And we cut off, I guess, about 25% of the error.

0:14:44	SPEAKER_03
 No, not quite that. Is it 2.6?

0:14:48	SPEAKER_03
 Not 18, but 16% or something of the error.

0:14:55	SPEAKER_03
 If we use multi-English instead of the magic condition.

0:14:59	SPEAKER_03
 But the Italian track.

0:15:02	SPEAKER_03
 Yeah.

0:15:03	SPEAKER_03
 Okay.

0:15:04	SPEAKER_08
 We select these stats because it's the more difficult.

0:15:10	SPEAKER_03
 Yes. Good.

0:15:13	SPEAKER_03
 Okay. So, then, you're assuming multi-English is closer to the kind of thing that you could use, since you're not going to have magic data for the other languages and so forth.

0:15:28	SPEAKER_03
 One thing is that, I think I asked you this before, but I want to double check.

0:15:33	SPEAKER_03
 When you say ME in these other tests, that's the multi-English.

0:15:39	SPEAKER_03
 But it is not all of the multi-English, right?

0:15:42	SPEAKER_03
 It's a part of it.

0:15:43	SPEAKER_07
 It's a part of it.

0:15:44	SPEAKER_07
 Or one million frames.

0:15:46	SPEAKER_07
 And the multi-English is how much?

0:15:49	SPEAKER_07
 It's one million and the half.

0:15:53	SPEAKER_03
 Yeah.

0:15:54	SPEAKER_03
 Oh, so you use almost all these two thirds of it.

0:15:57	SPEAKER_03
 So, it still, it hurts you.

0:16:00	SPEAKER_03
 It seems to hurt you a fair amount to add in this French and Spanish.

0:16:03	SPEAKER_03
 Yep.

0:16:04	SPEAKER_02
 That's why it's too wide.

0:16:07	SPEAKER_01
 Well, Stefan was saying that they weren't hand-label.

0:16:12	SPEAKER_01
 Yeah.

0:16:13	SPEAKER_01
 Yeah, he's French and Spanish.

0:16:15	SPEAKER_01
 It's a bit...

0:16:16	SPEAKER_08
 Maybe for that.

0:16:23	SPEAKER_03
 Still.

0:16:24	SPEAKER_03
 Okay.

0:16:25	SPEAKER_03
 All right, go ahead.

0:16:28	SPEAKER_08
 And then...

0:16:31	SPEAKER_08
 With the experiment type 2, I first tried to combine some feature from the MLP and other feature.

0:16:43	SPEAKER_08
 Another feature.

0:16:46	SPEAKER_08
 And we can...

0:16:49	SPEAKER_08
 First, the feature are without Delta Delta Delta and we can see that in this situation, the MSG3, the same help, nothing.

0:17:00	SPEAKER_08
 And then I do the same, but with the Delta Delta Delta, PLP Delta Delta Delta.

0:17:07	SPEAKER_08
 And the output of the MLP is without Delta Delta Delta.

0:17:13	SPEAKER_08
 And we have a little bit less result than the...

0:17:20	SPEAKER_08
 The baseline PLP with Delta Delta Delta.

0:17:26	SPEAKER_08
 Maybe when we have the new...

0:17:30	SPEAKER_08
 The new neural network, China with PLP Delta Delta Delta, maybe the final result must be better.

0:17:38	SPEAKER_08
 I don't know.

0:17:39	SPEAKER_07
 Actually, it's just to be so more...

0:17:42	SPEAKER_07
 This number, this 87.1 number has to be compared with...

0:17:50	SPEAKER_03
 Yes, yeah, I mean, you can't compare with the other because this is a with multi-English training.

0:17:54	SPEAKER_03
 She has to compare it with the one over that you've got in a box, which is that 84.6.

0:18:02	SPEAKER_07
 So...

0:18:03	SPEAKER_07
 Yeah, but I mean, in this case, for the 87.1, we use MLP outputs for the PLP net and straight features with Delta Delta.

0:18:11	SPEAKER_07
 And straight features with Delta Delta gives you what's on the first G, 88.6.

0:18:18	SPEAKER_03
 No, no, no, no, not trained with multi-English.

0:18:21	SPEAKER_07
 Yeah, but this is the second configuration.

0:18:24	SPEAKER_07
 So we use feature or net outputs together with features.

0:18:29	SPEAKER_07
 So, yeah, this is not perhaps not clear in, but in this table, the first column is for MLP and the second is for the features.

0:18:37	SPEAKER_07
 So, you're saying, so, so, in the question, what, what has adding the MLP down?

0:18:41	SPEAKER_07
 Yeah, so, actually, it, it decrease the accuracy because we have 88.6 and even the MLP alone, what gives the MLP alone?

0:18:52	SPEAKER_07
 Multi-English PLP, oh no, it gives 83.6.

0:18:58	SPEAKER_07
 So, we have 83.6 and 88.6 that gives 87.1.

0:19:05	SPEAKER_03
 I thought it was 80.

0:19:07	SPEAKER_03
 Okay, 83.6 and 88.6.

0:19:11	SPEAKER_05
 Okay, is that right?

0:19:13	SPEAKER_08
 Yeah.

0:19:14	SPEAKER_08
 But, you don't know, but maybe if we have the neural network, it will be the PLP delta Delta Delta, maybe.

0:19:24	SPEAKER_08
 Perhaps, yeah.

0:19:26	SPEAKER_03
 But that's one thing. But see, the other thing is that, I mean, it's good to take the difficult case, but let's consider what that means.

0:19:33	SPEAKER_03
 What, what we're saying is that, one of the things that, I mean, my interpretation of your, your, your, your suggestion is something like this, as motivation.

0:19:42	SPEAKER_03
 When we train on data, that is in one sense or another similar to the testing data, then we get a wind by having a instrument in training.

0:19:55	SPEAKER_03
 When we train on something that's quite different, we have a potential to have some problems.

0:20:00	SPEAKER_03
 And, if we get something that helps us when it's somewhat similar and doesn't hurt us too much, when it, when it's quite different, that's maybe not so bad.

0:20:12	SPEAKER_03
 So, the question is, if you took the same combination and you tried it out on, on, on, on, say digits, you know, was that experiment done?

0:20:22	SPEAKER_03
 No, okay.

0:20:23	SPEAKER_03
 Then, does that, you know, maybe with similar noise conditions and so forth, does it, does it then look much better?

0:20:30	SPEAKER_03
 And so, what is the range over these different kinds of tests? So, anyway, okay.

0:20:36	SPEAKER_03
 Yes.

0:20:37	SPEAKER_08
 And, with this type of configuration, what I do, I experiment using the new neural net with, named BloodClath 27, and I have found more let the same result.

0:20:55	SPEAKER_07
 So, it's slightly better.

0:20:58	SPEAKER_07
 It's slightly better.

0:20:59	SPEAKER_08
 Yeah, it's better, yes, it's better.

0:21:01	SPEAKER_03
 And, and, you know, again, maybe if you use the delta there.

0:21:06	SPEAKER_03
 Yeah, maybe.

0:21:07	SPEAKER_03
 You bring it up to where it was, you know, at least about the same, for a difficult case.

0:21:12	SPEAKER_07
 Yeah, so, well, so perhaps let's, let's jump at the last experiment.

0:21:16	SPEAKER_07
 Yes.

0:21:17	SPEAKER_07
 It's either less information from the neural network, if we use only the silence output, it's again better.

0:21:23	SPEAKER_07
 So, it's 89.

0:21:24	SPEAKER_08
 40, 40, 40, 40, because in the situation, we prefer one kind of answer.

0:21:31	SPEAKER_08
 Yeah.

0:21:36	SPEAKER_08
 And then, with the first configuration, I am found that work, that's not work, work, work, but it's better the second configuration.

0:21:54	SPEAKER_08
 Because, for the, in the PLP delta and delta delta, we have 85.3 agglance, and with the second configuration, we have 87.1.

0:22:09	SPEAKER_03
 And, by the way, there was another suggestion that would apply to the second configuration, which was made by, and that was that if you have a feed two streams into HTK, and you change the variances, you scale the variances associated with these streams, you can effectively scale the streams.

0:22:51	SPEAKER_03
 Right, so, you know, without changing the scripts, for HTK, which is the rule here, you can still change the variances, which would effectively change the scale of these two streams that come in.

0:23:11	SPEAKER_03
 And so, if you do that, for instance, it may be the case that the MLP should not be considered as strongly.

0:23:28	SPEAKER_03
 And so, this is just setting them to be equal weight. Maybe it shouldn't be equal weight. I'm sorry to say that gives more experiments if we want to look at that.

0:23:42	SPEAKER_03
 Yeah, on the other hand, it's just experiments at the level of the HTK recognition. It's not even HTK. Well, I guess you have to do the HTK training also. Do you?

0:23:59	SPEAKER_03
 Yeah, you have to change the... No, you can just do it. Once you've done the training, the training is just coming up with variances, so I guess you can scale them all.

0:24:14	SPEAKER_03
 Scaled variances. But, is it... I mean, HTK models are diagonal variances, so... That's exactly the point I think that if you change what they are, it's diagonal variance matrices, but you say what those variances are.

0:24:40	SPEAKER_03
 So, that, you know, it's diagonal means that then you're going to... It's going to generally multiply it.

0:24:52	SPEAKER_03
 It's implicitly expenetuated to get probabilities, and so it's going to affect a range of things if you change the variances of some of the features. So, it's precisely given that model, you can very simply affect the strength of the two by the features.

0:25:14	SPEAKER_03
 So, that was... I already suggested. Yeah. So... So, it could just be that repeating them equally, treating two streams equally is just not the right thing to do.

0:25:36	SPEAKER_03
 Of course, it's potentially opening a can of worms because maybe it should be a different number of free queries. That's it.

0:25:46	SPEAKER_03
 Okay. So, I guess the other thing is to take... Yeah, if you want more to take a couple of the most successful of these.

0:25:59	SPEAKER_07
 Yeah, test, press everything. Yeah, try out these different tests.

0:26:12	SPEAKER_07
 So, the next point here, we've had some discussion with Steven Chauen about the artillery stuff. So, we'll perhaps start something next week.

0:26:33	SPEAKER_07
 The discussion with Inek, Sunil and Pratyba for trying to plug in our networks within their block diagram, where to plug in the network after the feature before or as a plug-in or as another path.

0:26:58	SPEAKER_07
 The discussion about multi-bound traps actually in Inek would like to see, perhaps if you remember the block diagram, there is a temporal LDA followed by a spectral LDA for each critical bound.

0:27:18	SPEAKER_07
 And it would like to replace these by a network which would make the system look like a trap. Well, basically it would be a trap system.

0:27:30	SPEAKER_07
 Basically, this is a trap system, kind of trap system, I mean, but where the neural network are replaced by LDA.

0:27:42	SPEAKER_07
 Yeah, and about multi-bound. I started multi-bound MLP training. Actually, I prefer to do exactly what I did when I was in Belgium.

0:27:58	SPEAKER_07
 So, I take exactly the same configuration, seven bands with nine frames of context, which is trained on the T-MIT and on the large database. So, with Spine and everything.

0:28:12	SPEAKER_07
 I started to train all the networks with larger contexts. So, this would be something between traps and multi-bound because we still have quite large bands, but with a lot of context also.

0:28:32	SPEAKER_07
 Yeah, we still have to work on finish. Basically, to make a decision on which MLP can be the best across the different languages for the moment, it's the T-MIT network and perhaps the network trained on everything.

0:28:50	SPEAKER_07
 So, we can test these two networks with delta and large networks. Test them also on finish and see which one is the best.

0:29:04	SPEAKER_07
 Well, the next part of the document is basically a kind of summary of everything that has been done. So, we have 79 MLPs trained on 1, 2, 3, 4, 5, 10 on 10 different databases.

0:29:27	SPEAKER_07
 The number of frames is also, so we have 1 million and half for some, 3 million for other and 6 million for the last one.

0:29:38	SPEAKER_07
 Yeah, as we mentioned, T-MIT is the only that's unlabeled. And perhaps this is what makes the difference. Yeah, the other are just Viter B-Lite.

0:29:52	SPEAKER_07
 So, these 79 MLPs differ on different things. First, with respect to the online normalization, there are that use bad online normalization and other good online normalization.

0:30:07	SPEAKER_07
 With respect to the features, with respect to the use of delta or no, with respect to the hidden layer size and to the targets. But of course, we don't have all the combination of these different parameters.

0:30:25	SPEAKER_07
 What's this? We only have 288 trained tests, not 2000. I was impressed by 2000.

0:30:40	SPEAKER_07
 Yeah, basically the observation is what we discussed already, the MLG problem. The fact that the MLP trained on target task decreased the error rate.

0:31:00	SPEAKER_07
 But when the MLP trained on the target task increased the error rate compared to using straight features. Except if the features are bad, actually except if the feature are not correctly online normalized.

0:31:20	SPEAKER_07
 In this case, the T-M is still better even if it's trained on not on the target digits. Yeah, so it sounds like the net corrects some of the problems with some poor normalization. But if you can do good normalization, it's...

0:31:37	SPEAKER_07
 So the fourth point is, yeah, the T-Mit plus noise seems to be the training set that gives the best network.

0:31:47	SPEAKER_03
 Before you go on to the possible issue, so on the MSG problem, I think that in the short time solution, that is trying to figure out what we can proceed forward with to make the greatest progress.

0:32:12	SPEAKER_03
 As I said with J-Rasta, I really like J-Rasta and I really like MSG. I think it's kind of in the category that it may be complicated.

0:32:22	SPEAKER_03
 And it might be if someone's interested in it, certain encourage anybody to look into it in a longer term.

0:32:29	SPEAKER_07
 So we get out of this particular rush for results, but in the short term, unless you have some strong idea of what's wrong.

0:32:45	SPEAKER_07
 No bypass filter. Yeah, there's supposed to be an MSG. Supposed to have an online normalization now. There is an edge kind of a GC.

0:32:59	SPEAKER_03
 Yeah, but also there's an online norm. Besides the a GC, there's an online normalization that you're supposed to be.

0:33:05	SPEAKER_03
 Yeah, taking out means and variances and so forth. In fact, the online normalization that we're using came from the MSG design.

0:33:17	SPEAKER_07
 Yeah, but this was the bad online normalization. Actually.

0:33:23	SPEAKER_08
 Are you a result of still with the bad online two?

0:33:35	SPEAKER_07
 Online two is good.

0:33:39	SPEAKER_03
 Yeah, so yeah, I agree. It's probably something simple. If someone, you know, let's play with it for a little bit. I mean, you're going to do what you're going to do, but my guess would be that it's something that is a simple thing that could take a while to find.

0:33:59	SPEAKER_03
 Yeah, and the other results observations two and three is, yeah, it's pretty much what we've seen that what we were concerned about is that if it's not on the target task, if it's on the target task, then it helps to have the MLP transforming it.

0:34:23	SPEAKER_03
 If it's not on the target task, then depending on how different it is, you can get a reduction in performance.

0:34:31	SPEAKER_03
 And the question is now how to get one and not the other or how to ameliorate the problems.

0:34:39	SPEAKER_03
 Because it certainly does is nice to have in there when there is something like that.

0:34:51	SPEAKER_07
 Yeah, so that's what you say.

0:34:53	SPEAKER_07
 The reason is that perhaps the target, the task dependency, the language dependency, and the noise dependency.

0:35:01	SPEAKER_07
 Well, but this is still not clear because I don't think we have enough result to talk about the language dependency.

0:35:14	SPEAKER_07
 Well, the team network is still the best, but there is also the other difference, the fact that it's unlabeled.

0:35:22	SPEAKER_04
 Hey.

0:35:24	SPEAKER_04
 I don't have a link.

0:35:26	SPEAKER_03
 I'm just sitting here.

0:35:30	SPEAKER_03
 I don't think we want to mess with the microphones, but just have a seat.

0:35:38	SPEAKER_03
 The summary of the first 45 minutes is that some stuff works and some stuff doesn't.

0:35:48	SPEAKER_07
 Okay.

0:35:50	SPEAKER_07
 We still have one of these.

0:35:53	SPEAKER_03
 Yeah, I guess we can do a little better than that.

0:35:58	SPEAKER_03
 I think if you start off with the other one, it sort of has it in words, and that has the associated result.

0:36:06	None
 Okay.

0:36:08	SPEAKER_03
 So you're saying that although we see, yes, there's what you would expect in terms of a language dependency and a noise dependency.

0:36:16	SPEAKER_03
 That is when the neural net is trained on one of those and tested on something different.

0:36:22	SPEAKER_03
 You don't do as well as in the target thing, but you're saying that it is, although that general thing is observable so far, there's something you're not completely convinced about.

0:36:32	SPEAKER_03
 And what is that?

0:36:36	SPEAKER_07
 When you say not clear yet, what do you mean?

0:36:38	SPEAKER_07
 I mean, the fact that for the IDGITs, the timet net is the best, which is the English net, but the other has likely worse.

0:36:50	SPEAKER_07
 But you have to do affect the effect of changing language and the effect of training on something that's bitterly aligned instead of end and level.

0:37:00	SPEAKER_07
 Yeah.

0:37:06	SPEAKER_03
 Do you think the alignments are bad?

0:37:08	SPEAKER_03
 I mean, have you looked at the alignments at all? What do the terribly alignments do?

0:37:14	SPEAKER_07
 I don't know.

0:37:16	SPEAKER_07
 Did you look at the Spanish alignments, Carmen?

0:37:20	SPEAKER_03
 No.

0:37:22	SPEAKER_03
 It's interesting to look at it, because I mean, that is just looking, but it's not clearly necessarily what you do so badly from a terribly aligned net.

0:37:34	SPEAKER_03
 Depends on whether the ranking measure is that the engine is doing the alignment.

0:37:40	SPEAKER_05
 Yeah.

0:37:42	SPEAKER_07
 But perhaps it's not really the alignment that's bad, but just the phoneme string that's used for the alignment.

0:37:54	SPEAKER_07
 The pronunciation.

0:37:56	SPEAKER_07
 I mean, it's single pronunciation.

0:38:00	SPEAKER_07
 French phoneme strings were corrected manually, so we ask people to listen to the sentence, and we give the phoneme string and they kind of correct them.

0:38:11	SPEAKER_07
 But still, there might be errors just in the string of phonemes.

0:38:23	SPEAKER_07
 Yeah, so this is not really the real deal, I mean.

0:38:31	SPEAKER_07
 The third issue is the noise dependency, perhaps, but this is not clear yet, because all the nets are trained on the same noises.

0:38:43	SPEAKER_03
 I thought some of the nets were trained with the spine and so forth, so they're not that nice.

0:38:49	SPEAKER_07
 But the results are only coming for the nets.

0:38:56	SPEAKER_03
 Okay, yeah, just don't need more results there with that.

0:39:04	SPEAKER_07
 So, from these results, we have some questions with answers.

0:39:08	SPEAKER_07
 What should be the network input?

0:39:11	SPEAKER_07
 PLP work as well as MFCC, I mean.

0:39:17	SPEAKER_07
 But it seems important to use the delta.

0:39:21	SPEAKER_07
 We respect to the network size. There's one experiment that's still running, and we should have the result today, comparing networks with 500 and 1000 units.

0:39:35	SPEAKER_07
 Still no answer actually.

0:39:38	SPEAKER_07
 The training set, well, some kind of answer.

0:39:41	SPEAKER_07
 We can tell which training set gives the best result, but we don't know exactly why.

0:39:49	SPEAKER_03
 Right, I mean, the multi-English so far is the best.

0:39:53	SPEAKER_03
 Multi-English just means Tim.

0:39:57	SPEAKER_03
 So, yeah, so when you add other things into broad nets, it gets worse.

0:40:09	SPEAKER_07
 So, some questions with answers. Training set.

0:40:19	SPEAKER_07
 Training targets.

0:40:21	SPEAKER_03
 I like that the training set is both questions with answers and without answers.

0:40:25	SPEAKER_03
 It's multi-purpose.

0:40:29	SPEAKER_07
 Training, so yeah, the training targets actually.

0:40:33	SPEAKER_07
 The two of the main issues perhaps are still the language dependency and the noise dependency.

0:40:39	SPEAKER_07
 And perhaps to try to reduce the language dependency, we should focus on finding some other kind of training targets.

0:40:47	SPEAKER_07
 And labeling seems important because of the limit results.

0:40:54	SPEAKER_07
 For a moment, we use phonetic targets, but we could also use articulatory targets, soft targets, perhaps even use networks that doesn't do classification, but just regression.

0:41:06	SPEAKER_07
 So, trying to have neural networks that...

0:41:14	SPEAKER_07
 There's a regression and, well, basically, compute features without noise.

0:41:24	SPEAKER_07
 I mean, transform the noisy features in other features that are not noisy, but continuous features, not art targets.

0:41:34	SPEAKER_03
 Yeah, that seems like a good thing to do, probably not again a short term sort of thing.

0:41:42	SPEAKER_03
 I mean, one of the things about that is that...

0:41:48	SPEAKER_03
 I guess the major risk you have there being is being dependent on the kind of noise.

0:41:56	SPEAKER_07
 Yeah, but yeah, so this is...

0:42:00	SPEAKER_07
 Well, this one thing could help perhaps to reduce language dependency and for the noise part, we could combine this with other approaches like, the clenchmit approach, so the idea of putting all the noise that we can find inside the database, I think clenchmit works using more than 50 different noises to train this network.

0:42:23	SPEAKER_07
 So, this is one approach, and the other is multi-band.

0:42:29	SPEAKER_07
 I think it's more robust to noise changes, so perhaps doing something like multi-band, train on a lot of noises with feature space targets.

0:42:41	SPEAKER_03
 Yeah, if you could...

0:42:43	SPEAKER_03
 It's interesting though, maybe if you just trained up, I mean, one fancy would be you have something like articulate-right targets, and you have some reasonable database, which is copied over many times with a range of different noises.

0:43:01	SPEAKER_03
 And because what you're trying to do is come up with a core reasonable feature set, which is then going to be used by the HMF system.

0:43:13	SPEAKER_07
 So, yeah, the future work is... well, try to connect to the... to plug in the system to the OGI system.

0:43:31	SPEAKER_07
 There are still open questions there, where to put the MLB, basically.

0:43:39	SPEAKER_03
 And I guess, you know, the real open question, I mean, there's lots of open questions, but one of the core core open questions for that is...

0:43:49	SPEAKER_03
 If we take the best ones here, maybe not just the best ones, but the best few, or something, the most promising group from these other experiments, how well do they do over a range of these different tests, not just the Italian?

0:44:06	SPEAKER_03
 And then, then, then, see, again, how we know that there's a loss of performance from the neural net is trained on conditions that are different than we're going to test on.

0:44:22	SPEAKER_03
 But if you look over a range of these different tests, how well do these different ways combining the straight features with the MLB features stand out over that range?

0:44:34	SPEAKER_03
 That seems like the real question, if you know that.

0:44:38	SPEAKER_03
 So, if you just take PLP with double deltons, assume that's the feature.

0:44:44	SPEAKER_03
 Look at these different ways of combining it, and take... let's say, just take multi-English, because that works pretty well for the training.

0:44:52	SPEAKER_03
 Just look, take that case, and then look over all the different things. How does that compare between these?

0:44:58	SPEAKER_03
 All the tests set. All different test sets, and for the couple different ways that you have of combining them.

0:45:08	SPEAKER_03
 How well do they stand out over that?

0:45:11	SPEAKER_07
 And perhaps doing this for changing the variance of the streams, and so on.

0:45:16	SPEAKER_07
 That's another possibility.

0:45:18	SPEAKER_07
 Different times.

0:45:20	SPEAKER_07
 Yeah, so this would be more working on the MLP as an additional path instead of an insert to their diagram.

0:45:32	SPEAKER_07
 Perhaps the insert idea is kind of strange because they make an LDA, and then we will, again, add a network that is discriminant and that...

0:45:44	SPEAKER_03
 Yeah, this is a little strange, but on the other hand, they did before.

0:45:50	SPEAKER_07
 And because of so perhaps we know that when we have very good features, the MLP doesn't help.

0:45:58	SPEAKER_03
 So, I don't know.

0:46:00	SPEAKER_03
 The other thing though is that...

0:46:04	SPEAKER_03
 So, we want to get their path running here, right?

0:46:08	SPEAKER_03
 So we can add this other stuff as an additional path, right?

0:46:13	SPEAKER_07
 Yeah, the way we...

0:46:15	SPEAKER_03
 Because what are doing LDA Rasta?

0:46:17	SPEAKER_03
 What?

0:46:19	SPEAKER_03
 They're doing LDA Rasta.

0:46:21	SPEAKER_07
 Yeah, the way we want to do it, perhaps, is just to get the VAD labels and the final features.

0:46:27	SPEAKER_07
 So they will send us the...

0:46:30	SPEAKER_07
 Well, I see.

0:46:31	SPEAKER_07
 So, the feature files and with the VAD binary labels so that we can get our MLP features and filter them with the VAD and then combine them with their feature stream.

0:46:51	SPEAKER_03
 So, the first thing we're going to do there is to make sure that when we get those labels to the final features that we get the same result system without putting in a second path.

0:47:00	SPEAKER_07
 Yeah.

0:47:02	SPEAKER_07
 You mean...

0:47:04	SPEAKER_07
 Yeah, just retraining...

0:47:06	SPEAKER_03
 Yeah, just to make sure that we have...

0:47:08	SPEAKER_03
 We understand properly what things are.

0:47:10	SPEAKER_03
 The very first thing to do is to double check that we get the exact same results as the MLP and the K.

0:47:16	SPEAKER_03
 I mean, I don't know that we need to...

0:47:20	None
...training?

0:47:22	SPEAKER_03
 I mean, we can just take their training files also, but just for the testing, just to make sure that we get the same results.

0:47:31	SPEAKER_03
 We can duplicate it before we add in another...

0:47:33	SPEAKER_03
...because otherwise, yeah, we won't be able to do anything.

0:47:36	SPEAKER_07
 Yeah, so LDA Rasta, I don't know if we want to...

0:47:46	SPEAKER_07
 We can try networks with LDA Rasta, filter with features.

0:47:50	None
 I'm sorry.

0:47:52	None
 Yeah, well...

0:47:56	None
 Yeah.

0:47:58	None
 Oh, you know, the other thing is when you say...

0:48:01	SPEAKER_05
 I'm sorry, I'm sorry, I'm sorry, I'm sorry, I'm sorry.

0:48:04	SPEAKER_03
 When you're talking about combining MLP features, so, suppose we said, okay, we've got these different features and so forth, but the PLP seems pretty good.

0:48:20	SPEAKER_03
 If we take the approach that Mike did, and have...

0:48:24	SPEAKER_03
 I mean, one of the situations we have is we have these different conditions, different languages, we have different noises.

0:48:31	SPEAKER_03
 If we have some drastically different conditions, then we're just trying to have different MLPs.

0:48:38	SPEAKER_03
 And put them together. What Mike found for the reverberation case, at least, I mean, who knows if we'll work for these other ones, that you did have nice, interpretative effects.

0:48:48	SPEAKER_03
 That is that, yes, if you knew what the reverberation condition was going to be, and you trained for that, then you got the best results.

0:48:56	SPEAKER_03
 But if you had, say, a heavily reverberation case, and I know reverberation case, and then you fed the thing, something that was modest on a reverberation, then you get some results in between the two, so sort of behaviorism.

0:49:11	SPEAKER_03
 That affair?

0:49:13	SPEAKER_04
 Yeah, that's fair.

0:49:14	SPEAKER_04
 It also seems like if you try to train a little bit, so much noise, you'll just like to put a little help in the right case,

0:49:24	None
 and you have space, so it's better. Yeah, so you think it's better to have several MLPs?

0:49:32	SPEAKER_05
 Of course, it's easier.

0:49:34	SPEAKER_04
 I don't know how you interpret this on.

0:49:38	SPEAKER_04
 Yeah, I think I won't feel much for the work, but it's a lot of making it happen, which is a lot of pictures.

0:49:49	SPEAKER_03
 It works better if what?

0:49:54	SPEAKER_04
 Well, you were doing something that was, so maybe the analogy isn't quite right, you were doing something that was in a way a little better behaved.

0:50:17	SPEAKER_03
 But, you know, it's a very simple variable, which is reverberation.

0:50:24	SPEAKER_03
 Here the problem seems to be is that we don't have a really huge net with a really huge amount of training data, but we have, for this kind of task, I would think, sort of a modest amount, many million frames actually isn't that much.

0:50:38	SPEAKER_03
 A modest amount of training data from a couple different conditions.

0:50:44	SPEAKER_03
 So, the, that we anticipate in the test set in terms of language, and noise type, and channel characteristic, sort of all of them at a bunch of different dimensions.

0:50:57	SPEAKER_03
 And so, I'm just concerned that we don't really have the data to train up.

0:51:05	SPEAKER_03
 I mean, one of the things that we were seeing is that when we added in, we don't have a good explanation for this, we are seeing that we're adding in a few different databases, and the performance is getting worse.

0:51:21	SPEAKER_03
 And we just take one of those databases, a pretty good one. It actually is better.

0:51:29	SPEAKER_03
 And that says to me, yes, there might be some problems with the pronunciation models, some of the databases writing in or something like that, but one way or another, we don't have, seemingly, the ability to represent in the neural net of the size that we have, all of the variability that we're going to be covering.

0:51:49	SPEAKER_03
 So, I'm hoping that this is another take on the efficiency arc we're making, which I'm hoping it would moderate size neural nets, that if we look at more constrained conditions, then we'll have enough parameters to really represent them.

0:52:30	SPEAKER_04
 That also has a huge, and it's very online.

0:52:35	SPEAKER_04
 I feel that I feel that the online conversation that we've over-bad, online conversation, has to do some extrusion.

0:52:47	SPEAKER_04
 And take away the online conversation, online conversation, so that we can talk about that.

0:52:53	SPEAKER_06
 So doing both is not right.

0:53:00	SPEAKER_04
 That's not right, but if you fill in online conversation, then it might not be necessary to use the word that's going to be.

0:53:07	SPEAKER_03
 I just sort of have a feeling, but yeah. I mean, I think it's true that the OGI-folk found that using LDA Rasta, which is a kind of log-rasta, it's just that they have, I mean, it's done the log domain as Eric Allen, and it's just that they've just trained up, right?

0:53:29	SPEAKER_03
 That that benefited from online normalization.

0:53:38	SPEAKER_03
 So they did, at least in their case, it did seem to be somewhat complimentary.

0:53:44	SPEAKER_03
 So will it be in our case where we're using the neural net? I mean, they were not using the neural net.

0:53:51	SPEAKER_03
 I don't know.

0:53:55	SPEAKER_03
 Okay, so the other things you have here are trying to improve results from a single, yeah, make stuff better.

0:54:07	SPEAKER_03
 Basically, yeah, and CPU memory issues, yeah, we've just sort of ignoring that.

0:54:12	SPEAKER_07
 Yeah, so I don't know.

0:54:14	SPEAKER_07
 Yeah, but I have to address this problem of CPU memory?

0:54:18	SPEAKER_03
 Well, I think my impression, you folks have been looking at this more than me, but my impression was that there was a strict constraint on the delay.

0:54:31	SPEAKER_03
 But beyond that, it was kind of that using less memory was better, using less CPU was better, something like that.

0:54:41	SPEAKER_05
 Yeah, but yeah.

0:54:45	SPEAKER_07
 So yeah, but we don't know. We have to get some reference point to where we, what's a reasonable number?

0:54:56	SPEAKER_07
 Perhaps because it's too late or large.

0:55:01	SPEAKER_03
 Well, I don't think we're completely off the wall. I mean, I think that if we have, I mean, the ultimate fallback that we could do, if we find, I mean, we find that we're not really going to worry about the MLP.

0:55:24	SPEAKER_03
 Yeah, if the MLP ultimately, if they're all said and done, doesn't it really help? And we have it in. If the MLP does, we find help us enough in some conditions.

0:55:34	SPEAKER_03
 We might even have more than one MLP. We could simply say that that is done on the server.

0:55:41	SPEAKER_03
 And it's, we do the other manipulations that we're doing before that.

0:55:47	SPEAKER_03
 So I think that's, that's okay.

0:55:54	SPEAKER_03
 So I think the key thing was this plug-in doji.

0:56:01	SPEAKER_03
 What are they, what are they going to be working on? We know what they're going to be working on while we take their features.

0:56:10	SPEAKER_07
 They're starting to work on some kind of multiband. So that was pretty bad. Sunil, what was he doing?

0:56:21	SPEAKER_07
 Sunil?

0:56:22	SPEAKER_07
 Yeah. He was doing something new.

0:56:25	SPEAKER_08
 I don't think so.

0:56:28	SPEAKER_08
 I'm trying to tune.

0:56:31	SPEAKER_05
 What? Networks?

0:56:33	SPEAKER_07
 I think they were also mainly, well, working a little bit of new things like network and multiband, but mainly trying to tune their system as it is now.

0:56:47	SPEAKER_07
 Just trying to get the best from this architecture.

0:56:50	SPEAKER_03
 Okay, so I guess the way it would work is that you get, there be some point where you say, okay, this is their version one or whatever.

0:56:58	SPEAKER_03
 And we get these VAD labels and features and so forth for all these test sets from them.

0:57:03	SPEAKER_03
 And then that's what we work with.

0:57:07	SPEAKER_03
 We have a certain level, we try to improve it with this other path.

0:57:10	SPEAKER_03
 And then when it gets to be January, at some point, we say, okay, we have shown that we can improve this in this way.

0:57:22	SPEAKER_03
 So now, what's your newest version?

0:57:28	SPEAKER_03
 Maybe they'll have something that's better and then we combine it.

0:57:30	SPEAKER_03
 This is always hard.

0:57:31	SPEAKER_03
 I mean, I used to work with folks who were trying to improve a good HMEM system with the neural net system.

0:57:40	SPEAKER_03
 And it was a common problem that you, oh, and this is actually a true not just for neural nets, but just for the general people working with rescoring and best lists or lattice systems.

0:57:51	SPEAKER_03
 And then you get something from the other side at one point and you work really hard on making it better with rescoring.

0:58:02	SPEAKER_03
 But they're working really hard too.

0:58:04	SPEAKER_03
 So by the time you have improved their score, they have also improved their score.

0:58:11	SPEAKER_03
 And now there isn't any difference because the other.

0:58:14	SPEAKER_03
 So I guess at some point we'll have to, I don't know, I think we're integrated a little more tightly than happens.

0:58:22	SPEAKER_03
 A lot of those cases, I think, at the moment they say that they have a better thing.

0:58:28	SPEAKER_03
 What takes all the time here is that we're trying so many things, presumably, in a day we could turn around taking a new set of things from them and rescoring.

0:58:42	SPEAKER_03
 Well, OK, I think this is good. I think that the most wide open thing is the issues about the different trainings, training targets and devices and so forth.

0:58:57	SPEAKER_07
 So we can forget combining multiple features and MSG perhaps or focus more on the targets and on the training data.

0:59:07	SPEAKER_03
 Yeah, I think for right now, I really like MSG. I think that one of the things I like about it is it has such different temporal properties.

0:59:16	SPEAKER_03
 And I think that there is ultimately a really good potential for bringing in things with different temporal properties.

0:59:27	SPEAKER_03
 But we only have limited time and there's a lot of other things we have to look at. It seems like much more core questions are issues about the training set and the training targets and fitting in what we're doing with what they're doing.

0:59:46	SPEAKER_03
 But with limited time, yeah, I think we have to start cutting down. So I think so. And then, you know, once we have been going through this process and trying many different things, I would imagine certain things come up that you are curious about that you're not getting to.

1:00:10	SPEAKER_03
 So when that does settles from the evaluation, I think that would be time to go back and take whatever intrigued you most, you know, got your most interested and work with it for the next round.

1:00:25	SPEAKER_03
 As you can tell from these numbers, nothing that any of us are going to do is actually completely solve the problems.

1:00:33	SPEAKER_03
 That's still exciting to do. Very, very quiet. Well, I figured that out.

1:00:44	SPEAKER_03
 What were you involved in in this primarily?

1:00:47	SPEAKER_01
 Helping out preparing, well, they've been kind of running all the experiments and stuff. I've been doing some work on the preparing all the data for them to train and to test out.

1:01:07	SPEAKER_01
 Yeah, right now I'm focusing mainly on this final project I'm working on Jordan's class. What's that?

1:01:18	SPEAKER_01
 I'm trying to, so there was a paper in ICSLP about this multi-band belief in that structure. This guy did basically use two HMMs with a dependency arrow between the two HMMs.

1:01:36	SPEAKER_01
 I'm going to try coupling them instead of having the arrow that flows from one subband to another subband, trying having the arrows go both ways.

1:01:48	SPEAKER_01
 I'm just going to see if that better models AC-creening in any way or... No? Yeah. That sounds interesting.

1:02:06	SPEAKER_03
 Anything to do? No. Okay. Sound partner in the meeting. We got laughed out of them. Okay, everyone must contribute to our sound files here.

1:02:21	SPEAKER_03
 Okay, so speaking of which, if we don't have anything else, we're happy with where we are. No, no, no, no, we're going. I think so. Yeah. Yeah. Do you happy? Yeah. Okay. Everyone, should be happy.

1:02:36	SPEAKER_03
 You only have to be happy, you're almost done. Yeah. Okay.

1:02:42	SPEAKER_00
 Actually, I should mention about the Linux machine in Sweden. Yeah. So it looks like the neural net tools are installed there. And Dan Ellis, I believe, knows something about using that machine.

1:02:54	SPEAKER_07
 So if people are interested in getting jobs running on that, maybe I could help with that. Yeah, but I don't know if we really need a lot of machines.

1:03:06	SPEAKER_03
 But we could start computing another niche table. Well, yeah, I think we want a different table, please. Yeah, sure.

1:03:17	SPEAKER_03
 There's some different things that we're going to get at now. But yeah. So as far as you can tell, you're actually okay on CPU for training and so on.

1:03:32	SPEAKER_07
 Yeah, I think so. Well, more is always better. But I don't think we have to train a lot of networks. You know, we just select what works fine.

1:03:48	SPEAKER_03
 I'm okay. I'm okay. I'm okay. I'm disc.

1:03:52	SPEAKER_07
 Okay. Yeah. Well, sometimes we have some problems. But they're correct. Yeah. We're starting to script busy. Yeah. Yeah.

1:04:03	SPEAKER_03
 That's okay. Alright. So, we didn't give a channel out for you. You don't have to read the digits, but rest of it.

1:04:14	SPEAKER_03
 Is it not? Well, I think I won't touch anything because I'm afraid of making the driver crash.

1:04:25	SPEAKER_03
 It seems to do. Okay. So, I'll start off the connect my battery slow. Let's hope it works. Maybe you should go first.

1:04:42	SPEAKER_07
 I'm reading transcript. 2571 to 590. 1943. 263.

1:04:56	SPEAKER_07
 24. 5. 7. 1. 8. 3067. 4. 4. 9. 3048. 4. 9. 9. 8. 4. 0. 1. 2. 0. 2. 8. 6. 9. 1. 4. 1. 5. 6. 9. 0. 7. 5. 4. 6. 6. 7. 8.

1:05:25	SPEAKER_07
 9. 00. 1. 2. 7. 3. 0. 7. 3.

1:05:32	SPEAKER_03
 Transcript. 2. It's battery. Going down too. Oh, okay. I want you to go next.

1:05:39	SPEAKER_08
 Transcript number 2511-2530. 1905. 004. 7. 1307. 2637. 2554.

1:05:59	SPEAKER_08
 3314. 354. 3314. 7. 0. 5. 6. 7. 0. 7. 9. 1. 0. 4. 0. 4. 7. 1. 7. 5. 2. 0. 4. 0.

1:06:21	SPEAKER_08
 234. 0. 5. 5. 2. 6. 8. 6. 8. 9. 0. 9. 0. 7. 6. 4. 7. 8. 6. 1. 9.

1:06:41	SPEAKER_03
 Transcript. 2531-2550. 0. 0. 0. 0. 1035217. 311-0656. 4336-463.

1:07:01	SPEAKER_03
 5811-244. 699-7801. 8. 00. 9. 0. 1. 6. 0. 1. 2. 3. 8. 1. 2. 6. 0. 4. 3. 9. 4. 9. 5. 6. 0. 4. 8. 3. 8. 2. 4. 2. 9. 3. 3. 3. 0. 5.

1:07:30	SPEAKER_00
 I'm reading transcript 2551-2570. 0. 0. 6. 6. 9. 5. 4. 7. 1. 2. 3. 0. 0. 5. 1. 6. 2. 5. 7. 7. 7. 7. 8. 9. 0. 0. 0. 5. 0. 8. 9. 0. 0. 8. 9. 0. 0. 0. 5. 0. 8. 9. 0. 0. 8. 9. 0. 0. 0. 8. 9. 9. 0. 0. 8. 9. 0. 0. 0. 8. 9. 0. 0. 0.

1:08:00	SPEAKER_00
 6 2 1 3 0 5 3 5 7 2 3 6 0 4 3 5 6 9 9 6 7 7 0 6 8 0 6 5 0 0 3 8 5 4 0 2

1:08:25	SPEAKER_01
 I'm reading transcript 2491-2510 on Channel 2 8 9 0 7 9 0 2 1 4 0 6 2 6 3 1 3 8 2 205 8 4 4 5 6 0 8 8 1 2 0 6 9 6 2 0 4 4 3 0 7 3 0 7 1 2 0 5 4 1 5 1 5 6 6 9 7 5 9 1 3 8 7 2 9 7 2 6

1:09:42	SPEAKER_03
 I guess we can turn off our microphones.

1:10:12	None
 I am always well gathered

