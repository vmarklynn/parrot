0:00:00	SPEAKER_04
 Okay, we're recording.

0:00:02	SPEAKER_02
 Say the word zero.

0:00:03	SPEAKER_02
 I'm doing something.

0:00:04	SPEAKER_02
 We have brackets, coffee sipping.

0:00:06	SPEAKER_02
 It's not allowed, I think.

0:00:09	SPEAKER_01
 Carly brackets.

0:00:10	SPEAKER_01
 Is that voice?

0:00:11	SPEAKER_01
 Still a voice.

0:00:12	SPEAKER_04
 Okay.

0:00:13	SPEAKER_04
 Okay.

0:00:14	SPEAKER_04
 Channel two.

0:00:15	SPEAKER_04
 Do you square brackets running?

0:00:17	SPEAKER_04
 I have.

0:00:18	SPEAKER_04
 He's poor transcribers.

0:00:19	SPEAKER_07
 Not right now.

0:00:20	SPEAKER_07
 I mean.

0:00:21	SPEAKER_05
 There's going to be some zeros from this morning's meeting because I noticed that, very, I think, maybe you turned your mic off before the digits were...

0:00:27	SPEAKER_05
 Oh, it's during digits also.

0:00:28	SPEAKER_05
 It doesn't matter.

0:00:29	SPEAKER_06
 So it's not that bad if it's at the end, but it's...

0:00:32	SPEAKER_04
 Yeah.

0:00:33	SPEAKER_04
...and at the beginning it's bad.

0:00:34	SPEAKER_04
 You want to keep it warm so you get good noise.

0:00:36	SPEAKER_04
 Noise floors.

0:00:38	SPEAKER_04
 It's a beautiful meeting.

0:00:40	SPEAKER_03
 Oh, I know, I just showed a book.

0:00:42	SPEAKER_03
 Yeah, I did that.

0:00:44	SPEAKER_01
 Is there any way to change that in a software?

0:00:46	SPEAKER_01
 Change what?

0:00:47	SPEAKER_01
 Where, like, you just don't...

0:00:48	SPEAKER_01
 Like, if you...

0:00:49	SPEAKER_01
 If it starts catching zeros, like in the driver or something, in the card or somewhere in the hardware, where if you start seeing zeros on what cross-month channel, you just add some random noise floor, like a small noise floor.

0:01:00	SPEAKER_04
 And certainly we could do that, but I don't think that's a good idea.

0:01:03	SPEAKER_04
 We could do that in post-processing.

0:01:04	SPEAKER_04
 Yeah.

0:01:05	SPEAKER_04
 And the application needs a manual post-processing.

0:01:07	SPEAKER_03
 Well, I think we don't know what the default is anymore.

0:01:10	SPEAKER_03
 It's how we're using the front-end stuff, but for when we use the X-E, but it's argument.

0:01:15	SPEAKER_03
 There is an option.

0:01:17	SPEAKER_03
 An option, which...

0:01:19	SPEAKER_03
 When I first put it in, that means when I answer real things, I did actually put in a random address.

0:01:28	SPEAKER_03
 Okay.

0:01:29	SPEAKER_03
 Then I realized that putting in random address, you could go to the equivalent to adding a lot of spectrum.

0:01:34	SPEAKER_03
 Right.

0:01:35	SPEAKER_03
 And it was a lot faster than you would say, to add a constant to the spectrum.

0:01:39	SPEAKER_03
 To the certain thing.

0:01:40	SPEAKER_03
 Okay.

0:01:41	SPEAKER_03
 Calling random, or something.

0:01:42	SPEAKER_01
 Right.

0:01:43	None
 So, this doesn't...

0:01:49	SPEAKER_03
 Gee, here we all are.

0:01:51	SPEAKER_04
 So, the only agenda items where Jane wanted to talk about some of the IBM transcription process.

0:01:58	SPEAKER_04
 I sort of condensed the three things you said into that.

0:02:01	SPEAKER_04
 And then, just...

0:02:02	SPEAKER_04
 I only have, like, this afternoon and maybe tomorrow morning to get anything done before I go to Japan for 10 days.

0:02:07	SPEAKER_04
 So, if there's anything that absolutely desperately needs to be done, should let me know now.

0:02:12	SPEAKER_03
 You just sent off their speech paper.

0:02:21	SPEAKER_02
 Right.

0:02:22	SPEAKER_02
 I hope they accepted both, as a submission and as a paper.

0:02:29	SPEAKER_02
 But...

0:02:30	SPEAKER_02
 Well, yeah, you sent in.

0:02:32	SPEAKER_02
 First, you have to read the first thing.

0:02:34	SPEAKER_02
 We actually exceeded the delayed deadline by another day.

0:02:37	SPEAKER_02
 So, oops.

0:02:38	SPEAKER_03
 They had some extension.

0:02:40	SPEAKER_02
 Well, yeah, Liz had sent them.

0:02:42	SPEAKER_02
 I know what's saying.

0:02:43	SPEAKER_02
 Could we please have another, I don't know, three days.

0:02:46	SPEAKER_02
 There's a three days.

0:02:47	SPEAKER_02
 They said yes.

0:02:48	SPEAKER_02
 And then, did I say three?

0:02:50	SPEAKER_04
 That was the same thing.

0:02:51	SPEAKER_04
 Dave Galbert sent me an email.

0:02:54	SPEAKER_04
 I think it's in the YouTube that there's a special topic section in Eurospeach on New Corp.

0:03:03	SPEAKER_04
 Corp.

0:03:04	SPEAKER_04
 Corp.

0:03:05	SPEAKER_04
 And it's not due until, like, May 15th.

0:03:07	SPEAKER_04
 Well, this isn't new or?

0:03:09	SPEAKER_04
 No, it's new.

0:03:10	SPEAKER_04
 No, it's new.

0:03:11	SPEAKER_04
 And I got this.

0:03:12	SPEAKER_04
 I thought it was a Jane as I thought being the most relevant person.

0:03:17	SPEAKER_04
 So, I thought it was highly relevant.

0:03:19	SPEAKER_04
 I'm interested to.

0:03:20	SPEAKER_07
 Have you looked at the URL?

0:03:21	SPEAKER_07
 I haven't gotten over to there yet, but what I just mentioned yesterday, yeah.

0:03:24	SPEAKER_06
 I want to send a message.

0:03:26	SPEAKER_06
 I think Christopher Throck was meant to.

0:03:29	SPEAKER_04
 I'll help, but obviously I can't really do most of it.

0:03:33	SPEAKER_04
 So, I don't need any help being that can certainly provide.

0:03:37	SPEAKER_02
 But there were some interesting results in this paper, though.

0:03:41	SPEAKER_02
 For instance, that Morgan accounted for 56% of the robustness meanings in terms of number four.

0:03:46	SPEAKER_02
 Wow.

0:03:47	SPEAKER_02
 In terms of what?

0:03:48	SPEAKER_02
 Number four.

0:03:49	SPEAKER_07
 It's just because he talks really fast.

0:03:52	SPEAKER_04
 Do you mean...

0:03:53	SPEAKER_04
 Oh, that's...

0:03:54	SPEAKER_07
 Is it partly correctly identified words?

0:03:58	SPEAKER_04
 No, well, according to the transcripts.

0:04:01	SPEAKER_04
 That worked well regardless.

0:04:03	SPEAKER_04
 I think it's he's in all of them.

0:04:05	SPEAKER_02
 We've been working by name, we just...

0:04:08	SPEAKER_04
 One participant.

0:04:09	SPEAKER_04
 Did you identify him as a senior member?

0:04:13	SPEAKER_02
 No, we identified him as the person dominating the conversation.

0:04:16	SPEAKER_03
 Yeah.

0:04:17	SPEAKER_03
 I think it's a RP thing, but it's a meal.

0:04:23	SPEAKER_03
 But, other than that, the like, what was the rest of the paper about?

0:04:28	SPEAKER_02
 Well, it was about...

0:04:30	SPEAKER_02
 In terms of the reactions, three kinds of results, if you will.

0:04:35	SPEAKER_02
 The one was that just the amount of overlap...

0:04:38	SPEAKER_02
 That's the ugly subject.

0:04:39	SPEAKER_02
 In terms of number of words, and also we computed something called a spurt, which is essentially a stretch of speech with no pause as exceeding five million seconds.

0:04:50	SPEAKER_02
 And we computed how many overlap...

0:04:54	SPEAKER_02
 Spurt's, there were, and how many overlap words there were, four different corpora, the meeting recorded meetings, the robust meetings, switchboard and call home.

0:05:07	SPEAKER_02
 And found, and sort of compared the numbers, and found that the...

0:05:15	SPEAKER_02
 You know, as you might expect, the meeting recorder, meetings are the most overlap.

0:05:21	SPEAKER_02
 But next, we're switched what and call home, which both had roughly the same, almost identical in effect.

0:05:27	SPEAKER_02
 And the robust meetings were at the least.

0:05:30	SPEAKER_02
 So one sort of unexpected result there is that two party telephone conversations have about the same amount of overlap, sort of, you know, order of magnitude wise, as face-to-face meetings were...

0:05:45	SPEAKER_02
 I have had that as a work-changing all my slides.

0:05:47	SPEAKER_02
 Yeah.

0:05:48	SPEAKER_02
 Also, in the Levenson, the pragmatics book, you know, textbook, I found this great quote where he says, you know, how people talk about how people are so good at turn-taking.

0:06:02	SPEAKER_02
 And so, they're so good that generally, the overlap speech does not is less than 5%.

0:06:10	SPEAKER_02
 So, this is way more than 5%.

0:06:14	SPEAKER_01
 Did he mean face-to-face or...?

0:06:17	SPEAKER_02
 Well, in real conversations, everyday conversations.

0:06:20	SPEAKER_02
 I've been studying these conversation L.S. have been studying for years.

0:06:23	SPEAKER_07
 Chris, no, it doesn't necessarily go against what he said, because he said generally speaking in order to go against that kind of line.

0:06:29	SPEAKER_07
 Well, he's made a claim on the big hand-basing.

0:06:32	SPEAKER_06
 Yeah, but 5% of time or 5% of work is going to ask that.

0:06:35	SPEAKER_06
 Well, it's time.

0:06:36	SPEAKER_02
 So, it's still...

0:06:37	SPEAKER_02
 It's not a discussion.

0:06:38	SPEAKER_07
 It just says that is it big bell curve and that you have something that has a nice range of...

0:06:43	SPEAKER_02
 Yeah, so there are differences in how you measure it.

0:06:45	SPEAKER_02
 But still, it's, you know, the difference between...

0:06:48	SPEAKER_02
 between that number and what we have in meetings, which is more like, you know, close to...

0:06:54	SPEAKER_02
 in meetings like these, you know, close to 20%.

0:06:57	SPEAKER_02
 What was it like saying in the room?

0:06:59	SPEAKER_02
 That's just meaning.

0:07:00	SPEAKER_02
 Robustness meeting?

0:07:01	SPEAKER_02
 It was about half of the...

0:07:03	SPEAKER_02
 So, in terms of number of words, it's like 17 or 18% for the meeting recording meetings and about half that for...

0:07:11	SPEAKER_04
 But I don't know if that's really a fair way of comparing between multi-party conversations and two-party conversations.

0:07:19	SPEAKER_04
 Yeah, I didn't have to.

0:07:21	SPEAKER_04
 I mean, that's just something.

0:07:22	SPEAKER_05
 Yeah, I just wonder if you have to normalize, but then I'm going to speak or normalize.

0:07:24	SPEAKER_05
 Yeah, I just need to look at that.

0:07:25	SPEAKER_02
 But it's obviously to see if there's a dependence on that number of participants.

0:07:31	SPEAKER_04
 I bet there's a weak dependence.

0:07:33	SPEAKER_04
 I'm sure it's not a real strong one.

0:07:36	SPEAKER_04
 There's not everybody talks.

0:07:37	SPEAKER_04
 Right.

0:07:38	SPEAKER_04
 You have a lot of, a lot of two-party subsets within the meeting.

0:07:42	SPEAKER_04
 Well, regardless.

0:07:43	SPEAKER_04
 It's an interesting result, right?

0:07:44	SPEAKER_02
 Right.

0:07:45	SPEAKER_02
 And we also computed this both with and without back channels.

0:07:48	SPEAKER_02
 So, you might think that back channels have a special status because they're essentially just...

0:07:52	SPEAKER_04
 We all said, aha, not at the same time.

0:07:54	SPEAKER_02
 But even if you take out all the back channels, so basically you treat back channels as non-speech, as pauses, you still have significant overlap.

0:08:02	SPEAKER_02
 You know, it goes down from maybe for a switchboard, it goes down from, I don't know, 14% of the words to maybe...

0:08:14	SPEAKER_02
 I don't know, 11% or something.

0:08:18	SPEAKER_02
 It's not a dramatic change.

0:08:20	SPEAKER_02
 So it's...

0:08:21	SPEAKER_02
 Anyway, so that was one side of results.

0:08:26	SPEAKER_02
 And then the second one was just basically the stuff we had in the HLT paper on how overlaps affect the recognition performance.

0:08:35	SPEAKER_02
 And we rescored things a little bit more carefully.

0:08:39	SPEAKER_02
 We also fixed the transcripts in numerous ways.

0:08:43	SPEAKER_02
 But mostly we added one number, which was, what if you basically score ignoring all...

0:08:52	SPEAKER_02
 So the conjecture from the HLT results was that most of the added recognition errors from insertions due to background speech.

0:09:03	SPEAKER_02
 So we scored all the recognition results in such a way that the...

0:09:12	SPEAKER_04
 By the way, who's on channel 4?

0:09:14	SPEAKER_04
 You're getting one red.

0:09:15	SPEAKER_06
 Yeah, I was just wondering.

0:09:16	SPEAKER_01
 That's me.

0:09:19	SPEAKER_02
 Well, that's been working hard.

0:09:21	SPEAKER_02
 That's right.

0:09:22	SPEAKER_02
 Okay, so if you have the foreground speaker speaking here and then there's some background speech, maybe overlapping it somehow.

0:09:31	SPEAKER_02
 And this is the time been that we used.

0:09:34	SPEAKER_02
 Then of course you're going to get insertion errors here and here.

0:09:37	SPEAKER_02
 Right, right?

0:09:38	SPEAKER_02
 So we scored everything, and I must say that this scoring tools are pretty nice for this, where you just basically ignore everything outside of the region that was...

0:09:48	SPEAKER_02
...to be foreground speech.

0:09:49	SPEAKER_02
 And where that was, we had to use the first alignment results from the four.

0:09:54	SPEAKER_02
 So that's somewhat subject to error, but still we...

0:09:58	SPEAKER_02
...donded some hand checking, and we think that based on that, we think that the results are valid, and of course some errors are going to be in there.

0:10:08	SPEAKER_02
 But basically what we found is after we take out these regions, so we only score the regions that were certified as foreground speech, the recognition error went down to almost the level of the non-overlapped speech.

0:10:23	SPEAKER_02
 So that means that even if you do have background speech, if you can somehow separate out or find where it is, the recognizer does a good job, even though there isn't...

0:10:33	SPEAKER_04
 Yeah, I guess that doesn't surprise me, because with the close talking mics, the signal will be so much stronger.

0:10:39	SPEAKER_04
 What sort of normalization do you do?

0:10:44	SPEAKER_02
 Well, we do...

0:10:48	SPEAKER_04
 You know, we do recognize it, and the SRI recognize it.

0:10:51	SPEAKER_02
 Well, we do VTL, MoCotractLengthNomization, and we make all the features have zero mean and unit variance over an entire utterance.

0:11:05	SPEAKER_02
 Over the entire...

0:11:08	SPEAKER_02
 Over the entire channel.

0:11:11	SPEAKER_02
 Now we didn't rerun the recognizer for this.

0:11:13	SPEAKER_02
 We just took the old...

0:11:15	SPEAKER_02
 So this is actually a suboptimal way of doing it, right?

0:11:18	SPEAKER_02
 The old recognition output, and we just scored it differently.

0:11:21	SPEAKER_02
 So the recognize didn't have the benefit of knowing where the foreground speech started.

0:11:26	SPEAKER_03
 Were you able to develop the...

0:11:30	SPEAKER_03
 Did the problems with the local way also...

0:11:33	SPEAKER_02
 Yeah, not completely, but...

0:11:36	SPEAKER_02
 Yes, dramatically.

0:11:38	SPEAKER_02
 So we have to...

0:11:40	SPEAKER_02
 I mean, still...

0:11:41	SPEAKER_02
 I should bring the table with results.

0:11:43	SPEAKER_03
 We can look at it.

0:11:44	SPEAKER_03
 I would presume that you still would have somewhat higher error with the local assertions.

0:11:47	SPEAKER_02
 Yes.

0:11:48	SPEAKER_03
 Because again, looking forward to the non-close mic case.

0:11:53	SPEAKER_03
 I'm not looking forward to it.

0:11:55	SPEAKER_03
 It's a high signal noise ratio.

0:11:57	SPEAKER_02
 Right.

0:11:59	SPEAKER_02
 Right.

0:12:00	SPEAKER_02
 So that was number...

0:12:02	SPEAKER_02
 That was the second set of...

0:12:04	SPEAKER_02
 The second section.

0:12:05	SPEAKER_02
 And then the third thing was we looked at...

0:12:09	SPEAKER_02
 What we call interrupts, although that's maybe a misnomer.

0:12:14	SPEAKER_02
 Basically, we looked at cases where...

0:12:17	SPEAKER_02
 So we used the punctuation from the original transcripts.

0:12:21	SPEAKER_02
 And we inferred the beginnings and ends of sentences.

0:12:26	SPEAKER_02
 So...

0:12:29	SPEAKER_07
 Did you use Eberler case also or not?

0:12:31	SPEAKER_07
 Eberler case...

0:12:32	SPEAKER_02
 No, we only used, you know, appearance, question marks and...

0:12:37	SPEAKER_02
...exclamation.

0:12:38	SPEAKER_02
 And we know that there's...

0:12:39	SPEAKER_02
 That's not a very...

0:12:41	SPEAKER_02
 I mean, we miss a lot of them.

0:12:42	SPEAKER_02
 Yes, okay.

0:12:43	SPEAKER_07
 How about also or not?

0:12:44	SPEAKER_02
 No, how about?

0:12:45	SPEAKER_02
 Okay.

0:12:46	SPEAKER_02
 And then we looked at locations where...

0:12:50	SPEAKER_02
 If you have overlapping speech and someone else starts a sentence.

0:12:59	SPEAKER_02
 You know, where do these...

0:13:00	SPEAKER_02
 Where do other people start their...

0:13:02	SPEAKER_02
...turns, not turns really, but, you know, sentences?

0:13:07	SPEAKER_02
 So we only looked at cases where there was a foreground speaker...

0:13:11	SPEAKER_02
...and then at the time...

0:13:13	SPEAKER_02
 So the foreground speaker started into their sentence...

0:13:15	SPEAKER_02
...and then someone else started later.

0:13:18	SPEAKER_02
 Somewhere in between the...

0:13:19	SPEAKER_02
 And so...

0:13:20	SPEAKER_02
 What?

0:13:21	SPEAKER_06
 Sorry?

0:13:22	SPEAKER_06
 Somewhere in between the...

0:13:23	SPEAKER_02
 Yes.

0:13:24	SPEAKER_02
 So that there was overlap between the two sentences.

0:13:27	SPEAKER_02
 So the question was...

0:13:29	SPEAKER_02
 How can we...

0:13:30	SPEAKER_02
 What can we say about the places where the second...

0:13:33	SPEAKER_02
...or actually several second speakers...

0:13:36	SPEAKER_02
...start their interrupts, as we call them?

0:13:38	SPEAKER_05
 Three words from the end.

0:13:40	SPEAKER_04
 And pause the batteries.

0:13:41	SPEAKER_02
 And we looked at this in terms of...

0:13:44	SPEAKER_02
 On T closures, only.

0:13:46	SPEAKER_02
 So we had...

0:13:48	SPEAKER_02
 We had...

0:13:50	SPEAKER_02
 For the purpose of this analysis, we tagged the word sequences...

0:13:54	SPEAKER_02
...and we timeline them.

0:13:56	SPEAKER_02
 And we considered an interrupt...

0:13:58	SPEAKER_02
...if it occurred in the middle of a word...

0:14:00	SPEAKER_02
...we basically, you know, considered that to be interrupt...

0:14:04	SPEAKER_02
...as if it were at the beginning of the word.

0:14:06	SPEAKER_02
 So that if any part of the word was overlap, it was considered an interrupted word.

0:14:11	SPEAKER_02
 And then we looked at the location...

0:14:14	SPEAKER_02
...the...

0:14:16	SPEAKER_02
...you know, the features, the tags...

0:14:18	SPEAKER_02
...because we had tagged these word strings.

0:14:20	SPEAKER_02
 Taked.

0:14:21	SPEAKER_02
 That occurred right before these interrupt locations.

0:14:25	SPEAKER_02
 And the tags we looked at are...

0:14:28	SPEAKER_02
...the spurt tag, which basically says...

0:14:31	SPEAKER_02
...are actually...

0:14:32	SPEAKER_02
...sorry, end of spurt.

0:14:34	SPEAKER_02
 So whether there was a pause, essentially, here...

0:14:37	SPEAKER_02
...because spurt's defined as being, you know, 500-minute seconds or longer pauses.

0:14:42	SPEAKER_02
 And then we had things like discourse markers, back channels, disloancies, field pauses.

0:14:53	SPEAKER_02
 So disloan...

0:14:54	SPEAKER_02
...the ds are for...

0:14:56	SPEAKER_02
...the interruption points of disloancies.

0:14:59	SPEAKER_02
 So where you hesitate or where you start them, repair.

0:15:02	SPEAKER_02
 What else do we have?

0:15:04	SPEAKER_02
 Repeated words, it's another kind of disloancies and so forth.

0:15:08	SPEAKER_02
 So we had both the beginnings and ends of these.

0:15:12	SPEAKER_02
 So the end of a field pause...

0:15:15	SPEAKER_02
...and the end of a discourse marker.

0:15:19	SPEAKER_02
 And we just eyeballed.

0:15:20	SPEAKER_02
 I mean, we didn't really hand tag all of these things.

0:15:23	SPEAKER_02
 We just looked at the distribution of words.

0:15:25	SPEAKER_02
 And so every...

0:15:26	SPEAKER_02
...so yeah, and okay.

0:15:28	SPEAKER_02
 And aha, where the word deemed to be back channels and well and so and...

0:15:35	SPEAKER_02
...rights, where...

0:15:37	SPEAKER_02
...not right is a back channel.

0:15:39	SPEAKER_02
 So we sort of just based on the lexical identity of the words we...

0:15:44	SPEAKER_02
...tapped them as one of these things.

0:15:47	SPEAKER_02
 And of course, the interruption points we got from the original transcripts.

0:15:52	SPEAKER_02
 So...

0:15:53	SPEAKER_02
...and then we looked at the distribution of these different kinds of tags...

0:15:57	SPEAKER_02
...overall and in particularly at the interruption points.

0:16:01	SPEAKER_02
 And we found that there is a mark difference.

0:16:04	SPEAKER_02
 So that for instance, after...

0:16:06	SPEAKER_02
...so at the end after a discourse marker or after back channel or after a field pause...

0:16:10	SPEAKER_02
...you're much more likely to be interrupted than before.

0:16:14	SPEAKER_02
 Okay.

0:16:15	SPEAKER_02
 And also of course, after spurt ends, which means basically in point-side pauses.

0:16:19	SPEAKER_02
 So pauses are always an opportunity for...

0:16:21	SPEAKER_02
 So we have this little histogram that shows these distributions.

0:16:25	SPEAKER_02
 I wonder if it's not no big surprises, but this sort of...

0:16:30	SPEAKER_02
...it's a nice actually measure.

0:16:31	SPEAKER_05
 I wonder about the cause and effect there.

0:16:34	SPEAKER_05
 In other words, if you weren't going to pause, you...

0:16:37	SPEAKER_05
...will be because you're being interrupted.

0:16:39	SPEAKER_05
 Right, there's no statement about cause and effect.

0:16:42	SPEAKER_05
 Right.

0:16:43	SPEAKER_05
 It's just a statistic.

0:16:44	SPEAKER_03
 No, no, no.

0:16:45	SPEAKER_03
 Yeah, he's right to me.

0:16:46	SPEAKER_03
 Maybe we're intending to pause it all.

0:16:48	SPEAKER_03
 Right.

0:16:49	SPEAKER_03
 We're intending to stop for 57 milliseconds than chucking.

0:16:53	SPEAKER_03
 Yeah.

0:16:55	SPEAKER_02
 Pause for a second anyway.

0:16:57	SPEAKER_02
 And that was basically it.

0:16:59	SPEAKER_02
 And so we wrote this and then we found we were at six pages when we started cutting furiously.

0:17:05	SPEAKER_02
 And we thought half of the material again and played with the latex stuff.

0:17:11	SPEAKER_02
 And it was fun small, yeah?

0:17:13	SPEAKER_02
 No, no, well, you couldn't really make everything smaller, but we...

0:17:17	SPEAKER_02
 The abstract.

0:17:18	SPEAKER_02
 Oh, I...

0:17:19	SPEAKER_02
 You know, the gap between the two columns is like 10 millimeters, so I track it to eight millimeters.

0:17:25	SPEAKER_02
 That helps seven stuff like that.

0:17:27	SPEAKER_05
 Wasn't there some result under us?

0:17:29	SPEAKER_05
 I thought maybe Liz presented this at some conference a while ago about back channels.

0:17:34	SPEAKER_05
 And that they tend to happen when the pitch drops.

0:17:38	SPEAKER_05
 You know, you had a falling pitch.

0:17:40	SPEAKER_05
 Yeah.

0:17:41	SPEAKER_05
 And so that's when people tend to back channel.

0:17:43	SPEAKER_02
 We didn't talk about presenting.

0:17:45	SPEAKER_02
 Right.

0:17:46	SPEAKER_02
 Right.

0:17:47	SPEAKER_02
 So that's... I take it that's something that Don will look at.

0:17:51	SPEAKER_02
 Yeah, we're going to be looking at that.

0:17:53	SPEAKER_02
 So this is purely based on, you know, the words.

0:17:57	SPEAKER_07
 I have a reference for that though.

0:17:59	SPEAKER_05
 How you do?

0:18:00	SPEAKER_05
 So am I recalling correctly?

0:18:02	SPEAKER_07
 Well, I didn't know about Liz's finding on that, but I know of another paper that talks about something.

0:18:09	SPEAKER_01
 I think to see that reference too.

0:18:11	SPEAKER_05
 It made me think about a cool little device that could be built to handle those people that call you.

0:18:16	SPEAKER_05
 And just like to talk and talk and talk.

0:18:18	SPEAKER_05
 And you just have this little detector that listens for these drops and pitch and gives them the back channel.

0:18:23	SPEAKER_05
 So then you hook that to the phone and go off and do whatever you want to do while that thing keeps them busy.

0:18:29	SPEAKER_02
 There's actually... there's this former student of here from Berkeley, Nigel Ward.

0:18:34	SPEAKER_02
 He did a system in... he lives in Japan now and he did this back channeling, automatic back channeling system.

0:18:42	SPEAKER_02
 So very... so exactly what you described for Japanese.

0:18:46	SPEAKER_02
 And apparently for Japanese, it's really important that you back channel.

0:18:50	SPEAKER_02
 It's really impolite if you don't.

0:18:54	SPEAKER_03
 Actually, for a lot of these people, I think you just serve back channel continuously.

0:18:59	SPEAKER_05
 It wouldn't matter if it's when I ran the Minervals course.

0:19:03	SPEAKER_04
 There was of course a Monty Python sketch with that.

0:19:06	SPEAKER_04
 Or the barber who was afraid of scissors was playing a tape of clipping sounds.

0:19:10	SPEAKER_04
 And then they say, uh-huh, yeah, how about then Swordsteen?

0:19:15	SPEAKER_02
 Anyway, so the paper is online.

0:19:18	SPEAKER_02
 And I think I... I see a message to meeting recorded with the URL.

0:19:25	SPEAKER_02
 Or one more thing.

0:19:27	SPEAKER_02
 So I'm actually about to send Brian Kingsbury an email saying where he can find the material he wanted for this speech recognition experiment.

0:19:39	SPEAKER_02
 So, but I haven't sent it out yet because actually my desktop locked up.

0:19:44	SPEAKER_02
 I can't type anything.

0:19:46	SPEAKER_02
 So if there's any suggestions for that, I was just going to...

0:19:50	SPEAKER_05
 Is that the same directory that you had suggested?

0:19:52	SPEAKER_05
 I made a directory. I called it...

0:19:56	SPEAKER_07
 He still has his Unix account here, you know?

0:19:58	SPEAKER_07
 He does?

0:19:59	SPEAKER_07
 Yeah.

0:20:00	SPEAKER_02
 Yeah, but he has to...

0:20:03	SPEAKER_02
 He said he would prefer FTP.

0:20:06	SPEAKER_02
 And also, the other person that wants to do... There's one person that SRI who wants to look at the...

0:20:12	SPEAKER_02
 You know, the data we have so far.

0:20:16	SPEAKER_02
 And so I figured FTP is the best approach.

0:20:18	SPEAKER_02
 So what I did is I...

0:20:22	SPEAKER_02
 I made a new directory after a check set that was going to be a good thing.

0:20:29	SPEAKER_02
 So it's FTP, pub, real.

0:20:33	SPEAKER_02
 Real, exactly.

0:20:36	SPEAKER_02
 MTGC.

0:20:38	SPEAKER_02
 What is it again?

0:20:40	SPEAKER_04
 Has Danielis.

0:20:42	SPEAKER_02
 Yeah, right. The same as the main list.

0:20:46	SPEAKER_02
 And then under there... Actually, on this directory is not readable.

0:20:52	SPEAKER_02
 It's only accessible.

0:20:54	SPEAKER_02
 So in other words, to access anything under there, you have to be told what the name is.

0:20:59	SPEAKER_02
 So that's sort of a quick and dirty way of doing access control.

0:21:04	SPEAKER_02
 And the directory for this, I call it ISR0.1 because it's sort of meant for recognition.

0:21:11	SPEAKER_02
 And then there I have a file that lists all the other files so that someone can get that file and then know the file names.

0:21:19	SPEAKER_02
 And therefore download them.

0:21:20	SPEAKER_02
 If you don't know the file names, you can't...

0:21:23	SPEAKER_01
 Don't say.

0:21:26	SPEAKER_02
 Anyway, so all I was going to do there was stick the transcripts after the way that we munched them for scoring.

0:21:35	SPEAKER_02
 Because that's what he cares about.

0:21:39	SPEAKER_02
 And then the waveforms that Don segmented.

0:21:44	SPEAKER_02
 I mean, just basically tar them all up for each meeting and tar them all into one tar file and giz of them and stick them there.

0:21:51	SPEAKER_04
 So they put digits in my own home directory, home FTP directory, but I'll probably move them there as well.

0:21:57	SPEAKER_05
 So we could point Mari to this also for her March 01 request.

0:22:03	SPEAKER_02
 March 01.

0:22:04	SPEAKER_02
 Oh, remember, she was...

0:22:05	SPEAKER_05
 We wanted that also.

0:22:06	SPEAKER_05
 Well, she was saying that it would be nice if we had...

0:22:09	SPEAKER_05
 Or was she talking...

0:22:10	SPEAKER_05
 Yeah, she was saying it would be nice if they had the same set so that when they did experiments, they could compare.

0:22:15	SPEAKER_02
 But they don't have a recognition.

0:22:18	SPEAKER_02
 But yeah, I can see Mari on this one of that she knows.

0:22:21	SPEAKER_05
 So for the thing that we need to give Brian the Beab's file, so I was going to probably put it in the same place.

0:22:27	SPEAKER_04
 Yeah, I'll make another directory.

0:22:29	SPEAKER_05
 Yeah, exactly.

0:22:31	SPEAKER_01
 And Andreas, I think those files that I gave you are all down sampled.

0:22:35	SPEAKER_01
 They are?

0:22:36	SPEAKER_01
 I think so.

0:22:37	SPEAKER_01
 Yeah.

0:22:38	SPEAKER_01
 So either we should regenerate the original versions or we should just make a note of it.

0:22:44	SPEAKER_02
 Okay, because in one directory there's two versions.

0:22:47	SPEAKER_01
 Yeah, that's the first meeting I kept both versions.

0:22:49	SPEAKER_01
 Just to check which one.

0:22:50	SPEAKER_01
 There's significant difference.

0:22:51	SPEAKER_01
 Okay, so for the other meetings it's the down sampled version.

0:22:54	SPEAKER_01
 Yeah, down sampled, yeah.

0:22:55	SPEAKER_02
 Oh, okay.

0:22:56	SPEAKER_02
 Oh, that's important to know.

0:22:58	SPEAKER_02
 Okay, so we should probably give them the non-down sampled versions.

0:23:03	SPEAKER_01
 Yeah.

0:23:04	SPEAKER_01
 So...

0:23:05	SPEAKER_02
 Okay.

0:23:06	SPEAKER_02
 All right, then I'll hold off on that and wait for you to...

0:23:09	SPEAKER_02
 Probably by tomorrow.

0:23:10	SPEAKER_01
 I'll send you an email.

0:23:12	SPEAKER_02
 All right.

0:23:13	SPEAKER_02
 Okay.

0:23:14	SPEAKER_02
 Yeah, definitely they should have the full bandwidth.

0:23:16	SPEAKER_02
 Yeah.

0:23:17	SPEAKER_01
 Yeah, because I mean, I think Liz decided to go ahead with the down sampled versions because we can...

0:23:24	SPEAKER_01
 Well, it's significant difference.

0:23:25	SPEAKER_01
 It takes a less this space from all over the world.

0:23:26	SPEAKER_01
 It does take a less this space.

0:23:27	SPEAKER_01
 And apparently it didn't even better than the original versions, which, you know, is just probably random.

0:23:34	SPEAKER_01
 It's a small difference, but they probably want the originals.

0:23:37	SPEAKER_02
 Okay.

0:23:38	SPEAKER_02
 Okay, good.

0:23:39	SPEAKER_02
 Good thing.

0:23:40	SPEAKER_04
 I think we're losing Dawn and Andreas at 330, right?

0:23:44	SPEAKER_01
 Yeah.

0:23:45	SPEAKER_01
 So, I'm going to put it in the description.

0:23:46	SPEAKER_03
 It's fine.

0:23:47	SPEAKER_03
 It's okay.

0:23:48	SPEAKER_03
 It's okay.

0:23:49	SPEAKER_03
 So, we're going to put the transcription in the next step.

0:23:52	SPEAKER_03
 Okay.

0:23:53	SPEAKER_07
 So, you know, Adam created a script to generate the beat file to then create something just into IBM.

0:24:03	SPEAKER_07
 And you should probably talk about that, but you were going to use the originally transcribed file because I tightened the time bins, and that's also the one that they had already been trying to debug the first stage of this.

0:24:15	SPEAKER_07
 And my understanding was that I haven't listened to it yet, but it sounded very good.

0:24:21	SPEAKER_07
 And I understand that you guys were going to have a meeting today before this meeting.

0:24:25	SPEAKER_04
 It was just to talk about how to generate it.

0:24:27	SPEAKER_04
 Just so that while I'm gone, you can regenerate it if you decide to do it a different way.

0:24:32	SPEAKER_04
 So Chuck and Tilo should now more or less know how to generate the file.

0:24:36	SPEAKER_04
 And the other thing Chuck pointed out is that since this one is hand-marked, there are discourse boundaries.

0:24:44	SPEAKER_04
 So when one person is speaking, there's breaks, whereas Tilo's won't have that.

0:24:49	SPEAKER_04
 So what we're supposed to do is just write a script that if two chunks are very close to each other on the same channel, we'll just merge them.

0:24:57	SPEAKER_07
 Oh, sure.

0:24:58	SPEAKER_07
 Yeah, sure.

0:24:59	SPEAKER_04
 Makes sense.

0:25:00	SPEAKER_04
 And that will get around the problem of the one word, deep one word, deep one word,

0:25:04	SPEAKER_07
 deep one word. Clever, yes.

0:25:06	SPEAKER_07
 Clever.

0:25:07	SPEAKER_07
 Yeah, excellent.

0:25:12	SPEAKER_05
 After this morning, Tilo came in and said that there could be other differences between the already transcribed meeting with the beeps in it and one that has just been run through his process.

0:25:26	SPEAKER_05
 So tomorrow, when we go to make the chunked file for IBM, we're going to actually compare the two.

0:25:33	SPEAKER_05
 So he's going to run his process on that same meeting.

0:25:36	SPEAKER_05
 And then we're going to do the beepify on both and listen to them and see if we notice any real differences.

0:25:41	SPEAKER_07
 Okay, one thing that prevented us from applying, you from applying exactly the training.

0:25:46	SPEAKER_07
 So that is a training meeting.

0:25:48	SPEAKER_05
 Yeah, and we know that.

0:25:49	SPEAKER_05
 We just want to see if there are any major differences between doing it on the hand.

0:25:55	SPEAKER_07
 Oh, interesting.

0:25:56	SPEAKER_07
 Ah, okay.

0:25:58	SPEAKER_07
 Interesting idea.

0:25:59	SPEAKER_02
 So this training meeting, is that some data where we have very accurate time marks for?

0:26:10	SPEAKER_07
 I went back and hand marked the buttons.

0:26:13	SPEAKER_07
 I mentioned that.

0:26:14	SPEAKER_07
 Okay, yeah.

0:26:15	SPEAKER_05
 But there's, yeah, but there is this one issue with them in that there are time boundaries in there that occur in the middle of speech.

0:26:23	SPEAKER_05
 So like when we went to, when I was listening to the original file that I had, it's like you hear word, then you hear beep, and then you hear the continuation of what is the

0:26:33	SPEAKER_04
 same sentence. That's because of channel overlap.

0:26:37	SPEAKER_05
 Well, and so there are these chunks that look like that have, I mean, that's not going

0:26:44	SPEAKER_04
 to be true of the foreground speaker that will only be if it's the background speaker.

0:26:48	SPEAKER_05
 Right. So you'll have a chunk of channel A, which starts at zero and ends at 10.

0:26:55	SPEAKER_05
 And then the same channel starting at 11, ending at 15, and then again starting at 16, ending at 20.

0:27:01	SPEAKER_05
 Right.

0:27:02	SPEAKER_05
 So there's three chunks where actually we can just make one chunk out of that, which is A, zero, 20.

0:27:08	SPEAKER_04
 That's what I just said.

0:27:10	SPEAKER_05
 Yeah.

0:27:11	SPEAKER_05
 So I just want to make sure that it was like, so if you were to use these, you have to be careful not to pull up these individual.

0:27:18	SPEAKER_02
 Right.

0:27:19	SPEAKER_02
 So I mean, what I would, I was interested in this having, having time marks for the beginnings and ends of speech by each speaker.

0:27:29	SPEAKER_02
 Oh, that's definitely probably because we could use that to find you in our alignment process to make it more accurate.

0:27:36	SPEAKER_02
 Battery.

0:27:37	SPEAKER_02
 So I don't care that, you know, there's actually a budding segments that we have to join together.

0:27:44	SPEAKER_02
 That's fine.

0:27:45	SPEAKER_02
 Okay.

0:27:46	SPEAKER_02
 So I think that's the reason why I think that the beginnings and ends are actually

0:27:53	SPEAKER_05
 close to the speech inside of that.

0:27:56	SPEAKER_02
 Yeah. I think Jane tightened these up by hand.

0:27:58	SPEAKER_02
 Okay.

0:27:59	SPEAKER_07
 So what is the sort of how tight are they?

0:28:00	SPEAKER_07
 Next good.

0:28:01	SPEAKER_07
 They were reasonably tight, but not excruciatingly tight.

0:28:04	SPEAKER_07
 That would have taken more time.

0:28:05	SPEAKER_02
 No, no, I don't actually have like, yeah, that's fine because we don't want to, that's perfectly fine.

0:28:12	SPEAKER_02
 In fact, it's good.

0:28:13	SPEAKER_02
 I always want to have a little bit of pause or non-speech around the speech, say, for recognition purposes.

0:28:19	SPEAKER_02
 But just, you know, again, I just want to have an idea of how much extra you allow so that I can interpret the numbers if I compare that with a forced alignment segmentation.

0:28:33	SPEAKER_07
 I can't answer that, but my main goal was in these areas where you have a three-way overlap and one of the overlaps involved, yeah.

0:28:43	SPEAKER_07
 And it's swimming in this huge bin.

0:28:45	SPEAKER_07
 I wanted to get it so that it was closely localized.

0:28:48	SPEAKER_02
 But are we talking about, I don't know, 10th of a second, you know, how much extra would you allow?

0:28:57	SPEAKER_07
 I wanted to be able to be heard normally so that if you play back that bin and have it in the mode where it stops at the boundary, it sounds like a normal word.

0:29:10	SPEAKER_07
 It doesn't sound like the person, it sounds normal.

0:29:13	SPEAKER_07
 It's as if the person could have stopped there.

0:29:15	SPEAKER_07
 Okay.

0:29:16	SPEAKER_07
 And it wouldn't have been an awkward place to stop.

0:29:18	SPEAKER_07
 Now sometimes, you know, these are involved in places where there was no time.

0:29:22	SPEAKER_07
 And so there wouldn't be a gap afterwards because, I mean, in some cases, there are some people who have very long segments of discourse where, you know, they'll breathe and then I put a break.

0:29:36	SPEAKER_07
 But other than that, it's really pretty continuous.

0:29:38	SPEAKER_07
 This includes things like going from one sentence into the next one sentence into the next without really stopping.

0:29:47	SPEAKER_07
 You know, in writing, you have this two spaces in a big gap, you know.

0:29:51	SPEAKER_07
 But some people are planning and, you know, we always are planning what we're going to say next.

0:29:57	SPEAKER_07
 But in which case, the gap between these two complete syntactic units, which of course spoken things are not always complete syntactically, but it would be a shorter break than maybe you might like.

0:30:14	SPEAKER_07
 But the goal there was to not have the text be so crudely parsed in a time bin.

0:30:21	SPEAKER_07
 I mean, because from a discourse purpose, it's more useful to be able to see.

0:30:27	SPEAKER_07
 And also, you know, from a speech recognition purpose, my impression is that if you have too long a unit, it doesn't help you very much either because of the memory.

0:30:36	SPEAKER_07
 That's why.

0:30:37	SPEAKER_07
 So, that means that the amount of time after something is variable depending partly on context, but my general goal, when there was sufficient space room pause after it to have it be kind of a natural feeling gap, which I don't know what it would be quantified as.

0:30:58	SPEAKER_07
 You know, well, the chase says that in producing narratives, the spurts that people use tend to be, what would be a pause might be something like two seconds.

0:31:09	SPEAKER_07
 And that would be one speaker.

0:31:12	SPEAKER_07
 The discourse, the people who look at turn-taking often do use, I was interested that you chose the, you know, the use, because I think that would be more consistent with sociolanguistics.

0:31:24	SPEAKER_02
 Or we chose, you know, half a second because if you go much larger, you have, you know, your statement about how much overlap there is becomes less precise because you include more of actual pause time into what you consider overlap speech.

0:31:45	SPEAKER_02
 So it's sort of a compromise.

0:31:47	SPEAKER_02
 And it's also based, I mean, Liz suggested that value based on the distribution of pause times that you see in switchboard and other corpora.

0:32:00	SPEAKER_06
 So yeah, I also used, I think, something around 0.5 seconds for the speech-man speech detector for minimum silence length.

0:32:09	SPEAKER_06
 I see.

0:32:10	SPEAKER_06
 So.

0:32:11	SPEAKER_07
 Okay.

0:32:12	SPEAKER_07
 In any case, this meeting that I hand, I handed just to two of them I mentioned before.

0:32:20	SPEAKER_07
 Okay.

0:32:21	SPEAKER_02
 And I sent email.

0:32:22	SPEAKER_02
 At some point we will try to find you in our first alignment, maybe using those as references because, you know, what you would do is you would play with different parameters and to get an objective, you need an objective measure of how closely you can align the models to the actual speech.

0:32:41	SPEAKER_02
 And that's where your data would be very important to have.

0:32:46	SPEAKER_02
 So.

0:32:47	SPEAKER_06
 And hopefully the new meetings which will start from the channelized version will have better time boundaries and alignments.

0:32:56	SPEAKER_02
 Right.

0:32:57	SPEAKER_07
 But I'd like this idea of, for our purposes, for the IBM preparation, having these joined together and it makes a lot of sense.

0:33:08	SPEAKER_07
 And in terms of transcription, it would be easy to do it that way, the way that they have, with the longer units, not having to fuss with adding these things.

0:33:15	SPEAKER_06
 Which could have one draw back if there is a back channel in between those three things, the back channel will occur at the end of those three and in the previous version which is used now, the back channel would be in between there somewhere.

0:33:33	SPEAKER_06
 So that would be more natural.

0:33:35	SPEAKER_07
 That's right.

0:33:36	SPEAKER_07
 But you know, this brings me to the other stage of this which I discussed with you earlier today, which is the second stage is what to do in terms of the transcribers adjustment of these data.

0:33:46	SPEAKER_07
 I discussed this with you.

0:33:48	SPEAKER_07
 So the idea initially was we would get for the new meetings.

0:33:52	SPEAKER_07
 So the E.D.U meetings that Tilo has now pre-segmented all of them for us on a channel by channel bases.

0:33:59	SPEAKER_07
 And so I've assigned them to our transcribers and so far I've discussed it with one.

0:34:08	SPEAKER_07
 And I had about an hour discussion with her about this yesterday.

0:34:11	SPEAKER_07
 We went through E.D.U.

0:34:12	SPEAKER_07
 One at some extent.

0:34:14	SPEAKER_07
 And it occurred to me that basically what we have in this kind of a format is you could consider it as a staggered mixed file.

0:34:23	SPEAKER_07
 We had some discussion over the weekend about at this other meeting that we were all at about whether the IBM transcribers should hear a single channel audio or a mixed channel audio.

0:34:34	SPEAKER_07
 And in a way, by having this chunk and then the back channel after it, it's like a staggered mixed channel.

0:34:45	SPEAKER_07
 The maximal gain from the IBM people may be in long stretches of connected speech.

0:34:56	SPEAKER_07
 So it's basically a whole bunch of words which they can really do because of the continuity within that person's turn.

0:35:03	SPEAKER_07
 So what I'm thinking, and it may be that not all meetings will be good for this, but what I'm thinking is that in the E.D.U meetings they tend to be driven by a couple of dominant speakers.

0:35:14	SPEAKER_07
 And if the chunked files focused on the dominant speakers, then when it got patched together when it comes back from IBM, we can add the back channels.

0:35:25	SPEAKER_07
 It seems to me that, you know, back channels per se wouldn't be so hard, but then there's this question of the time marking and whether the beeps would be, and I'm not exactly sure how that would work with the back channels.

0:35:40	SPEAKER_07
 And certainly things that are intrusions of multiple words taken out of context and displaced in time from where they occurred, that would be hard.

0:35:49	SPEAKER_07
 So my thought is, I'm having this transcriber go through the E.D.U. one meeting and indicate a start time for each dominant speaker and time for each dominant speaker and the idea that these units would be generated for the dominant speakers and maybe not for the other channels.

0:36:06	SPEAKER_04
 The only disadvantage of that is then it's hard to use an automatic method to do that.

0:36:13	SPEAKER_04
 The advantage is that it's probably faster to do that than it is to use the automated method and correct it.

0:36:19	SPEAKER_07
 Well, I think the original plan was that the transcriber would adjust to the boundaries and all that for all the channels, but you know, that is so time consuming.

0:36:30	SPEAKER_07
 And since we have a bottleneck here, we want to get IBM things that are usable as soon as possible, then the scene would be a way to get them a flood of data, which would be useful when it comes back to us.

0:36:42	SPEAKER_07
 And also at the same time, when she goes through this, she'll be, if there's anything that was encoded as a pause but really has something transcribable in it, then she's going to make a mark.

0:36:55	SPEAKER_07
 So that bin would be marked as double dots and she'll just add an S. And in the other case, if it's marked as speech and really there's nothing transcribable in it, then she's going to put a dash and I'll go through it and you know, with a substitution command, get it so that it's clear that those are the other category.

0:37:18	SPEAKER_07
 I'll just, you know, re-code them.

0:37:20	SPEAKER_07
 But the transcribable events that I'm considering in this continue to be left as well as speech and cough and things like that, so I'm not stripping at anything just, you know, being very lenient in what's considered speech.

0:37:35	SPEAKER_05
 So Jane, in terms of the new procedure suggesting, what is the, so I'm a little confused because how do we know where to put beeps?

0:37:46	SPEAKER_07
 Okay, so what it involves is really the original procedure, but only applied to a certain strategically chosen aspect of the data.

0:37:59	SPEAKER_04
 We pick the easy parts of the data basically and transcribable marks it by hand.

0:38:03	SPEAKER_04
 But after we've done T-Los thing.

0:38:06	SPEAKER_04
 No.

0:38:07	SPEAKER_04
 Yes.

0:38:08	SPEAKER_04
 Oh, after.

0:38:09	SPEAKER_04
 Okay, I didn't understand that.

0:38:10	SPEAKER_06
 Okay.

0:38:11	SPEAKER_06
 So I'm, no, I'm confused.

0:38:12	SPEAKER_07
 Okay, we start with your pre-segmented version.

0:38:14	SPEAKER_04
 Okay, leave the mics on and just put them on the table.

0:38:18	SPEAKER_04
 Okay.

0:38:19	SPEAKER_01
 Thanks.

0:38:20	SPEAKER_07
 We start with the pre-segmented version.

0:38:24	SPEAKER_06
 You start with the pre-segmentation.

0:38:27	SPEAKER_07
 And then the transcriber, instead of going painstakingly through all the channels and moving the boundaries around and deciding if it's speech or not, but not transcribing anything.

0:38:37	SPEAKER_07
 Okay, instead of doing that, which was our original plan, they just do that on the main channel.

0:38:45	SPEAKER_07
 Yeah, so what they do is they identify who's the dominant speaker and when the speaker starts.

0:38:50	SPEAKER_06
 Okay.

0:38:51	SPEAKER_07
 So, I mean, you're still going to, so based on your pre-segmentation, that's the basic

0:38:55	SPEAKER_06
 thing. And you just use the segments of the dominant speaker then for sending to IBM or.

0:39:02	SPEAKER_05
 Exactly.

0:39:03	SPEAKER_05
 So now Jane, my question is, when they're all done adjusting the time boundaries for the dominant speaker, have they then also erased the time boundaries for the other ones?

0:39:11	SPEAKER_05
 No, no, no.

0:39:12	SPEAKER_05
 So how will we know who?

0:39:14	SPEAKER_07
 That's why she's notating the start and end points of the dominant speakers.

0:39:18	SPEAKER_07
 So in EDU1, as far as I listen to it, you start off with a section by Jerry.

0:39:24	SPEAKER_07
 So Jerry starts at minute, so and so, and goes until minute, so and so.

0:39:28	SPEAKER_07
 And then Mark Pascon comes in and he starts at minute, such and such and goes until minute, so and so.

0:39:34	SPEAKER_07
 Okay.

0:39:35	SPEAKER_07
 And then meanwhile, she's listening to both of these guys' channels, determining if there are any cases of misclassification of speech as nothing and nothing in speech.

0:39:45	SPEAKER_07
 Okay.

0:39:46	SPEAKER_07
 Just the adjustments on those guys.

0:39:48	SPEAKER_07
 But you know, I wanted to say, his segmentation is so good that the part that I listened to with her yesterday didn't need any adjustments to the bins so far we haven't.

0:39:58	SPEAKER_07
 So this is not going to be a major part of the process.

0:40:00	SPEAKER_05
 So if you don't have to adjust the bins, why not just do it for all the channels?

0:40:04	SPEAKER_05
 Why not just throw all the channels to IBM?

0:40:06	SPEAKER_07
 Well, there's the question of whether, well, okay, it's a question of how much time we want our transcriber to invest here when she's going to have to invest that when it comes back from IBM anyway.

0:40:21	SPEAKER_07
 So if it's only inserting mums here and there, then wouldn't that be something that would be just as efficient to do at this end instead of having it go through IBM then be patched together then be double checked here.

0:40:33	SPEAKER_06
 But then we could just use the output of the detector and do the beeping on it and send

0:40:39	SPEAKER_05
 it to IBM without having to check anything.

0:40:42	SPEAKER_07
 Well, I guess for some meetings, I'm sure it wouldn't see how good they are. I'm open to that.

0:40:48	SPEAKER_07
 Yes, it's working well.

0:40:49	SPEAKER_06
 It's on some meetings, it's good.

0:40:51	SPEAKER_07
 I mean, we have to fix it when it comes back.

0:40:54	SPEAKER_07
 You were saying that they differ in how well they work depending on channels to systems.

0:40:59	SPEAKER_06
 We should perhaps just select meetings on which the speech non speech detection works well and just use those meetings to send to IBM and do the analysis.

0:41:10	SPEAKER_03
 So I forget, it's from the little town of the water.

0:41:13	SPEAKER_06
 It really depends.

0:41:17	SPEAKER_06
 My impression is that it's better for meetings with fewer speakers and it's better for meetings than nobody is breathing.

0:41:26	SPEAKER_03
 Yeah, that's it.

0:41:30	SPEAKER_05
 So in fact, this might suggest an alternative sort of a hybrid between these two things.

0:41:34	SPEAKER_05
 So the one suggestion is we run T-Lose thing and then we have somebody go and adjust all the time boundaries and we send it to IBM.

0:41:40	SPEAKER_05
 The other one is we just run his thing and send it to IBM.

0:41:43	SPEAKER_05
 There's another possibility if we find that there are some problems and that is we go ahead and we just run his and we generate the beeps file, then we have somebody listen to the beeps file and they write each section and say yes, no, whether that section is intelligible or not.

0:42:00	SPEAKER_05
 It's just a little interface which for all the yeses, then that will be the final.

0:42:06	SPEAKER_07
 It's interesting because that's directly related to the N-Task.

0:42:09	SPEAKER_05
 Stress test.

0:42:10	SPEAKER_05
 I mean, it wouldn't be that much fun for a transcriber to sit there, hear it, yes or no, but it would be quick.

0:42:17	SPEAKER_03
 It would be kind of quick but they're still listening to everything.

0:42:20	SPEAKER_05
 But there's no adjusting and that's what's slow.

0:42:22	SPEAKER_05
 There's no adjusting of time boundaries.

0:42:23	SPEAKER_03
 Well, this thing's just take time too.

0:42:25	SPEAKER_03
 Yeah.

0:42:26	SPEAKER_03
 I don't know.

0:42:27	SPEAKER_00
 I really have to answer your thoughts.

0:42:28	SPEAKER_03
 I mean, what's the worst that happens to transcribers?

0:42:31	SPEAKER_03
 I mean, as long as on the other end they can say there's something.

0:42:35	SPEAKER_03
 It's not a convention so they say, huh?

0:42:37	SPEAKER_03
 Right.

0:42:38	SPEAKER_05
 If I go I was later.

0:42:40	SPEAKER_05
 That's true.

0:42:41	SPEAKER_05
 We can just catch it, catch everything at this side.

0:42:43	SPEAKER_05
 Maybe that's the best way to go.

0:42:44	SPEAKER_05
 Just interesting.

0:42:45	SPEAKER_05
 I mean, it just depends on how.

0:42:46	SPEAKER_05
 Yeah.

0:42:47	SPEAKER_07
 So I was going to say E-DU1 is good enough.

0:42:49	SPEAKER_07
 Maybe we could include it in this set of this stuff we send.

0:42:53	SPEAKER_06
 Yeah, I think there are some meetings we're with.

0:42:56	SPEAKER_04
 I think it's possible like this.

0:42:58	SPEAKER_04
 Until we generate a bunch of beeps files automatically.

0:43:01	SPEAKER_04
 Yeah.

0:43:02	SPEAKER_05
 We won't be able to include it with this first thing because there's a part of the process of the beep file which requires knowing the normalization coefficients.

0:43:09	SPEAKER_05
 Oh, see.

0:43:10	SPEAKER_04
 It's hard to do.

0:43:11	SPEAKER_04
 It just takes five minutes rather than taking a second.

0:43:15	SPEAKER_04
 Right.

0:43:16	SPEAKER_05
 Except I don't think that the instructions for doing that was in that directory, right?

0:43:20	SPEAKER_05
 I didn't see where you had generous easy messages.

0:43:22	SPEAKER_06
 Doing the game that's no problem.

0:43:24	SPEAKER_05
 Adjusting the game?

0:43:26	SPEAKER_05
 Getting the coefficients for each channel.

0:43:28	SPEAKER_04
 Yeah, that's no problem.

0:43:29	SPEAKER_04
 Okay.

0:43:30	SPEAKER_04
 So we just run that one.

0:43:31	SPEAKER_04
 I have one program that I do it.

0:43:32	SPEAKER_04
 You can find it.

0:43:33	SPEAKER_05
 I do.

0:43:35	SPEAKER_05
 And that J sounds that.

0:43:36	SPEAKER_03
 Yep.

0:43:37	SPEAKER_03
 Okay.

0:43:38	SPEAKER_03
 Okay.

0:43:39	SPEAKER_03
 Okay.

0:43:40	SPEAKER_03
 I have a suggestion on that which is since really what this is is is trying to in the large send the right thing to them and there is going to be this post bus synced up.

0:43:49	SPEAKER_03
 Why don't we check through a bunch of things by sampling it?

0:43:53	SPEAKER_03
 Right.

0:43:54	SPEAKER_03
 And other than saying we're going to listen to everything.

0:43:59	SPEAKER_04
 I didn't mean listen to everything.

0:44:01	SPEAKER_03
 So you do much to see if there is a little bit here in there.

0:44:04	SPEAKER_03
 Yeah.

0:44:05	SPEAKER_03
 It sounds like it's almost always right.

0:44:07	SPEAKER_03
 There's not any big problem.

0:44:08	SPEAKER_03
 You send it to him.

0:44:09	SPEAKER_03
 Okay.

0:44:10	SPEAKER_03
 And then they'll send us back with what they send back to us and we'll fix things up.

0:44:15	SPEAKER_03
 Which is.

0:44:16	SPEAKER_03
 We should.

0:44:17	SPEAKER_04
 We should just double check with Brian on a few simple conventions on how they should mark things.

0:44:23	SPEAKER_05
 When they when there's either no speech in there or something they don't understand things like that.

0:44:28	SPEAKER_04
 Because what I had originally said to Brian was well they'll have to mark when they can't distinguish between the foreground and background.

0:44:34	SPEAKER_04
 Because I thought that was going to be the most prevalent.

0:44:37	SPEAKER_04
 But if we send them without editing then we're also going to have to have a notations forwards that are cut off.

0:44:42	SPEAKER_04
 Yeah.

0:44:43	SPEAKER_04
 And other sorts of acoustic problems.

0:44:45	SPEAKER_05
 And they may just guess at what those cut off words are.

0:44:48	SPEAKER_05
 But I mean we're going to adjust.

0:44:49	SPEAKER_05
 But everything.

0:44:50	SPEAKER_04
 But we would like them to do is be conservative so that they should only write down the transcript if they're sure.

0:44:55	SPEAKER_04
 And otherwise they should mark it to a check.

0:44:57	SPEAKER_06
 Yep.

0:44:58	SPEAKER_07
 Well we have the unintelligibility convention.

0:45:01	SPEAKER_07
 And actually they have one also.

0:45:03	SPEAKER_00
 Brian.

0:45:04	SPEAKER_03
 Maybe have an order of probably in the paper that I have not got my name.

0:45:10	SPEAKER_03
 An order magnitude notion of how on a good meeting how often do you get segments that come into work and so forth.

0:45:19	SPEAKER_03
 And then they're badly often.

0:45:23	SPEAKER_03
 And what is the good meeting?

0:45:28	SPEAKER_03
 The E.D.U meeting was a good meeting.

0:45:30	SPEAKER_03
 Yeah.

0:45:31	SPEAKER_03
 It was almost always doing the right thing.

0:45:34	SPEAKER_03
 So I wanted to get some sense of what almost always meant.

0:45:37	SPEAKER_03
 And then in a bad meeting or some meetings where he said he's had some problems.

0:45:41	SPEAKER_03
 What does that mean?

0:45:42	SPEAKER_03
 So does it mean one percent, ten percent?

0:45:45	SPEAKER_03
 Does it mean five percent, fifty percent?

0:45:49	SPEAKER_06
 So the number I gave in the paper is just some frame error rate so that's not really what will be effective for the transcribuses.

0:46:07	SPEAKER_06
 They have to ensure that that's a real support or something.

0:46:13	SPEAKER_06
 But the number is oops.

0:46:19	SPEAKER_06
 So the speech, the amount of speech that is missed by the detector for a good meeting is around or under one percent I would say.

0:46:32	SPEAKER_06
 But that can be more amount of speech, a more amount of the detector says there is speech but it's not.

0:46:45	SPEAKER_06
 So that can be a lot when it's really a breathy channel.

0:46:50	SPEAKER_03
 But I think that's less of a problem.

0:46:53	SPEAKER_03
 And that's for good meeting.

0:46:55	SPEAKER_03
 What about in a meeting that you said you had some more trouble with?

0:46:59	SPEAKER_06
 I can't really, I don't have really representative numbers I think.

0:47:06	SPEAKER_06
 I did this on four meetings and only five minutes of every meeting, of these meetings.

0:47:12	SPEAKER_06
 So it's not that representative but it's perhaps.

0:47:20	SPEAKER_06
 Yeah, it's perhaps then it's perhaps five percent or something which the speech frames which I missed but I can't really tell.

0:47:32	SPEAKER_03
 So sometimes when I want to go back and look at it more in terms of how many times is there a spurt that's interrupted?

0:47:42	SPEAKER_07
 The other problem is when it went on the breathy ones where you get breathing indicated a speech.

0:47:50	SPEAKER_07
 And I guess we could just indicate to the transgarbers not to encode that if they still do the B file.

0:47:56	SPEAKER_03
 That is probably less of a problem because if there's, if a word is split then they might have to listen to a few times to really understand it.

0:48:06	SPEAKER_03
 I think that's really, it doesn't happen very often that the various cut in the middle or something that's really not normal.

0:48:27	SPEAKER_03
 So what you're saying is that nearly always what happens when there's a problem is that there's some non-speech that there's marker speech.

0:48:37	SPEAKER_03
 Well then we really should just send this stuff.

0:48:41	SPEAKER_03
 That doesn't do any harm.

0:48:43	SPEAKER_03
 They say here dog bark and they say what was the word?

0:48:48	SPEAKER_06
 Yeah, I also thought of there are really some channels where it is almost only breathing in it and to reruns.

0:48:58	SPEAKER_06
 I've got a method that looks into the cross correlation with the PCM mic and then to reject everything which seems to be breath.

0:49:09	SPEAKER_06
 So I could run this on those pressy channels and perhaps throughout.

0:49:14	SPEAKER_03
 Yeah, I think that would be good.

0:49:18	SPEAKER_03
 I think none of this stuff is really something that these are.

0:49:24	SPEAKER_07
 I'd be delighted with that.

0:49:26	SPEAKER_07
 I was very impressed with the result.

0:49:28	SPEAKER_03
 Yeah, the thing I was concerned about was that seemed kind of specialized to the media meeting and that meeting like this or something.

0:49:34	SPEAKER_03
 Oh yeah, a bunch of different governments, speakers and how do you handle it?

0:49:38	SPEAKER_03
 Oh yeah.

0:49:39	SPEAKER_07
 I'm much prefer this. I was just trying to find a way because I don't think the staggered mix channel is awfully good as a way of handling overlaps.

0:49:49	SPEAKER_05
 Well good. That really simplifies saying that.

0:49:52	SPEAKER_05
 We can just get the meeting, process it, put the beeps file, send it off to IBM.

0:49:57	SPEAKER_06
 We have very little work on our processes here in Trit.

0:50:02	SPEAKER_06
 Listen to it and then sample it.

0:50:10	SPEAKER_05
 Yeah, that would be very good.

0:50:14	SPEAKER_05
 And then we can, you know, that'll be a good way to get the pipeline going.

0:50:19	SPEAKER_06
 And there's one point which I, which I recalculate when I listen to one of the new meetings and that somebody is playing sound from his laptop.

0:50:31	SPEAKER_06
 And the speech non-speech detector just assigns randomly the speech to one of the channels.

0:50:39	SPEAKER_06
 So I didn't think of this before, but what shall we do about things like this?

0:50:47	SPEAKER_07
 You suggested maybe just not sending that part of the meeting.

0:50:51	SPEAKER_06
 But sometimes the laptop is in the background and somebody is talking and that's really a little bit confusing.

0:51:01	SPEAKER_06
 It's a little bit confusing.

0:51:04	SPEAKER_04
 Even a hand transcription with a hand transcriber would have trouble.

0:51:08	SPEAKER_06
 Yeah, that's a second question. What will the transcribers do with the laptop sound?

0:51:14	SPEAKER_03
 What was the laptop sound?

0:51:16	SPEAKER_06
 Was it speech?

0:51:21	SPEAKER_07
 So my standard approach has been if it's not someone close-miked, then they don't end up on one of the close-mike channels.

0:51:28	SPEAKER_07
 They end up on a different channel.

0:51:30	SPEAKER_07
 And we have any number of channels available.

0:51:34	SPEAKER_06
 When this is sent to the IBM transcribers, I don't know if they can tell that's really...

0:51:40	SPEAKER_04
 Yeah, because there will be no channel on the sheet.

0:51:43	SPEAKER_07
 Well, they have a convention in their own procedures, which is for a background sound.

0:51:49	SPEAKER_04
 Right, but in general, I don't think we want them transcribing the background because that would be too much work.

0:51:54	SPEAKER_04
 Right, because in the overlap sections.

0:51:56	SPEAKER_05
 Well, I don't think Jane's saying they're going to transcribe it, but they'll just mark it as being...

0:52:00	SPEAKER_04
 There's some background stuff that's going to be right over the place.

0:52:02	SPEAKER_04
 How will they tell the difference between that sort of background and the normal background of two people talking at once?

0:52:08	SPEAKER_07
 Oh, I think it could be easy to say background laptop.

0:52:11	SPEAKER_05
 Why would they treat them differently?

0:52:13	SPEAKER_04
 Well, because otherwise it's going to be too much work for them to market.

0:52:17	SPEAKER_07
 They'll be marketing it all over the place.

0:52:19	SPEAKER_07
 Oh, background laptop or background LT wouldn't take any time.

0:52:23	SPEAKER_04
 Sure, but how are they going to tell the difference between that and two people just talking at once?

0:52:27	SPEAKER_07
 Oh, you can tell acoustically. Can't you tell?

0:52:29	SPEAKER_06
 It's really good sound, so...

0:52:31	SPEAKER_07
 Oh, is it?

0:52:32	SPEAKER_03
 Well, isn't there a category something like sounds for someone for whom there is no close-mike?

0:52:38	SPEAKER_06
 Yeah, that would be very important.

0:52:41	SPEAKER_04
 How do we do that for the IBM folks?

0:52:43	SPEAKER_04
 How can they tell that?

0:52:45	SPEAKER_05
 Well, we may just have to do it when it gets back here.

0:52:47	SPEAKER_05
 Yes, that's my opinion as well.

0:52:49	SPEAKER_04
 Okay, that sounds good.

0:52:50	SPEAKER_04
 And they'll just mark it however they mark it.

0:52:52	SPEAKER_04
 So it'll correct it when it gets back.

0:52:53	SPEAKER_06
 That is a category for...

0:52:55	SPEAKER_06
 Yes, that's a problem.

0:52:56	SPEAKER_07
 Well, as it comes back, when we have a...

0:52:58	SPEAKER_07
 When we can use the channelized interface for coding it, then it'll be easy for us to handle.

0:53:02	SPEAKER_07
 But if out of context they can't tell if it's a channeled speaker...

0:53:07	SPEAKER_07
 When a close-mike speaker or not, then that would be confusing to them.

0:53:10	SPEAKER_07
 Right.

0:53:11	None
 Okay.

0:53:12	SPEAKER_07
 I don't know. I don't...

0:53:14	SPEAKER_07
 Either way, it'd be fine with me, I don't really care.

0:53:18	SPEAKER_03
 So, can we...

0:53:19	SPEAKER_03
 You did it, get out of here?

0:53:21	SPEAKER_07
 Yeah.

0:53:22	SPEAKER_07
 I have one question.

0:53:23	SPEAKER_07
 Do you think we should send that whole meeting to them and not worry about preprocessing it?

0:53:27	SPEAKER_07
 Or...

0:53:28	SPEAKER_07
 What I mean is, we should leave the part with the audio in the...

0:53:35	SPEAKER_07
 Beap file that we send to IBM for that one, or should we start after the...

0:53:39	SPEAKER_07
 That part of the meeting is over.

0:53:41	SPEAKER_07
 And what we send...

0:53:42	SPEAKER_07
 What?

0:53:43	SPEAKER_07
 So the part where they're using sounds from their...

0:53:44	SPEAKER_07
 From their laptop.

0:53:45	SPEAKER_06
 With the laptops on for...

0:53:46	None
 Just...

0:53:48	SPEAKER_07
 Have speech from the laptop.

0:53:49	SPEAKER_07
 Should we just...

0:53:50	SPEAKER_07
 Exercise that from what we send to IBM, or should we...

0:53:52	SPEAKER_07
 Give it to them and let them do what they can.

0:53:54	SPEAKER_05
 I think we should just...

0:53:55	SPEAKER_05
 It's going to be too much work if we have to worry about that, I think.

0:53:58	SPEAKER_05
 Yeah, I think if we just send it all to them, you know.

0:54:02	SPEAKER_05
 Good.

0:54:03	SPEAKER_05
 Let's see how it works.

0:54:05	SPEAKER_07
 Yeah, and worry about it when we get back in.

0:54:07	SPEAKER_07
 And give them freedom to indicate if it's just not workable.

0:54:09	SPEAKER_03
 Yeah.

0:54:10	SPEAKER_03
 Okay, excellent.

0:54:11	SPEAKER_03
 Don't you lose mind having that.

0:54:13	SPEAKER_03
 I think that's right.

0:54:14	SPEAKER_04
 Yeah, we'll just have to listen to it and see how well it is.

0:54:16	SPEAKER_04
 Okay.

0:54:17	SPEAKER_06
 Sample it right there.

0:54:18	SPEAKER_06
 Yeah.

0:54:19	SPEAKER_06
 I think that will be a little bit of a problem, us.

0:54:21	SPEAKER_06
 It really switches around between two different channels, I think.

0:54:24	SPEAKER_04
 And they're very...

0:54:25	SPEAKER_04
 It's very audible on the closed talking channels.

0:54:28	SPEAKER_06
 Yeah.

0:54:29	SPEAKER_04
 Oh well.

0:54:31	SPEAKER_04
 Yeah, that's the same problem as the lapel mic.

0:54:33	SPEAKER_06
 Yeah.

0:54:34	SPEAKER_07
 Oh, interesting.

0:54:35	SPEAKER_06
 Comparable, real.

0:54:36	SPEAKER_07
 Okay, good.

0:54:37	SPEAKER_07
 Digits.

0:54:38	SPEAKER_07
 Okay, so we read the transcript number first.

0:54:42	SPEAKER_04
 So we're going to do it all together separately.

0:54:44	SPEAKER_06
 What time is it?

0:54:45	SPEAKER_06
 Ah, why do we go together?

0:54:47	SPEAKER_03
 Okay.

0:54:48	SPEAKER_03
 That's what we do.

0:54:49	SPEAKER_03
 One, two, three, go.

0:54:53	SPEAKER_03
 Transcript.

0:54:54	SPEAKER_03
 Transcript.

0:54:55	SPEAKER_06
 All 58.

0:55:02	SPEAKER_05
 546.

0:55:03	SPEAKER_05
 437.

0:55:04	SPEAKER_05
 827.

0:55:05	SPEAKER_05
 948.

0:55:06	SPEAKER_05
 448.

0:55:07	SPEAKER_05
 498.

0:55:08	SPEAKER_05
 1, 2, 8.

0:55:09	SPEAKER_05
 922.

0:55:10	SPEAKER_05
 490.

0:55:11	SPEAKER_05
 422.

0:55:12	SPEAKER_05
 970.

0:55:13	SPEAKER_06
 970.

0:55:14	SPEAKER_00
 970.

0:55:15	SPEAKER_06
 970.

0:55:16	SPEAKER_06
 970.

0:55:17	SPEAKER_06
 970.

0:55:18	SPEAKER_06
 970.

0:55:19	SPEAKER_06
 970.

0:55:20	SPEAKER_06
 970.

0:55:21	SPEAKER_05
 970.

0:55:22	SPEAKER_05
 970.

0:55:23	SPEAKER_05
 970.

0:55:24	SPEAKER_05
 980.

0:55:25	SPEAKER_06
 970.

0:55:26	SPEAKER_00
 926.

0:55:27	SPEAKER_00
 5886.

0:55:28	SPEAKER_00
 6123.

0:55:29	SPEAKER_00
 324.

0:55:30	SPEAKER_00
 170.

0:55:31	SPEAKER_00
 517.

0:55:32	SPEAKER_00
 417.

0:55:33	SPEAKER_07
 Okay, it's going to be interesting if there are any more errors in these.

0:55:36	SPEAKER_07
 Yeah, they're really pretty low.

0:55:38	SPEAKER_05
 You guys plug your errors when you do it?

0:55:39	SPEAKER_05
 I do.

0:55:40	SPEAKER_05
 Nope.

0:55:41	SPEAKER_05
 I usually do it.

0:55:42	SPEAKER_05
 I don't.

0:55:43	SPEAKER_05
 You don't?

0:55:44	SPEAKER_05
 Nope.

0:55:45	SPEAKER_05
 How can you do that?

0:55:46	SPEAKER_06
 I have so many errors in it, but I- You hate to have your eyes plugged?

0:55:52	SPEAKER_00
 Really?

