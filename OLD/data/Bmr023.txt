0:00:00	None
 Hey, we're recording.

0:00:10	None
 Oh, wait a minute, wait a minute.

0:00:12	None
 Oh boy, I got the harness.

0:00:16	SPEAKER_08
 What's the channel?

0:00:38	SPEAKER_00
 Make sure to turn your microphone on.

0:00:40	SPEAKER_00
 There's a battery.

0:00:42	SPEAKER_05
 There we go.

0:00:45	SPEAKER_00
 Your channel number is already on this blank sheet.

0:00:48	SPEAKER_03
 Channel 5.

0:00:49	SPEAKER_05
 Channel 5.

0:00:50	SPEAKER_05
 Channel 5.

0:00:51	SPEAKER_05
 Channel whatever.

0:00:52	SPEAKER_05
 Camera 1.

0:00:53	SPEAKER_05
 Camera 2.

0:00:54	SPEAKER_05
 Channel 4.

0:00:55	SPEAKER_03
 Channel 5.

0:00:57	SPEAKER_03
 Channel 4.

0:00:58	SPEAKER_00
 The game's up at it what it usually is.

0:01:01	SPEAKER_00
 But if you think it's sort of a default.

0:01:04	SPEAKER_00
 But I can set it higher if you like.

0:01:07	SPEAKER_04
 Yeah.

0:01:08	SPEAKER_03
 Yeah.

0:01:23	SPEAKER_03
 Test test test test test test.

0:01:24	SPEAKER_03
 Okay, that seems better.

0:01:25	SPEAKER_03
 Yeah, okay, good.

0:01:26	SPEAKER_03
 That's good.

0:01:27	SPEAKER_03
 That's good.

0:01:28	SPEAKER_04
 Okay.

0:01:35	SPEAKER_03
 So I had a question for Adam.

0:01:54	SPEAKER_03
 Have we started to read?

0:01:55	SPEAKER_00
 Well, we started recording.

0:01:57	SPEAKER_03
 Yeah.

0:01:58	SPEAKER_03
 It's January.

0:01:59	SPEAKER_03
 I saw it earlier.

0:02:01	SPEAKER_06
 She can just walk in, I guess.

0:02:06	SPEAKER_00
 Yeah, right.

0:02:07	SPEAKER_00
 So we're starting late.

0:02:08	SPEAKER_00
 I figured we'd better just start.

0:02:10	SPEAKER_03
 I was going to ask Adam to say if he thought any more about the demo stuff.

0:02:18	SPEAKER_03
 It occurred to me that this is late May and the DARPA meetings in mid-July.

0:02:27	SPEAKER_03
 But I remember we...

0:02:32	SPEAKER_03
 I know we were going to do something with the transcriber interface.

0:02:35	SPEAKER_03
 There's one thing, but I thought there was a second thing.

0:02:40	SPEAKER_03
 Anybody remember?

0:02:41	SPEAKER_00
 Well, we were going to do a mock-up question answering or something I thought.

0:02:47	SPEAKER_00
 That was totally separate from the interface.

0:02:49	SPEAKER_00
 Do you remember?

0:02:51	SPEAKER_00
 Remember, like, asking questions and retrieving, but in a pre-stored fashion.

0:02:58	SPEAKER_00
 That was the thing we talked about, I think, before the transcriber.

0:03:03	SPEAKER_00
 Yeah.

0:03:04	SPEAKER_03
 All right.

0:03:05	SPEAKER_03
 So anyway, we have to sort of that out.

0:03:07	SPEAKER_03
 Somebody going on it.

0:03:09	SPEAKER_03
 Got a month left, basically.

0:03:13	SPEAKER_00
 You like these, right?

0:03:14	SPEAKER_03
 Okay, good.

0:03:18	SPEAKER_03
 Okay.

0:03:25	SPEAKER_03
 Okay, so what do we get else we got?

0:03:31	SPEAKER_03
 You just wrote about your stuff.

0:03:33	SPEAKER_00
 No, that was all previously here.

0:03:36	SPEAKER_00
 I was writing the digits and then I realized I could see Roxas.

0:03:41	SPEAKER_04
 Oh, okay.

0:03:42	SPEAKER_00
 Because I didn't want people to turn their heads from these microphones.

0:03:45	SPEAKER_00
 We have, by the way, have the same digit form for the record.

0:03:51	SPEAKER_03
 That's cool.

0:03:52	SPEAKER_03
 So the choice is which we want more the comparison.

0:03:57	SPEAKER_03
 Everybody is saying it at the same time or the comparison of people saying the same digits at different times.

0:04:02	SPEAKER_00
 It's just because I didn't have any more digit sheets.

0:04:04	SPEAKER_00
 I know that.

0:04:05	SPEAKER_03
 Which opportunity should we exploit?

0:04:11	SPEAKER_00
 It might be good to have them separately and have the same exact strings.

0:04:17	SPEAKER_00
 I mean, you could use them for normalizing or something.

0:04:20	SPEAKER_00
 But it, of course, goes more quickly doing a menu.

0:04:23	SPEAKER_00
 I guess we'll see.

0:04:24	SPEAKER_00
 I guess we'll see how long we go.

0:04:25	SPEAKER_03
 How long we go and how good this snack is out there.

0:04:28	SPEAKER_07
 Anyway, there's some pants talked to us.

0:04:30	SPEAKER_07
 Somebody is saying zero in some things.

0:04:32	SPEAKER_07
 Right.

0:04:33	SPEAKER_07
 Right.

0:04:34	SPEAKER_07
 It's really not identical.

0:04:36	SPEAKER_03
 Yeah, we'd have to train.

0:04:37	SPEAKER_00
 We'd be like a chorus.

0:04:39	SPEAKER_03
 We'd have to get some experience.

0:04:42	SPEAKER_03
 Yeah.

0:04:43	SPEAKER_03
 Really boring.

0:04:45	SPEAKER_03
 Chorus.

0:04:46	SPEAKER_03
 Do we have an agenda?

0:04:51	SPEAKER_03
 I had them usually tries to put that together.

0:04:54	SPEAKER_03
 I've got a couple of things to talk about.

0:04:57	SPEAKER_03
 Yeah.

0:04:58	SPEAKER_02
 What might those be?

0:04:59	SPEAKER_02
 IBM stuff and just getting meeting information organized.

0:05:07	SPEAKER_03
 Okay.

0:05:09	SPEAKER_03
 You're applying that it's currently disorganized.

0:05:13	SPEAKER_08
 In my mind.

0:05:14	SPEAKER_03
 Is there stuff that's happened about the SRI, recognizer, et cetera, those things that were happening before with?

0:05:30	SPEAKER_03
 You guys were doing bunch of experiments with different finance.

0:05:34	SPEAKER_03
 Is that still sort of where it was the other day we're improving?

0:05:39	SPEAKER_02
 Yeah.

0:05:40	SPEAKER_02
 Now, you saw the note that the PLP now is getting basically the same as the MOTC.

0:05:46	SPEAKER_02
 Yeah.

0:05:47	SPEAKER_08
 Actually, it looks like it's getting better.

0:05:50	SPEAKER_08
 Just with age.

0:05:51	SPEAKER_08
 With age.

0:05:52	SPEAKER_08
 Yeah.

0:05:53	SPEAKER_08
 But that's not tricky related to me.

0:05:57	SPEAKER_08
 So we can talk about it.

0:05:59	SPEAKER_08
 It looks like I haven't, but it's the experiment is still not complete.

0:06:04	SPEAKER_08
 But it looks like the Polotract-Actualization is working good.

0:06:10	SPEAKER_08
 Like, actually, using the warp factors that we computed for the SRI system, just applying them to the PC.

0:06:17	SPEAKER_08
 That's pretty funny.

0:06:18	SPEAKER_00
 So you just need to copy of it.

0:06:20	SPEAKER_08
 Just have to take the supercult to the number of the data.

0:06:23	SPEAKER_08
 They have different meanings in the system.

0:06:25	SPEAKER_03
 Yeah, all that's always good to do.

0:06:30	SPEAKER_08
 One issue, actually, that just came up in discussion with Liz and Darn, was, as far as meeting recognition is concerned, we would really like to move to doing the recognition on automatic segmentations.

0:06:48	SPEAKER_08
 Because in all our previous experiments, we were essentially cheating by having the hand segmentation system based on the recognition.

0:07:00	SPEAKER_08
 And so now, with Tilo's segment, we're working so well.

0:07:03	SPEAKER_08
 I think we should...

0:07:05	SPEAKER_03
 We think we should increase the error rate.

0:07:08	SPEAKER_03
 Yeah.

0:07:09	SPEAKER_07
 That's what I wouldn't do.

0:07:12	SPEAKER_00
 Yeah.

0:07:13	SPEAKER_00
 And even the good thing is that since you have high recall, even if you have low precision because you're over-generating, that's good, because we could train noise models and the recognizer for these kinds of transients and things that come from the microphones.

0:07:27	SPEAKER_00
 But I know that if we run recognition unconstrained on a whole waveform, we do very poorly because we're getting insertions in places that you may well be cutting out.

0:07:39	SPEAKER_00
 So we do need some kind of pre-sequentation.

0:07:41	SPEAKER_08
 Some extra things like retraining or adapting the models for background noise to the environment.

0:07:51	SPEAKER_00
 And using Tilo's, you know, pustyriers or some kind of...

0:07:56	SPEAKER_00
 Or right now they're discreet, yes or no, for a speaker to consider those particular speaker background models.

0:08:04	SPEAKER_00
 There's lots of interesting things that could be done.

0:08:07	SPEAKER_03
 Yeah, if you could do that.

0:08:10	SPEAKER_03
 So when we do the IBM stuff?

0:08:14	SPEAKER_02
 Yeah, so talked with Brian and gave him the alternatives to the single beep at the end of each utterance that we had generated before.

0:08:25	SPEAKER_02
 And so...

0:08:26	SPEAKER_02
 Truck, trunks.

0:08:28	SPEAKER_02
 Yeah, truck, trunks, right.

0:08:29	SPEAKER_02
 And so he talked over the transcriber and the transcriber thought that the easiest thing for them would be if there was a beep and then a number of digit and then a beep at the beginning of each one.

0:08:39	SPEAKER_02
 And that would help keep them from getting lost.

0:08:42	SPEAKER_02
 And so Adam wrote a little script to generate those style beeps.

0:08:47	SPEAKER_02
 And so where...

0:08:48	SPEAKER_02
 I think that the digits are...

0:08:49	SPEAKER_02
 I came up here and just recorded the numbers one through ten.

0:08:52	SPEAKER_02
 So...

0:08:53	SPEAKER_02
 That's a great idea.

0:08:55	SPEAKER_02
 So, yeah, we just used those.

0:08:57	SPEAKER_08
 A few splice to the right for four.

0:09:00	SPEAKER_02
 Yeah, I recorded, actually I recorded one through ten three times, three different speeds, and then he picked.

0:09:05	SPEAKER_02
 He liked the fastest one.

0:09:06	SPEAKER_02
 So he just cut those out and spliced them in between two beeps.

0:09:10	SPEAKER_07
 It will be funny.

0:09:12	SPEAKER_07
 It will be funny when you're really reading digits and then there are the trunks with...

0:09:18	SPEAKER_07
 Yeah, with my digits.

0:09:20	SPEAKER_02
 All right.

0:09:22	SPEAKER_02
 That'll throw.

0:09:24	SPEAKER_03
 Maybe we should have you record a bc for that one.

0:09:28	SPEAKER_03
 And she said it wasn't going to...

0:09:31	SPEAKER_02
 The transcriber said it wouldn't be a problem because they can actually make a template that has beep, number, beep.

0:09:36	SPEAKER_02
 So for them it will be very quick to put those in there and then transcribing.

0:09:41	SPEAKER_02
 So we're going to send in one more sample meeting and Tilo is running his segmentation.

0:09:47	SPEAKER_02
 Adam is going to generate the chunk file and then we'll give it to Brian and they can try that out.

0:09:53	SPEAKER_02
 When we get that back we'll see if that sort of fixes the problem we had with too many beeps in the last transcription.

0:09:59	SPEAKER_03
 Okay.

0:10:00	SPEAKER_03
 Okay. Do you have any idea to turn around on those steps you just said?

0:10:06	SPEAKER_02
 Are on our side or including IBMs?

0:10:09	SPEAKER_02
 Including IBMs.

0:10:12	SPEAKER_02
 Well I don't know. The last one seemed like it took a couple of weeks.

0:10:17	SPEAKER_02
 Maybe even three.

0:10:19	SPEAKER_02
 That's just the IBM side.

0:10:21	SPEAKER_02
 Our side is quick. I mean, how long does your...

0:10:24	SPEAKER_02
 Well I'm at the overall thing.

0:10:26	SPEAKER_03
 The reason I'm asking is because Jane and I have just been talking and Jesus has been doing a further hiring of transcribers.

0:10:37	SPEAKER_03
 We don't really know exactly what they'll be doing and how long they'll be doing it and so forth.

0:10:43	SPEAKER_03
 Because right now she has no choice but to operate in the mode that we already have working.

0:10:49	SPEAKER_03
 So it'd be good to sort of get that resolved.

0:10:54	SPEAKER_02
 I hope we can get a better estimate from this one that we send them.

0:11:01	SPEAKER_02
 So I don't know yet.

0:11:04	SPEAKER_03
 Yeah.

0:11:05	SPEAKER_03
 In particular, I would really hope that when we do the start meeting in July that we sort of have...

0:11:11	SPEAKER_03
 We're into production mode.

0:11:14	SPEAKER_03
 We actually have a stream going and we know how well it does and how it operates.

0:11:19	SPEAKER_03
 I think that would be a very good thing to be able to do.

0:11:23	SPEAKER_04
 Okay.

0:11:24	SPEAKER_03
 Maybe before we do the meeting info organized thing, maybe you could say a little bit stuff about where we are in transcriptions.

0:11:37	SPEAKER_01
 Okay. So the heat transfer was continued to our past one concept one, which was the second thing.

0:11:46	SPEAKER_01
 Talking about it at this point.

0:11:56	SPEAKER_01
 They got in five meetings down in that set right now they're in the positive end.

0:12:01	SPEAKER_03
 I hired two transcribers today and he hired another one, which was because we had a lot of nutrition.

0:12:07	SPEAKER_02
 They died off after they do this for a hell.

0:12:10	SPEAKER_01
 Burn out.

0:12:11	SPEAKER_01
 Well, that was a nice thing.

0:12:18	SPEAKER_01
 One of them had never planned a work past January.

0:12:21	SPEAKER_01
 It means that all these various things, because we represented it as possibly month project at 10.

0:12:26	SPEAKER_01
 And it's not an extensive nutrition way to be productive to two, but they're really solid.

0:12:33	SPEAKER_01
 We're really lucky to really have a lot of me.

0:12:36	SPEAKER_00
 I mean basically spending money on coffee to truck drives off

0:12:44	SPEAKER_01
 Computer safety sprints Backbie I'm just saying, the key point right now is to keep the staff on the leaner side, rather than hiring like eight to 10 right now, because if the IBM thing comes through really quickly, then we don't want to have to make people all the time so.

0:13:21	SPEAKER_01
 That's why I think. I got really a lot of response from my notice and I think I could hire additional people online.

0:13:28	SPEAKER_03
 Yeah, and the other thing is, I mean, in the unlikely event, since we're so far from this, it's a little hard to plan this way, in the unlikely event that we actually find that we have transcribers on staff who are twiddling their thumbs because there's all the stuff that was sitting there has been transcribed and they're faster, the pipeline is faster than the generation.

0:13:53	SPEAKER_03
 In the event that they actually don't, I bet we could find some other stuff for them to do. So I think that as we were talking, if we hired 12, then we could rent to a problem later. We also just couldn't sustain that for everything, but also it's a reason.

0:14:13	SPEAKER_03
 But if we hire, we have five on staff, five or six on staff, then we give time, then it's a small enough number so we can be flexible either way.

0:14:25	SPEAKER_00
 It'd be great too if we can, we might need some help again getting the tighter boundaries or some hand to experiment with, you know, to have a ground truth for this segmentation work, which I guess you have some already that was really helpful and could probably use more.

0:14:43	SPEAKER_07
 Yeah, that was the thing I planned working on is to use the transcriptions which are done by now and to use them as...

0:14:51	SPEAKER_07
 The new ones with the tighter boundaries, yeah.

0:14:53	SPEAKER_07
 And to use them for training or for whatever, yeah, to create some speech, non-speech labels out of them. But that's the thing was what I am just looking into.

0:15:07	SPEAKER_07
 Okay.

0:15:08	SPEAKER_01
 So, there you go, presentation to so much, I was so extremely helpful.

0:15:13	SPEAKER_01
 Now there was a couple weeks ago, I needed some new ones and it happened to be during the time that we was on the presentation.

0:15:19	SPEAKER_01
 I thought it was just very few days, but I happened to be during that time on humans, so I started them on the non-presegment, and then switched them on in two years and they always appreciate that.

0:15:31	SPEAKER_01
 And he's really, really appreciate it.

0:15:36	SPEAKER_01
 I was going to say that they do adjust once in a while, you know, once in a while, and they actually talk to them, didn't you?

0:15:43	SPEAKER_07
 Yeah, I talked to Helm.

0:15:45	SPEAKER_01
 And so I asked her, they're very perceptive.

0:15:50	SPEAKER_01
 I really want to have this meeting of trans farms.

0:15:52	SPEAKER_01
 I haven't done it yet, but I want to do that, and she's out there for a couple of weeks.

0:15:57	SPEAKER_01
 I'm going to do it as she returns.

0:15:59	SPEAKER_01
 Because she was saying in a span of very short-fared, it seems like the ones that need to be adjusted are these things.

0:16:06	SPEAKER_01
 As she was saying short-fared illnesses, you're here, you're aware of this.

0:16:11	SPEAKER_01
 But actually, it's so correct for so much of the time, it's not all this time, it's just this route to a long time.

0:16:18	SPEAKER_00
 That's great.

0:16:20	SPEAKER_01
 I think it would be interesting to take a moment.

0:16:23	SPEAKER_00
 Is there actually a record of where they change?

0:16:27	SPEAKER_00
 I mean, you can compare it, do a diff on the, just so that we knew...

0:16:31	SPEAKER_01
 It's complicated in that...

0:16:34	SPEAKER_07
 I feel when they create new segments or something, it will be not that easy, but...

0:16:42	SPEAKER_00
 I mean, if we keep an old copy of the old time marks, just so that if we run it, we know whether we're, which ones we're cheating and...

0:16:48	SPEAKER_01
 It would be great, which is a lot of good.

0:16:50	SPEAKER_01
 And then, when they start partly through, then when I do as I merge, I'll think down, they've been pre-signed into version.

0:16:56	SPEAKER_01
 So it's not a pure, it's not a pure condition.

0:16:59	SPEAKER_01
 And then, I think that they started with pre-signed methods and work with signal all the way through.

0:17:05	SPEAKER_01
 And I think it wasn't possible for that for many reasons, but it will be possible for future.

0:17:13	SPEAKER_00
 That's great.

0:17:14	SPEAKER_00
 As long as we have a record, I guess, of the original automatic one, we can always find out how well we would do from the recognition side by using those boundaries, you know, a completely non-shading version.

0:17:29	SPEAKER_00
 So if you need someone to record this meeting, I mean, I'd be happy to, for the transcribers, I could do it or chuck her.

0:17:43	SPEAKER_03
 So, you were saying something about organizing the meeting intro?

0:17:47	SPEAKER_02
 Yeah, so Jane and Adam and I had a meeting where we talked about the reorganization of the directory structure for all of the meeting record.

0:17:57	SPEAKER_02
 No.

0:17:58	SPEAKER_02
 For all of the meeting record today, we should have.

0:18:02	SPEAKER_02
 And so we've got a plan for what we're going to do there.

0:18:06	SPEAKER_02
 And then Jane also prepared a, started getting all of the meetings organized so she prepared a spreadsheet, which I spent the last couple of days adding to.

0:18:18	SPEAKER_02
 So I went through all of the data that we have collected so far and have been putting it into a spreadsheet with start time, the date, the old meeting name, the new meeting name, the number of speakers, the duration of the meeting, comments, you know, what it's transcription status is, all that kind of stuff.

0:18:36	SPEAKER_02
 And so the idea is that we can take this and then export it as HTML and put it on the meeting recorder.

0:18:42	SPEAKER_02
 Oh, great.

0:18:43	SPEAKER_02
 Keep people updated about what's going on.

0:18:45	SPEAKER_02
 I've got to get some more information from Jane because I have some gaps here that I need to get her to fill in.

0:18:51	SPEAKER_02
 But so far as of Monday, the 14th, we've had a total number of meeting, 62 hours of meetings that we've collected and some other interesting things.

0:19:07	SPEAKER_02
 Average number of speakers per meeting is six.

0:19:11	SPEAKER_02
 And I'm going to have on here the total amount that's been transcribed so far, but I've got a bunch of, that's what I have to talk to Jane about, figure out exactly which ones have been completed and so forth.

0:19:21	SPEAKER_02
 But this will be a nice thing that we can put up on the website and people can be informed of the status of various different ones.

0:19:30	SPEAKER_02
 And it'll also list, like under the status, if it's at IBM or if it's at ICSI or if it's completed or which ones were excluding, and there's a place for comments so we can say why we're excluding things and so forth.

0:19:44	SPEAKER_03
 Now with the ones that are already transcribed, we have enough there that, you know, we've already done some studies and so forth.

0:19:52	SPEAKER_03
 And shouldn't we go through and do the business of having the participants approve it for the transcriptions for distribution and so forth?

0:20:05	SPEAKER_01
 I would say as, although I still am doing some final pass and trying to convert it into a master file is being the channelized version of this.

0:20:17	SPEAKER_01
 It seems like I get into that a certain way that something else in the case is going to have to start cleaning up the things like the places where transcribed were in a certain way.

0:20:25	SPEAKER_01
 Doing a slouching here and there.

0:20:28	SPEAKER_01
 So I guess we may sense the weight of that's done.

0:20:34	SPEAKER_03
 Well, let me put another sort of milestone kind of as I get with the pipeline.

0:20:41	SPEAKER_03
 We are going to have this DARPA meeting in the whole July and I think it'll be given that we've been, we've given a couple public talks about already spaced by months and months.

0:20:50	SPEAKER_03
 I think it'll be pretty bad if we continue to say none of this is available.

0:20:57	SPEAKER_03
 We want to be able to say here is a subset that is available right now and that's been through the legal issues and so forth.

0:21:09	SPEAKER_03
 And they don't have to.

0:21:10	SPEAKER_08
 For July.

0:21:11	SPEAKER_08
 You know the netted version they can just give their approval to whatever version.

0:21:17	SPEAKER_03
 Well, in principle yes, but I mean if if if if somebody actually did get into some legal issue with it.

0:21:27	SPEAKER_08
 Yeah, but I mean the editing will continue presumably if there is a found they will be fixed but they won't change the content of the meetings.

0:21:33	SPEAKER_00
 Well, if Jane is clarifying question question, then you know how can they agree to it before they know her final version.

0:21:41	SPEAKER_01
 And the thing is, the subtleties where a person uses this word instead of that word which could have been transferred in the other way.

0:21:48	SPEAKER_01
 And not and they wouldn't have been signed or submitted in the other word.

0:21:54	SPEAKER_03
 You know there is a point at which I agree it becomes ridiculous because you know you could do this final thing and then a year from now somebody could say you know that should be a period not a question.

0:22:04	SPEAKER_03
 And you don't you there's no way that we're going to go back and ask everybody do you approve this document now.

0:22:11	SPEAKER_03
 So I think what it is is that the the the the thing that they sign I looked at it while but it has to be open enough that it sort of says, okay from now on.

0:22:20	SPEAKER_03
 Now that I've read this you can use do anything you want with these data.

0:22:25	SPEAKER_03
 And but I think we want to so assuming that it's that kind of wording I don't remember I think we just want to have enough confidence ourselves that it's so close to the final form is going to be in a year from now that they are.

0:22:42	SPEAKER_01
 It's just a question of if the person is using the transfer does the way of them judging what they said when it was signed as.

0:22:58	SPEAKER_03
 Well I forget how we end I figured how we ended up on this but I remember my taking the position of not making it so so easy for everybody to observe everything and Adam was taking the position of of having it be really straightforward for people to check every aspect of it including the audio.

0:23:18	SPEAKER_03
 I don't remember who won Adam.

0:23:25	SPEAKER_03
 That's really nice again because I can't remember how we ended up that it was the transcript he wanted to do a web interface that would make it.

0:23:34	SPEAKER_03
 That would give you access to the transcript and the audience that's what Adam wanted and I remember how we ended up.

0:23:40	SPEAKER_00
 I mean with the web interface it's interesting because you could allow the person who signs to be informed when their transcript changes or something like that.

0:23:49	SPEAKER_00
 I would say no like I don't want to know but some people might be really interested and then in other words they would be informed if there was some significant change other than typos and things like that.

0:24:01	SPEAKER_00
 I was like you were whispering satanic and continuing under your breath and you were like you know the small heads thing but I'm just saying that like you can sort of say that any things that are deemed...

0:24:13	SPEAKER_00
 Anyway I agree that at some point people probably won't care about typos but they would care about significant meaning changes and then they could be asked for their consent I guess if those change.

0:24:27	SPEAKER_00
 Because assuming we don't really distribute things that have any significant changes from what they sign anyway.

0:24:33	SPEAKER_08
 How about having an approval of the audio and of the transcripts?

0:24:37	SPEAKER_00
 Oh my god. But no one will listen to hours and hours of...

0:24:43	SPEAKER_00
 That's like...

0:24:45	SPEAKER_08
 Unfortunately, this is not a such transcript.

0:24:49	SPEAKER_00
 Really?

0:24:51	SPEAKER_00
 I think that's a lot to ask for people that have been in a lot of meeting.

0:24:55	SPEAKER_03
 We've gone down this path a number of times I know this can lead to extended conversations and not really getting anywhere so let me just suggest that offline that the people involved figured out and take care of it before it's still alive.

0:25:06	SPEAKER_03
 So that in July we can tell people yes we have this and you can use it.

0:25:14	SPEAKER_03
 So let's see, what else we got?

0:25:22	SPEAKER_03
 Don did the report about his project in class and we're all making a version so that was stuff he was doing with you.

0:25:32	SPEAKER_00
 I guess one thing we're learning is that we have eight meetings there because we couldn't use the non-native, all non-native meetings.

0:25:40	SPEAKER_00
 It's probably below threshold on enough data for us for the things we're looking at because the prosotic features are very noisy and so you need a lot of data in order to model them.

0:25:52	SPEAKER_00
 So we're starting to see some patterns and we're hoping that maybe with I don't know, double or triple the data with 20 meetings or so that we would start to get better results.

0:26:02	SPEAKER_00
 But we did find that some of the features that Jane would know about that are expressing sort of the distance of boundaries from peaks in the utterance and some local range pitch range effects like how close people are to their floor.

0:26:20	SPEAKER_00
 So we're also going to be able to see some of the different features that are showing up in these classifiers which are also being given some word features that are cheating because they're true words.

0:26:28	SPEAKER_00
 So these are based on force alignment. Word features like word frequency and whether or not something is a back channel and so forth.

0:26:36	SPEAKER_03
 So we're starting to see I think some interesting things including everything where those quasi cheating things.

0:26:44	SPEAKER_05
 I think depends what you're looking at actually sometimes positions and sentences obviously or in spurts was helpful.

0:26:52	SPEAKER_00
 I don't know if that's cheating too.

0:26:56	SPEAKER_00
 Spurts is not cheating except that of course you know the real words but roughly speaking the recognized words are going to give you a similar type of position.

0:27:03	SPEAKER_00
 Right.

0:27:04	SPEAKER_05
 Either earlier or maybe you gave a number of words.

0:27:06	SPEAKER_00
 Not exactly but it should be.

0:27:08	SPEAKER_00
 Well we don't know and actually that's one of the things we're interested in doing is I think time position like when the word starts.

0:27:18	SPEAKER_08
 I don't know if I can start.

0:27:22	SPEAKER_08
 Yeah.

0:27:23	SPEAKER_05
 I would have to know how these things to do.

0:27:25	SPEAKER_05
 Like there's a lot of different features you could just pull out.

0:27:29	SPEAKER_08
 Right.

0:27:30	SPEAKER_08
 Right.

0:27:31	SPEAKER_00
 And it depends on speaking right.

0:27:33	SPEAKER_00
 Yeah.

0:27:38	SPEAKER_00
 One of the interesting things was I guess you reported on some punctuation type finding sense boundaries finding disfluency boundaries and then I had done some work on finding from the foreground speech whether or not someone was likely to interrupt.

0:27:53	SPEAKER_00
 So where you know if I'm talking now and someone and Andreas is about to interrupt me is he going to choose a certain place in my speech either prosaacically or word based.

0:28:02	SPEAKER_00
 And there the prosaac features actually showed up and a neat thing even though the word features were available and a neat thing there too is I tried some putting the speaker so I gave everybody a short version of their name so the real names are in there which we couldn't use.

0:28:21	SPEAKER_00
 Should use IDs or something and those don't show up so that means that overall.

0:28:27	SPEAKER_00
 It wasn't just modeling Morgan or it wasn't just modeling single person.

0:28:34	SPEAKER_00
 But was sort of trying to get a general idea the tree classifier was trying to find general locations that were applicable to different speakers even though there are huge speaker effects so.

0:28:47	SPEAKER_00
 But the main limitation now is I because we're only looking at things that happen every 10 words or every 20 words we need more more data and more data per speaker.

0:29:00	SPEAKER_00
 So it also be interesting to look at the EDU meetings because we did include meeting type as a feature so whether you were in a meeting recorder meeting or robustness meeting did matter to interrupts because there are just fewer interrupts in the robustness meeting.

0:29:16	SPEAKER_00
 And so the classifier learns more about Morgan than it does about sort of the average person which is not bad.

0:29:24	SPEAKER_00
 It probably do better than but it wasn't generalizing.

0:29:27	SPEAKER_00
 So it's and I think Don what we have a long list of things he's starting to look at now over the summer where we can he'll be able to report on more things in the future but it was great that we could at least go from the you know James transcripts and the recognizer output and get it to this point and I think it's something Mara can probably use in her preliminary report like yeah we're at the point where we're training these classifiers and we just reporting very preliminary but suggestive results that some features both word and prozotic work.

0:30:05	SPEAKER_00
 The other thing that was interesting to me is that the pitch features are better than in switchboard and I think that really is from the close talking mics because the pitch processing that was done has much cleaner behavior than the switchboard telephone bandwidth.

0:30:24	SPEAKER_00
 First of all the pitch tracks are have less having the doubleings than switchboard and there's a lot less dropout so if you ask how many regions where you would normally expect some balls to be occurring are completely devoid of pitch information.

0:30:42	SPEAKER_00
 In other words a pitch tracker just didn't get a high enough probability of voicing for words for for you know five word they're much fewer than in switchboard so the missing we had a big missing data problem in switchboard and so the features weren't as reliable because they were often just not available.

0:31:00	SPEAKER_02
 So that's actually good with the lower frequency cutoff on the support.

0:31:04	SPEAKER_00
 Maybe I mean the telephone we had telephone bandwidth for switchboard and we had the annoying sort of telephone handset movement problem that I think may also affect it.

0:31:16	SPEAKER_00
 So we're just getting better signals in this data which is nice.

0:31:25	SPEAKER_00
 Anyway, Dawn's been doing a great job and we hope to continue with Andreas's help and also some of Tilo's help on this to try to get a non cheating version of how all this would work.

0:31:40	SPEAKER_03
 I think just talk about this the other day but has anybody had a chance to try changing insertion penalty sort of things with the using the tandem system.

0:31:56	SPEAKER_08
 Oh yeah I tried that. It didn't help dramatically.

0:32:04	SPEAKER_02
 Were they out of balance? I didn't notice.

0:32:08	SPEAKER_08
 We were a little relative number of, I think there were higher number of collisions actually.

0:32:16	SPEAKER_08
 Deletions?

0:32:18	SPEAKER_08
 So actually it preferred to have a positive, so negative insertion penalty which means that but you know it didn't change by adjusting that the, yeah the arrow changed by probably 1% or so.

0:32:37	SPEAKER_08
 I don't know if that's not the problem.

0:32:40	SPEAKER_08
 That's not the problem.

0:32:42	SPEAKER_08
 But we just, you know, Chuck and I talked and the next thing to do was probably to tune the size of the Gaussian system to this feature vector which we haven't done at all.

0:32:58	SPEAKER_08
 We just used the same configuration as we used for the standard system. And for instance, then they understand me a message saying that see me used something like 10 Gaussian per cluster.

0:33:13	SPEAKER_08
 Each mixture has 10 Gaussian.

0:33:17	SPEAKER_08
 We're using 64.

0:33:19	SPEAKER_08
 So that's obviously a big difference and it might be way off and give a very poorly trained, you know, Gaussian set way and poorly trained mixture.

0:33:30	SPEAKER_08
 So we have the turnaround time on the training when we train only the male system.

0:33:38	SPEAKER_08
 So our small training set is less than 24 hours. So we can run lots of, basically just brute force try a whole bunch of different settings with the new machines that will be better.

0:33:53	SPEAKER_03
 Yeah, we get 12 of those.

0:33:56	SPEAKER_08
 The PLP features work. You know, continue to improve the, as I said before, using dance, vocal track normalization option works very well.

0:34:14	SPEAKER_08
 So I ran one experiment where we just did the vocal track normalization only in the test data. So I did bother to retrain the models and all and the proof I 1% which is about what we get with, you know, just actually doing both training antists normalization with the standard system.

0:34:41	SPEAKER_08
 So in a few hours we'll have the numbers for the, for retrain everything with the tracking, so that might be the problem.

0:34:50	SPEAKER_08
 So it looks like the PLP features do very well after having triggered out all these little tricks to get it to work.

0:34:59	SPEAKER_00
 So you mean you improve 1% over a system that doesn't have any VTL and it already?

0:35:08	SPEAKER_03
 Okay, so then we'll have our baseline to compare the currently hideous new thing.

0:35:14	SPEAKER_08
 Right, and what that's just also is of course that the current switchboard, MOP, isn't trained on very good features.

0:35:24	SPEAKER_08
 Because it was trained on whatever, you know, was used the last time you did up five stuff, which didn't have any of the...

0:35:35	SPEAKER_03
 Right, but all of these effects were like a couple percent, right? I mean...

0:35:39	SPEAKER_08
 Well, but if you add them all up, you have almost 5% difference now.

0:35:44	SPEAKER_03
 And all of them, I thought one was 1.5% and one was 0.8%.

0:35:48	SPEAKER_08
 Yeah, and now we have another percent with the VTL.

0:35:51	SPEAKER_03
 That's 3.3%.

0:35:53	SPEAKER_08
 Actually, and it's...

0:35:56	SPEAKER_08
 What's actually interesting is that with...

0:36:00	SPEAKER_08
 Well, maybe another half percent if you do the VTL and training.

0:36:05	SPEAKER_08
 And then interestingly, if you optimize, you get more of a win out of restoring the...

0:36:12	SPEAKER_08
 the investments and optimizing the weights.

0:36:16	SPEAKER_08
 Then you do with the standard?

0:36:18	SPEAKER_03
 Yeah, but the part that's actually adjustment of the front end per se is opposed to doing putting VTN or something is...

0:36:24	SPEAKER_03
 It was a couple percent.

0:36:26	SPEAKER_03
 There was one thing that was 1.5% on the VTL.

0:36:30	SPEAKER_03
 And let's see if I remember what they were.

0:36:32	SPEAKER_03
 One of them was the change to...

0:36:37	SPEAKER_03
 because it did it all at once, from barc scale to male scale, which I really feel like saying in quotes, because...

0:36:45	SPEAKER_03
 Essentially the same...

0:36:46	SPEAKER_03
 Yeah, why did that change?

0:36:48	SPEAKER_03
 But any individual particular implementation of those things puts things in a particular place.

0:36:54	SPEAKER_03
 So that's why I wanted to look...

0:36:57	SPEAKER_03
 I wanted to look at exactly where the filters were in the two.

0:37:00	SPEAKER_03
 It's probably something like there's one fewer or one more filter in the sub...

0:37:05	SPEAKER_03
 when kill hurts band.

0:37:06	SPEAKER_03
 And for whatever reason, with this particular experiment, it was better.

0:37:11	SPEAKER_03
 It could be there's something more fundamental, but I don't know yet.

0:37:15	SPEAKER_03
 And the other...

0:37:16	SPEAKER_03
 That was like 1.5% or something, then there was 0.8% which was...

0:37:20	SPEAKER_02
 Well, that was combined with the triangular, right?

0:37:22	SPEAKER_03
 Yeah, those two were together.

0:37:24	SPEAKER_03
 We were able to separate them out as a system and one thing.

0:37:26	SPEAKER_03
 But then there was 0.8%, which was something else.

0:37:28	SPEAKER_02
 The low frequency cutoff.

0:37:30	SPEAKER_03
 Oh yeah, so that was...

0:37:31	SPEAKER_03
 That one I can claim credit for in terms of screwing it up in the first place.

0:37:35	SPEAKER_03
 So someone else fixed it, which is that I never put...

0:37:39	SPEAKER_03
 We had some problems before with offsets.

0:37:42	SPEAKER_03
 This one back to, I think, Wall Street Journal.

0:37:46	SPEAKER_03
 So we had...

0:37:48	SPEAKER_03
 Everybody else who was doing Wall Street Journal knew that there were big DC offsets in these data and those data and nobody had the mention into us.

0:37:54	SPEAKER_03
 And we were getting really terrible results, like two, three times the error everybody else was getting.

0:37:59	SPEAKER_03
 And then in casual conversation, someone mentioned, well, I guess, of course, you're taking care of the offsets.

0:38:04	SPEAKER_03
 I said, what offsets?

0:38:05	SPEAKER_03
 And at that point, we were pretty into the data and we never really looked at it on a screen.

0:38:09	SPEAKER_03
 And then we put it on the screen and we...

0:38:11	SPEAKER_03
 This big DC offset.

0:38:13	SPEAKER_03
 So...

0:38:14	SPEAKER_00
 There was that like a hammer?

0:38:16	SPEAKER_00
 Or when they recorded?

0:38:17	SPEAKER_03
 It's not at all uncommon for record electronics to have different DC offsets.

0:38:24	SPEAKER_03
 It's no big deal.

0:38:26	SPEAKER_03
 You could have 10, 20, 30 models, whatever.

0:38:28	SPEAKER_03
 And if it's consistently in there.

0:38:30	SPEAKER_03
 The thing is, most people, front ends, have pre-emphasis with zero-zero frequency so that it's irrelevant.

0:38:36	SPEAKER_03
 But with PLP, we didn't actually have that.

0:38:40	SPEAKER_03
 We had the equivalent of pre-emphasis in a pletcher-months-in-style waiting that occurs in the middle of PLP.

0:38:48	SPEAKER_03
 But it doesn't actually have a zero-zero frequency, like typical simple pre-emphasis does.

0:38:54	SPEAKER_03
 We had something more fancy.

0:38:55	SPEAKER_03
 It was later on, it didn't have that.

0:38:57	SPEAKER_03
 So at that point, I really...

0:38:58	SPEAKER_03
 Oh, we better have a high pass filter just, you know, just take care of the problem.

0:39:03	SPEAKER_03
 So I put in a high pass filter at, I think, 90 hertz or so for a 16-kiloward sampling rate.

0:39:11	SPEAKER_03
 And I never put anything in to adjust it for different sampling rates.

0:39:17	SPEAKER_03
 And so the code doesn't know anything about that.

0:39:20	SPEAKER_03
 So this is all at 8-kiloward, so it was at 45 hertz instead of 90.

0:39:25	SPEAKER_03
 So I don't know if Dan fixed it or...

0:39:30	SPEAKER_08
 Well, he made it the prime of her.

0:39:32	SPEAKER_03
 He made a parameter, so I guess if he did it right, he did fix it.

0:39:35	SPEAKER_03
 And it's taking care of sampling rate, which is great.

0:39:38	SPEAKER_02
 What is the parameters, just the lower cutoff that you want?

0:39:42	SPEAKER_08
 It's called H-P-F.

0:39:45	SPEAKER_03
 Yeah, that's H-P-F on its...

0:39:47	SPEAKER_08
 But H-P-F, you know, when you put a number after it, it's the set of the hertz-vide.

0:39:52	SPEAKER_08
 Yeah, cutoff.

0:39:54	SPEAKER_03
 I mean, frankly, we never did that with the Rasta filter either.

0:39:57	SPEAKER_03
 So the Rasta filter is actually doing a different thing in the modulations, where I could remain depending on what sampling rate you're doing, which is another old bugger pipe.

0:40:06	SPEAKER_03
 But...

0:40:08	SPEAKER_03
 So that was the problem there.

0:40:10	SPEAKER_03
 We had always intended to cut off below 100 hertz and we just wasn't doing this or now it is.

0:40:15	SPEAKER_03
 So that helped us by like a 10-3 percent, it still wasn't a big deal.

0:40:22	SPEAKER_08
 Well, but...

0:40:24	SPEAKER_08
 Well, again, after completing the current experiments, we can add up all the...

0:40:30	SPEAKER_08
 Oh, yeah.

0:40:32	SPEAKER_03
 I guess my point was that the hybrid system thing we did was primitive in many ways.

0:40:45	SPEAKER_03
 And I think I agree with you that if we fixed lots of different things and they're all that up, we probably have a competitive system. But I think not that much of it is due to the front end per se.

0:40:56	SPEAKER_03
 I think maybe a couple percent of it is as far as you can see from this.

0:40:59	SPEAKER_03
 Unless you call... Well, if you call VT, all the front end, that's a little more, but that's sort of more, both.

0:41:06	SPEAKER_02
 One experiment, we should...

0:41:08	SPEAKER_02
 We'll probably need to do, though, when...

0:41:11	SPEAKER_02
 At some point, since we're using that same...

0:41:14	SPEAKER_02
 The net that was trained on PLP without all these things in it for the tandem system, we may want to go back and retrain...

0:41:21	SPEAKER_02
 Well, that's what I meant.

0:41:23	SPEAKER_02
 Yeah, for the tandem, so we can see what effect it has on the tandem process.

0:41:28	SPEAKER_08
 So the thing is, do we expect, at this point, I'm wondering, can we expect the tandem system to do better than a properly trained...

0:41:38	SPEAKER_08
 A Gaussian system trained directly on the features with the right choice of parameters?

0:41:44	SPEAKER_03
 Well, that's what we're seeing in other areas, yes.

0:41:48	SPEAKER_03
 So it's...

0:41:51	SPEAKER_02
 So we may not...

0:41:54	SPEAKER_02
 I mean, if it doesn't perform as well, we may not know why, right?

0:41:57	SPEAKER_02
 Because we need to do the exact experiment.

0:42:01	SPEAKER_03
 I mean, the reason to think it should is because you're putting in the same information and you're transforming it to be more discriminative.

0:42:11	SPEAKER_03
 So... Now, the thing is, in some databases, I wouldn't expect it to necessarily give you much.

0:42:18	SPEAKER_03
 And part of what I view as the real power of it is that it gives you a transformation, an okay probability for taking all sorts of different wild things that we do, not just the standard front end, but other things like with multiple streams and so forth.

0:42:33	SPEAKER_03
 And it allows you to feed them to the other system through this funnel.

0:42:37	SPEAKER_03
 So I think that's the real power, but I wouldn't expect huge improvements.

0:42:43	SPEAKER_03
 But it should at least be roughly the same and maybe a little better if it's in way, way worse than...

0:42:50	SPEAKER_02
 So we're going to... Another thing that under S and I were talking about was...

0:42:54	SPEAKER_02
 In the first experiment that he did, we just took the whole 56 outputs and that's basically compared to a 39 input feature vector from either MFCC or PLP.

0:43:07	SPEAKER_02
 But one thing we could do is...

0:43:09	SPEAKER_03
 Let me just ask you, say take the 56 outputs, these are the pre-final nonlinearity outputs.

0:43:15	SPEAKER_02
 Yeah, through the regular tandem outputs.

0:43:17	SPEAKER_02
 Through the KLT.

0:43:18	SPEAKER_02
 Through the KLT, all that kind of stuff.

0:43:19	SPEAKER_03
 And so then do you use all 56 of the KLT or...?

0:43:22	SPEAKER_02
 That's what we did, right?

0:43:24	SPEAKER_02
 So one thing we were wondering is if we did principal components and say took out just 13 and then did Delta's and Double Delta's on that.

0:43:31	SPEAKER_02
 So we treated the first 13 as though they were standard features.

0:43:36	SPEAKER_02
 I mean, did Dandu experiments like that?

0:43:39	SPEAKER_03
 Talked with Stefan.

0:43:41	SPEAKER_03
 He did some things like that.

0:43:43	SPEAKER_03
 He was either him or Carmen, I forget.

0:43:45	SPEAKER_03
 I mean, all different databases and different HDK and all that.

0:43:49	SPEAKER_03
 So it may not apply, but my recollection of it was that it didn't make it better, but it didn't make it worse.

0:43:55	SPEAKER_03
 But again, given all these differences, maybe it's more important in your case that you now take a lot of these low variance components.

0:44:04	SPEAKER_02
 Because in a sense, the net's already got quite a bit of context in those features.

0:44:09	SPEAKER_02
 So if we did Delta's and Double Delta's on top of those, we're getting sort of even more...

0:44:17	SPEAKER_02
 Should be good, right?

0:44:19	SPEAKER_03
 Yeah.

0:44:25	SPEAKER_08
 But the main point is that, you know, it took us a while, but we have a procedure for coupling the two systems debug now.

0:44:36	SPEAKER_08
 I mean, there's still conceivably some bug somewhere in the way we're feeding the tenant features.

0:44:44	SPEAKER_08
 We're generating even more feeding them to the SRI system.

0:44:48	SPEAKER_03
 But there might be, because that's a pretty big difference.

0:44:51	SPEAKER_08
 Yeah.

0:44:52	SPEAKER_08
 I'm wondering how we can debug that.

0:45:03	SPEAKER_08
 I'm actually quite sure that feeding the features into the system and training it up.

0:45:11	SPEAKER_08
 I think that's essentially the same as we use with the POP features.

0:45:17	SPEAKER_08
 That's obviously working great.

0:45:20	SPEAKER_02
 Yeah, there could be a bug in the somewhere before that.

0:45:23	SPEAKER_08
 Another degree of freedom is how do you generate the POP transform?

0:45:28	SPEAKER_04
 That's right.

0:45:29	SPEAKER_03
 One other one is the normalization of the inputs to the net.

0:45:35	SPEAKER_03
 These nets are trained with particular normalization, and that could screwed up.

0:45:41	SPEAKER_02
 I'm doing what Eric coached me through them that part of it.

0:45:46	SPEAKER_02
 So I'm pretty confident in that.

0:45:48	SPEAKER_02
 I mean, the only slight differences that I use normalization values that underest calculated from the original PLP, which is right.

0:46:00	SPEAKER_02
 Yeah.

0:46:01	SPEAKER_02
 So I do, we actually don't do that normalization for the PLP doing for just the straight PLP features.

0:46:10	SPEAKER_08
 No, the SRI system.

0:46:12	SPEAKER_02
 SRI system does that, right?

0:46:14	SPEAKER_08
 So there's room for bugs that we might not have.

0:46:21	SPEAKER_03
 I would actually double check with Stefan at this point.

0:46:25	SPEAKER_03
 Because he's probably the one here and he and Dan are the ones who are at this point most experienced with the tandem.

0:46:34	SPEAKER_03
 There may be some little bit here and there that is not being handled right.

0:46:40	SPEAKER_02
 That's hard with features because you don't know what they should look like.

0:46:44	SPEAKER_02
 I mean, you can't just print the values out and ask you and you know, look at them and see if they're there.

0:46:50	SPEAKER_00
 And also, they're not, I mean, as I understand, you don't have a way to optimize the features for the final word error, right?

0:46:58	SPEAKER_00
 I mean, these are just discriminative, but they're not optimized for the final right.

0:47:04	SPEAKER_00
 So there's always this question of whether you might do better with those features if there was a way to train it for the word error metric that you're actually.

0:47:13	SPEAKER_03
 Well, you're actually, but in an indirect way.

0:47:17	SPEAKER_03
 Well, right. Just in direct so you don't know.

0:47:20	SPEAKER_03
 You may not be in this case come to think of it because you're just taking something was trained up elsewhere.

0:47:26	SPEAKER_03
 So what you do in the full procedure is you have an embedded training.

0:47:33	SPEAKER_03
 So in fact, the net is trained on a Vaterbi alignment of the training did it.

0:47:41	SPEAKER_03
 It comes from your full system.

0:47:43	SPEAKER_03
 And so that's where the feedback comes around so that it is actually discriminative.

0:47:48	SPEAKER_03
 You can prove that it's a, if you believe in the Vaterbi assumption that getting the best path is almost equivalent to getting the best total probability, then you actually do improve that by training up on local frames.

0:48:12	SPEAKER_03
 But we aren't actually doing that here because we did, we did that for a hybrid system.

0:48:17	SPEAKER_03
 And now we're plugging it into another system. So it isn't, it wouldn't quite apply here.

0:48:22	SPEAKER_02
 So another huge experiment we could do would be to take the tandem features, do SRI, forced alignments using those features.

0:48:32	SPEAKER_00
 Exactly. It's exactly.

0:48:33	SPEAKER_00
 And redo the net so that you can optimize it.

0:48:35	SPEAKER_03
 So since you're not using the net for recognition per se, but just for this transformation is probably bigger than it needs to be.

0:48:42	SPEAKER_03
 So that would save a lot of time.

0:48:44	SPEAKER_08
 And there's a mismatch in the phone sets.

0:48:47	SPEAKER_08
 So you're using a large of phone sets.

0:48:51	SPEAKER_03
 Yeah, actually all those things could could could could could could have acted as well.

0:48:56	SPEAKER_03
 The other thing, just to mention that Stefan, this was an innovation, I Stefan's, which was a pretty neat one. And my particularly apply here given all these things we're mentioning.

0:49:06	SPEAKER_03
 Stefan's idea was that discriminant approaches are great.

0:49:12	SPEAKER_03
 Even the local ones given, you know, these potential outer loops, which you can convince yourself, turn into the global ones.

0:49:21	SPEAKER_03
 However, this time is not good. When something about the test set is different enough from the training set that the discrimination that you're learning is not a good one.

0:49:33	SPEAKER_03
 So his idea was to take as the input feature vector to the Gaussian mixture system, a concatenation of the neural net outputs and the regular features.

0:49:47	SPEAKER_00
 Yeah, that didn't you do that already or oh, that makes a lot of sense.

0:49:53	SPEAKER_08
 When I first started corresponding with Dan about how to go about this, I think that was one of the things that we, I mean, I'm sure that Stefan was the first to think of it, but actually Stefan did it.

0:50:02	SPEAKER_03
 And it helped a lot.

0:50:04	SPEAKER_03
 So that's our current best system in the, yeah.

0:50:08	SPEAKER_03
 Yeah, that makes sense.

0:50:10	SPEAKER_08
 You should never do worse.

0:50:12	SPEAKER_08
 I'm on the combined feature vector. I miss what you said you do a KLT transform on the combined feature vector.

0:50:19	SPEAKER_03
 Yeah, well, actually, you should check with him because he tried several different combinations.

0:50:24	SPEAKER_08
 Because you ended up with this huge feature vector. So that might be a problem unless you do something from the first place.

0:50:29	SPEAKER_03
 Yeah, I, what I don't remember is which came out best. So he did one where he put a put the whole thing into one KLT.

0:50:35	SPEAKER_03
 And another one since the PLP things are already orthogonalized, he left them alone and, and just did a KLT on the, on the net outputs and again a that.

0:50:45	SPEAKER_03
 And I don't remember which was better.

0:50:48	SPEAKER_02
 Did he, did he try to, so he always ended up with a feature vector that was twice as long as either one of the, no, I don't know, I don't know.

0:50:56	SPEAKER_03
 You have to check with him.

0:50:59	SPEAKER_03
 I meant a big idea these days.

0:51:02	SPEAKER_00
 You need to close up because I need to save the data.

0:51:06	SPEAKER_00
 Not to mention that I have a few snacks.

0:51:09	SPEAKER_00
 Right. Did people want to do the digits or do them together?

0:51:13	SPEAKER_03
 I think given that we're doing for snacks, maybe we should do them together.

0:51:17	SPEAKER_00
 Okay. I mean, we're trying to do them in synchrony. That might be fun.

0:51:22	SPEAKER_00
 So he's not here to tell me no.

0:51:25	SPEAKER_03
 It's not going to work out, but we could, we could just see if we find the rhythm, you know.

0:51:33	SPEAKER_03
 Sure.

0:51:34	SPEAKER_03
 Oh, there's zero. So we want to agree on that.

0:51:37	SPEAKER_00
 Maybe just whatever people would naturally do. I don't know.

0:51:40	SPEAKER_03
 Well, but if we were singing group, we would want to decide.

0:51:44	SPEAKER_00
 Viet Harman, you know.

0:51:47	SPEAKER_00
 Sorry. So I set up and we didn't have enough digit form. So I zerox the same one seven times.

0:51:53	SPEAKER_03
 I'm going to have a problem with saying zero.

0:51:56	SPEAKER_03
 No.

0:51:57	SPEAKER_03
 Okay.

0:51:58	SPEAKER_03
 Okay. One and two and three.

0:52:01	SPEAKER_04
 Seven eight seven one five two zero three zero two eight one two zero two two six one four six zero three.

0:52:14	SPEAKER_04
 Two seven eight two six two two three four nine eight seven zero seven five two nine one zero nine one eight zero six zero five one five six two eight four three six five seven nine five one eight eight.

0:52:43	SPEAKER_04
 Eight eight four nine five three two five three eight one two zero zero one seven three three eight six zero zero.

0:52:57	SPEAKER_03
 What's more with feeling?

0:52:59	SPEAKER_00
 It's transcript L one three eight.

0:53:02	SPEAKER_00
 Oh, yeah.

0:53:03	SPEAKER_00
 It was.

0:53:04	SPEAKER_05
 It sounded like it.

0:53:13	SPEAKER_04
 It sounded very.

0:53:14	SPEAKER_05
 It was the lack of prasadica.

0:53:16	SPEAKER_00
 Exactly.

0:53:17	SPEAKER_00
 Everybody's sort of lowers their pitch.

0:53:19	SPEAKER_00
 And now we're going to go out and have some access.

0:53:21	SPEAKER_05
 Now we know.

0:53:22	SPEAKER_05
 No.

0:53:23	SPEAKER_05
 All right.

