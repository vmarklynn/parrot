0:00:00	None
 I am Guess so radio to

0:00:16	SPEAKER_04
 All right

0:00:18	SPEAKER_03
 It works really well people say this thing Everybody's on yeah So you guys had a meeting with Henik which I unfortunately had to miss And And I guess Chuck you weren't there either so I was there or you were there with Henik yeah, so everybody knows what happened except me Maybe somebody should tell me

0:01:08	None
 All right Well first we discussed about some of the points That I was addressing in the mail I sent last week So yeah But well the don't sampling problem Yeah And about the feet of the filters

0:01:34	SPEAKER_03
 So what was the time sampling problem again I think

0:01:40	SPEAKER_05
 Is that the fact that there is no low pass filtering before the don't sample well there is because there is a LDA filtering but that's perhaps not the best

0:01:52	SPEAKER_03
 But it depends but it's a Consicure requesting this yeah so you could do a you could do a structure one maybe yeah so we discussed about this about

0:02:02	SPEAKER_05
 Was there any conclusion about that? Or try it yeah I guess

0:02:14	SPEAKER_03
 Yeah so again this is the this is the down sampling of the feature vector stream And yeah I guess the LDA filters they were doing do have It's so that the feature vectors are calculated every 10 milliseconds so The question is how far down they are 50 50 hertz Sorry at 25 hertz and so down sampling right too So does anybody know the frequency characteristic is

0:02:52	SPEAKER_05
 We don't have yet So yeah we should have a look for that perhaps yeah the modulation spectra So there is this there is the length of the filters So the idea of trying to find filters with shorter delays We started to work with this And the third point was the yeah the online normalization where Well the recursion for the min estimation is a filter with some kind of delay Yeah that's not taken into account right now Yeah and there again for this conclusion the fin acquiesce

0:03:50	SPEAKER_03
 We can try it but try try what?

0:03:56	SPEAKER_05
 So try to take into account the delay of the recursion for the min estimation Okay And this we've not worked on this yet And so while discussing about these LDA filters some issues appeared Like well the fact that if we look at the frequency response of these filters it's Well we don't know really what's the important part in the frequency response And there is the fact that in the very low frequency these filters don't really remove a lot Compared to the standard Rasta filter And that's probably the reason why yeah online normalization helps because Yeah to remove this maze Yeah but perhaps everything could be in the filter I mean the min normalization Yeah so Yeah so basically that's what we discussed about Good things to do also generally good stuff to do for the research And this was this LDA tuning perhaps and in fact proposed again to these traps

0:05:28	SPEAKER_03
 Okay I mean I guess the key thing for me is figuring out how to better coordinate between two sides Because I was talking with Henrik about it later And the sense sort of that neither group of people wanted to bother the other group too much And I don't think anybody is closed in and they're thinking or I'm willing to talk about things But I think you were sort of waiting for them to tell you that they had something for you And then they expected they would do certain things and they didn't want to bother you And we were sort of waiting for you and we ended up with this thing Where they were filling up all of the possible latency for themselves And they just hadn't thought of that Yeah I mean it's true that maybe no one really thought about that this latency thing would be such a strict issue

0:06:28	SPEAKER_05
 And yeah I don't know what happened really but I guess it's also the time constraints Because we discussed about this problem and they told us well we will do all that's possible to have enough space for network But then the wraps never ends But the rest was a problem of communication So we will try to talk more

0:07:08	SPEAKER_03
 So there's... All right well maybe we should just... I mean you're busy, other than that you folks are busy doing all the things that you're trying that we talked about before And machines are busy and you're busy Okay well let's... I mean I think that as we said before one of the things that we're imagining is that there will be in system There will be something to explicitly do something about noise in addition to the other things that we're talking about And that's probably the best thing to do And there was that one email that said that it sounded like things looked very promising up there in terms of...

0:07:56	SPEAKER_03
 I think they were using... approach or something in addition to... they're doing some noise removal thing

0:08:04	SPEAKER_05
 So yeah we will start to do this also So Carmen is just looking at the Ericsson code

0:08:12	SPEAKER_00
 I modified it, modified it I studied there is some code in the world To take only the first step the spectral substitution And we have some... the feature for Italian database And we will try with this feature with the filter to find the result But we have the result under this moment Yeah, sure We are working in this also and maybe try another type of spectrarset ratio

0:08:40	SPEAKER_03
 When you say you don't have a result yet you mean it's just that it's in focus or it finished and it didn't get a good result

0:08:48	SPEAKER_00
 No, no, we have... we have the experiment Or we have the feature, the feature but... this experiment... we have not made this experiment Maybe it would be good to resend all the resend... we don't know

0:09:04	SPEAKER_03
 Yeah So I suggest actually now we move on and tear what's happening in another areas like... what's happening with your investigations Oh, I don't know about echoes and so on

0:09:24	SPEAKER_01
 I haven't started running the test yet, I'm meeting with Adam today And he's going to show me the scripts he has for running recognition on the meeting recorder digits I also haven't got the code yet I haven't asked for the quiz code yet So that's how Adam Down on the pieces And I don't really understand what he's doing yet It sounded like the channel normalization part of his thesis was done in a bit of... I don't know what the word is A bit of a rough way, it sounded like he... he wasn't really fleshed out and maybe he did something that was interesting for the test situation But I'm not sure if it's what I'd want to use So I have to read it more, I don't really understand what he's doing yet

0:10:18	SPEAKER_03
 I haven't read it in a while so it's not going to be too much help unless I read it again So...

0:10:26	SPEAKER_03
 And then you're also going to be doing this echo cancelling between the question and the...

0:10:34	SPEAKER_03
 We're calling cheating experiment

0:10:38	SPEAKER_01
 I'm hoping... I'm hoping you ask me what to do

0:10:44	SPEAKER_03
 Oh, okay Delegate It's good to be Delegate

0:10:50	SPEAKER_01
 I think he's at least planning to do it for the close mic crosstalk And so maybe I can just take the other set of he has and use it

0:10:58	SPEAKER_03
 Great, great Yeah, actually he should...

0:11:02	SPEAKER_03
 Like maybe it's the analysis going to be doing a different cancellation One of the things that people working in the meeting task want to get at is We'd like to have cleaner close mic recordings So this is especially true for the lapel but even for the close mic cases We'd like to be able to have other sounds from other people on so forth removed So when someone isn't speaking you'd like to part whether or not speaking to actually So what they're talking about doing is using echo cancellation like techniques It's not the way I go but just taking the input from other mics and using an adaptive filtering approach to remove the effect of that other speech So what was it? There was some point where Eric or somebody was speaking And he had lots of silence in his channel and I was saying something to somebody else Which is in the background and it was not... it was recognizing my words which was the background speech On the close mic

0:12:20	SPEAKER_02
 Oh, we talked about yesterday Yeah, that was actually in my eyes I was wearing the lapel and you were sitting next to me Yeah, and I only said one thing But you were talking and it was picking up all your words

0:12:32	SPEAKER_03
 Yeah, so they were like clean channels And for that purpose, so let's pull it out So I think that's something that somebody was working with That's going to work out So Right And I don't know if we've talked lately about the plans You're developing and we talked about this morning If we talked about that last week or not But you just do work with Ryze and probably I guess I'm just pointing So

0:13:10	None
 We're going to Next day It's on the way It's really hot What about the stuff that Miriam has been doing?

0:13:42	SPEAKER_02
 And Sean, yeah.

0:13:45	SPEAKER_02
 Yeah.

0:13:46	SPEAKER_01
 What's good about you and I think that's good.

0:13:53	SPEAKER_02
 So they're training up nets to try to recognize these acoustic features, I see.

0:14:06	SPEAKER_03
 But that's a certainly relevant study and you know what are the features that they're finding.

0:14:14	SPEAKER_03
 We have this problem with the overloading of the term features.

0:14:18	SPEAKER_03
 What are the variables we're calling this one?

0:14:20	SPEAKER_03
 What are the variables that they're finding useful?

0:14:24	SPEAKER_02
 And their targets are based on canonical mappings of phones to acoustic.

0:14:30	SPEAKER_03
 Right. And there's certainly one thing to do and we're going to try and do something more fine than that.

0:14:38	SPEAKER_03
 So I guess I was trying to remember some of the things we were saying.

0:14:48	SPEAKER_03
 Yeah. So some issues we were talking about was just getting a good handle on what good features are.

0:15:00	SPEAKER_02
 What did Larry Saul use for this sonarant detector?

0:15:06	SPEAKER_02
 How did he do that?

0:15:09	SPEAKER_02
 What was his detector?

0:15:11	SPEAKER_04
 Yeah. It was a tonnage.

0:15:21	None
 It was variable.

0:15:23	SPEAKER_02
 It was a measure of the hand to the left.

0:15:27	SPEAKER_02
 A thing.

0:15:28	SPEAKER_04
 Actually, it was a measure of the correlation.

0:15:33	SPEAKER_04
 So how did he combine all these features?

0:15:39	SPEAKER_02
 What classifier did he use?

0:15:45	SPEAKER_02
 What did he use for this test?

0:16:11	SPEAKER_03
 What are the variables that you use?

0:16:17	SPEAKER_03
 You combine them using the software or something more complicated.

0:16:23	SPEAKER_03
 And then the other thing was where to get the targets from.

0:16:27	SPEAKER_03
 The initial thing is just the obvious that we're discussing is starting off with phone labels from somewhere and then doing the transformation.

0:16:35	SPEAKER_03
 But then the other thing is to do something better.

0:16:41	SPEAKER_03
 What did you tell us about this database?

0:16:47	SPEAKER_03
 I don't know.

0:17:07	SPEAKER_02
 I guess if you had people who had like, like, a computer, a computer, a computer.

0:17:19	SPEAKER_02
 Pierce Tongues.

0:17:21	SPEAKER_03
 You just mounted it to that and they wouldn't even notice.

0:17:25	SPEAKER_03
 Welled it.

0:17:29	SPEAKER_02
 That's right.

0:17:39	SPEAKER_03
 Okay.

0:18:05	SPEAKER_02
 There's a bunch of data around people who have done studies like that way, way back.

0:18:11	SPEAKER_02
 I can't remember where Wisconsin or someplace that used to have a big database.

0:18:19	SPEAKER_02
 Remember there was this guy at AT&T Randolph?

0:18:25	SPEAKER_02
 Researcher at AT&T, a while back that was studying, trying to do speech recognition from these kinds of features.

0:18:37	SPEAKER_03
 Mark Randolph.

0:18:45	SPEAKER_02
 Oh, is he?

0:18:49	SPEAKER_05
 I can't remember exactly what he was using now.

0:18:55	SPEAKER_02
 I just remember it had to do with, you know, positional parameters and trying to, you know, speech recognition based on them.

0:19:03	SPEAKER_03
 The only hesitation I had about it since I haven't seen the data is it sounds like it's continuous variables and a bunch of them.

0:19:13	SPEAKER_03
 And so I don't know how complicated it is to go from there, but you really want these binary labels just a few of them.

0:19:23	SPEAKER_03
 And maybe there's a trivial mapping.

0:19:27	SPEAKER_03
 I worry a little bit that this is a research project in itself.

0:19:33	SPEAKER_03
 Because if you did something instead that like having some manual annotation by, you know, agristic students, this would, there'd be a limited set of things that you could do as per our discussions with John before.

0:19:51	SPEAKER_03
 But the things that you could do like anxiety and voicing a couple other things, you probably could do reasonably well.

0:19:59	SPEAKER_03
 And then it would really be this binary variable.

0:20:04	SPEAKER_03
 Of course, then that's the other question is do you want binary variables?

0:20:07	SPEAKER_03
 So the other thing you could do is boot trying to get those binary variables and take the continuous variables from the data itself there.

0:20:21	SPEAKER_02
 But I'm not sure.

0:20:23	SPEAKER_02
 Could you cluster the, just do some kind of clustering?

0:20:27	SPEAKER_02
 Yeah, then I'm up into different categories.

0:20:30	SPEAKER_03
 So anyway, that's another whole direction that could be looked at.

0:20:38	SPEAKER_03
 I mean, in general, it's going to be for new data that you look at, it's going to be hidden variable because we're not going to get everybody sitting in these meetings to where the pellets and.

0:20:50	SPEAKER_02
 So you're talking about using that data to get instead of using canonical mappings of phones.

0:20:58	SPEAKER_02
 So you use that data to give you sort of what the true mappings are for each phone.

0:21:10	SPEAKER_03
 Yeah, where this fits into the rest in my mind, I guess, is that we're looking at different ways that we can combine different kinds of printed representations in order to get robustness and do difficult or even typical conditions.

0:21:29	SPEAKER_03
 And part of it, this robustness seems to come from multi-stream and multi-band sorts of things and Saul seems to have a reasonable way of looking at it, at least for one particular toy feature.

0:21:44	SPEAKER_03
 The question is, can we learn from that to change some of the other methods we have since any one of the things that's nice about what he had, I thought was that it, the decision about how strongly trained the different pieces is based on a reasonable criterion with it variables rather than just assuming that you should train every detector with equal.

0:22:13	SPEAKER_03
 With equal strength towards it being this phone or that phone.

0:22:19	SPEAKER_03
 So he's got these.

0:22:26	SPEAKER_03
 The ends between these different features.

0:22:31	SPEAKER_03
 It's a soft end, I guess, but in principle, you want to get a strong concurrence of all the different things that indicate something. And then he oars across the different soft oars across the different multi-band channels.

0:22:46	SPEAKER_03
 And the weight, the target for the training of the AND ended things is something that's kept as a hit variable and is learned with the app.

0:23:01	SPEAKER_03
 Whereas what we were doing is taking the phone target and then just back propagating from that, which means that it could be, for instance, that for a particular point in the data, you don't want to train a particular band, train the detector for a particular band, you want to ignore that band.

0:23:29	SPEAKER_03
 That's a band is a noisy measure. And we're still going to try to train it up in our scheme. We're going to try to train it up to do as well as it can at predicting.

0:23:39	SPEAKER_03
 Maybe that's not the right thing to do.

0:23:42	SPEAKER_02
 So he doesn't have to have truth marks?

0:23:47	SPEAKER_03
 Well, at the talent, he has to know where it's sonarant. But what he's not training up, what he doesn't depend on his truth is, I guess, one way of describing it would be, if a sound is sonarant, is it sonarant in this band?

0:24:05	SPEAKER_03
 It's hard to even answer that, what you really mean is that the whole sound is sonarant. So then it comes down to what extent should you make use of information from particular band towards making your decision?

0:24:19	SPEAKER_03
 I see. And we're making, in a sense, sort of this hard decision that you should use everything with equal strength. And because in the ideal case, we would be going for posterior probabilities, if we had enough data to really get posterior probabilities.

0:24:41	SPEAKER_03
 And if we also had enough data so that it was representative of the test data, then we would, in fact, be doing the right thing to train everything as hard as we can.

0:24:52	SPEAKER_03
 But this is something that's more built up along an idea of robustness from the beginning, so you don't necessarily want to train everything up towards the...

0:25:01	SPEAKER_02
 So where did he get his high level targets about what sonarant and what's not?

0:25:07	SPEAKER_04
 From canonical mappings, from a person, then it's unclear. Using timet? Using timet, right?

0:25:15	SPEAKER_04
 Yeah, and then he does some fine tuning.

0:25:27	SPEAKER_03
 I mean, we have a kind of iterative training because we do this embedded with Ruby. So there is something that's adjusted based on the data.

0:25:39	None
 I think it's seemed like quite the same. Because then whatever that line is, is that wrong?

0:25:47	None
 No, bands. Well, that's quite...

0:25:50	None
 I'm trying to do something. That'll be a little more like it.

0:25:59	SPEAKER_03
 But it's still quite the same because then it's a target based on what you'd say the sound begins in a particular band where he's not labeling per se.

0:26:15	SPEAKER_03
 It might be closer, I guess, if we did a soft target embedded training, we'd have done a few times before we did a forward calculations to get the gammas and train our bells.

0:26:40	SPEAKER_02
 What's next? I can say a little bit about stuff I've been playing with.

0:26:51	SPEAKER_02
 So I wanted to do this experiment to see what happens if we try to improve the performance of the backend recognizer for the Aurora task and see how that affects things.

0:27:06	SPEAKER_02
 I think I sent around last week a plan I had for an experiment, this matrix, where I would take the original system.

0:27:21	SPEAKER_02
 So there's the original system trained on the Mel Kepstrow features and then optimize the HTK system and run that again. So look at the difference there.

0:27:36	SPEAKER_02
 And then do the same thing for the XE-OGI front end.

0:27:41	SPEAKER_04
 Which test was this?

0:27:43	SPEAKER_02
 If I look at it, I'm looking at the Italian right now. So as far as I've gotten, I've been able to go through from beginning to end the full HTK system for the Italian data and got the same results that Stefan had.

0:28:01	SPEAKER_02
 So I started looking at the point where I want to know what should I change in the HTK backend in order to try to improve it.

0:28:13	SPEAKER_02
 One of the first things I thought of was the fact that they use the same number of states for all of the models. And so I went online and I found a pronunciation dictionary for Italian digits and just looked at the number of phones in each one of the digits.

0:28:32	SPEAKER_02
 So the canonical way of setting up an HMM system is that you use three states per phone. And so then the total number of states for a word would just be the number of phones times three.

0:28:46	SPEAKER_02
 And so when I did that for the Italian digits, I got a number of states ranging on a low end from nine to the high end 18.

0:28:55	SPEAKER_02
 Now you have to really add two to that because in HTK there's an initial null and a final null. So when they use models that have 18 states, they're really 16 states. They've got this initial and final null states.

0:29:08	SPEAKER_02
 And so their guess of 18 states seems to be pretty well matched to the two longest words, the Italian digits, the four and five, which according to my sort of off the cuff calculation should have 18 states each. And so they had 16. So that's pretty close.

0:29:27	SPEAKER_02
 But for the most of the words are much shorter. So the majority of them want to have nine states. And so there's sort of twice as long. So my guess. And then if you, I printed out a confusion matrix for the well matched case.

0:29:45	SPEAKER_02
 And it turns out that the longest words are actually the ones that do the best. So my guess about what's happening is that if you assume a fixed the same amount of training data for each of these digits and a fixed length model for all of them.

0:29:59	SPEAKER_02
 But the actual words for some of them are half as long. You really have half as much training data for those models.

0:30:09	SPEAKER_02
 Because if you have a long word and you're training it to 18 states, you've got, you've got the same number of Gaussian's. You've got a train in each case. But for the shorter words, you know, the total number of frames is actually half as many.

0:30:24	SPEAKER_02
 So it could be that, you know, for the short words, there's because you have so many states, you just don't have enough data to train all those Gaussian's. So I'm going to try to create more word specific prototype HMMs to start training from.

0:30:43	SPEAKER_03
 Yeah, I mean, it's not at all uncommon. You do where send long words on short words and long words anyway, just because you're accumulating more evidence.

0:30:54	SPEAKER_02
 Yeah, so I'll, I'll, the next experiment I'm going to try is to just, you know, create models that seem to be more matched to my guess about how long they should be.

0:31:06	SPEAKER_02
 And as part of that, I wanted to see sort of how the, how these models were coming out, you know, when we train up the model for one, which wants to have nine states, you know, what is the, what are the transition probabilities look like in the self loops look like in those models.

0:31:28	SPEAKER_02
 And so I talked to Andreas and he explained to me how you can calculate the expected duration of an HMM just by looking at the transition matrix.

0:31:37	SPEAKER_02
 And so I wrote a little MATLAB script that calculates that. And so I'm going to sort of print those out for each of the words to see what's happening, you know, how these models are training up, you know, the long ones versus the short ones.

0:31:49	SPEAKER_02
 I did, quickly I did the silence model and, and that's coming out with about 1.2 seconds is its average duration. And the silence model is the one that's used at the beginning and the end of each of the string of digits.

0:32:03	SPEAKER_02
 Lots of silence.

0:32:04	SPEAKER_02
 Yeah, yeah. And so the SP model, which is what they put in between digits, I haven't calculated that for that one yet.

0:32:11	SPEAKER_02
 So they basically they're their model for a whole digit string is silence digit, SP digit, SP, blah blah and then silence at the end.

0:32:20	SPEAKER_02
 So are the SPs optional?

0:32:23	SPEAKER_02
 I have to look at that, but I'm not sure that they are. Now the one thing about the SP model is really it only has a single emitting state to it.

0:32:33	SPEAKER_02
 So if it's not optional, you know, it's it's not going to hurt a whole lot. And it's tied to the center state of the silence.

0:32:40	SPEAKER_02
 It's not a little, it doesn't require some training data, it just shares that state.

0:32:45	SPEAKER_02
 So I mean it's pretty good the way that they have it set up, but, so I want to put that a little bit more curious about looking at, you know, how these models have trained and looking at the expected durations models.

0:32:58	SPEAKER_02
 And I want to compare that into the well matched case, the unmatched case and see if you can get an idea just from looking at the durations of these models, you know, what's happening.

0:33:09	SPEAKER_03
 Yeah, I'm going to think, yeah, I'm going to think, yeah, I'm going to think, yeah, it's good to, so I'm not doing anything really tricky.

0:33:17	SPEAKER_03
 Not doing anything really finely. The premise is kind of if you have a good person look at this for two weeks and what you come up with.

0:33:29	SPEAKER_02
 And he nick when I told him about this, he had an interesting point and that was the final models that they ended up training up have, I think probably something on the order of six Gaussian per state.

0:33:42	SPEAKER_02
 So they're fairly, you know, hefty models and he was saying that, well, probably in a real application, you wouldn't have enough compute to handle models that are very big or complicated.

0:33:53	SPEAKER_02
 So in fact, what we may want are simpler models and compare how they perform to that.

0:33:59	SPEAKER_02
 But, you know, it depends on what the actual application is and it's really hard to know what your limits are in terms of how many Gaussian you can have.

0:34:07	SPEAKER_03
 Right. And at the moment, that's not the limitation. So, I mean, what I thought you were going to say, but what I was thinking was where did six come from?

0:34:18	SPEAKER_03
 Probably came from the same place, 18 came from.

0:34:20	SPEAKER_03
 Yeah. So that's another parameter, right?

0:34:24	SPEAKER_03
 Yeah. Maybe, you really want to do one thing.

0:34:27	SPEAKER_02
 If I start reducing the number of states for some of these shorter models, that's going to reduce the total number of Gaussian. So in a sense, it will be a simpler system.

0:34:39	SPEAKER_03
 Yeah. But I think right now, again, the idea is doing just very simple things, how much better can you make it?

0:34:47	SPEAKER_03
 And since there are only simple things, there's nothing that you're going to do that is going to blow up the amount of computation. So if you found that nine was better than six, that would be okay.

0:34:58	SPEAKER_02
 I really wasn't even going to play with that part of the system yet. I was just going to change the work with the models.

0:35:05	SPEAKER_02
 Yeah. Just look at the models and see what happened.

0:35:08	SPEAKER_02
 Yeah.

0:35:09	SPEAKER_02
 So.

0:35:13	SPEAKER_03
 Cool. Okay. So what's I guess your plan for you guys playing for the next next week is just continue on these same things you've been talking about.

0:35:27	SPEAKER_05
 Yeah.

0:35:28	SPEAKER_05
 I guess you can try to have some kind of new baseline for next week, perhaps with all these minor things.

0:35:37	SPEAKER_05
 And then you modify it, and then do other things play with the spectrospection and retry to a MFG.

0:35:49	SPEAKER_03
 Yeah. Yeah. We have a big list.

0:35:53	SPEAKER_03
 You have a big list of things to do.

0:35:58	SPEAKER_03
 So that's good. I think that after all of this confusion settles down. At some point a little later next year, there will be some sort of standard.

0:36:11	SPEAKER_03
 We'll get out there and hopefully a little have some effect from something that has been done by a group of people.

0:36:19	SPEAKER_03
 But even if it doesn't, there's going to be standards after that.

0:36:25	SPEAKER_02
 Does anybody know how to run MATLAB sort of in batch mode like you send it to commands to run it? Is it possible to do that?

0:36:37	SPEAKER_04
 I think Mike tried it.

0:36:39	SPEAKER_04
 Yeah.

0:36:40	SPEAKER_04
 And he said it was impossible. So he went to active.

0:36:43	SPEAKER_04
 I thought it was the Unix clone of MATLAB.

0:36:46	SPEAKER_04
 Which you can dodge.

0:36:47	SPEAKER_02
 Okay. Great. Thank you.

0:36:49	SPEAKER_02
 Yeah.

0:36:50	SPEAKER_02
 I was going crazy trying to do that.

0:36:53	SPEAKER_05
 Yeah. What is that?

0:36:56	SPEAKER_04
 It's a free software.

0:36:58	SPEAKER_04
 I think we have it here running somewhere.

0:37:03	SPEAKER_05
 Great.

0:37:04	SPEAKER_05
 And it does the same syntax.

0:37:06	SPEAKER_05
 I think it's a little behind it.

0:37:10	SPEAKER_04
 It's a little behind in that MATLAB went to these like, like, half-sales and you can implement object-oriented type things.

0:37:20	SPEAKER_04
 Active doesn't do that yet.

0:37:23	SPEAKER_04
 I think you've, like, active MATLAB or point something.

0:37:27	SPEAKER_02
 If it'll do a lot of the basic matrix and vector stuff.

0:37:31	SPEAKER_02
 That's perfect.

0:37:33	SPEAKER_02
 Great.

0:37:37	SPEAKER_03
 Okay. I guess we're done.

0:37:40	SPEAKER_03
 I don't find it.

