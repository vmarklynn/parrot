0:00:00	SPEAKER_05
 Okay, now we're on it. It seems to be working.

0:00:03	SPEAKER_04
 So it seems like it's been sitting for a long time.

0:00:08	SPEAKER_05
 I don't know what it is, but all I know is that it seems like every time I am up here after a meeting and I start it, it works fine.

0:00:18	SPEAKER_05
 And if I'm up here and I start it and we're all sitting here waiting to have a meeting, it gives me that error message and I have not yet sat down with being able to get that error message at a point where I can sit down and find out where it's occurring in the code.

0:00:29	SPEAKER_05
 Yeah, we will.

0:00:30	SPEAKER_05
 One of these days.

0:00:31	SPEAKER_05
 Was it on pause or something?

0:00:33	SPEAKER_03
 No.

0:00:34	SPEAKER_03
 So the new procedural change that Scott suggested, I think is a good idea, is that we do the digit recording at the end.

0:00:45	SPEAKER_03
 And that way, if we're recording somebody else's meeting and the number of participants have to run off to some other meeting who don't have the time, then they can run off.

0:00:55	SPEAKER_03
 Then we'll get somewhat fewer sets of digits, but I think that way we'll cut into people's time.

0:01:02	SPEAKER_03
 There's someone's on strict time.

0:01:04	SPEAKER_03
 Less.

0:01:06	SPEAKER_03
 So I think we should start doing that.

0:01:11	SPEAKER_03
 So let's see, we were having discussion the other day.

0:01:14	SPEAKER_03
 I mean, we should bring that up.

0:01:16	SPEAKER_03
 The nature of the data that we're collecting.

0:01:20	SPEAKER_03
 That we should have a fair amount of data that is collected for the same meeting so that we can.

0:01:30	SPEAKER_03
 I know.

0:01:31	SPEAKER_03
 What was on the point again about that?

0:01:34	None
 Well, okay.

0:01:35	SPEAKER_00
 I'll back up.

0:01:36	SPEAKER_00
 Yeah.

0:01:37	SPEAKER_00
 At the previous, at last week's meeting, this meeting, I was brave.

0:01:42	None
 I didn't have about wanting to get more data.

0:01:45	SPEAKER_00
 I talked about this with Jane and Adam, and was thinking of this mostly just so that we could do research on this data since we'll have a new student, does want to work with us.

0:01:59	SPEAKER_00
 That was at the last meeting.

0:02:00	SPEAKER_00
 Great.

0:02:01	SPEAKER_00
 And he's already funded part time, so we'll be paying him only for half of the normal part time.

0:02:06	SPEAKER_05
 What did he?

0:02:07	SPEAKER_05
 Yeah.

0:02:08	SPEAKER_05
 And what's he interested in specifically?

0:02:09	SPEAKER_00
 He comes from a signal processing background, but I like to unlock because he's very interested in higher level things like language and disfluencies and all kinds of, maybe, positive.

0:02:20	SPEAKER_00
 So he's just getting his feedback in that.

0:02:22	SPEAKER_00
 Anyway, I thought, okay, maybe we should have enough data so that he starts, he'd be starting in January next semester, that we'd have enough data to work with.

0:02:31	SPEAKER_00
 But Jane and Adam brought up a lot of good points that just posting a note to Berkeley

0:02:38	None
 people that have them come down here has some problems in that. We need to make sure that the speakers are who you want and that the meeting type is what you want and so forth.

0:02:47	SPEAKER_00
 So I thought about that and I think it's still possible.

0:02:51	SPEAKER_00
 But I'd rather try to get more regular meetings of types that we know about in here than sort of a mishmash of a bunch of one time.

0:03:01	SPEAKER_00
 Yeah, just because it would be very hard to process the data in all senses, both to get the figure out what type of meeting it is and to do any kind of higher level work on it like while I was talking to Morgan about things like summarization or what's this meeting about.

0:03:17	SPEAKER_00
 I mean, it's very different if you have a group that's just giving a report on what they did that week versus coming to a decision and so forth.

0:03:25	SPEAKER_00
 So then I was talking to Morgan about some new proposed work in this area sort of a separate issue from one student would be working on where I was thinking of doing some kind of summarization of meetings or trying to find cues in both the utterances and in the utterance patterns like in numbers of overlaps and amount of speech sort of raw cues from the interaction that can be measured from the signals and from the different microphones that point to

0:03:58	None
 sort of hotspots in the meeting or things where stuff is going on that might be important for someone who didn't attend to listen to.

0:04:05	SPEAKER_00
 And in that regard, I thought we definitely will need, it'd be nice for us to have a bunch of data from a few different domains or a few different kinds of meetings.

0:04:17	SPEAKER_00
 So this meeting is one of them, although I'm not sure I could participate if I would feel very strange being part of a meeting that you were then analyzing later for things like summarization.

0:04:28	SPEAKER_00
 And then there are some others that Morgan mentioned, like the front end meeting, maybe a networking group meeting.

0:04:35	SPEAKER_05
 We're hoping that they'll let us start recording regularly.

0:04:37	SPEAKER_00
 So if that were the case, then I think we'd have enough.

0:04:41	SPEAKER_00
 But basically for anything where you're trying to get a summarization or some kind of meeting out of the meeting, it would be too hard to have 50 different kinds of meetings where we didn't really have a good grasp of what does it mean to summarize, but rather we should have different meetings by the same group, but hopefully that have different summaries.

0:05:04	SPEAKER_00
 And then we need a couple of, we don't want to just have one group because that might be very specific to that particular group.

0:05:11	None
 But three more times.

0:05:12	SPEAKER_05
 Here we have a overlap between this meeting and the morning meeting.

0:05:17	SPEAKER_00
 See, that I've never listened to the data for the front end meeting.

0:05:21	SPEAKER_05
 We've only had three.

0:05:22	SPEAKER_00
 But maybe that's enough.

0:05:24	SPEAKER_00
 So in general, I was thinking more data, but also data where we hold some parameters, constant or fairly similar like a meeting about people doing a certain kind of work where at least have to participate in each time or the same.

0:05:40	SPEAKER_03
 Now let me just give the other side to that because I don't disagree with that.

0:05:45	SPEAKER_03
 But I think there is a complimentary piece to it too.

0:05:49	SPEAKER_03
 For other kinds of research, particularly the acoustic oriented research, I actually feel the opposite need.

0:05:56	SPEAKER_03
 I'd like to have lots of different people.

0:05:58	SPEAKER_03
 As many people here and talking about the kind of thing that you're just talking about, it would have too few people from my point of view.

0:06:06	SPEAKER_03
 I'd like to have many different speakers.

0:06:08	SPEAKER_03
 So I think I would also very much like us to have a fair amount of really random scattered meetings or somebody coming down from campus.

0:06:17	SPEAKER_03
 And I mean, sure, if we can get more from them fine, but if we only get one or two from each group, it still could be useful acoustically just because we have close and distant microphones with different people.

0:06:28	SPEAKER_01
 Okay, can I say about that?

0:06:30	SPEAKER_01
 The issues that I think Adam and I raised were more a matter of advertising so that you get more native speakers.

0:06:36	SPEAKER_01
 Because I think if you just say, and in particular, my suggestion was to advertise to linguistics grad students because there you have people who would have proficiency enough in English that it would be useful for purposes.

0:06:49	SPEAKER_01
 But I think I've gathered data from undergrad students at an on campus.

0:06:54	SPEAKER_01
 You just post randomly to undergrad students.

0:06:56	SPEAKER_01
 I think you'd get such a mix back.

0:06:57	SPEAKER_01
 It would be hard to know how much conversation you'd have at all.

0:07:00	SPEAKER_01
 Well, you want- The English you'd have with the language models would be really hard to build because it would not really be- it would be an inner language with that.

0:07:07	SPEAKER_03
 Well, okay.

0:07:08	SPEAKER_03
 First place, I don't think we just want to have random people come down and talk to one another.

0:07:13	SPEAKER_03
 There should be a meeting that has some goal and point because I think that's what we're

0:07:17	SPEAKER_00
 investigating. It needs to be a pre-existing meeting.

0:07:19	SPEAKER_00
 Yeah.

0:07:20	SPEAKER_00
 Right.

0:07:21	SPEAKER_00
 That would always happen.

0:07:22	SPEAKER_03
 So I was thinking more in terms of talking to professors and senior doctoral students who are leading projects and offering to them that they have the whole their meeting down here.

0:07:37	SPEAKER_03
 That's the first point.

0:07:38	SPEAKER_03
 One point is I think that for some time now going back through birth, I think that we have had speakers that we've worked with who had non-native access.

0:07:49	SPEAKER_01
 Oh, I'm not saying access.

0:07:50	SPEAKER_01
 I think that- The access is not the problem.

0:07:52	SPEAKER_01
 Okay.

0:07:53	SPEAKER_01
 No, it's more a matter of proficiency, just simply fluency.

0:07:56	SPEAKER_01
 I mean, ideal for people on campus who I think sometimes people undergraduates in computer science have language skills that make, you know, they're balancing the writing skills.

0:08:09	SPEAKER_01
 Oh, you're not talking about the poor language at all.

0:08:13	SPEAKER_01
 Yeah, I just think- I just think- But, you know, it's like when you get into the graduate level, no problem.

0:08:17	SPEAKER_01
 I mean, I'm not saying access.

0:08:18	SPEAKER_01
 Yeah, that's what we're saying.

0:08:19	SPEAKER_01
 It's the same.

0:08:20	SPEAKER_03
 It's the same.

0:08:21	SPEAKER_03
 It's the same.

0:08:22	SPEAKER_03
 So that the habits are already burnt in.

0:08:24	SPEAKER_05
 Well, I think that- I think the only thing that we should say in the advertisement is that the meeting should be held in English.

0:08:32	SPEAKER_05
 Yeah.

0:08:33	SPEAKER_05
 And I think if it's a pre-existing meeting and it's held in English, I think it's probably okay if a few of the people don't have particularly good English skills.

0:08:43	SPEAKER_05
 Can I-

0:08:44	SPEAKER_01
 Can I say the other aspect of this from my perspective, which is that there's this- This issue you have a corpus out there it should be used for- for multiple things because it's so expensive to put together.

0:08:54	SPEAKER_01
 Right.

0:08:55	SPEAKER_01
 And if people want to approach- So I know- you know, this is the idea of computational linguistics and probabilistic grammars and all may not be the folks in this group.

0:09:06	SPEAKER_01
 But the idea of language models, which are fun, you know, generally speaking, you know, in terms of like the amount of benefit per dollar spent on our invested in preparing the data, if you have a choice between people who are more proficient in- more fluent, more close to being academic English, then it would seem to be a good thing.

0:09:31	SPEAKER_03
 I guess- Maybe.

0:09:33	SPEAKER_01
 Because otherwise you don't have the ability to have- so if you have a bunch of media like- that's the worst possible case.

0:09:39	SPEAKER_01
 If you have people who are using English as an interlanguage, because they don't- they can't speak in their native languages, but their interlanguage isn't really a match to any existing language model.

0:09:52	SPEAKER_01
 This is the worst case scenario.

0:09:54	SPEAKER_03
 Well, that's pretty much what you're going to have in the networking group.

0:09:57	SPEAKER_03
 Right?

0:09:58	SPEAKER_03
 Because the network group is almost entirely Germans and Spaniards.

0:10:02	SPEAKER_01
 But the thing is, I think that these people are of high enough level in their language proficiency.

0:10:08	SPEAKER_01
 And I'm not objecting to accents.

0:10:09	SPEAKER_01
 I'm just thinking that we have to think at a higher level view, could we have a language model, a grammar, a grammar basically, that would be a possibility?

0:10:21	SPEAKER_01
 So if you wanted to bring in a model like Dandjer asks you to model and do some top-down stuff to help up the bottom of the merge of the things or whatever, it seems like I don't see that there's an argument.

0:10:33	SPEAKER_01
 What I think is that why not have the corpus since it's so expensive to put together useful for the widest range of central corp things that people generally use corp-brough for and which are used in computational linguistics.

0:10:47	SPEAKER_01
 That's my point.

0:10:48	SPEAKER_01
 Okay.

0:10:49	SPEAKER_01
 So you include both top-down and bottom-up.

0:10:51	SPEAKER_01
 Okay.

0:10:52	SPEAKER_03
 Well, let's see what we can get.

0:10:55	SPEAKER_03
 I mean, I think that if we're aiming at groups of graduate students and professors, if they were talking about things together, and it's from the Berkeley campus, probably most of it.

0:11:05	SPEAKER_03
 Exactly.

0:11:06	SPEAKER_01
 And my point in my note to Liz was, I think, under graduate, are any iffy pocket-related for me to agree with that?

0:11:12	SPEAKER_00
 I mean, for this person.

0:11:13	SPEAKER_05
 Well, not to mention the fact that I would be hesitant, certainly, to take anyone under 18, probably even in anyone under 21.

0:11:22	SPEAKER_05
 So, what's that?

0:11:23	SPEAKER_05
 What's that?

0:11:24	SPEAKER_05
 Well, the 18 is because of the consent form.

0:11:27	SPEAKER_05
 We have to get to find their parent to sign for them.

0:11:30	SPEAKER_00
 That's true.

0:11:31	SPEAKER_00
 Yeah.

0:11:32	SPEAKER_00
 I have a question.

0:11:33	SPEAKER_00
 Well, Morgan, you were mentioning that Murray may not use the equipment from IBM if they found something else because...

0:11:41	SPEAKER_03
 Yeah, they're assessing whether they should do that or you do something else, hopefully, with the next few weeks.

0:11:48	SPEAKER_00
 Because I mean, one remote possibility is that if we inherited that equipment, if she weren't using it, could we set up a room in the linguistics department?

0:11:57	SPEAKER_00
 And maybe a lot more or in psych, or wherever, in another building where we could record people there.

0:12:08	SPEAKER_00
 I think we'd have a better chance with it.

0:12:09	SPEAKER_05
 I think we'd need a real motivated partner to do that.

0:12:13	SPEAKER_00
 Right.

0:12:14	SPEAKER_00
 We need to find someone on campus who is interested in this.

0:12:16	SPEAKER_00
 If there were such a...

0:12:17	SPEAKER_00
 I mean, it's a remote possibility, then one of us could go out there and record the media or something, rather than bring all of them down here.

0:12:25	SPEAKER_00
 So this is the...

0:12:26	SPEAKER_00
 Well, the other thing...

0:12:27	SPEAKER_00
 The end of not using.

0:12:28	SPEAKER_03
 Yeah, and the other thing that I was hoping to do in the first place was to turn it into some kind of portable thing.

0:12:33	SPEAKER_03
 Right.

0:12:34	SPEAKER_03
 So you could wheel it around.

0:12:36	None
 But...

0:12:37	SPEAKER_05
 I know that space is really scarce on at least NCS, to actually find a room that we could use regularly might be very difficult.

0:12:46	SPEAKER_00
 You may not need a separate room.

0:12:47	SPEAKER_00
 That's true.

0:12:48	SPEAKER_00
 You know, if they have a meeting room and they can guarantee that the equipment will be safe and so forth, and if one of us is up there to record the meeting once a week,

0:12:55	SPEAKER_03
 or something. Yeah.

0:12:57	SPEAKER_03
 Well, maybe Janu, that is pretty good for now with the other person.

0:12:59	SPEAKER_00
 Yeah.

0:13:00	SPEAKER_00
 I think it's not out of the question.

0:13:01	SPEAKER_05
 Yeah.

0:13:02	SPEAKER_05
 Yeah, I think it would be interesting because then we could regularly get another meeting, another type of meeting.

0:13:07	SPEAKER_05
 Right.

0:13:08	SPEAKER_02
 Right.

0:13:09	SPEAKER_02
 I think you need another portable team, another portable equipment to do...

0:13:15	SPEAKER_02
 More easier the recording process out from next thing.

0:13:21	SPEAKER_02
 Right.

0:13:22	SPEAKER_02
 And probably I don't know.

0:13:25	SPEAKER_02
 If you want to record a seminar or a class in the university, it could be very difficult to put a lot of headphones.

0:13:39	SPEAKER_02
 Yeah, but...

0:13:40	SPEAKER_02
 If you want to record a recording with this kind of...

0:13:45	SPEAKER_05
 If we want to just record with the tabletop microphones, that's easy.

0:13:49	SPEAKER_05
 Right.

0:13:50	SPEAKER_05
 That's very easy, but that's not the corpus that we're collecting.

0:13:53	SPEAKER_03
 Actually, that's an interesting point that came up in our discussions.

0:13:56	SPEAKER_03
 Maybe we're through a meeting.

0:13:58	SPEAKER_03
 We realized that when we're talking about this, that, okay, there's these different things we want to do with it.

0:14:03	SPEAKER_03
 So it's true that we want to be selective in some ways, the way that you're speaking about with not having an interlingua and these other issues.

0:14:13	SPEAKER_03
 But on the other hand, it's not necessarily true that we need all of the corpus to satisfy all of it.

0:14:19	SPEAKER_03
 So, as for the example, that we want to have a fair amount that's done with a small...

0:14:23	SPEAKER_03
 We recorded with a small...

0:14:25	SPEAKER_03
 Tight number of types of meetings.

0:14:27	SPEAKER_03
 But we can also have another part that's just one or two meetings of each of a range of them.

0:14:32	SPEAKER_03
 That's okay, too.

0:14:34	SPEAKER_03
 We realized in discussion that the other thing is, what about this business of distant and close microphones?

0:14:41	SPEAKER_03
 I mean, we really want to have a substantial amount recorded this way.

0:14:44	SPEAKER_03
 That's what we did it.

0:14:46	SPEAKER_03
 But what about for these issues of summarization, a lot of these higher level things, you don't really need the distant microphone.

0:14:53	SPEAKER_00
 Right.

0:14:54	SPEAKER_00
 I mean, I don't really need the close microphone.

0:14:56	SPEAKER_00
 You actually don't really need any.

0:14:58	SPEAKER_00
 You just need some microphone somewhere.

0:15:00	SPEAKER_00
 You can use a found data.

0:15:02	SPEAKER_00
 You can.

0:15:03	SPEAKER_00
 I mean, I can use a found data.

0:15:05	SPEAKER_00
 But I think that any data that we spend a lot of effort to collect, each person who's interested, we have a bunch of different slants and perspectives on what it's useful for, they need to be taking charge and making sure they're getting enough of the kind of data that they want.

0:15:23	SPEAKER_00
 Right.

0:15:24	SPEAKER_00
 And so, in my case, I think there's enough data for some kinds of projects and not enough of any other projects.

0:15:30	SPEAKER_00
 So I'm looking and thinking, well, I'd be glad to walk over and record people and go forward to help my interest.

0:15:36	SPEAKER_00
 And other people need to do that for themselves.

0:15:39	SPEAKER_00
 Right.

0:15:40	SPEAKER_00
 So that discusses that we can find some optimal.

0:15:42	SPEAKER_03
 But I think I'm raising that because I think it's relevant exactly for this idea up there that if you think about, well, gee, we have this really complicated setup to do.

0:15:48	SPEAKER_03
 Well, maybe you don't.

0:15:50	SPEAKER_03
 Maybe if really all you want is to have a recording that's good enough to get a transcription from later, you just need to grab a tape recorder and go up and make a recording.

0:16:01	SPEAKER_03
 I mean, we could have a fairly, we could just go to that machine.

0:16:04	SPEAKER_00
 Well, I agree with Jane, though on the other hand, that that may be true.

0:16:07	SPEAKER_00
 You may say, for instance, summarization or something that sounds very language oriented.

0:16:13	SPEAKER_00
 You may say, well, oh yeah, you just do that from transcripts of a radio show.

0:16:16	SPEAKER_00
 I mean, you don't even need to miss speech.

0:16:18	SPEAKER_00
 But what I was thinking is long-term, what would be needed to be able to pick up on, I suppose you just had a distant microphone there and you really wanted to be able to determine this.

0:16:30	SPEAKER_00
 There's lots of cues you're not going to have.

0:16:32	SPEAKER_00
 So I do think that long-term, you should always try to satisfy the greatest number of interest and have this parallel information, which is really what makes this special powerful.

0:16:42	SPEAKER_00
 Otherwise, you know, lots of other sites can propose.

0:16:45	SPEAKER_03
 I agree.

0:16:46	SPEAKER_03
 So.

0:16:47	SPEAKER_03
 But I think that the, we can't really underestimate the difficulty.

0:16:52	SPEAKER_03
 It shouldn't really underestimate the difficulty of getting a set of like this up.

0:16:57	SPEAKER_03
 And so it took quite a while to get that together and to say, oh, we'll just do it up there.

0:17:01	SPEAKER_03
 If you're talking about something simple, we throw away a lot of these dimensions, then you can do that right away.

0:17:06	SPEAKER_03
 I'm talking about something that has all of these different facets that we have here.

0:17:10	SPEAKER_03
 It won't happen quickly.

0:17:11	SPEAKER_03
 It won't be easy.

0:17:12	SPEAKER_03
 And there's all sorts of issues about keeping the equipment safe or else, hauling it around and all sorts of things.

0:17:17	SPEAKER_00
 So then we'll try to bring people here.

0:17:19	SPEAKER_03
 I think your first priority should be to try to get people to come here.

0:17:23	SPEAKER_03
 We're set up for it.

0:17:24	SPEAKER_03
 The room is really underused.

0:17:26	SPEAKER_03
 I thought the free lunch idea was a great idea.

0:17:30	SPEAKER_05
 Yeah, I felt so too.

0:17:31	SPEAKER_00
 Free lunch is good.

0:17:32	SPEAKER_00
 I think we can get people to come here, but the issue is you definitely want to make sure that the kind of group that you're getting is the right groups that you don't waste a lot of your time in the overhead of bringing people down.

0:17:42	SPEAKER_04
 No crunchy food.

0:17:43	SPEAKER_00
 Well, I was thinking lunch afterwards, right?

0:17:46	SPEAKER_00
 And they have to do their digits.

0:17:47	SPEAKER_03
 Yeah, they have to do their digits or they don't get their food.

0:17:52	SPEAKER_05
 I spoke with some people up at Hoss Business School who volunteered.

0:17:55	SPEAKER_05
 Should I pursue that?

0:17:56	SPEAKER_00
 Oh, definitely.

0:17:57	SPEAKER_05
 Yeah.

0:17:58	SPEAKER_05
 So they originally, they've decided not to go into speech.

0:18:02	SPEAKER_05
 So I'm not sure whether they'll still be so willing to volunteer, but all of a sudden we're about the free lunch.

0:18:06	SPEAKER_05
 I'll tell them about the free lunch.

0:18:07	SPEAKER_05
 And they'll say there's no such thing.

0:18:09	SPEAKER_00
 I'd love to get people that are not linguists or engineers.

0:18:12	SPEAKER_00
 Right.

0:18:13	SPEAKER_00
 They need a wider sampling.

0:18:20	SPEAKER_05
 The problem with engineers is be.

0:18:28	SPEAKER_03
 They make funny sounds.

0:18:29	SPEAKER_03
 The other thing is that we're talking about is giving them a burn and extra CD run and give them.

0:18:37	SPEAKER_00
 So if they want an audio record up there, I thought he meant giving them a music CD.

0:18:42	SPEAKER_00
 I guess it depends on what audience you're talking to.

0:18:47	SPEAKER_00
 I personally would not want to see my meeting.

0:18:51	SPEAKER_00
 But maybe.

0:18:52	SPEAKER_03
 If you're having some planning meeting of some sort, it would just be fun if nothing else.

0:18:58	SPEAKER_03
 But it also I think builds up towards the goal.

0:19:02	SPEAKER_03
 We're saying, look, you're going to get this.

0:19:03	SPEAKER_03
 Isn't that neat?

0:19:04	SPEAKER_03
 Then you're going to go home with it.

0:19:05	SPEAKER_03
 It's probably going to be pretty useless to do.

0:19:08	SPEAKER_03
 But you'll appreciate where it's useful and where it's useless.

0:19:11	SPEAKER_03
 And then we're going to move this technology so it'll become useful.

0:19:14	SPEAKER_00
 I think that's a great idea, actually.

0:19:16	SPEAKER_04
 What if you could tell in the award and send it to the transcripts when they come back?

0:19:20	SPEAKER_04
 Oh, yeah.

0:19:21	SPEAKER_05
 Really anyone can have the transcripts.

0:19:23	SPEAKER_05
 So I have to add a good point to that.

0:19:25	SPEAKER_01
 So you can see what's it concerned about doing, given the CD immediately, because of these issues of this kind of stuff.

0:19:33	SPEAKER_01
 Good point.

0:19:35	SPEAKER_01
 That's a very good point.

0:19:36	SPEAKER_01
 So we can.

0:19:37	SPEAKER_01
 So we can.

0:19:38	SPEAKER_01
 Right.

0:19:42	SPEAKER_00
 That's right.

0:19:43	SPEAKER_00
 That's the same thing that we just reviewed publicly, right?

0:19:45	SPEAKER_00
 Right.

0:19:46	SPEAKER_01
 Otherwise, you're not allowed to go or like you're not allowed to go up or anyone.

0:19:48	SPEAKER_01
 So after the transcripts screen phase.

0:19:50	SPEAKER_01
 Yeah, that's true.

0:19:51	SPEAKER_01
 Otherwise we need to do lawyer's day.

0:19:52	SPEAKER_01
 Yeah, it's right.

0:19:53	SPEAKER_01
 You say, yeah, I got the CD and your honor, I.

0:19:59	SPEAKER_00
 That's a good point.

0:20:02	SPEAKER_03
 Yeah, so let's start with Haaz.

0:20:04	SPEAKER_00
 Sorry, I have to leave.

0:20:05	SPEAKER_00
 I will be your full time.

0:20:07	SPEAKER_05
 Okay, see you.

0:20:08	None
 Okay.

0:20:09	SPEAKER_06
 Yeah.

0:20:10	None
 Sorry.

0:20:11	SPEAKER_06
 See you.

0:20:12	SPEAKER_06
 Okay.

0:20:13	SPEAKER_06
 So, let's see.

0:20:14	SPEAKER_03
 So that was that topic.

0:20:18	SPEAKER_03
 And then I guess another topic would be where are we in the whole disc resources question for?

0:20:30	SPEAKER_05
 We are slowly, slowly getting to the point where we have enough room to record meetings.

0:20:36	SPEAKER_05
 So I did a bunch of archiving and still doing a bunch of archiving.

0:20:40	SPEAKER_05
 I am in the midst of doing the P files from broadcast news and it took 11 hours to copy it and it will take another 11 to do the clone.

0:20:51	SPEAKER_05
 Well, it's Abbott.

0:20:53	SPEAKER_05
 It's Abbott, so it's just, but it's a lot of data.

0:20:56	SPEAKER_03
 It's copying from one place to another place to another place to another place.

0:20:58	SPEAKER_03
 Tape.

0:20:59	SPEAKER_03
 Oh, I did not want to tape.

0:21:01	SPEAKER_05
 So I'm archiving it and then I'm going to delete the files.

0:21:03	SPEAKER_05
 So that will give us 10 gigabytes of free space.

0:21:06	SPEAKER_05
 We are archiving for a long time.

0:21:09	SPEAKER_05
 And so that will be done in about two hours and so at that point we will be able to record five more meetings.

0:21:17	SPEAKER_05
 So.

0:21:18	SPEAKER_01
 One thing the good news about that is that once it's archived it's pretty quick to get back.

0:21:22	SPEAKER_01
 I mean, the other options fast, but the instructions are really slow.

0:21:25	SPEAKER_05
 Well, especially because I'm generating a clone also.

0:21:27	SPEAKER_05
 Yeah.

0:21:28	SPEAKER_05
 Okay.

0:21:29	SPEAKER_05
 And it takes a while.

0:21:30	SPEAKER_05
 Generating a clone?

0:21:31	SPEAKER_05
 Two copies.

0:21:32	SPEAKER_05
 Right.

0:21:33	SPEAKER_01
 Oh.

0:21:34	SPEAKER_01
 Now, what about is the plan to, so stuff will be saved.

0:21:39	SPEAKER_01
 It's just that you're relocating it.

0:21:40	SPEAKER_05
 I mean, so we're going to get more disk space or did I know that these are the P files from broadcast news, which are regeneratable, regeneratable, if we really need to, but we have a lot of them.

0:21:52	SPEAKER_05
 And for the full 140 hour sets.

0:21:56	SPEAKER_05
 And so they were two gigabytes per file and we had six of them or something.

0:22:02	SPEAKER_03
 We are getting my space.

0:22:03	SPEAKER_03
 We are getting another disk rack and 436 gigabyte disks.

0:22:09	SPEAKER_03
 So, but that's not going to happen in some time.

0:22:13	SPEAKER_03
 Or maybe six.

0:22:14	SPEAKER_05
 Maybe six?

0:22:15	SPEAKER_05
 The sun takes more disks than the Andataco one did.

0:22:19	SPEAKER_05
 The sun rack takes.

0:22:23	SPEAKER_05
 One took four and one took six or maybe it was eight and twelve.

0:22:26	SPEAKER_05
 Whatever it was, it was, you know, 50 percent more.

0:22:28	SPEAKER_05
 Was there a difference in price?

0:22:30	SPEAKER_05
 Well, what happened is that we bought all our racks and disks from Andataco for years according to Dave.

0:22:35	SPEAKER_05
 And Andataco got bought by another company and doubled their prices.

0:22:39	SPEAKER_05
 And so we're looking into other vendors.

0:22:42	SPEAKER_05
 By we, of course, I mean Dave.

0:22:44	SPEAKER_04
 So, I've been looking at the Aurora data.

0:22:50	SPEAKER_04
 And first, first look at it, there were basically three directories on there that could be moved.

0:22:59	SPEAKER_04
 One was called Aurora.

0:23:00	SPEAKER_04
 One was Spanish, which was Carmen Spanish stuff.

0:23:03	SPEAKER_04
 And the other one was Spine.

0:23:06	SPEAKER_04
 And so I wrote to Dan and he was very concerned that the Spine stuff was moving to a non-backed up disk.

0:23:15	SPEAKER_04
 So I realized that what probably not all of that should be moved just the CD-ROM type data, the static data.

0:23:24	SPEAKER_04
 So I moved that and then I asked him to check out and see if it was okay for I actually deleted the old stuff, but I haven't heard back.

0:23:32	SPEAKER_04
 I told him he could delete it if he wanted.

0:23:33	SPEAKER_04
 I haven't checked today to see if he's deleted it or not.

0:23:36	SPEAKER_04
 And then Carmen's stuff, I realized that when I had copied all of her stuff to XA, I had copied stuff there that was dynamic data.

0:23:44	SPEAKER_04
 And so I had to redo that one and just copy over the static data.

0:23:48	SPEAKER_04
 And so I need to get with her now and delete the old stuff off of the disk.

0:23:51	SPEAKER_04
 And then I looked, haven't done any of the Aurora stuff.

0:23:53	SPEAKER_04
 I have to meet with Stefan to do that.

0:23:57	SPEAKER_03
 So but you're figuring you can record in other five meetings or something with the space that you're clearing up from broadcast news.

0:24:04	SPEAKER_03
 But we have some other disks, some of which you're using for Aurora, but do we have some other?

0:24:11	SPEAKER_03
 Yep.

0:24:12	SPEAKER_05
 So we have space on the current disk right now where Meeting Recorder is.

0:24:17	SPEAKER_05
 And that's probably enough for about four meetings.

0:24:19	SPEAKER_05
 Yeah.

0:24:20	SPEAKER_05
 Is that the one that has, is that DC?

0:24:21	SPEAKER_05
 Yep.

0:24:22	SPEAKER_05
 Okay.

0:24:23	SPEAKER_05
 No, no.

0:24:24	SPEAKER_05
 Well, to wherever the Meeting Recorder currently is, I think it's DI.

0:24:26	SPEAKER_05
 Okay, but I don't remember.

0:24:28	SPEAKER_04
 I'm moving from Aurora's on the DC disk that we, I think it's DC.

0:24:31	SPEAKER_05
 It's whatever that one is.

0:24:32	SPEAKER_05
 Okay.

0:24:33	SPEAKER_05
 I just don't remember it.

0:24:34	SPEAKER_05
 It might be DC.

0:24:35	SPEAKER_05
 And that has enough room for about former meetings right now.

0:24:37	SPEAKER_05
 I mean, we were at 100% and then we dropped down to 86 for reasons I don't understand.

0:24:43	SPEAKER_05
 Someone deleted something somewhere.

0:24:44	SPEAKER_05
 And so we have some room again.

0:24:46	SPEAKER_05
 And then with the broadcast news, that's five or six more meetings.

0:24:49	SPEAKER_05
 So you know, we have a couple of weeks.

0:24:52	SPEAKER_05
 So I think we're okay until we get the new disk.

0:24:55	SPEAKER_04
 So should, one question I had for you was, we need, we probably should move the Aurora and all that other stuff off of the Meeting Recorder disk.

0:25:08	SPEAKER_04
 Is there another backed up disk that you know of?

0:25:11	SPEAKER_05
 We should put it onto the broadcast news one.

0:25:13	SPEAKER_05
 That's probably the best thing to do.

0:25:15	SPEAKER_05
 And that way we can solidate Meeting Recorder onto one disk rather than spreading the mic.

0:25:18	SPEAKER_04
 Do you know what happened to know what disk guy is on?

0:25:20	SPEAKER_05
 Nope.

0:25:21	SPEAKER_05
 I mean, I can tell you I just don't know off the top of my head.

0:25:23	SPEAKER_05
 I'll find out for that.

0:25:24	SPEAKER_05
 We could just do that at the end of today once the archive is complete and I verified it.

0:25:29	SPEAKER_05
 Okay.

0:25:30	SPEAKER_05
 Is that what gives us plenty of disk?

0:25:33	SPEAKER_03
 Okay.

0:25:34	SPEAKER_03
 So then I guess the last thing I had in my agenda was to just hear her not paid on what Jose has been doing.

0:25:43	SPEAKER_03
 Okay.

0:25:44	SPEAKER_02
 I have the result of my work during the last days.

0:25:49	SPEAKER_02
 Thank you for the information because I read the last days.

0:25:54	SPEAKER_02
 I work in my house in the database and thinking within a different thing about the Meeting Recorder project.

0:26:03	SPEAKER_02
 And I have some ideas.

0:26:05	SPEAKER_02
 This information is very useful because you have the distribution.

0:26:10	SPEAKER_02
 For me, it's interesting because here is the demonstration of the overlap problem.

0:26:19	SPEAKER_02
 It's a real problem, a frequently problem because you have overlapping sums all the time.

0:26:29	SPEAKER_02
 By the moment I have the IDETA mark all the overlap zone in the Meeting Recorder with a set mark.

0:26:39	SPEAKER_05
 Oh, you did that by hand.

0:26:41	SPEAKER_05
 That's a jet.

0:26:43	SPEAKER_02
 Can I see that?

0:26:44	SPEAKER_02
 Yeah, but I can't because why?

0:26:48	SPEAKER_02
 My idea is to work.

0:26:50	SPEAKER_02
 I don't know if it will be possible because I have enough time to work on this as you know.

0:27:02	SPEAKER_02
 But my idea is very interesting to work in the line of automatic segment.

0:27:10	SPEAKER_02
 But in my opinion, we need a reference session.

0:27:16	SPEAKER_05
 Yes, absolutely.

0:27:17	SPEAKER_05
 So are you planning to do that or have you done that already?

0:27:21	SPEAKER_05
 No, sorry.

0:27:22	SPEAKER_05
 Have you done that or are you planning to do that?

0:27:25	SPEAKER_02
 No, I plan to do that.

0:27:27	SPEAKER_02
 Okay, I plan.

0:27:28	SPEAKER_02
 I plan.

0:27:29	SPEAKER_02
 But the idea is the following.

0:27:33	SPEAKER_02
 Now I need to delete all the overlapping sums exactly.

0:27:39	SPEAKER_02
 I will talk about the in the in the lab.

0:27:44	SPEAKER_02
 This information with the exactly time marks for the overlapping sums.

0:27:54	SPEAKER_02
 Overlapping zone and speaker, pure speech, speaker, song.

0:28:00	SPEAKER_02
 I mean, songs of speech of one speaker without any noise, any acoustic event that is not speech.

0:28:13	SPEAKER_02
 I need to do a silence for that because my idea is to study the set of parameters.

0:28:25	SPEAKER_02
 What are more discriminant to classify the overlapping sounds in comparison with the speech sounds.

0:28:35	SPEAKER_02
 The idea is to use a not sure yet, but my idea is to use a cluster algorithms or a PerseStron neural nets to study what is the property of the different feature to classify speech and overlapping speech.

0:28:59	SPEAKER_02
 My idea is to have a control set.

0:29:05	SPEAKER_02
 My control set will be the silence, silent without any noise.

0:29:11	SPEAKER_01
 Which means that we still use the different sounds.

0:29:14	SPEAKER_01
 With the backgrounds.

0:29:15	SPEAKER_02
 I mean noise, clubs, tape, clips, the difference.

0:29:24	SPEAKER_02
 Which has a hard effect of the distortion in the.

0:29:32	SPEAKER_05
 So you intend to hand mark those and exclude them?

0:29:36	SPEAKER_02
 I have mark in that not in all the file.

0:29:41	SPEAKER_02
 Only I have a, I don't remember what is the quantity, but I have marked enough speech and all the overlapping sounds.

0:29:55	SPEAKER_02
 I have 230 more or less overlapping sounds and it is similar to this information.

0:30:03	SPEAKER_02
 Because with the problem I cross the information of the gene with my experimentation by hand.

0:30:11	SPEAKER_02
 And it is more similar.

0:30:14	SPEAKER_02
 Exactly.

0:30:15	SPEAKER_02
 But, sorry.

0:30:25	SPEAKER_02
 My idea is to.

0:30:32	SPEAKER_05
 I should get digital camera.

0:30:35	SPEAKER_02
 To classify.

0:30:37	SPEAKER_02
 I need the set mark of the different sound because I want to put for each frame a level indicating it's a supervised and a class in process.

0:30:53	SPEAKER_02
 I put for each frame a level indicating what is the type, what is the class which belong.

0:31:07	SPEAKER_02
 I mean the class overlapping speech, the class speech.

0:31:22	SPEAKER_04
 And the class will be assigned by hand based on the.

0:31:28	SPEAKER_02
 I put the mark by hand because my idea is in the first session.

0:31:33	SPEAKER_02
 I need to be sure that information can be in validation.

0:31:41	SPEAKER_02
 Sure.

0:31:42	SPEAKER_02
 It's right because if not I will return to the speech file to analyze what is the problem.

0:31:51	SPEAKER_02
 And I would prefer to have this level automatically.

0:31:56	SPEAKER_02
 You need to.

0:31:58	SPEAKER_01
 I ask you the difference between the top two.

0:32:06	SPEAKER_01
 By speech do you mean one person only?

0:32:10	SPEAKER_01
 One, two, three.

0:32:12	SPEAKER_01
 One, two, three.

0:32:13	SPEAKER_01
 One speaker in a breath overlapping.

0:32:17	SPEAKER_01
 Someone else in the back.

0:32:19	SPEAKER_01
 By the moment.

0:32:20	SPEAKER_01
 Clicking overlapping speech.

0:32:21	SPEAKER_02
 That's all those possibilities in the top.

0:32:24	SPEAKER_02
 In the first moment because I have information of the overlapping sounds.

0:32:31	SPEAKER_02
 Information about the overlapping sound is from speech, clear speech from a true speaker or three speaker.

0:32:40	SPEAKER_02
 It's a song where the impregnance of a speaker overlaps onto a speech.

0:32:46	SPEAKER_01
 A speech with something overlapping which could be speech but doesn't need to be.

0:32:52	SPEAKER_02
 You know, especially overlapping speech from different speakers.

0:32:57	SPEAKER_03
 No, but I think she's saying where do you in these three categories?

0:33:01	SPEAKER_03
 Where do you put the instances in which there is one person speaking and other sounds which are not speech?

0:33:11	SPEAKER_02
 Which category do you put that?

0:33:14	SPEAKER_02
 Here I put a speech from one speaker without any events.

0:33:24	SPEAKER_03
 So where do you put speech from one speaker that does have a non-speech event at the same time?

0:33:30	SPEAKER_02
 Which category?

0:33:31	SPEAKER_02
 Which category?

0:33:32	SPEAKER_02
 No, by the moment no.

0:33:33	SPEAKER_02
 Oh, you see, not marked.

0:33:35	SPEAKER_02
 No, not marked.

0:33:36	SPEAKER_02
 Because I want to meet the study.

0:33:41	SPEAKER_02
 Fine, so even for the all of the data.

0:33:44	SPEAKER_01
 So you're ignoring overlapping events unless their speech was speech.

0:33:48	SPEAKER_02
 Yeah, that's fine.

0:33:49	SPEAKER_02
 Why?

0:33:50	SPEAKER_02
 What's the reason?

0:33:51	SPEAKER_02
 Because it's the first study.

0:33:53	SPEAKER_02
 Oh, no, no.

0:33:54	SPEAKER_03
 It's perfectly sensible way to go.

0:33:56	SPEAKER_03
 We just wanted to try and understand what you're doing.

0:33:58	SPEAKER_01
 Because you've talked about other overlapping events in the past.

0:34:00	SPEAKER_02
 So in the future, the idea is to extend the class.

0:34:06	SPEAKER_02
 Is to consider all the information you mentioned.

0:34:08	SPEAKER_03
 Yeah, I don't think we're asking for that.

0:34:10	SPEAKER_02
 I don't know what we would have.

0:34:16	SPEAKER_04
 Is your silence category pure silence or?

0:34:19	SPEAKER_02
 Is there a door slammer?

0:34:21	SPEAKER_04
 No, no, it's pure silence.

0:34:23	SPEAKER_02
 Is the control set?

0:34:24	SPEAKER_02
 OK.

0:34:24	SPEAKER_02
 Is the control set?

0:34:26	SPEAKER_03
 What you will be silent with the majority of the world.

0:34:30	SPEAKER_03
 I think what you mean is that it's non-speech segments that don't have impulsive noises, right?

0:34:36	SPEAKER_03
 Because what you're calling a vent is somebody coughing or clicking a wrestling paper or hitting something, which are impulsive noises.

0:34:45	SPEAKER_03
 But steady state noises are part of the background, which it will be included in that.

0:34:50	SPEAKER_02
 Right?

0:34:51	SPEAKER_02
 Here.

0:34:52	SPEAKER_01
 Yeah.

0:34:53	SPEAKER_02
 So it's like a signal noise.

0:34:54	SPEAKER_02
 I think there are some kind of noises that don't water to be in that control set.

0:35:02	SPEAKER_02
 But I prefer the silence with this kind or the off.

0:35:09	SPEAKER_03
 Right.

0:35:10	SPEAKER_03
 It means background might be better word than silence.

0:35:12	SPEAKER_03
 It's just sort of the background of the acoustic.

0:35:15	SPEAKER_03
 Right.

0:35:16	SPEAKER_02
 So it's only going on.

0:35:18	SPEAKER_02
 OK.

0:35:19	SPEAKER_02
 And with this information, the idea is I have a level for each friend.

0:35:29	SPEAKER_02
 And with a cluster algorithms, I am sorry.

0:35:35	SPEAKER_02
 And I am going to prepare a set of features, a structure, molds.

0:35:47	SPEAKER_02
 Right.

0:35:48	SPEAKER_02
 And maybe it's, tell me whatever.

0:36:00	SPEAKER_02
 So I have a pitch structure yet.

0:36:06	SPEAKER_02
 I have to test.

0:36:07	SPEAKER_02
 But you have your own?

0:36:08	SPEAKER_02
 Yeah.

0:36:09	SPEAKER_02
 Yeah.

0:36:10	SPEAKER_02
 I have to prepare.

0:36:11	SPEAKER_02
 It's a modified version of a pitch tracker from a Stanford universe.

0:36:16	SPEAKER_02
 Stanford, no, from Cambridge.

0:36:20	SPEAKER_02
 Oh, what's it really?

0:36:23	SPEAKER_02
 I don't remember what is the name of the author.

0:36:25	SPEAKER_02
 Because I have several library tools from a festival, from Edinburgh, from Cambridge, and from our department.

0:36:38	SPEAKER_02
 And I have to, because in general, the pitch tracker, that's a waste.

0:36:43	SPEAKER_05
 Right.

0:36:44	SPEAKER_05
 Very well.

0:36:45	SPEAKER_05
 Because the feature it might be OK.

0:36:47	SPEAKER_05
 Yeah.

0:36:48	SPEAKER_02
 So we don't know.

0:36:49	SPEAKER_02
 This is an idea is to attain, for example, a different, a grid number of emphesies, for example, 25, 30, 30 parameter for each one.

0:37:10	SPEAKER_02
 In the first step in the research, my idea is try to prove what is the performance of the difference parameter to classify the difference, what is the performance approach to classify the difference frames of each class.

0:37:34	SPEAKER_02
 What is the error about it?

0:37:40	SPEAKER_02
 This is the first idea.

0:37:42	SPEAKER_02
 And the second is try to use some ideas similar to the linear discriminant analysis.

0:37:54	SPEAKER_02
 Similar.

0:37:55	SPEAKER_02
 Because the idea is to study what is the contribution of each parameter to the process of classify the different parameter.

0:38:07	SPEAKER_02
 What sort of classifier?

0:38:09	SPEAKER_02
 The classifier, by the moment, is a similar classifier used in Victoria, Quantified, is used to some distance to put a vector in a class difference.

0:38:28	SPEAKER_05
 Unimodal?

0:38:29	SPEAKER_05
 So is it just one cluster?

0:38:30	SPEAKER_02
 It's only two clusters using a Kinear SNF or similar.

0:38:37	SPEAKER_02
 Another possibility is to use a neural network.

0:38:42	SPEAKER_02
 But what is my idea?

0:38:45	SPEAKER_02
 What is the problem?

0:38:46	SPEAKER_02
 I see.

0:38:47	SPEAKER_02
 If you use the neural network.

0:38:52	SPEAKER_02
 And this kind of cluster inaugurated to can test to can a share of what happened.

0:39:00	SPEAKER_02
 You can't analyze it.

0:39:03	SPEAKER_02
 Right.

0:39:04	SPEAKER_02
 You can't analyze it.

0:39:05	SPEAKER_02
 You use a neural network, a good idea.

0:39:08	SPEAKER_02
 But you don't know what happened in the interior of the neural network.

0:39:12	SPEAKER_03
 Well, actually, you can do sensitivity analyses, which show you what the importance of different parts of pieces input are.

0:39:22	SPEAKER_03
 What's going on internally?

0:39:25	SPEAKER_03
 But it's actually not that hard to analyze it and figure out the effects of different inputs, especially if they're all normalized.

0:39:32	SPEAKER_05
 Well, using something simpler first, I think.

0:39:35	SPEAKER_03
 Well, if you really wonder what different...

0:39:37	SPEAKER_03
 Decision tree.

0:39:38	SPEAKER_03
 Yeah, then, it's decision tree is really good.

0:39:40	SPEAKER_03
 But the thing is, he's not like he has one, a bunch of very distinct variables like pitch and this, he's talking about all these capture all coefficients.

0:39:48	SPEAKER_03
 So for the much case, any reasonable classifier is going to be a mess.

0:39:52	SPEAKER_03
 Right.

0:39:53	SPEAKER_03
 It's going to be hard to figure out what...

0:39:54	SPEAKER_02
 I would include you to the differential.

0:39:57	SPEAKER_02
 Yeah, that would be...

0:39:58	SPEAKER_03
 I mean, I think the other thing, I mean, this is, I think, a good thing to do to sort of look at these things at least.

0:40:03	SPEAKER_03
 See what...

0:40:04	SPEAKER_03
 Let me tell you what I would do.

0:40:05	SPEAKER_03
 I would take just a few features.

0:40:06	SPEAKER_03
 Instead of taking all the MFCCs or all the EPLPs or whatever, I would just take a couple.

0:40:12	SPEAKER_03
 Okay, like C1, C2, something like that, so that you can visualize it.

0:40:16	SPEAKER_03
 And look at these different examples and look at scatter plots.

0:40:19	SPEAKER_03
 Okay, so before you build up any kind of fancy classifiers, just take a look in two dimensions at how these things are split apart.

0:40:27	SPEAKER_03
 That I think will give you a lot of insight of what is likely to be a useful feature when you put it to a more complicated classifier.

0:40:33	SPEAKER_03
 Yeah.

0:40:34	SPEAKER_03
 And the second thing is, once you actually get to the point of building these classifiers, what this lacks so far is the temporal properties.

0:40:41	SPEAKER_03
 So if you're just looking at a frame at a time, you don't know anything about the structure of it over time.

0:40:46	SPEAKER_03
 And so you may want to build a mark off a model of some sort or else have features that really are based on some bigger chunk of time.

0:40:57	SPEAKER_03
 But I think this is a good place to start.

0:40:59	SPEAKER_03
 But don't...

0:41:00	SPEAKER_03
 Anyway, this is my suggestion.

0:41:01	SPEAKER_03
 Don't just throw in 20 features at it, the delta is in the delta, and all that into some classifier, even if it's K-nearest neighbors, you still won't know what it's doing.

0:41:10	SPEAKER_03
 You know it's not an Earl Matt.

0:41:12	SPEAKER_03
 I think to know what it's...

0:41:13	SPEAKER_03
 Have a better feeling for what it's doing, you want to look at it.

0:41:15	SPEAKER_03
 So you want to look at some picture that shows you, here's these things are offered some separation.

0:41:23	SPEAKER_03
 And in LPC, the thing that particularly look at is, I think, is something like the residual, the energy and the residual.

0:41:33	SPEAKER_01
 Can I ask, it strikes me that there's another piece of information that might be useful, and that's simply the transition.

0:41:41	SPEAKER_01
 So if you go from a transition of silence to overlap versus transition from silence to speech, it's going to be a big informative area there, it seems to be.

0:41:49	SPEAKER_02
 But it's my ambition of the project.

0:41:57	SPEAKER_02
 The meeting record project for me has a two, several parts, an adjective because it's a good thing to do.

0:42:06	SPEAKER_02
 At the first, in the acoustic parts of the project, I think we have two main adjectives.

0:42:16	SPEAKER_02
 One of these is to detect the chain, the acoustic chain.

0:42:22	SPEAKER_02
 For that, if you don't use a speech recognizer, a pro-class or not pro-class, to try to level the different friends, I think the Ike criterion, or big criterion, will be enough to detect the chain.

0:42:43	SPEAKER_02
 And probably, I would like to prove.

0:42:47	SPEAKER_02
 Probably, when you have the transition of speech or silence to overlap song, this criterion is enough with probably with this kind of, the more use a regular parameter, NCC, you have to find, you can find the mark, you can find the good chain.

0:43:17	SPEAKER_02
 But I understand that your adjective is too classified, to know that that song is not only a new song in the file, but you have to know that it is an overlap song because in the future, you will try to process that song with a no-regular speech recognizer, you will pretend to process the overlapping song with another claim, because it is very difficult to obtain the trackition from using a regular, normal speech recognizer.

0:44:04	SPEAKER_02
 I think it is the idea, the system will have two models.

0:44:18	SPEAKER_02
 A model to detect, the most, the most, the most, the most, the mark, the chain, and another model, or several models, to try, but several models, rowing models, simple models, to try to classify the different class.

0:44:46	SPEAKER_05
 I am sorry, I didn't understand you, what model?

0:44:49	SPEAKER_02
 The classifies, to detect the different class to the different song before trying to recognize, to track life with a speech recognizer.

0:45:02	SPEAKER_02
 The idea is to use, for example, a neural net with the information we obtain from this stage, the parameter with the selected parameter to try to put a class of each frame for the different song, you have to obtain it in the first step with the, for example, BK, Heterium, Compere-Mole.

0:45:46	SPEAKER_03
 I think in any event we are great that the first step is, because what we had before for speaker change detection did not include these overlaps.

0:45:58	SPEAKER_03
 So the first thing is for you to build something, you will detect the overlaps.

0:46:02	SPEAKER_03
 So again, I think the first thing to do to detect the overlaps is to look at these, and in, well, again, the things that you have written up there, I think are way too big.

0:46:14	SPEAKER_03
 If you are talking about, say, 12th order NFCC or something like that, it is way too much, you will not be able to look at it.

0:46:20	SPEAKER_03
 All you will be able to do is put into a class of fire and see how well it does.

0:46:24	SPEAKER_03
 I think if you pick one or two dimensional things, or three, if you have some very fancy display, and look at how the different classes separate themselves out, you will have much more insight about what is going on.

0:46:38	SPEAKER_03
 What are you doing?

0:46:39	SPEAKER_03
 Well, you will get a feeling for what is happening.

0:46:41	SPEAKER_03
 So if you look at, suppose you look at first and second order, capture coefficients for some of these kinds of things, and you find that the first order is much more effective than the second, and then you look at the third and there is not too much there, you may just take first and second order capture coefficients.

0:46:58	SPEAKER_03
 With LPC, I think LPC per se isn't going to tell you much more than the other, maybe.

0:47:05	SPEAKER_03
 On the other hand, the LPC residual, the energy in the LPC residual, would say how well a loader LPC models fitting it, which should be pretty poorly for two or more people speaking at the same time, should be pretty well for one.

0:47:20	SPEAKER_03
 And so again, if you take a few of these things that are promising features, and look at them in pairs, I think you will have much more of a sense of, okay, I now have, doing a bunch of these analyses, I now have ten likely candidates, and then you can do decision

0:47:39	SPEAKER_02
 countries or whatever to see how they combine. I've got a question.

0:47:51	SPEAKER_02
 Sorry, but I don't know the first way to do that, and I would like to know what's the European Union.

0:47:54	SPEAKER_02
 All these studies in the first moment, I will pretend to do with the equalizes pitch.

0:48:04	SPEAKER_02
 The misses pitch, the mix, the mix, the mix, the mix, the speech.

0:48:11	SPEAKER_02
 Why?

0:48:12	SPEAKER_02
 Because the spectral distortion is a lot clearer, very much clearer if we compare with the PDA.

0:48:19	SPEAKER_02
 PDA is pitchfile, it will be difficult.

0:48:23	SPEAKER_01
 It's messier, the PDA is messier.

0:48:25	SPEAKER_02
 Because the signal to know is relation is slow.

0:48:31	SPEAKER_02
 I think that's a good way to start.

0:48:34	SPEAKER_02
 I don't know that the result of the study within this speech, the mix speech, would be interesting that sounds to see.

0:48:47	SPEAKER_02
 It's actually with the PDA file.

0:48:50	SPEAKER_02
 Well, I think that would be an interesting result.

0:48:52	SPEAKER_02
 I mean, what is the effect of the low signal to know is relation?

0:48:58	SPEAKER_03
 Well, I think it's not at all unreasonable, it makes sense to start with a simpler signal, because if you have features which aren't even helpful in the high signal noise ratio, then there's no point putting them into the low signal ratio, one would think.

0:49:16	SPEAKER_03
 And so if you can get, again, my prescription would be that you would with the mixed signal, you would take a collection of possible features, look at them, look at how these different classes that you've marked separate themselves, and then collect in pairs, and then collect ten of them or something, and then proceed with a bigger classifier.

0:49:37	SPEAKER_03
 And then if you can get that to work well, then you go to the other signal.

0:49:41	SPEAKER_03
 And you know, they won't work as well, but how much, and then you can re-optimize.

0:49:47	SPEAKER_05
 But I think it would be interesting to try a couple with both, because it might be interesting to see if some features work well with close mix.

0:49:54	SPEAKER_03
 And that's true, that it also could be useful to do this exploratory analysis where you're looking at scatter plots and so on in both cases.

0:50:04	SPEAKER_02
 Sure.

0:50:05	SPEAKER_02
 I think the parameter we found, the word with both speech file, but what is the relation of the performance when you use the speech file, the BDA, you speech file, you don't know, but I think it will be important, because people, different groups, have experience with this kind of problem, it's not easy to solve, because if you, I have seen the speech file from a PDA and some parts, but it's difficult because you don't see the spectra.

0:50:46	SPEAKER_02
 That's another reason why very simple features, things like energy and things like car

0:50:59	SPEAKER_03
 density and residual energy are you here? Yeah, are better to use than very complex ones because the marble libel, Chuck was going to ask something.

0:51:10	SPEAKER_04
 Yeah, maybe this is a dumb question, but I thought it would be easier if you use the PDA because, couldn't you like use beam forming or something to detect speaker overlaps?

0:51:24	SPEAKER_05
 I mean, well, if you use the array rather than the signal from just one.

0:51:29	SPEAKER_03
 Yeah, no, you're right, that in fact, if we made use of the fact that there are two microphones, you do have some location information, which we don't have with the one.

0:51:39	SPEAKER_03
 And so that's not allowed with this.

0:51:42	SPEAKER_03
 Well, no, I mean, we don't have any rules, really.

0:51:45	SPEAKER_04
 I mean, given the goal, I mean, is that the violation of that?

0:51:50	SPEAKER_03
 I think it's an additional interesting question.

0:51:54	SPEAKER_03
 I mean, I think you want to know whether you can do it with one because it's not necessarily true that every device that you're trying to do this with will have two.

0:52:04	SPEAKER_03
 If on the other hand, we show that there's a huge advantage with two, then that could be a real point.

0:52:09	SPEAKER_03
 But we don't even know yet what the effect of detecting, having the ability to detect overlaps is.

0:52:14	SPEAKER_03
 Maybe it doesn't matter too much.

0:52:16	SPEAKER_03
 So this is all pretty early stages.

0:52:17	SPEAKER_03
 But no, you're absolutely right.

0:52:18	SPEAKER_03
 That's a good thing to consider.

0:52:19	SPEAKER_01
 There's a correlation, though.

0:52:20	SPEAKER_01
 And that is, a person turns their back to the PD8, then some of the positional information goes away.

0:52:26	SPEAKER_01
 Well, it does not.

0:52:27	SPEAKER_01
 It does not.

0:52:28	SPEAKER_01
 That's so much.

0:52:29	SPEAKER_01
 The issue is that the...

0:52:30	SPEAKER_01
 And everyone on the axis, on the axis of it, that's the other thing I was saying.

0:52:33	SPEAKER_01
 You mentioned this last time.

0:52:34	SPEAKER_01
 Yeah, we had to put it on a little turn table.

0:52:36	SPEAKER_01
 If you just write down the midline, then the left right is going to be different.

0:52:39	SPEAKER_01
 And in his case, he's closer to it anyway.

0:52:42	SPEAKER_01
 It seems to me that it's not a...

0:52:44	SPEAKER_01
 But it's another source of information.

0:52:46	SPEAKER_01
 It's a topology of it is.

0:52:47	SPEAKER_01
 I don't know.

0:52:48	SPEAKER_02
 I think...

0:52:49	SPEAKER_02
 I think because the reason between the two microphones, microphone in the PDI's brain here, it's from my opinion, it's an interesting idea to try to study the brain role, a problem with the question.

0:53:05	SPEAKER_02
 Yes, because I found a difference between the speech from each microphone in the PDI.

0:53:12	SPEAKER_02
 Yeah, it's timing difference.

0:53:13	SPEAKER_03
 It's an important issue, right?

0:53:14	SPEAKER_01
 I mean, it means the cells.

0:53:15	SPEAKER_01
 I know, that's very important.

0:53:16	SPEAKER_01
 Right.

0:53:17	SPEAKER_01
 But I'm just saying that the way we're seated around the table is not the same with respect to each person with respect to the PDA.

0:53:25	SPEAKER_01
 So we're going to have a lot of differences with reference.

0:53:27	SPEAKER_01
 But that's fine.

0:53:28	SPEAKER_03
 That's fine.

0:53:29	SPEAKER_03
 That's...

0:53:30	SPEAKER_03
 So I think the issue is, is there a clean signal coming from only one direction?

0:53:35	SPEAKER_03
 If it's not coming from just one direction, if there's a broader pattern, it means there's more likely these multiple people speaking.

0:53:43	SPEAKER_03
 Wherever they are.

0:53:44	SPEAKER_03
 So it's sort of like how...

0:53:45	SPEAKER_03
 Is it a...

0:53:46	SPEAKER_03
 Is there a narrow beam pattern or is it a distributed beam pattern?

0:53:52	SPEAKER_03
 Does it distribute a beam pattern?

0:53:53	SPEAKER_03
 Then it looks more like it's multiple people.

0:53:56	SPEAKER_03
 Wherever you are, even if he moves around.

0:53:58	SPEAKER_01
 Okay.

0:53:59	SPEAKER_01
 It just seemed to me that this isn't the ideal type of separation.

0:54:04	SPEAKER_01
 I think it's...

0:54:05	SPEAKER_03
 Oh, ideal would be to have the wall filled with him.

0:54:07	SPEAKER_03
 But I mean, the thing is just having too much...

0:54:09	SPEAKER_03
 If you looked at that thing on Dan's page, it was when there were two people speaking, it looked really, really different.

0:54:15	SPEAKER_03
 Oh, yeah, yeah, yeah.

0:54:16	SPEAKER_03
 Okay.

0:54:17	SPEAKER_03
 What looked different?

0:54:18	SPEAKER_03
 Well, basically, he was looking at correlation.

0:54:19	SPEAKER_03
 Just cross-correlation between two sides.

0:54:21	SPEAKER_03
 So cross-correlation is very sensitive.

0:54:23	SPEAKER_04
 I'm not sure what Dan's page is.

0:54:24	SPEAKER_04
 If you mean he was looking at the...

0:54:26	SPEAKER_03
 He took a signal from the two microphones and he crossed...

0:54:28	SPEAKER_03
 And you cross-correlate them with different blacks.

0:54:31	SPEAKER_03
 Okay.

0:54:32	SPEAKER_03
 And one person is speaking, then wherever they happen to be at the point where they're speaking, then there's a pretty big maximum right around that point in the like.

0:54:40	SPEAKER_03
 So whatever angle you are...

0:54:42	SPEAKER_03
 So if there's two...

0:54:43	SPEAKER_03
 At some like corresponding to the time difference between the two there, you get this boost in the cross-correlation.

0:54:48	SPEAKER_05
 And if there are multiple people talking, you'll see two peaks.

0:54:51	SPEAKER_05
 It's spread out.

0:54:52	SPEAKER_01
 Let me ask you, if both people were over there...

0:54:55	SPEAKER_01
 Yeah.

0:54:56	SPEAKER_01
 It would be less effective than if one was there and one was across Catechord.

0:54:59	SPEAKER_01
 Oh, I'm sorry.

0:55:00	SPEAKER_03
 If they're right next to another one.

0:55:01	SPEAKER_04
 If I was here and Morgan was there and we're both talking right, it wouldn't work.

0:55:05	SPEAKER_01
 Yeah.

0:55:06	SPEAKER_01
 Versus you versus...

0:55:07	SPEAKER_01
 And we're Catechord across the table and I'm farther away from this one and you're farther away from the other one.

0:55:11	SPEAKER_01
 Or even if that would be strong.

0:55:13	SPEAKER_01
 If people were saying right across from each other, you could tell them from either.

0:55:16	SPEAKER_01
 Cross-correlate, same axis, you don't have as much difference.

0:55:18	SPEAKER_01
 Well, we don't have a third dimension there.

0:55:20	SPEAKER_01
 Yeah, so...

0:55:21	SPEAKER_01
 It's differentially very valuable.

0:55:22	SPEAKER_01
 I mean, it's not to say...

0:55:23	SPEAKER_01
 I mean, I certainly think it's extremely bad.

0:55:25	SPEAKER_01
 And we humans depend on...

0:55:27	SPEAKER_01
 Yeah, but it's almost...

0:55:28	SPEAKER_03
 It's almost... but it's almost a... I think what you're talking about is there's two things.

0:55:33	SPEAKER_03
 There's a sensitivity issue and then there's a pathological or issue.

0:55:37	SPEAKER_03
 So the one where someone is just right directly in line is sort of pathological here.

0:55:41	SPEAKER_03
 If someone just happens to be sitting right there, then we won't get good information from it.

0:55:44	SPEAKER_01
 Okay, and if they're close...

0:55:45	SPEAKER_01
 If they're close...

0:55:46	SPEAKER_03
 Same subject.

0:55:47	SPEAKER_03
 It's just a question of the sensitivity.

0:55:49	SPEAKER_03
 So if the sensitivity is good enough and we just don't have enough experience with it to know how...

0:55:54	SPEAKER_01
 Oh, I'm not trying to argue against using it by any means.

0:55:57	SPEAKER_01
 I just wanted to point out that weakness that it's top of the level.

0:56:00	SPEAKER_01
 And I think Dan is still working on it.

0:56:02	SPEAKER_05
 So he actually... he wrote me about it a little bit.

0:56:06	SPEAKER_05
 Great.

0:56:07	SPEAKER_03
 No, I don't understand.

0:56:08	SPEAKER_03
 I mean, the other thing you can do...

0:56:09	SPEAKER_03
 I mean, we're assuming that it would be a big deal just to get somebody...

0:56:13	SPEAKER_03
 Come in somebody to put two microphones on the PDA.

0:56:15	SPEAKER_03
 But if you have put a third in, you could put in the other axis and then you got to...

0:56:19	SPEAKER_03
 You've got to.

0:56:20	SPEAKER_03
 Yeah, then you pretty much could cover.

0:56:22	SPEAKER_04
 What about just doing it from these mics, you know?

0:56:25	SPEAKER_02
 Yeah.

0:56:26	SPEAKER_02
 I mean, it's actually more interesting to study the PCN because...

0:56:29	SPEAKER_02
 Say, Parisian, anything.

0:56:31	SPEAKER_03
 But that's...

0:56:32	SPEAKER_03
 And they're much broader.

0:56:33	SPEAKER_03
 I mean, we can...

0:56:34	SPEAKER_03
 We'll be...

0:56:35	SPEAKER_03
 All of this is there for us to study.

0:56:36	SPEAKER_03
 Yeah, we can do whatever we want.

0:56:38	SPEAKER_03
 But the thing is...

0:56:39	SPEAKER_03
 One of the...

0:56:40	SPEAKER_03
 At least one of the things I was hoping to get out of this is what can we do with what we think would be the normal situation if some people get together and one of them has a PDA.

0:56:48	SPEAKER_03
 That's what I was asking about.

0:56:49	SPEAKER_03
 What are the constraints?

0:56:50	SPEAKER_03
 Yeah.

0:56:51	SPEAKER_03
 Well, that's the constraint of one question and I think both Adam and I were interested in.

0:56:56	SPEAKER_03
 But, you know, if you can instrument a room, this is really minor league compared with what some people are doing.

0:57:02	SPEAKER_03
 Right?

0:57:03	SPEAKER_03
 Some people...

0:57:04	SPEAKER_03
 Eight micro-round.

0:57:05	SPEAKER_03
 Yeah, brown and...

0:57:06	SPEAKER_03
 And...

0:57:07	SPEAKER_03
 Didn't they have the main cape?

0:57:08	SPEAKER_03
 And...

0:57:09	SPEAKER_03
 And Cape...

0:57:10	SPEAKER_03
 They both have these, you know, bigger rays on the wall.

0:57:12	SPEAKER_03
 And, you know, if you can...

0:57:13	SPEAKER_03
 You've got microphones all over the place.

0:57:15	SPEAKER_03
 You know, tens of microphones.

0:57:18	SPEAKER_03
 Oh, I saw it.

0:57:19	SPEAKER_03
 I don't know.

0:57:20	SPEAKER_03
 And if you do that, then you can really get very nice...

0:57:22	SPEAKER_03
 Kind of selectivity.

0:57:23	SPEAKER_05
 So, I saw one that was like 100 microphones.

0:57:26	SPEAKER_04
 Yeah.

0:57:27	SPEAKER_04
 10 by 10, right?

0:57:28	SPEAKER_04
 And you could...

0:57:29	SPEAKER_04
 And you could...

0:57:30	SPEAKER_04
 And you could...

0:57:31	SPEAKER_04
 And you could...

0:57:32	SPEAKER_05
 Very, very...

0:57:33	SPEAKER_05
 They could have all kinds of noises and you can zoom right in...

0:57:34	SPEAKER_05
 Pretty much.

0:57:35	SPEAKER_05
 It was all in software and you could pick out an individual beam and listen to it.

0:57:36	SPEAKER_05
 Yeah.

0:57:37	SPEAKER_03
 That's cool.

0:57:38	SPEAKER_03
 But, I was interested.

0:57:39	SPEAKER_03
 The reason why I haven't focused on that is the first concern is because I'm interested in what happens for people, random people out in some random place where they're having an improv to discussion.

0:57:49	SPEAKER_03
 And you can't just always go, well, let's go to this heavily instrumented room that we spent tens of thousand dollars to set up.

0:57:54	SPEAKER_04
 No, what you need to do is you have a little fabric thing that you enroll and hang on a wall.

0:57:59	SPEAKER_04
 It has all these mics and it has a plug-in jack to the PDA.

0:58:04	SPEAKER_03
 The other thing actually gets it this little bit of something else I'd like to do is what happens if you have two PDAs.

0:58:08	SPEAKER_03
 Yeah.

0:58:09	SPEAKER_03
 And they communicate with each other.

0:58:10	SPEAKER_03
 And then, you know, they're in random positions.

0:58:11	SPEAKER_03
 The likelihood, I mean, basically, there wouldn't be any...

0:58:14	SPEAKER_05
 That's likely to be any kind of network.

0:58:16	SPEAKER_05
 You have two.

0:58:17	SPEAKER_05
 If you're three or four.

0:58:18	SPEAKER_05
 All sorts of interesting things you can do with that.

0:58:20	SPEAKER_05
 I mean, not only can you do microphone arrays, but you can do all sorts of multi-band as well.

0:58:26	SPEAKER_04
 I still like my rug on the wall, I guess.

0:58:29	SPEAKER_04
 But it happens.

0:58:30	SPEAKER_01
 In terms of...

0:58:31	SPEAKER_01
 Yeah.

0:58:32	SPEAKER_05
 In terms of the research, it's really...

0:58:35	SPEAKER_05
 Whatever the person who is doing the research wants to do.

0:58:37	SPEAKER_05
 So if Jose is interested in that, that's great.

0:58:40	SPEAKER_05
 But if he's not, that's great, too.

0:58:45	SPEAKER_03
 I would actually kind of like us to wind it down, see if we can still get the end of the birthday thing there.

0:58:51	SPEAKER_05
 Well, I had a couple things that I didn't want to bring out.

0:58:54	SPEAKER_05
 One is, do we need to sign new...

0:58:56	SPEAKER_05
 Well, it's slightly different.

0:58:57	SPEAKER_01
 So I would say a big idea.

0:58:59	SPEAKER_01
 Oh, they need?

0:59:00	SPEAKER_01
 Yeah.

0:59:01	SPEAKER_03
 Oh, this morning we didn't sign anything because we said if anybody had signed it already, we have to.

0:59:07	SPEAKER_05
 I should have checked with Jane first, but the form has changed.

0:59:10	SPEAKER_05
 So we may want to have everyone sign the new form.

0:59:14	SPEAKER_05
 I had some things I wanted to talk about with the thresholding stuff I'm doing, but if we're in a hurry, we can put that off.

0:59:22	SPEAKER_05
 And then also anonymity, how we want to anonymize the data.

0:59:25	SPEAKER_05
 Well, should I...

0:59:26	SPEAKER_01
 I mean, I have some results to present, but I guess we'll have time to do that this time.

0:59:31	SPEAKER_01
 But it seems like the anonymization is also something that we might want to discuss and greatly.

0:59:37	None
 I mean, what...

0:59:38	SPEAKER_03
 We're about to wind down.

0:59:40	SPEAKER_01
 I think what I would prefer is that we delay the anonymization thing to...

0:59:44	SPEAKER_01
 I think, until next week, and I would like to present the results that I have on the

0:59:48	SPEAKER_04
 overlap. We still have to do this, too, right?

0:59:50	SPEAKER_04
 Right.

0:59:51	SPEAKER_04
 Digits.

0:59:52	SPEAKER_05
 Right.

0:59:53	SPEAKER_05
 No, well, we don't have to do digits.

0:59:56	SPEAKER_03
 Well, I mean...

1:00:03	SPEAKER_03
 So, okay.

1:00:04	SPEAKER_03
 It sounds like there were a couple technical things people would like to talk about.

1:00:08	SPEAKER_03
 Why don't we just take a couple minutes to briefly do them?

1:00:11	SPEAKER_03
 And then...

1:00:12	SPEAKER_03
 Go ahead, Jane.

1:00:13	SPEAKER_01
 I would prefer to have more time for my results.

1:00:15	SPEAKER_01
 Could I do that next week, maybe?

1:00:17	SPEAKER_01
 Oh, yeah, sure.

1:00:18	SPEAKER_01
 That's what I'm asking.

1:00:19	SPEAKER_01
 Oh, yeah.

1:00:20	SPEAKER_01
 And I think the anonymization, if you want to proceed with that.

1:00:21	SPEAKER_01
 Now, I just think that that's a discussion, which also really deserves...

1:00:25	SPEAKER_01
 Because...

1:00:26	SPEAKER_01
 You know, more than just a minute, I really do think that because you raised a couple of possibilities yourself.

1:00:30	SPEAKER_01
 You and I have discussed it previously.

1:00:32	SPEAKER_01
 And there are different ways that people approach it.

1:00:35	SPEAKER_05
 Right.

1:00:36	SPEAKER_05
 We're just...

1:00:37	SPEAKER_05
 We're getting enough data now that I'd sort of like to do it now before I get overwhelmed with once we decide how to do it.

1:00:41	SPEAKER_05
 Well, okay.

1:00:43	SPEAKER_01
 It's just...

1:00:44	SPEAKER_01
 Okay, I'll give you the short version, but I do think that it's an issue that we can't resolve in five minutes.

1:00:49	SPEAKER_01
 Okay, so the short thing is we have...

1:00:55	SPEAKER_01
 Table recording...

1:00:56	SPEAKER_01
 Sorry, digitized recording.

1:00:58	SPEAKER_01
 Those we won't be able to change if someone says, hey Roger, or so and so.

1:01:01	SPEAKER_01
 So that's going to stay that person's name.

1:01:03	SPEAKER_01
 Now in terms of like the transcript, the question becomes, what's simpler?

1:01:07	SPEAKER_01
 Are you going to put in there for everybody's name?

1:01:09	SPEAKER_01
 And whether you're going to put it in the text where he says, hey Roger, are we going to put that person's anonymized name in instead?

1:01:15	SPEAKER_05
 No, because that would give you a mapping.

1:01:17	SPEAKER_05
 And you don't want to have a mapping.

1:01:18	SPEAKER_01
 So the first decision is we're going to anonymize the same name for the speaker identifier and also in the text whenever the speaker's name is mentioned.

1:01:25	SPEAKER_05
 No.

1:01:26	SPEAKER_05
 Because that would give you a mapping between the speaker's real name and the tag we're using.

1:01:29	SPEAKER_01
 And we don't want...

1:01:30	SPEAKER_01
 I think you're going to see what I said.

1:01:31	SPEAKER_01
 Okay.

1:01:32	SPEAKER_01
 So within the context of an utterance, someone says, so Roger, what do you think?

1:01:38	SPEAKER_01
 Okay.

1:01:39	SPEAKER_01
 And it seems to me that...

1:01:42	SPEAKER_01
 Well, maybe it seems to me that if you change the name, the transcript is going to disagree with the audio video.

1:01:47	SPEAKER_01
 We don't want to...

1:01:48	SPEAKER_05
 We don't want to...

1:01:49	SPEAKER_05
 We don't want to.

1:01:50	SPEAKER_05
 We want the transcript to be Roger.

1:01:51	SPEAKER_05
 Because if we made the transcript be the tag that we're using for Roger, someone who had the transcript and the audio would then have a mapping between the anonymized name and the real name.

1:02:00	SPEAKER_01
 And we want to avoid that.

1:02:01	SPEAKER_01
 Okay.

1:02:02	SPEAKER_01
 But then there's this issue of if we're going to use this for a discourse type of thing.

1:02:05	SPEAKER_01
 And you know, Liz is mentioning stuff in previous meeting about things like Gays direction and who's the address C and all.

1:02:12	SPEAKER_01
 Then to have Roger be the thing in the utterance and then actually have this speaker identify who was Roger be Frank, that's going to be really confusing and make it pretty much useless for discourse in those.

1:02:22	SPEAKER_01
 Yes.

1:02:23	SPEAKER_01
 It's a good point.

1:02:24	SPEAKER_01
 Now, if you want to, you know, I mean, in some cases, I know that Susan Irvingtrip and some of hers actually did do a filter of the signal-worth person's name was mentioned, and I saw, I mean, the question then becomes one level back.

1:02:46	SPEAKER_01
 How important is it for a person to be identified by first name versus full name?

1:02:50	SPEAKER_01
 Well, on the one hand, it's not a full identity.

1:02:53	SPEAKER_01
 We're taking all these precautions and they'll be taking precautions, which are probably even the more important ones to, they'll be reviewing the transcripts, see if there's something they don't like.

1:03:02	SPEAKER_01
 Okay.

1:03:03	SPEAKER_01
 So, maybe that's enough protection.

1:03:05	SPEAKER_01
 On the other hand, this is a small pool and people who say things about topic X who are researchers and well known in the field, they'll be identifiable simply from first name.

1:03:17	SPEAKER_01
 However, taking one step further back, they'd be identifiable anyway, even if we changed all the names.

1:03:21	SPEAKER_01
 Right.

1:03:22	SPEAKER_01
 So, is it really, you know, now in terms of like, so I did some results which I'll report on next time, which do mention individual speakers by name.

1:03:30	SPEAKER_01
 Now, there, the human subjects community is very precise.

1:03:34	SPEAKER_01
 You don't want to mention subjects by name and published reports.

1:03:38	SPEAKER_01
 Now, it'd be very possible for me to take those data, put them in a study and just change everybody's name for the purpose of the publication.

1:03:44	SPEAKER_03
 Yeah, once you get to the publication, you can certainly do that.

1:03:47	SPEAKER_03
 You know, Z.

1:03:48	SPEAKER_03
 Yeah, exactly.

1:03:49	SPEAKER_01
 Doesn't matter.

1:03:50	SPEAKER_03
 Yeah, I mean, it doesn't, I mean, I'm not knowledgeable about this, but it certainly just bother me to have someone's first name in the transcript.

1:04:01	SPEAKER_03
 I think you don't want their full name to be listed.

1:04:04	SPEAKER_01
 And in the form that they sign, it does say your first name may arise in the course of the meetings.

1:04:08	SPEAKER_01
 Yeah.

1:04:09	SPEAKER_03
 So again, the issue is if you're tracking discourse things, if someone says, Frank said this and then you want to connect it to something later, you've got to have this part where that's Frank going, right?

1:04:19	SPEAKER_01
 Yeah, and even more immediate than that, just being able to, well, it just seems like to track from one utterance to the next utterance, who's speaking and who's speaking to whom, because that can be important.

1:04:34	SPEAKER_01
 You raise the point so and so it's kind of nice to be able to know who you are.

1:04:38	SPEAKER_01
 I'm thinking too much.

1:04:39	SPEAKER_01
 I remember, you remember last time we had this discussion of how I was sort of avoiding mention people's names.

1:04:44	SPEAKER_01
 I was too.

1:04:45	SPEAKER_01
 And we made the decision that was kind of artificial.

1:04:48	SPEAKER_01
 So well, I mean, if we're going to step in after the fact and change people's names in the transcript, we've basically done something once to have worse.

1:04:53	SPEAKER_05
 Yeah.

1:04:54	SPEAKER_05
 Well, I don't want to change the name in the transcript, but that's because I'm focused so much on the acoustics instead of on the discourse.

1:05:01	SPEAKER_05
 And so I think that's a really good point.

1:05:03	SPEAKER_05
 You're right.

1:05:04	SPEAKER_05
 This is going to require more thought.

1:05:05	SPEAKER_03
 Yeah.

1:05:06	SPEAKER_03
 Let me just back up this to make a brief comment about the, what we're covering in the meeting.

1:05:11	SPEAKER_03
 I realized when you're doing this that I didn't realize that you had a bunch of things that you wanted to talk about.

1:05:17	SPEAKER_03
 And so I was proceeding somewhat of random, frankly.

1:05:22	SPEAKER_03
 So I think what would be helpful would be, you know, I'll mention this to Liz and Andreas too, that before the meeting, if anybody could send me any agenda items that they were interested in, and I'll take the role of organizing them into the agenda.

1:05:41	SPEAKER_03
 But I'd be very pleased if everyone else completely make up the agenda.

1:05:45	SPEAKER_03
 No, sorry to make it up, but if no one's told me things, then I'm just proceeding from my guesses.

1:05:51	SPEAKER_03
 And yeah, I'm sorry, and it's up with you in the out here.

1:05:55	SPEAKER_03
 Time to, I mean, I'm just always asking, you know what he's doing, you know what?

1:05:59	SPEAKER_03
 And so it's, there's a, there's a lot of other things going on.

1:06:03	SPEAKER_05
 How would the person who is doing the transcript even know who they're talking about?

1:06:09	SPEAKER_05
 Do you know what I'm saying?

1:06:11	SPEAKER_04
 The person who's doing the transcript, the IBM people?

1:06:13	SPEAKER_05
 Yeah.

1:06:14	SPEAKER_05
 I mean, so, so how is that information going to get labeled anyway?

1:06:18	SPEAKER_01
 How do you mean what they're talking about?

1:06:20	SPEAKER_05
 I mean, so if I'm saying in a meeting, oh and Bob, by the way, wanted to do so and so, they're just going to write Bob wanted to do so.

1:06:28	SPEAKER_05
 They're just going to write Bob.

1:06:30	SPEAKER_01
 And so they won't be able to change it themselves.

1:06:32	SPEAKER_05
 If you're, if you're doing discourse analysis, how are you going to do any of this?

1:06:37	SPEAKER_03
 Yeah, really.

1:06:38	SPEAKER_01
 I'm bet we're going to have huge chunks that are just totally un, I mean, they're going

1:06:42	SPEAKER_03
 to say speaker one or speaker two.

1:06:43	SPEAKER_05
 Do you speak, I mean, well, the current one, they don't do speaker identity because in naturally speaking or excuse me in via voice, it's only one person.

1:06:52	SPEAKER_05
 And so in their current conventions, there are no multiple speaker conventions.

1:06:57	SPEAKER_03
 So it may just be one long transcript of a bunch of words.

1:06:59	SPEAKER_01
 Yeah, I think that my understanding for me is it in Changs, how are you pronouncing

1:07:03	SPEAKER_03
 me? You change, you change.

1:07:05	SPEAKER_01
 You change, you change.

1:07:06	SPEAKER_01
 It was that they will adopt the part of the conventions that we discussed where they put speaker identifier down, but you know, they won't know these people.

1:07:15	SPEAKER_01
 So I think it's well, they'll adopt some convention, but we haven't specified to them.

1:07:19	SPEAKER_01
 So they'll do something like speaker one, speaker two is one of it.

1:07:22	SPEAKER_01
 But I'm betting there will be huge variations in the accuracy of their labeling of speakers.

1:07:26	SPEAKER_01
 We'll have to review the transcripts in any case.

1:07:28	SPEAKER_03
 And it may very well be, I mean, since they're not going to sit there and worry about it being the same speaker, they may very well go.

1:07:37	SPEAKER_03
 So the first time it changes to another speaker, that will be speaker two.

1:07:41	SPEAKER_03
 And the next time it will be speaker three, even if it's actually speaker one.

1:07:44	SPEAKER_01
 That would be a very practical solution on that part.

1:07:47	SPEAKER_01
 But then we need to label it.

1:07:48	SPEAKER_05
 Yeah, we could probably regenerate it pretty easily from the close talking mics.

1:07:52	SPEAKER_05
 I was thinking the attempt, the attempt, the attempt, the analysis, what changes.

1:07:56	SPEAKER_05
 That doesn't answer the question.

1:07:58	SPEAKER_05
 It's a good point.

1:07:59	SPEAKER_05
 Which is what you do for this course tracking.

1:08:01	SPEAKER_02
 You don't need to know what is the identification of the speaker.

1:08:06	SPEAKER_02
 You don't need to know.

1:08:07	SPEAKER_05
 For acoustics you don't, but for discourse you do.

1:08:11	SPEAKER_05
 For the question.

1:08:12	SPEAKER_03
 Yeah, if someone says what is Jose doing and then Jose says something, you need to know that that was Jose responding.

1:08:20	SPEAKER_01
 And let's be adopted different set of norms, which is to not to make a point of not identifying people by name, which then leads you to be more contextual explicit.

1:08:31	SPEAKER_04
 That would be hot.

1:08:32	SPEAKER_01
 Well, people are very flexible.

1:08:34	SPEAKER_01
 You know what I mean?

1:08:35	SPEAKER_01
 So when we did this last week, I think that's what I'm saying.

1:08:36	SPEAKER_01
 I felt that, you know, Andreas, he sometimes people think of something else at the same time and they miss a sentence or something.

1:08:44	SPEAKER_01
 And because he missed something, then he missed the initial introduction of who we were talking about and was unable to do the tracking.

1:08:51	SPEAKER_01
 But I felt like most of us were doing the tracking and knew who we were talking about and we just weren't mentioning the name.

1:08:56	SPEAKER_01
 So people are really flexible.

1:08:58	SPEAKER_04
 But you know, like at the beginning of this meeting or you, I think said, you know, Liz said something about, is Morgane used the equipment?

1:09:07	SPEAKER_04
 I mean, how would you say that?

1:09:09	SPEAKER_04
 I mean, you have to really think, you know, about what you're saying.

1:09:14	SPEAKER_03
 Does you know who up and you know where?

1:09:16	SPEAKER_03
 Yeah.

1:09:17	SPEAKER_04
 I think it would be really hard if we made a call for you and saying that.

1:09:20	SPEAKER_05
 I was going to say is that the other option is that we can't leave out the names.

1:09:24	SPEAKER_05
 But then again, that kills your discourse now.

1:09:27	SPEAKER_05
 Yeah.

1:09:28	SPEAKER_04
 I think the, I think, I don't know, my own two-sense worth is that you don't do anything about what's in the recordings.

1:09:36	SPEAKER_04
 You only anonymize to the extent you can.

1:09:40	SPEAKER_05
 Well, but that said, that works great for the acoustics, but it hurts you a lot for trying to do discourse.

1:09:46	SPEAKER_05
 Yeah, why?

1:09:47	SPEAKER_05
 Because you don't have a map of who's talking versus their name that they're being referred

1:09:52	SPEAKER_04
 to.

1:09:53	SPEAKER_05
 I thought we were going to be referred to. Sure, but then you have to know that Jose is Speaker One.

1:09:56	SPEAKER_03
 Then you have to know who's being referred to.

1:09:57	SPEAKER_03
 Okay, so suppose someone says, well, I don't know if I really heard what, what, what Jose said.

1:10:05	SPEAKER_03
 And then Jose responds.

1:10:07	SPEAKER_03
 And part of your learning about the dialogue is Jose responding to it, but it doesn't say Jose, it says Speaker Five.

1:10:14	SPEAKER_03
 Okay.

1:10:15	SPEAKER_04
 So, oh, I see you want to associate the word Jose in the dialogue with the fact that then he responded.

1:10:22	SPEAKER_03
 Right.

1:10:23	SPEAKER_03
 And so if we pass out the data to someone else and it says Speaker Five there, we also have to pass them this little guide that says Speaker Five is Jose.

1:10:31	SPEAKER_03
 And we're going to do that.

1:10:33	SPEAKER_05
 We might as well give them Jose, say, and that violates our privacy issue.

1:10:37	SPEAKER_01
 Now, I think that we have these two phases in the data, which is the one which is our US University of Washington's use, IBM SRI.

1:10:44	SPEAKER_01
 And within that, it may be that it's sufficient to not change the, to not incorporate an automatization yet, but always, always in the publications we have to.

1:10:55	SPEAKER_01
 And I think also when we take it that next step and distribute it to the world we have to.

1:10:59	SPEAKER_01
 I don't, that's a long way for now.

1:11:01	SPEAKER_01
 And it's a matter between now and then.

1:11:03	SPEAKER_01
 I have to say.

1:11:04	SPEAKER_01
 It makes a decision.

1:11:05	SPEAKER_01
 You know, it may be that we will need to do something like actually ex out that part of the, for the public one, the audio and just put in bracket speaker one.

1:11:14	SPEAKER_05
 You know, what we could do also is have more than one version of release, one that's public and one that requires licensing.

1:11:21	SPEAKER_05
 And so the license one would, we could, it would be a sticky limitation.

1:11:25	SPEAKER_05
 You know, like, well, we can talk about that later.

1:11:27	SPEAKER_01
 I think that the public should be the same.

1:11:28	SPEAKER_01
 I think that when we do that world release it should be the same.

1:11:31	SPEAKER_01
 I agree with Jane.

1:11:32	SPEAKER_03
 I think that we, we have a need to have a consistent licensing policy as I'm sort.

1:11:37	SPEAKER_01
 I also think it consists of licensing.

1:11:39	SPEAKER_04
 Well, one thing to, to take into consideration is, are there any, for example, the people who are funding this work, they want this work to get out and be useful for discourse?

1:11:49	SPEAKER_04
 If we all of a sudden do this and then release it to the public and it's no longer useful for discourse, you know.

1:11:54	SPEAKER_05
 Well, depending on how much editing we do, you might be able to still have it useful.

1:11:58	SPEAKER_05
 Because for discourse, you don't need the audio, right?

1:12:02	SPEAKER_05
 So you could bleep out the names in the audio and use the anonymized one through the transcript.

1:12:06	SPEAKER_05
 Excuse me.

1:12:07	SPEAKER_05
 But if you release the audio for discourse, but, excuse me, you could bleep out just the names.

1:12:12	SPEAKER_03
 No, but she's saying from the argument before she wants to be able to save someone said Jose in their, in their thing and then connect to, right?

1:12:19	SPEAKER_05
 But in the transcript, you could say everywhere they said Jose that you could replace it with speaker seven.

1:12:26	SPEAKER_05
 Oh, I see.

1:12:27	SPEAKER_01
 Yeah, but I also want to see you.

1:12:30	SPEAKER_05
 And then it wouldn't match the audio anymore, but it would be still useful.

1:12:33	SPEAKER_05
 But both of those are publicly available.

1:12:36	SPEAKER_03
 But they, right.

1:12:39	SPEAKER_03
 And the other thing is if Liz were here, what she might say is that she wants to look at things that cut across between the audio and the dialogue.

1:12:46	SPEAKER_01
 And so, yeah, I think we have to think about how, I think this can't be decided today.

1:12:53	SPEAKER_01
 Yeah, okay.

1:12:54	SPEAKER_01
 It was good to introduce the thing in.

1:12:58	SPEAKER_05
 When I wrote you that email, I wasn't thinking it was a big can of worms, but I guess it

1:13:01	SPEAKER_01
 is.

1:13:02	SPEAKER_05
 Yeah, a lot of discourse.

1:13:03	SPEAKER_01
 Well, discourse, you know, also, I'm going to make the point that discourse is going to be more than just looking at a transcript.

1:13:08	SPEAKER_01
 It's going to be interesting.

1:13:09	SPEAKER_01
 Oh, yeah, sure.

1:13:10	SPEAKER_01
 And prosoprosotic stuff is involved.

1:13:12	SPEAKER_01
 And that means you're going to be listening to the audio.

1:13:14	SPEAKER_01
 And then you come directly into this, confronting this problem.

1:13:17	SPEAKER_04
 Maybe we should just not allow anybody to do research on discourse.

1:13:19	SPEAKER_04
 I'm really glad.

1:13:20	SPEAKER_01
 I wish you just marketed to non-English speaking countries.

1:13:26	SPEAKER_03
 Maybe we should only have meetings between people who don't know one another and who are also amnesiax who don't know their own names.

1:13:32	SPEAKER_01
 Did you mean the paper and yours?

1:13:34	SPEAKER_01
 We have little labels.

1:13:35	SPEAKER_01
 I want to introduce my reservoir dog solution again.

1:13:38	SPEAKER_01
 Mr. White.

1:13:39	SPEAKER_01
 Mr. White, Mr. Pink.

1:13:40	SPEAKER_05
 Did you read the paper a few years ago where they were reversing the syllables?

1:13:46	SPEAKER_05
 They had utterances and they would extract out the syllables and they would play them backwards.

1:13:52	SPEAKER_04
 But the syllables were in the same order.

1:13:56	SPEAKER_04
 Everything was in the soil.

1:13:57	SPEAKER_05
 But the individual syllables were played backwards.

1:14:00	SPEAKER_05
 And you could listen to it.

1:14:01	SPEAKER_05
 And it would sound the same if people had no difficulty interpreting it.

1:14:05	SPEAKER_05
 So what we need is something that's the reverse.

1:14:07	SPEAKER_05
 That a speech recognizer works exactly the same on it, but people can't understand.

1:14:11	SPEAKER_05
 Oh, well, that's easy way to do that.

1:14:15	SPEAKER_03
 Just play it all backwards.

1:14:17	SPEAKER_03
 Oh, right.

1:14:18	SPEAKER_03
 That speech recognizer is totally symmetric.

1:14:20	SPEAKER_03
 Was the speech recognizer correct?

1:14:21	SPEAKER_03
 No, anyway.

1:14:22	SPEAKER_03
 How do we do digit zero?

1:14:25	SPEAKER_05
 We already missed the party.

1:14:27	SPEAKER_05
 Okay.

1:14:28	SPEAKER_05
 Reading 1471-1490-9015-2430-39425456084833936-03702-08348302 Strike that 086311823053900628375168729039989276

1:15:03	SPEAKER_03
 Transcript 1531-155012050830536778 9896 0 0 0 131 2 1 0 35 4 2914 5702 6 7 8 0 308 0 0 1 0 1 14 9 1 0 0 3

1:15:41	SPEAKER_04
 Transcript 1631-16505 0 7 2 8 5 9 8 6 8 7 0 8 3 0 9 1 1 0 8 4 1 2 0 4 3 5 2 6 5 8 7 7 2 7 8 9 0 0 8 0 3 1 3 1 2 6 3 3 4 7 1 5

1:16:20	SPEAKER_01
 Transcript 1331-1350305396804 6 2 7 6 8 8 9 0 9 7 6 9 9 4 6 0 0 0 3 2 1 0 5 3 4 4 2 7 5 0 4 6 7 3 5 8 9 5 7 2 9 8 2 3 6 7 8 8 0 8 8 0 2 9 0 4 7 1 8 0 9

1:16:57	SPEAKER_02
 9 2 6 5 3 903. 7 9 7 6 3 0 0 7 0 0 4 0 8 6 8 7 1 3 1 2 3 0 3 0 5 3 3 0 6 6 5 8 7 8 2 0 7 0 0

1:17:40	SPEAKER_04
 Okay, go off here. I think it would be fun sometime to read them with different intonations, like is if you were talking like 9 8 6 8 7.

1:17:52	SPEAKER_01
 Well, you know, in the one I transcribed, I did find it, I found one instance of contrastive stress where it was like the string had a, so it was like 9 8 2 4 9 9 2 4.

1:18:02	SPEAKER_01
 Oh, really? So they were like looking ahead, huh?

1:18:06	SPEAKER_01
 I mean, they differed. I mean, at that, that session, I did feel like they did it more sentences, but sometimes people do it as phone numbers.

1:18:13	SPEAKER_01
 I mean, I, I'm interested in, and sometimes, you know, and I, I never, when I do it, I, I ask myself what I'm doing.

1:18:20	SPEAKER_04
 Yeah, well, I was thinking that it must get kind of boring for the people who are going to have to transcribe this.

1:18:25	SPEAKER_01
 Well, except Rowan's interesting information.

1:18:27	SPEAKER_01
 I like your question, that's very funny. I haven't heard that one.

1:18:29	SPEAKER_05
 We have the transcript. We have the actual numbers they're reading, so we're not necessarily depending on that.

1:18:33	SPEAKER_05
 Okay, I'm going to go off.

