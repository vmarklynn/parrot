0:00:00	SPEAKER_03
 Okay, so I got these results from CIFON.

0:00:21	SPEAKER_03
 So I think that we might hear later today about other results.

0:00:31	SPEAKER_03
 And there are some other very good results compared to other results from other places.

0:00:39	SPEAKER_03
 I'm sorry.

0:00:40	SPEAKER_03
 I got this from you.

0:00:42	SPEAKER_03
 And then I sent a note to CINNAL about because he has been running some other systems other than the XEOG.

0:00:52	SPEAKER_03
 I want to see what that is.

0:00:53	SPEAKER_03
 But, you know, so we'll see what is comparatively later.

0:00:56	SPEAKER_03
 But it looks like most of the time even though it's true that the overall number for damage is we didn't improve it.

0:01:07	SPEAKER_03
 If you look individually, what I really say is that there's looks like out of the six cases between the different kinds of matching conditions.

0:01:21	SPEAKER_03
 Out of the six cases, there's basically a couple of states about the same.

0:01:29	SPEAKER_03
 Three work gets better and one work gets worse.

0:01:34	SPEAKER_04
 Actually, for the damage, there's still some kind of mystery because when we use the straight features, we are not able to get this nice number with the XEOG I1.

0:01:50	SPEAKER_04
 We don't have this 93.78.

0:01:53	SPEAKER_00
 89.44.

0:01:57	SPEAKER_04
 So, there's probably something wrong with the feature that we get from Boji and Sunili is working on.

0:02:06	SPEAKER_03
 Oh, let me have a little time on that actually.

0:02:09	SPEAKER_03
 We have a little bit of time on that actually.

0:02:12	SPEAKER_03
 Yeah, there it sounds.

0:02:14	SPEAKER_03
 When do you folks leave?

0:02:16	SPEAKER_04
 Sunday.

0:02:18	SPEAKER_03
 Sunday.

0:02:21	SPEAKER_03
 Saturday, midnight or something.

0:02:30	SPEAKER_03
 That would be good.

0:02:33	SPEAKER_03
 That would be good.

0:02:36	SPEAKER_03
 And, you know, whenever anybody figures it out, they should also, for sure, email Heenik because Heenik will be over there telling people we did some of these.

0:02:57	SPEAKER_03
 So, we'll hold off on that a little bit. Even with these results as they are, it's really not that bad.

0:03:06	SPEAKER_03
 It looks like the overall result, as they are now, even without any bugs being fixed, is that on the other tasks, we had this average of 49% or so improvement.

0:03:23	SPEAKER_03
 And here we have somewhat better than that in the Danish and so on.

0:03:27	SPEAKER_03
 Worst than that in German.

0:03:29	SPEAKER_03
 But, I mean, it sounds like one way or another of the methods that we're doing can reduce the error rate of mail capture down by 4th of them to a half of them.

0:03:44	SPEAKER_03
 So, I'm not depending on that.

0:03:46	SPEAKER_03
 Yeah, the exact case.

0:03:48	SPEAKER_03
 So, that's good.

0:03:52	SPEAKER_03
 I mean, I think that one of the things that Heenik was talking about was understanding what was in the other really, the proposals and trying to see if what should ultimately be proposed to some combination of things.

0:04:07	SPEAKER_03
 Because there's things that they are doing there that we certainly are not doing.

0:04:13	None
 And there's things that we're doing that they're not doing.

0:04:16	SPEAKER_02
 Like the things.

0:04:22	SPEAKER_03
 How much better was the best system than ours?

0:04:25	SPEAKER_03
 Well, we don't know yet.

0:04:27	SPEAKER_03
 I mean, first place there's still this thing to work out.

0:04:30	SPEAKER_03
 And second place, second thing is that the only results that we have so far before were really development and results.

0:04:36	SPEAKER_03
 And this community that's of interest, it's not like everything is being pinned on the evaluation set. But for the development set, our best result was a little bit short of 50%.

0:04:49	SPEAKER_03
 And the best result of any system was about 54.

0:04:53	SPEAKER_03
 Where these numbers are the relative reduction in word error rate.

0:04:59	SPEAKER_03
 Oh, okay.

0:05:01	SPEAKER_03
 The other systems were somewhat lower than that.

0:05:06	SPEAKER_03
 There was actually, it was much less of a huge range than there was in a RR1.

0:05:10	SPEAKER_03
 There were systems that basically didn't approve things.

0:05:14	SPEAKER_03
 And here the worst system still reduced their rate by 33%.

0:05:20	SPEAKER_03
 So, you know, sort of everybody is doing things roughly 30 years and half a year is being created and bearing on different tests and so forth.

0:05:30	SPEAKER_03
 So, I think it's probably a good time to look at what's really going on.

0:05:35	SPEAKER_03
 And see if there's a way to combine the best ideas while at the same time not blowing up the amount of resources used.

0:05:43	None
 That's critical.

0:05:46	SPEAKER_02
 Do we know anything about who's wasn't that had the lowest on the Devset?

0:05:51	SPEAKER_03
 There were two systems that were put forth by a combination of French telecom and Alcatel.

0:06:01	SPEAKER_03
 And they differ in some respects.

0:06:04	SPEAKER_03
 But one was called the French telecom, Alcatel system.

0:06:09	SPEAKER_03
 It was called the Alcatel French telecom system.

0:06:12	SPEAKER_03
 It was the biggest difference.

0:06:15	SPEAKER_03
 And they both did very well.

0:06:21	SPEAKER_03
 So, my impression is they also did very well on the evaluation set.

0:06:28	SPEAKER_03
 But we haven't seen any minor results from that.

0:06:33	SPEAKER_02
 And they used the main thing that they used with spectral subtraction?

0:06:37	SPEAKER_03
 There was a couple pieces to it.

0:06:39	SPEAKER_03
 There was a spectral subtraction.

0:06:41	SPEAKER_03
 And there was some modification of the capture of parameters.

0:06:48	SPEAKER_04
 Yeah, actually something that's close to kept strumming subtraction.

0:06:53	SPEAKER_04
 But the way the mean is adapted, it's signal dependent.

0:07:00	SPEAKER_04
 So basically the mean is adapted during speech and not during silence.

0:07:04	SPEAKER_04
 But it's very close to kept strumming subtraction.

0:07:07	SPEAKER_03
 And we've done exactly that sort of thing to look in speech only to try to measure these things.

0:07:17	SPEAKER_03
 So it looks like they did some reasonable things.

0:07:23	SPEAKER_03
 And we did unreasonable things.

0:07:29	SPEAKER_03
 Because we like to try strange things.

0:07:32	SPEAKER_03
 And our things work too.

0:07:36	SPEAKER_03
 It's possible that some combination of these different things that we're done will be the best thing to do.

0:07:42	SPEAKER_03
 But the only caveat to that is that everybody is being real conscious of how much memory, how much CPU they're using.

0:07:48	SPEAKER_03
 Because these standards are supposed to go on cell phones with moderate resources, both your specs.

0:07:55	SPEAKER_02
 Did anybody do anything with the models as an experiment?

0:08:00	SPEAKER_03
 They didn't report it.

0:08:02	SPEAKER_03
 I think everybody was focused elsewhere.

0:08:06	SPEAKER_03
 Now one of the things that's nice about the CPU did is we do have a filter in which leads to a production of the bandwidth and the modulation spectra, which allows us to down sample.

0:08:20	SPEAKER_03
 So as we know that we have a reduced transmission rate for the bands.

0:08:28	SPEAKER_03
 Now it was reported the first time out. It said the same amount because for convenience sake, in a particular way, this is being tested.

0:08:36	SPEAKER_03
 They were repeating the packets.

0:08:39	SPEAKER_03
 They had 2400 bits per second, but they were literally creating 4800 bits per second.

0:08:48	SPEAKER_02
 So you could have had a repeat count in there or something.

0:08:52	SPEAKER_03
 This was just a funny thing to fit into the software that was testing the errors, channel errors, and so on.

0:08:59	SPEAKER_03
 So in reality, if you put this system into the field, it would be 2400 bits per second.

0:09:07	SPEAKER_03
 So that's a nice feature of what we did.

0:09:12	SPEAKER_03
 But we still have to see how it all comes out. And then there's the process, which is a lot together.

0:09:22	SPEAKER_02
 When is the development set? I mean the test set results do. Like the day before you leave or something?

0:09:30	SPEAKER_03
 Probably the day after they leave, but we'll have to stop it the day before.

0:09:36	SPEAKER_03
 I think the meeting is on 13th or something.

0:09:43	SPEAKER_03
 Yeah, it's Tuesday.

0:09:47	SPEAKER_03
 And the results are due like the day before you leave or something.

0:09:57	SPEAKER_03
 Yeah, probably one.

0:09:59	SPEAKER_03
 I think they are. Yeah, so since we have a bit farther to travel.

0:10:08	SPEAKER_03
 I'll have to get that a little quicker.

0:10:11	SPEAKER_03
 I mean, it's just tracing down these bugs. I mean, just exactly this sort of thing.

0:10:16	SPEAKER_03
 Why these features seem to be behaving differently in California than in Oregon.

0:10:22	SPEAKER_03
 I guess something to do with electricity shortage. We can have enough electrons here.

0:10:31	SPEAKER_03
 But I think the main reason for having, you know, it takes to run the two test sets in just in computer time.

0:10:40	SPEAKER_03
 It's just a day or so.

0:10:44	SPEAKER_03
 And so I think the whole reason for having as long as we have, which is like we can have this because of bugs like that.

0:10:56	SPEAKER_03
 So we're going to end up with these same kind of sheets that have the percentages.

0:11:01	SPEAKER_04
 Yeah, so there are two more calamity machines. I guess it's the same sheets.

0:11:05	SPEAKER_04
 Yeah, it's the same sheets.

0:11:09	SPEAKER_03
 Yeah. So I'll just regard these numbers. That's good.

0:11:17	SPEAKER_04
 So you can try to push for trying to combine different things.

0:11:24	SPEAKER_03
 Well, let's.

0:11:29	SPEAKER_03
 Yeah, I mean, I think the question is, is there is there some advantage?

0:11:33	SPEAKER_03
 I mean, you could just take the best system and say that's the standard. But the thing is that if different systems are getting at good things, begin with in the constraint of the resources.

0:11:45	SPEAKER_03
 If there's something simple that you could do.

0:11:47	SPEAKER_03
 For instance, I think very reasonable to have a standard for the terminal side.

0:11:53	SPEAKER_03
 And then for the server side, say here's a number of things that could be done.

0:11:57	SPEAKER_03
 So everything we did could probably just be added on to what Alcatel did.

0:12:03	SPEAKER_03
 We're pretty well with them too.

0:12:07	SPEAKER_03
 So that's one aspect of it.

0:12:11	SPEAKER_03
 And then on the terminal side, I don't know how much memory and CPU it takes.

0:12:18	SPEAKER_03
 But it seems like the filtering.

0:12:21	SPEAKER_03
 I mean, the VAD stuff they both had, right?

0:12:25	SPEAKER_03
 So, and they both had some kind of online normalization.

0:12:31	SPEAKER_03
 So it seems like the main difference there is the filtering.

0:12:37	SPEAKER_03
 And the filtering, I think, if you can, it shouldn't take a lot of memory to do that.

0:12:43	SPEAKER_03
 And I also wouldn't think the CPU would be much either.

0:12:48	SPEAKER_03
 So if you can add those in, then you can cut the data right now.

0:12:57	SPEAKER_03
 So it seems like the right thing to do is to, on the terminal side, take what they did if it does seem to generalize well to German Danish.

0:13:06	SPEAKER_03
 Take what they did, add in a filter and add in some stuff on the server side.

0:13:12	SPEAKER_03
 And that's probably a reasonable standard.

0:13:16	SPEAKER_04
 They are working on this already because some filter will be that you are trying already to put some kind of...

0:13:24	SPEAKER_03
 Yeah, so that's the thing.

0:13:27	SPEAKER_03
 That would be ideal, if they could actually show that in fact the combination of some sort would work even better than any other system chat.

0:13:38	SPEAKER_03
 And then it would be something to discuss on the meeting.

0:13:45	SPEAKER_03
 But not clear what will go on.

0:13:50	SPEAKER_03
 I mean, on the one hand, sometimes people are just anxious to get a standard out there and you can always have another standard after that.

0:13:59	SPEAKER_03
 But this process is going on for a while already.

0:14:03	SPEAKER_03
 Might just want to pick something and say, okay, this is it.

0:14:07	SPEAKER_03
 And then that's a standard.

0:14:10	SPEAKER_03
 Standards are always optional, it's just that if you disobey them, then you risk not being able to sell your product.

0:14:21	SPEAKER_03
 And people often work on new standards, well-known standards, and so on.

0:14:25	SPEAKER_03
 So it's not final, even if they declare a standard.

0:14:28	SPEAKER_03
 The other hand, they might just say they just don't know enough yet to declare a standard.

0:14:35	SPEAKER_03
 You will become experts on this, more firm or than me, but this particular standard is brought since once you go to this meeting.

0:14:46	SPEAKER_03
 So I'd be interested hearing your thoughts now.

0:14:52	SPEAKER_03
 I mean, you're almost done.

0:14:54	SPEAKER_03
 I mean, you're done in the sense that maybe you'll get some new features from snail and we'll rerun it.

0:15:01	SPEAKER_03
 But other than that, you're basically done.

0:15:06	SPEAKER_03
 So you're just hearing your thoughts about where you think we should go from this.

0:15:14	SPEAKER_03
 I mean, you're trying a lot of things in a hurry.

0:15:18	SPEAKER_03
 And if we can back off from this now and sort of take our time with something that is doing things quickly, be quite so much the constraint, what you think would be the best thing to do.

0:15:31	SPEAKER_04
 Well, first, to really have a look at the speech from this database is because we tried several things, but we didn't really look.

0:15:46	SPEAKER_04
 What's happening?

0:15:48	SPEAKER_04
 Where is the noise?

0:15:55	SPEAKER_03
 It's a novel idea.

0:15:58	None
 Look at the data.

0:16:05	SPEAKER_03
 More generally, I guess, what is causing the degradation.

0:16:17	SPEAKER_03
 Yeah, yeah.

0:16:20	SPEAKER_04
 Actually, there is one thing that generally we think that most of the errors are within phoneme classes.

0:16:36	SPEAKER_04
 So I think it could be interesting to see if it, I don't think it's still true when we add noise.

0:16:42	SPEAKER_04
 So I guess the confusion, the confusion, matrices are very different when we have noise.

0:16:49	SPEAKER_04
 When it's clean speech.

0:16:52	SPEAKER_04
 And probably there is much more between classes errors or noisy speech.

0:17:02	SPEAKER_04
 So, perhaps we could have a large gain just by looking at improving the recognition, not phoneme, but phoneme classes simply.

0:17:20	SPEAKER_04
 Which is a simpler problem perhaps, but which is perhaps important for noisy speech.

0:17:27	SPEAKER_03
 So the other thing that strikes me just looking at these numbers is just taking the best cases.

0:17:32	SPEAKER_03
 Some of these, of course, even with all of our wonderful processes, still our horrible kinds of numbers.

0:17:37	SPEAKER_03
 Just take the best case, the well matched, the German case after, or well matched, Danish, after we, kind of numbers we're getting are about 8% error per digit.

0:17:55	SPEAKER_03
 Yeah, this is obviously not usable.

0:17:58	SPEAKER_03
 I mean, you have 10 digits.

0:18:00	SPEAKER_03
 Oh, no, not very bad.

0:18:02	SPEAKER_03
 Now then you get it right.

0:18:06	SPEAKER_03
 So, I mean the other thing is that, and also part of what's nice about this is that this is almost realistic database. I mean, it's still not people who are really trying to accomplish something.

0:18:26	SPEAKER_03
 But within the artificial setup, it isn't noise artificially simulated.

0:18:32	SPEAKER_03
 It's real noise condition.

0:18:36	SPEAKER_03
 And the training, I guess, is always done on close talking?

0:18:43	SPEAKER_04
 No, actually, actually the well matched condition is still quite difficult.

0:18:50	SPEAKER_04
 They have all these data from the close mic and from the decent mic, from different driving conditions, open window, close window, and they take all of this, and they take 70% for training and 30% for testing.

0:19:06	SPEAKER_04
 So training is done on different conditions and different microphones and testing also is done on different microphones and conditions.

0:19:15	SPEAKER_04
 So probably if we only take the closed microphones, I guess the research should be much, much better than this.

0:19:23	SPEAKER_03
 I see.

0:19:24	SPEAKER_03
 Okay, that's better.

0:19:25	SPEAKER_04
 So there is this, the mismatch is the same kind of thing, but the driving conditions, I mean the speed and the kind of road is different for training and testing.

0:19:42	SPEAKER_04
 And the last condition is closed microphone for training and this done for testing.

0:19:53	SPEAKER_03
 Okay, so the highly mismatched case is in some sense a good model for what we've been typically talking about when we talk about added noise.

0:20:11	SPEAKER_03
 And so it does correspond to a realistic situation in the sense that people might really be trying to call out telephone numbers or something like that in their cars.

0:20:26	SPEAKER_03
 They're trying to connect to something.

0:20:28	SPEAKER_04
 Actually, yeah, it's very close to clean speech training because the closed microphone and noisy speech testing.

0:20:36	SPEAKER_03
 And the well-matched condition is what you might imagine that you might be able to approach if you know that this is the application, you're going to record a bunch of people in cars and so forth, do these training.

0:20:49	SPEAKER_03
 And then when you sell it to somebody, it will be a different person with a different car and so on.

0:20:55	SPEAKER_03
 So this is somewhat optimistic to view on it.

0:20:59	SPEAKER_03
 So the real thing is probably somewhere in between the two. But even the optimistic one is working.

0:21:09	SPEAKER_03
 Yeah, right.

0:21:11	SPEAKER_03
 That's sort of the dominant thing is even say under development set stuff that we saw the numbers that Alcatel was getting, which was the best single numbers.

0:21:22	SPEAKER_03
 It just wasn't good enough for real system.

0:21:28	SPEAKER_03
 So still a lot of stuff to do.

0:21:35	SPEAKER_03
 And I don't know.

0:21:43	SPEAKER_03
 So looking at the data, what's the characteristic of the thing?

0:21:51	SPEAKER_03
 What are your thoughts about what else you're thinking about?

0:21:58	SPEAKER_00
 A lot of things. Because we're trying a lot of things and we're not working.

0:22:05	SPEAKER_00
 We remove this. Maybe we try again with the articulatory feature.

0:22:11	SPEAKER_00
 I don't know exactly because we tried with some one experiment and some work and forgot it.

0:22:18	SPEAKER_00
 I don't know if it's a trip because maybe to better some step of the general diagram.

0:22:29	SPEAKER_00
 I don't know if it's a trip to think what we can improve.

0:22:36	SPEAKER_03
 Yeah, because a lot of times it's true. There were a lot of times when we tried something and it didn't work right away.

0:22:43	SPEAKER_03
 Even though we had an intuition that there should be something there, so then we would just stop it.

0:22:50	SPEAKER_03
 One of the things, I don't remember the details on, but I remember at some point when we were working with a second stream in which I had a fast filtering and a cap stream.

0:23:02	SPEAKER_03
 In some case you got, well, it was an MSG-like thing, but it was an MSG.

0:23:08	SPEAKER_03
 I think in some case you got some little improvement, but it was sort of a small improvement and it was a big added complication, so you dropped it.

0:23:17	SPEAKER_03
 But that was just sort of one try, right? Just took one filter through it there, right?

0:23:22	SPEAKER_03
 And it seems to me that if that isn't an important idea, it might be that one could work at it for a while as you're saying.

0:23:33	SPEAKER_03
 And you had the multi-band thing, so there's an issue with that.

0:23:38	SPEAKER_03
 Barry is going to be continuing working on multi-band things as well.

0:23:43	SPEAKER_03
 We were just talking about some work that we were interested in, kind of inspired by the stuff where Larry saw the learning and articulatory feature, I think in the case of his paper, with Sonderance based on multi-band information, where you have a combination of gradient learning and, yeah.

0:24:09	SPEAKER_03
 So I think that this is a neat data set, and then, as we mentioned before, we also have the new digit set coming up from recordings in this room.

0:24:25	SPEAKER_03
 So there's a lot of things to work with.

0:24:29	SPEAKER_03
 Yeah, what I like about it in a way is that the results are still so terrible.

0:24:36	SPEAKER_03
 I mean, they're much better than they were. You know, we're talking about 30 to 60% error rate reduction, and it's really great stuff to do that relatively short time.

0:24:49	SPEAKER_03
 But even after that, it's still poor that we could use it.

0:24:56	SPEAKER_03
 I think that's great, and also because, again, it's not something... sometimes we've got terrible results by taking some data and are officially involving it with some new response or something to take it very one point of binding on downstairs into the basement.

0:25:13	SPEAKER_03
 It's a hallway that is very reverberant, and we made some recordings there, and then we made a simulation of the room acoustics there and applied it to other things.

0:25:27	SPEAKER_03
 But it was all pretty artificial, and how often would you really try to have your most crucial conversations in this very reverberant hallway?

0:25:37	SPEAKER_03
 So this was nice about the Aurora data and the data here is that it's sort of a realistic room situation, acoustics situation, with terms of noise and reflections and so on.

0:25:53	SPEAKER_03
 It's something that's still relatively realistic, it's still very hard to do it well.

0:26:00	SPEAKER_04
 Yeah, so... well... actually, that's why we... well, it's a different kind of data, we're not used to work with this kind of data.

0:26:15	SPEAKER_04
 That's why we should have a little more closer look at what's going on.

0:26:20	SPEAKER_04
 So this would be the first thing, and then of course try to... well, kind of debug what was wrong when we do a lot of tests on the MLG, particularly on the multiband.

0:26:39	SPEAKER_04
 Yeah.

0:26:40	SPEAKER_03
 Yeah. Yeah, I think there's lots of... it's a good thing to do with this.

0:26:50	SPEAKER_03
 So... so let's... I guess... you can see as well.

0:27:03	SPEAKER_02
 What do you think?

0:27:05	SPEAKER_02
 About... anything?

0:27:07	SPEAKER_02
 About other experiences.

0:27:10	SPEAKER_02
 Now I'm interested in looking at the experiments where you use data from multiple languages to train to neural net.

0:27:21	SPEAKER_02
 I don't know how far... or if you guys even had a chance to try that, but that would be something to be interesting to me.

0:27:27	SPEAKER_04
 Yeah, but again it's the kind of thing that you were thinking that it would work, but it didn't work.

0:27:37	SPEAKER_04
 And... sorry.

0:27:39	SPEAKER_04
 Not a bug, but something wrong in that we...

0:27:42	SPEAKER_04
 Right.

0:27:43	SPEAKER_04
 And... something wrong, perhaps, in the... just in the fact that the labels are... what work best is the end-leabled data?

0:27:53	SPEAKER_04
 So, yeah. I don't know if we can get some end-leabled data from other languages.

0:27:59	SPEAKER_04
 Yeah.

0:28:00	SPEAKER_04
 It's not so easy to find.

0:28:02	SPEAKER_04
 Right.

0:28:03	SPEAKER_04
 But that would be something interesting to me.

0:28:06	SPEAKER_03
 Yeah.

0:28:07	SPEAKER_03
 Also, there was just a whole notion of having multiple nets that were trained on different data.

0:28:13	SPEAKER_03
 So one form of different data is from different languages, but the other...

0:28:17	SPEAKER_03
 Well, in fact, in those experiments there wasn't so much combining multiple nets. It was a single net that had different.

0:28:23	SPEAKER_03
 Yeah.

0:28:24	SPEAKER_03
 So first thing is, would it be better if they were multiple nets?

0:28:27	SPEAKER_03
 So the second thing is never mind the different languages, just having different acoustic conditions, rather than training them all up and one,

0:28:35	None
 would it be helpful to have different ones? So that was a question that was kind of raised by Mike Chares, these were seen in that case in terms of through preparation.

0:28:46	SPEAKER_03
 Sometimes it might be better to do that.

0:28:51	SPEAKER_03
 But I think we know.

0:29:00	SPEAKER_03
 So, all right. So next week we won't meet because you'll be here.

0:29:08	None
 And when are you two getting back?

0:29:12	SPEAKER_00
 I'm...

0:29:16	SPEAKER_00
 Sunday because it's less expensive than practice.

0:29:21	SPEAKER_00
 I'm not a ticker.

0:29:23	SPEAKER_04
 Right. I'll be back Tuesday.

0:29:25	SPEAKER_02
 Where is the meeting?

0:29:27	SPEAKER_03
 Amsterdam, I think.

0:29:33	SPEAKER_03
 So we'll skip next week and we'll meet two weeks from now.

0:29:37	SPEAKER_03
 And I guess the main topic will be telling us what happened.

0:29:43	None
 Yeah.

0:29:44	SPEAKER_00
 Yeah.

0:29:46	SPEAKER_03
 So, yeah. Well, we don't have anything else we should turn off the machine and say we don't ask you for.

0:29:55	SPEAKER_02
 Should we do digits first?

0:29:57	SPEAKER_03
 Oh yes, digits. Yeah, good point.

0:30:00	SPEAKER_02
 Okay. Transcript 37913810904 02007 11704 240921 3613509 495 60607 85680 97 0509 0505 0701009 1 2 3 0 7 9 8 8 0 5 7 6 3 9 7 7 1 8 8 9

0:30:48	SPEAKER_03
 Transcript 3751-3770 8 557 306 9 6 6 0 0 0 1 2 0 4 2 5 5 6 6 6 7 8 2 8 9 0 0 1 1 2 3 4 3 8 6 4 4 8 3 5 6 7 0 4 3 0 0 7

0:31:26	SPEAKER_01
 Transcript 3671-36904 5004 27203 8530510 9718 476 0 9 4 5 103 2 4 115 5 4 9 9 2 6 6 3 7 7 9 8 8 0 0 2 8 5 9 0 7 0 0 0 8 1 2 2 8 6 8 3 5 3 7 10 9 4 5

0:32:20	SPEAKER_04
 Transcript 6 9, yeah, sorry. Transcript 3691-3714-5 6 9 4 5 015-032-1720-2624-304-405-4 617-hoho 758-628-3 8 8 4 9 8 0 0 0 19 8 1 0 0 3 2 8 0 9 4 2 5 4 5

0:33:10	SPEAKER_00
 Transcript number 3771-3790 9 1 0 8 0 4 6 9 0 0 0 6 4 7 6 5 9 9 0 8 5 7 6 7 2 8 5 6 8 3 6 7 4 1 3 9 8 9 0 0 1 1 I'm sorry 1 1 1 3 1 4 4 7 5 7 7 3 6 9 6 5 7 8

