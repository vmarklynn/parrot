0:00:00	SPEAKER_02
 Okay, so we had a meeting with Heneck, in which snow and stuff on the

0:00:48	SPEAKER_03
 What was the update? What was the update?

0:00:52	SPEAKER_03
 Yeah.

0:00:53	None
 So there is nothing.

0:00:55	None
 All the new features.

0:00:57	SPEAKER_03
 All right, suppression.

0:01:00	SPEAKER_03
 The CVS.

0:01:03	SPEAKER_05
 Is the CVS mechanism working well?

0:01:08	SPEAKER_05
 Are people epidemiogi-gramming code via that?

0:01:13	SPEAKER_01
 I don't think...

0:01:14	SPEAKER_01
 I don't think they use it?

0:01:15	SPEAKER_01
 Yeah, I don't think anybody up there is working on it right now.

0:01:20	SPEAKER_02
 I think it's more likely that what it means is that when Sunil is up there, he will grab it.

0:01:24	SPEAKER_01
 Yeah.

0:01:25	SPEAKER_01
 So right now nobody is working on it.

0:01:27	SPEAKER_02
 Yeah, they're working on different tasks.

0:01:30	SPEAKER_02
 But what will happen is he'll go back up there and Prattibah will come back from these coasts.

0:01:39	SPEAKER_02
 And I guess actually after your speech for a little bit, he'll go up there too.

0:01:44	SPEAKER_02
 So actually everybody who is working on it will be up there for at least a little while.

0:01:48	SPEAKER_02
 So they'll remotely access it.

0:01:50	SPEAKER_05
 So has anybody tried remotely accessing the CVS using SSH?

0:01:57	SPEAKER_03
 I don't know if I read that.

0:02:00	SPEAKER_01
 I can actually do it today.

0:02:01	SPEAKER_01
 I can just log into...

0:02:03	SPEAKER_01
 Have you tried it yet?

0:02:04	SPEAKER_01
 No, I didn't.

0:02:05	SPEAKER_03
 I tried it.

0:02:10	SPEAKER_03
 Yeah.

0:02:11	SPEAKER_03
 It worked really well.

0:02:14	SPEAKER_03
 Okay.

0:02:15	SPEAKER_03
 So right now it's a mechanism with SSH.

0:02:19	SPEAKER_03
 I didn't set up...

0:02:21	SPEAKER_03
 You can also set up a CVS server on a new core.

0:02:25	SPEAKER_05
 Yeah, right.

0:02:28	SPEAKER_05
 And that's used in CVS password.

0:02:30	SPEAKER_05
 So when you came in from Belgian, Belgian using SSH, was it asking you for your own password into ICSI?

0:02:44	SPEAKER_05
 So if you can only do that if you have an account to ICSI.

0:02:48	SPEAKER_05
 Because there isn't a way to set up anonymous CVS.

0:02:52	SPEAKER_03
 Yeah, this way you have to set up a CVS server or put them...

0:02:56	SPEAKER_03
 Yeah, you can access it.

0:02:58	SPEAKER_03
 Okay, so the anonymous mechanism...

0:03:01	SPEAKER_03
 You can access it.

0:03:04	SPEAKER_05
 Because a lot of the open-source stuff works with anonymous CVS.

0:03:08	SPEAKER_05
 And I'm just wondering...

0:03:10	SPEAKER_05
 I mean, for our transcripts, we may want to do that.

0:03:13	SPEAKER_02
 Yeah.

0:03:14	SPEAKER_02
 Yeah, for this stuff, I don't think we're quite up to that.

0:03:16	SPEAKER_02
 I mean, we're still so much in development.

0:03:18	SPEAKER_05
 We want to have just the insiders.

0:03:21	SPEAKER_05
 Of course.

0:03:22	SPEAKER_05
 Yeah.

0:03:23	SPEAKER_05
 Yeah.

0:03:24	SPEAKER_05
 Okay.

0:03:25	None
 Cool.

0:03:26	None
 Yeah.

0:03:27	SPEAKER_02
 So...

0:03:32	SPEAKER_05
 What's name?

0:03:34	SPEAKER_02
 Well, I mean, I think maybe the thing to be...

0:03:37	SPEAKER_02
 I'm sure you've just been working on details of that since the meeting, right?

0:03:42	SPEAKER_02
 I mean, so...

0:03:44	SPEAKER_03
 Since the meeting?

0:03:45	SPEAKER_02
 Yeah, that was Tuesday.

0:03:47	SPEAKER_02
 Training a new PD and a new feature name.

0:03:51	SPEAKER_04
 Okay.

0:03:52	SPEAKER_03
 So this should be right?

0:03:55	SPEAKER_02
 But I guess maybe the thing...

0:03:57	SPEAKER_02
 Since you guys weren't at that meeting, might be just to...

0:04:03	SPEAKER_02
 sort of recap the conclusions of the meeting.

0:04:07	SPEAKER_02
 You're talking about meeting with Heena.

0:04:09	SPEAKER_02
 Yeah, because that was sort of...

0:04:11	SPEAKER_02
 We'd sort of been working up to that that he would come here this week.

0:04:14	SPEAKER_02
 And we would sort of...

0:04:16	SPEAKER_02
 He's going out of town like now.

0:04:19	SPEAKER_02
 And I'm going out of town a couple of weeks.

0:04:22	SPEAKER_02
 And time is marching, sort of...

0:04:25	SPEAKER_02
 Given all the many wonderful things we could be working on, what will we actually focus on?

0:04:31	SPEAKER_02
 And what do we freeze?

0:04:33	SPEAKER_02
 And, you know, what do we...

0:04:35	SPEAKER_02
 So, I mean, this software that these guys created was certainly a key part.

0:04:39	SPEAKER_02
 So then there's something central.

0:04:41	SPEAKER_02
 And there are at least a bunch of different versions going off in ways that differ trivially.

0:04:48	SPEAKER_02
 And...

0:04:49	SPEAKER_02
 That's nice.

0:04:50	SPEAKER_02
 And then within that, I guess the idea was to freeze a certain set of options for now.

0:04:55	SPEAKER_02
 To run it a particular way and decide on what things are going to be experimented with, as opposed to just experimenting with everything.

0:05:05	SPEAKER_02
 So, a certain set of things constant.

0:05:08	SPEAKER_02
 So, maybe describe roughly what we are keeping constant for now.

0:05:18	SPEAKER_03
 Yeah, well, so we've been working like six weeks in the nice compensation.

0:05:24	SPEAKER_03
 We endeavor to...

0:05:26	SPEAKER_05
 So, you're going to use which of the two techniques?

0:05:33	SPEAKER_03
 So, finally, it's a winner-fragile on FSD-based, and it uses two steps, smoothing the transfer function.

0:05:44	SPEAKER_03
 And the first step, that's on the kind which is the direction.

0:05:49	SPEAKER_03
 And after these steps, there is a further smoothing and a frequency which use, and it's lighting and there are different techniques.

0:06:02	SPEAKER_05
 So, this is on the...

0:06:05	SPEAKER_05
 Before any mel scaling.

0:06:08	SPEAKER_05
 Yeah, that's it.

0:06:09	SPEAKER_02
 So, this smoothing is done on the estimate of what you're going to subtract, or on the thing that has already had something subtracted.

0:06:21	SPEAKER_03
 It's on the transfer function.

0:06:23	SPEAKER_02
 Oh, it's on the transfer function for the winner filter.

0:06:26	None
 Yeah, okay.

0:06:29	SPEAKER_03
 Yeah, so basically we tried different configuration within this idea.

0:06:38	SPEAKER_03
 We tried to add down these some mel bands, having spectroscopy, instead of phenophiltering.

0:06:47	SPEAKER_03
 But finally, we ended up with this configuration that works quite well.

0:06:55	SPEAKER_03
 So, we're going to fix this for the monitor work of the other aspects.

0:06:59	SPEAKER_03
 The world system, so...

0:07:02	SPEAKER_02
 Actually, let me...

0:07:03	SPEAKER_02
 Dave isn't here to talk about it, but let me just interject.

0:07:06	SPEAKER_02
 This module, in principle, I mean you would know whether it's true, in fact, is somewhat independent from the rest of it, because you recent the size speech, right?

0:07:18	SPEAKER_02
 So, well, you know, I guess you don't recent the size speech, but you could.

0:07:24	SPEAKER_03
 Well, we do, but we don't recent the size.

0:07:27	SPEAKER_03
 In the program, we don't recent the size, and then realize once again, we just used to clean the evidence.

0:07:33	SPEAKER_02
 But you have a recent the size thing that you, that's an option.

0:07:37	SPEAKER_02
 Yeah, I guess my point is that in some of the work he's doing in reverberation, one of the things that we're finding is that for an artificial situation, we can just deal with reverberation, and his techniques work really well.

0:07:52	SPEAKER_02
 But for the real situation, problem is that you don't just have reverberation, you have reverberation in noise, and if you don't include that in the model, it doesn't work very well.

0:08:01	SPEAKER_02
 So, in fact, it might be a very nice thing to do, to just take the noise, remove a part of it, and put that in front of what he's looking at, and generate new files or whatever, and then do the reverberation part.

0:08:16	SPEAKER_02
 So, it's...

0:08:19	SPEAKER_02
 Anyway.

0:08:21	SPEAKER_05
 The Dave hasn't tried that yet.

0:08:23	SPEAKER_02
 No, no, he's...

0:08:25	SPEAKER_05
 I guess he's busy with...

0:08:27	SPEAKER_05
 Prelims, right?

0:08:28	SPEAKER_02
 Yeah, so...

0:08:30	SPEAKER_02
 But, you know, that'll...

0:08:33	SPEAKER_02
 It's clear that we are not...

0:08:35	SPEAKER_02
 With the real case that we're looking at, we can't just look at reverberation and isolation because the interaction between that noise is considerable.

0:08:44	SPEAKER_02
 And that's...

0:08:45	SPEAKER_02
 I mean, in the past, we've looked at...

0:08:48	SPEAKER_02
 And this is hard enough.

0:08:49	SPEAKER_02
 The interaction between channel effects and...

0:08:53	SPEAKER_02
 And the additive noise is so convolutional effects and additive effects.

0:08:58	SPEAKER_02
 And that's hard enough.

0:09:00	SPEAKER_02
 I mean, I don't think we really...

0:09:02	SPEAKER_02
 I mean, we're trying to deal with that.

0:09:04	SPEAKER_02
 In a sense, that's what we're trying to deal with in this Aurora task.

0:09:07	SPEAKER_02
 And we have the...

0:09:09	SPEAKER_02
 LDA stuff that, in principle, is doing something about convolutional effects.

0:09:14	SPEAKER_02
 And we have the noise suppression that's doing something about noise.

0:09:19	SPEAKER_02
 Even that's hard enough in the online normalization as well.

0:09:23	SPEAKER_02
 There's all these interactions between these two, and they work so hard and...

0:09:28	SPEAKER_02
 And struggling everything around.

0:09:29	SPEAKER_02
 But now, when you throw in the reverberation, it's even worse, because not only do you have these effects, but you also have some long-time effects.

0:09:36	SPEAKER_02
 And so Dave has something which...

0:09:39	SPEAKER_02
 Is doing some nice things under some conditions with long-time effects, but when there's noise there too, it's pretty hard.

0:09:47	SPEAKER_02
 So we have to start.

0:09:49	SPEAKER_02
 Since any...

0:09:50	SPEAKER_02
 Almost any real situation is going to have...

0:09:52	SPEAKER_02
 Where you have the microphone distant, it's going to have both things.

0:09:57	SPEAKER_02
 We actually have to think about both at the same time.

0:10:07	SPEAKER_02
 So, there's this noise suppression thing, which has sort of worked out, and then maybe just continued telling what else is in the...

0:10:16	SPEAKER_02
 The former half.

0:10:18	SPEAKER_03
 What are parts of the system?

0:10:22	SPEAKER_03
 The blocks that were present before...

0:10:25	SPEAKER_03
 Would you have put it back in?

0:10:31	SPEAKER_02
 So that's again, that's the Wiener filtering followed by...

0:10:36	SPEAKER_02
 That's done at the FFT level.

0:10:39	SPEAKER_03
 Then...

0:10:40	SPEAKER_03
 Yeah, then the mail, sit or bank...

0:10:43	SPEAKER_03
 And the lug of the ratio.

0:10:46	SPEAKER_02
 Well, the filtering is done...

0:10:50	SPEAKER_02
 In frequency domain?

0:10:53	SPEAKER_02
 Yeah.

0:10:55	SPEAKER_02
 Then the mail, then the lug, and then the LDA filter.

0:11:02	SPEAKER_02
 And then...

0:11:05	SPEAKER_02
 Downsample...

0:11:08	SPEAKER_02
 DCT...

0:11:11	SPEAKER_02
 Online...

0:11:19	SPEAKER_03
 Online...

0:11:23	SPEAKER_03
 The same thing.

0:11:26	SPEAKER_03
 And then compute that.

0:11:29	SPEAKER_02
 And replace...

0:11:32	SPEAKER_02
 Then you run natural.

0:11:34	SPEAKER_02
 And then in parallel with...

0:11:37	SPEAKER_02
 In neural net and then following neural net,

0:11:39	SPEAKER_03
 and finally friend dropping, which... Would be a neural network, so you first need to sign up for these, and the input of this neural network would be somewhere between lug and mail band.

0:11:59	SPEAKER_04
 So...

0:12:02	SPEAKER_02
 So that's sort of...

0:12:03	SPEAKER_02
 Most of the stuff is...

0:12:04	SPEAKER_02
 Yeah, it's operating parallel with this other stuff.

0:12:08	SPEAKER_02
 Yeah.

0:12:11	SPEAKER_02
 So the things that we...

0:12:16	SPEAKER_02
 I guess we sort of...

0:12:18	SPEAKER_02
 There's some neat ideas for VADs.

0:12:21	SPEAKER_02
 So, I mean, I think there's sort of like...

0:12:24	SPEAKER_02
 There's a bunch of tuning things to improve stuff.

0:12:27	SPEAKER_02
 There's questions about raceplaces where there's an exponent.

0:12:30	SPEAKER_02
 If it's the right exponent, or ways that we're estimating noise, that we can prove estimating noise, and there's going to be a host of those.

0:12:37	SPEAKER_02
 And, certainly, it seemed like the things...

0:12:40	SPEAKER_02
 The main things that we were brought up that are going to need to get worked on seriously are...

0:12:46	SPEAKER_02
 A significantly better VAD...

0:12:51	SPEAKER_02
 Putting the neural net on...

0:12:54	SPEAKER_02
 Which, you know, we haven't been doing anything with the neural net at the end there.

0:13:00	SPEAKER_02
 And the...

0:13:02	SPEAKER_02
 Opening up the second front.

0:13:06	SPEAKER_05
 The other happens to sound.

0:13:08	SPEAKER_02
 Yeah, yeah, I mean, because we have...

0:13:11	SPEAKER_02
 We have half the data rate that they allow.

0:13:16	SPEAKER_02
 And so the initial thing, which came from the meeting that we had down south, was that we'll initially just put in a mouse spectrum.

0:13:28	SPEAKER_02
 That's the second one.

0:13:30	SPEAKER_02
 It's, you know, TEPZ.

0:13:34	SPEAKER_02
 There's a question about exactly how we do it.

0:13:36	SPEAKER_02
 We probably will go to something better later.

0:13:38	SPEAKER_02
 But, initial thing is that...

0:13:41	SPEAKER_02
 Capster and Spectre behave differently, so.

0:13:50	SPEAKER_02
 I think Tony Robinson used to do...

0:13:52	SPEAKER_02
 I was saying this before, I think he used to do...

0:13:54	SPEAKER_02
 Mel, Spectre and Mel Capster used them as alternate features.

0:13:58	SPEAKER_02
 Put them together.

0:14:00	SPEAKER_05
 So, if you took the system, the way it is now, the way it's... you're going to freeze it.

0:14:04	SPEAKER_05
 And ran it on the last evaluation.

0:14:06	SPEAKER_05
 Where would it be?

0:14:08	SPEAKER_05
 In terms of ranking.

0:14:10	SPEAKER_05
 So, again...

0:14:14	SPEAKER_02
 Well, you know, you haven't tested it actually on the German and Danish have you.

0:14:18	SPEAKER_02
 No, you didn't.

0:14:20	SPEAKER_05
 Yeah.

0:14:21	SPEAKER_05
 So, on the ones that you did test it on, it would have been second.

0:14:24	SPEAKER_02
 Yeah.

0:14:25	SPEAKER_02
 What did...

0:14:26	SPEAKER_02
 I mean, but when you're saying second, you're comparing to the numbers that the...

0:14:30	SPEAKER_02
 Yeah, the best system before got on...

0:14:32	SPEAKER_02
 We also without German and Danish.

0:14:36	SPEAKER_01
 And the ranking actually didn't change after the German and Danish.

0:14:40	SPEAKER_01
 So, yeah.

0:14:41	SPEAKER_02
 Well, ranking didn't before, but I'm just asking where this is to...

0:14:47	SPEAKER_02
 Yeah.

0:14:48	SPEAKER_02
 Where there was without the German and Danish, right?

0:14:51	SPEAKER_05
 Where were we actually on the last test?

0:14:54	SPEAKER_02
 Oh, we were also essentially second, although there were...

0:14:57	SPEAKER_02
 I mean, we had a couple systems and they had a couple systems.

0:15:00	SPEAKER_02
 And so, I guess by that, we were third, but I mean, there were two systems that were pretty close.

0:15:05	SPEAKER_02
 They came from the same place.

0:15:07	SPEAKER_02
 So, institutionally, we were second.

0:15:11	SPEAKER_02
 So, the second that you're saying now is...

0:15:14	SPEAKER_02
 Same-wide.

0:15:15	SPEAKER_02
 Oh, no, I think it's also institutionally.

0:15:17	SPEAKER_02
 Still, it's next-wide.

0:15:18	SPEAKER_02
 I mean, I think both of their systems probably...

0:15:20	SPEAKER_02
 We're between their two systems.

0:15:21	SPEAKER_02
 Oh, are we?

0:15:22	SPEAKER_01
 Yeah.

0:15:23	SPEAKER_01
 So, their first system is 54 points, something, and we are 53 points, something.

0:15:28	SPEAKER_01
 And their second system is all the 53 points, something.

0:15:30	SPEAKER_01
 Yeah, 1%.

0:15:31	SPEAKER_02
 Yeah, so basically, they're all pretty close.

0:15:34	SPEAKER_02
 And in some sense, we're all doing fairly similar things.

0:15:40	SPEAKER_02
 I mean, good argue about the LDA and so forth, but I think, yeah, a lot of ways are doing very similar things.

0:15:46	SPEAKER_05
 So, how do they fill up all these bits?

0:15:49	SPEAKER_05
 I mean, for...

0:15:52	SPEAKER_02
 Why are we using half?

0:15:53	SPEAKER_02
 Yeah.

0:15:54	SPEAKER_02
 Well, so you could...

0:15:55	SPEAKER_05
 How are they using more than half, I guess, maybe?

0:15:57	SPEAKER_02
 Yeah, so I think, guys, closer to it, me, so correctly, from wrong.

0:16:01	SPEAKER_02
 But I think that what's going on is that in both cases, some kind of normalization is done to deal with convolutional effects.

0:16:11	SPEAKER_02
 They have some capital modification, right?

0:16:14	SPEAKER_02
 In our case, we have a couple things.

0:16:16	SPEAKER_02
 We have the online normalization, and we have the LDA roster.

0:16:19	SPEAKER_02
 And they seem to complement each other enough and be different enough that they both seem to help us.

0:16:25	SPEAKER_02
 But then, anyway, they're both doing the same sort of thing, but there's one difference.

0:16:29	SPEAKER_02
 The LDA roster throws away high modulation frequencies, and they're not doing that.

0:16:38	SPEAKER_05
 So...

0:16:39	SPEAKER_02
 So that if you throw away high modulation frequencies, then you can downsample.

0:16:43	SPEAKER_05
 I see.

0:16:44	SPEAKER_05
 I see.

0:16:45	SPEAKER_05
 So...

0:16:49	SPEAKER_05
 So what if you didn't...

0:16:50	SPEAKER_05
 So do you explicitly downsample them?

0:16:52	SPEAKER_05
 Do we explicitly downsample them?

0:16:53	SPEAKER_05
 Yeah.

0:16:54	SPEAKER_05
 And what if we didn't do that?

0:16:56	SPEAKER_02
 Would we get worse performance?

0:16:58	SPEAKER_05
 I think it doesn't affect it, doesn't it?

0:17:00	SPEAKER_02
 Yeah.

0:17:01	SPEAKER_02
 I see.

0:17:02	SPEAKER_02
 Yeah.

0:17:03	SPEAKER_02
 So I think the thing is, since we're not evidently throwing away useful information, let's try to put it into useful information.

0:17:06	SPEAKER_02
 Yeah.

0:17:07	SPEAKER_02
 And so, you know, we've found in a lot of ways for quite a while that having a second stream helps a lot.

0:17:14	SPEAKER_02
 So that's put in.

0:17:15	SPEAKER_02
 And you know, I may even end up with Mel Spectrum, even though I'm saying I think we can do much better just because it's simple.

0:17:23	SPEAKER_02
 And, you know, in the long run having something everybody will look at and say, oh yeah, I understand, is very helpful.

0:17:29	SPEAKER_05
 So you're thinking to put the Mel Spectrum in before any of the noise removal stuff?

0:17:36	SPEAKER_05
 Well, that's a question.

0:17:37	SPEAKER_02
 I mean, we were talking about that.

0:17:39	SPEAKER_02
 It looks like it'd be straightforward to remove the noise.

0:17:46	SPEAKER_05
 And...

0:17:47	SPEAKER_05
 Because that happens before the Mel conversion, right?

0:17:50	SPEAKER_02
 Yeah.

0:17:51	SPEAKER_02
 So, I mean, to do it after the Mel conversion, after the noise removal, after the Mel conversion.

0:17:58	SPEAKER_02
 And it's even a question in my mind, anyhow, whether you should take the log or not.

0:18:05	SPEAKER_02
 I sort of think you should, but...

0:18:10	SPEAKER_04
 I don't know.

0:18:12	SPEAKER_03
 What about normal ideas?

0:18:16	SPEAKER_02
 Right.

0:18:24	SPEAKER_02
 Well, but normalizing Spectrum instead of Capster?

0:18:28	SPEAKER_02
 Yeah.

0:18:29	SPEAKER_02
 Yeah, probably.

0:18:30	SPEAKER_02
 Some kind would be good, you know, I would think.

0:18:33	SPEAKER_01
 Well, it actually makes it dependent on the overall energy of the frame.

0:18:41	SPEAKER_01
 If you do or don't, don't analyze.

0:18:43	SPEAKER_01
 If you don't, don't analyze.

0:18:45	SPEAKER_01
 And if you don't, don't analyze.

0:18:47	SPEAKER_02
 Right.

0:18:48	SPEAKER_02
 Yes, I mean, one would think that you'd want to normalize.

0:18:51	SPEAKER_02
 But my thought is, particularly if take the log, try it.

0:18:59	SPEAKER_02
 And then if normalization helps, then you have something to compare against and say, okay, this much effect.

0:19:06	SPEAKER_02
 I mean, you don't want to change six things and then see what happens.

0:19:09	SPEAKER_02
 You want to change them one at a time.

0:19:10	SPEAKER_02
 So, adding this other stream in, that's simple in some way.

0:19:14	SPEAKER_02
 And then, saying, particularly because we found the past, there's all these different results you get with slight modifications of how you do normalization.

0:19:22	SPEAKER_02
 Normalization is a really tricky sensitive thing and you learn a lot.

0:19:26	SPEAKER_02
 So, I would think you would want to have some baselines that says, okay, we don't normalize this is what we get.

0:19:31	SPEAKER_02
 And we do this normalization and we do that normalization.

0:19:34	SPEAKER_02
 But the other question is, so I think ultimately one depends on normalization, I agree.

0:19:39	SPEAKER_05
 So, this second stream, will it add latency to the system?

0:19:44	SPEAKER_02
 No, it's in parallel.

0:19:45	SPEAKER_02
 We're not talking about computation time here.

0:19:47	SPEAKER_02
 We're actually pretty far out.

0:19:49	SPEAKER_02
 So, it's just in terms of what data it's depending on.

0:19:51	SPEAKER_02
 It's depending on the same data as the other.

0:19:53	SPEAKER_02
 Same.

0:19:54	SPEAKER_00
 So, with this new stream, would you train up the VAD on both features somehow?

0:20:06	SPEAKER_01
 No, I guess the VAD has its own set of features.

0:20:09	SPEAKER_01
 Okay.

0:20:10	SPEAKER_01
 Which could be one of these streams or it can be something derived from these streams.

0:20:15	SPEAKER_03
 Okay.

0:20:16	SPEAKER_03
 And there is also the idea of using Crap's maybe.

0:20:21	SPEAKER_01
 Yeah, it's also.

0:20:24	SPEAKER_03
 Well, right, you bought for an empty show.

0:20:27	None
 It's a good idea.

0:20:30	SPEAKER_00
 With that fit on the handset or...

0:20:37	SPEAKER_00
 Oh.

0:20:38	SPEAKER_00
 Okay.

0:20:39	SPEAKER_01
 Let me test.

0:20:41	SPEAKER_01
 Yeah.

0:20:42	SPEAKER_01
 Let me test to fit the delays and all this stuff.

0:20:48	SPEAKER_02
 Well, this is delays in the storage, yeah.

0:20:52	SPEAKER_02
 But I don't think the storage is so big for that.

0:20:54	SPEAKER_02
 I think the biggest thing we've run into for storage is neural net.

0:20:57	SPEAKER_02
 You, right.

0:21:02	SPEAKER_02
 And so, I guess the issue there is, are we using neural net-based traps?

0:21:08	SPEAKER_02
 And how big are they?

0:21:10	SPEAKER_02
 That'll be an issue.

0:21:13	SPEAKER_00
 Maybe they could be little ones.

0:21:15	SPEAKER_00
 Right.

0:21:16	SPEAKER_00
 Because she also does the correlation-based traps without the neural net just looking at the coordinates.

0:21:25	SPEAKER_02
 Maybe for VAD, they would be okay.

0:21:28	SPEAKER_02
 Yeah.

0:21:29	SPEAKER_02
 Yeah.

0:21:30	SPEAKER_02
 It's true.

0:21:31	SPEAKER_02
 Or simple neural net, right?

0:21:32	SPEAKER_02
 I mean, the thing is, if you're doing correlation, you're just doing a simple dot product with some weights, which you happen to learn from the data.

0:21:47	SPEAKER_02
 And so, putting it on linearity on it is not that big a deal.

0:21:49	SPEAKER_02
 It certainly doesn't take much space.

0:21:51	SPEAKER_02
 Right.

0:21:52	SPEAKER_02
 So, the question is, how complex a function you need to have an added layer or something, in which case, potentially, you know, it could be big.

0:22:05	SPEAKER_02
 So, what's next?

0:22:13	None
 Maybe.

0:22:14	SPEAKER_02
 Not like this.

0:22:15	SPEAKER_05
 So, the meeting with Henik that you guys just had was to decide exactly what you were going to freeze in this system.

0:22:25	SPEAKER_05
 Is that, or was there, are you talking about what the new stuff for?

0:22:30	SPEAKER_02
 What the freeze and then what to do after we froze?

0:22:37	None
 Yeah.

0:22:38	SPEAKER_02
 And, like I said, I think that the basic directions are, I mean, there's lots of little things, such as improvement noise estimator, but the bigger things are adding on the neural net and the second stream and then improving the VAD.

0:22:58	SPEAKER_01
 So, I have actually, after the meeting, added the second stream to the data and maybe I'll start with the feature net in that case.

0:23:09	SPEAKER_01
 It's like you're looking at the VAD, right?

0:23:12	SPEAKER_03
 Yeah.

0:23:13	SPEAKER_01
 For the VAD?

0:23:16	SPEAKER_01
 No.

0:23:17	None
 But the network on the VAD and one.

0:23:20	SPEAKER_01
 So, you already have it?

0:23:21	SPEAKER_01
 Okay.

0:23:22	SPEAKER_01
 So, just to take the features from the final.

0:23:25	SPEAKER_01
 Okay.

0:23:26	SPEAKER_03
 But, yeah, I think that's your issue.

0:23:33	SPEAKER_05
 What about the new part of the evaluation, the Wall Street Journal part?

0:23:39	SPEAKER_02
 Right.

0:23:40	SPEAKER_02
 Have you ever, very good question.

0:23:44	SPEAKER_02
 Have you ever worked with the Mississippi State Software?

0:23:48	SPEAKER_04
 No.

0:23:49	SPEAKER_02
 Oh.

0:23:50	SPEAKER_02
 Well, you may be called up a hand to help.

0:23:53	SPEAKER_02
 I think that kind of all the work in this stuff here has been in the small vocabulary.

0:24:01	SPEAKER_05
 So, how was the interaction supposed to happen?

0:24:04	SPEAKER_05
 I remember last time we talked about this, it was sort of up in the air, whether they were going to be taking people's features and then running them or they were going to give the system out.

0:24:16	SPEAKER_05
 So, they're going to just deliver a system base.

0:24:18	SPEAKER_05
 Do we already have it?

0:24:19	SPEAKER_01
 Yeah, I guess it's almost ready.

0:24:22	SPEAKER_01
 So, that's what, so they have released a document describing the system.

0:24:29	SPEAKER_02
 Maybe you could point it at Chuck, because we'll have to grab this over CVS or something.

0:24:37	SPEAKER_01
 No, it's just downloadable from their website.

0:24:41	SPEAKER_02
 Because one of the things that might be helpful if you've got time and all of this is, is if these guys are really focusing on improving all the digit stuff, maybe you got the front end from them, maybe you could do the runs for the, and you know, iron out hassles that you have to tweak Joe about, or whatever, because you're more experienced who's going to urge vocabulary stuff.

0:25:10	SPEAKER_01
 So, I'll point you to the website and the mail corresponding.

0:25:20	SPEAKER_05
 And it's not ready yet, this is the thing.

0:25:25	SPEAKER_01
 I think they are still tuning something on that.

0:25:30	SPEAKER_01
 So, they're like varying different parameters like the insertion penalty and all those stuff and then seeing what's the performance.

0:25:37	SPEAKER_05
 So, what is going to be parameters that are frozen, nobody can change?

0:25:42	SPEAKER_01
 I guess there is time during which people can make suggestions.

0:25:47	SPEAKER_05
 Oh, but everybody's going to have to use the same value.

0:25:49	SPEAKER_05
 After that.

0:25:52	SPEAKER_01
 So, this suggestion, this, this, this, Peter, during which people can make suggestions is to know whether it is actually biased towards any set of features or.

0:26:01	SPEAKER_02
 Yeah, so, certainly the thing that I would want to know about is whether we get really hurt on insertion penalty, language model scaling, sorts of things.

0:26:13	SPEAKER_02
 Yeah, yeah, yeah.

0:26:15	SPEAKER_02
 In which case, Hary or Henik will need to, you know, push the case or about this.

0:26:26	SPEAKER_05
 And we may be able to revisit this idea about, you know, somehow modifying our features to.

0:26:34	SPEAKER_02
 Yes, in this case, that's right.

0:26:37	SPEAKER_02
 Yeah.

0:26:39	SPEAKER_02
 That's right.

0:26:40	SPEAKER_02
 Some of that may be a last minute rush thing because if our features are changing.

0:26:45	SPEAKER_02
 Yeah.

0:26:48	SPEAKER_02
 But, yeah, the other thing is that even though it's a month away, it's starting to seem to me now like November 15th is right around the corner.

0:27:01	SPEAKER_02
 And if they haven't decided things like this, what the parameters are going to be for this.

0:27:08	SPEAKER_02
 When deciding is not just somebody deciding, I mean, in fact, there should be some understanding behind the deciding, which means some experiments and so forth.

0:27:18	SPEAKER_02
 It seems pretty tight to me.

0:27:20	SPEAKER_05
 So, what's the significance of November 15th?

0:27:22	SPEAKER_02
 That's when the evaluation is.

0:27:24	SPEAKER_02
 Yeah.

0:27:25	SPEAKER_02
 So, yeah.

0:27:26	SPEAKER_02
 So, yeah.

0:27:27	SPEAKER_02
 So I have to, but, you know, they may even decide in the end to push it off.

0:27:31	SPEAKER_02
 It wouldn't, you know, entirely surprise me.

0:27:34	SPEAKER_02
 But due to other reasons, like some people are going away, I'm hoping it's not pushed off for a long while.

0:27:42	SPEAKER_02
 That would be, but it's an awkward position.

0:27:45	SPEAKER_02
 But anyway.

0:27:47	SPEAKER_02
 Okay.

0:27:48	SPEAKER_02
 Great.

0:27:53	SPEAKER_02
 Yeah, I think that'll be helpful.

0:27:55	SPEAKER_02
 There's not anybody, OGI currently, who's working with this.

0:28:01	SPEAKER_05
 Is this part of the evaluation just a small part of how important is this to the overall?

0:28:07	SPEAKER_02
 I think it depends how badly you do.

0:28:11	SPEAKER_02
 I mean, I think that it is...

0:28:13	SPEAKER_02
 This is one of those things that will be debated afterwards.

0:28:16	SPEAKER_02
 Yeah.

0:28:17	SPEAKER_02
 Well, I mean, it's conceptually, my impression, again, you guys correct me if I'm wrong, my impression is that they want it as a double check that you haven't come across, you haven't invented features, which are actually going to do badly for a significantly different task, particularly one with larger vocabulary.

0:28:38	SPEAKER_02
 But it's not the main emphasis.

0:28:41	SPEAKER_02
 I mean, the truth is most of the applications they're looking at are pretty small vocabulary.

0:28:45	SPEAKER_02
 So it's a double check.

0:28:47	SPEAKER_02
 So they'll probably assign it some sort of low weight.

0:28:50	SPEAKER_05
 It seems to me that if it's a double check, they should give you a 1 or a 0.

0:28:54	SPEAKER_05
 You passed the threshold, you didn't pass the threshold, and they shouldn't even...

0:28:57	SPEAKER_05
 Yeah, you're not going to score it.

0:28:59	SPEAKER_02
 But I mean, we'll see what they come up with.

0:29:02	SPEAKER_02
 But in the current thing, for instance, where you have this well-matched, moderately matched, and this highly mismatched, the emphasis is somewhat on the well-matched, but it's only a marginal, right?

0:29:16	SPEAKER_02
 It's a 40, 35, 25 or something like that.

0:29:20	SPEAKER_02
 So you still, if you were way, way off on the highly mismatched, it would have a big effect.

0:29:26	SPEAKER_02
 And it wouldn't surprise me if they did something like that with this.

0:29:31	SPEAKER_02
 So again, if you get...

0:29:33	SPEAKER_02
 If it doesn't help you much for noisy versions of this large vocabulary data, then it may not hurt you that much.

0:29:43	SPEAKER_02
 But if you don't... if it doesn't help you much at all, or put another way, if it helps some people a lot more than it helps other people, there are strategies too.

0:29:54	SPEAKER_05
 So is this...

0:29:56	SPEAKER_05
 Goodter was putting a bunch of Wall Street Journal data on our disks.

0:30:00	SPEAKER_05
 So that's the data that we'll be running on.

0:30:02	SPEAKER_02
 Yeah.

0:30:03	SPEAKER_02
 I see.

0:30:06	SPEAKER_02
 So if the data just not the recognized...

0:30:10	SPEAKER_02
 Okay.

0:30:20	SPEAKER_05
 So this test may take quite a while to run, then.

0:30:23	SPEAKER_05
 A judging by the amount of data that he was putting.

0:30:27	SPEAKER_02
 Well, it's training and test, right?

0:30:30	SPEAKER_05
 I guess I'm not sure.

0:30:32	SPEAKER_02
 No, I mean, if it's like the other things, there's data for training the HMMs and data for testing it.

0:30:37	SPEAKER_02
 So I wouldn't... so it's...

0:30:40	SPEAKER_05
 Okay.

0:30:42	SPEAKER_02
 So training, the recognizer.

0:30:46	SPEAKER_02
 But I think it's trained on clean.

0:30:51	SPEAKER_02
 Is it trained on clean?

0:30:53	SPEAKER_02
 Wall Street?

0:30:54	SPEAKER_03
 Yeah.

0:30:55	SPEAKER_03
 Probably no.

0:30:56	SPEAKER_03
 It's training range between 10 and 20 dB.

0:30:59	SPEAKER_03
 I think it's testing between 5 and 15 dB.

0:31:03	SPEAKER_03
 Yeah.

0:31:04	SPEAKER_02
 Okay.

0:31:06	SPEAKER_01
 So it's like a medium mismatch condition, sort of.

0:31:10	SPEAKER_04
 I see.

0:31:11	SPEAKER_03
 So the noise is...

0:31:14	SPEAKER_03
 There is a range of different noises.

0:31:16	SPEAKER_03
 So...

0:31:17	SPEAKER_03
 The jar select can run on the media.

0:31:21	SPEAKER_03
 Okay.

0:31:23	SPEAKER_03
 And to the files.

0:31:25	SPEAKER_03
 There are noises that are different.

0:31:27	SPEAKER_03
 And the noise is used on the 8 digits.

0:31:32	SPEAKER_04
 Yeah.

0:31:35	None
 Yeah.

0:31:38	SPEAKER_02
 Yeah.

0:31:39	SPEAKER_02
 I mean, I wouldn't imagine that the amount of testing data was that huge.

0:31:46	SPEAKER_02
 I probably put training...

0:31:48	SPEAKER_02
 Almost certainly, put training data there, too.

0:31:51	SPEAKER_02
 Maybe not.

0:31:56	SPEAKER_02
 So, that's that.

0:31:59	SPEAKER_05
 Okay.

0:32:02	SPEAKER_05
 One last question on that.

0:32:03	SPEAKER_05
 Did they estimate that they would have that system available for download?

0:32:08	SPEAKER_01
 I guess one...

0:32:09	SPEAKER_01
 Some preliminary version is already there.

0:32:12	SPEAKER_05
 Oh, so there's something you can download to just learn.

0:32:15	SPEAKER_01
 Yeah.

0:32:16	SPEAKER_01
 But they're actually paralleling doing some modifications also, I think.

0:32:19	SPEAKER_01
 Okay.

0:32:20	SPEAKER_01
 So I guess the final system will be frozen by middle of like one more week, maybe.

0:32:26	SPEAKER_02
 Oh, that's pretty simple.

0:32:28	SPEAKER_01
 Yeah, that's just one more.

0:32:31	SPEAKER_00
 Is this their SVM recognizer?

0:32:34	SPEAKER_01
 No, it's just a straight-forward achievement.

0:32:37	SPEAKER_02
 You know, they have a lot of options.

0:32:40	SPEAKER_02
 And they recognize your SVM is one of the things they've done with it.

0:32:43	SPEAKER_02
 But it's not their more standard thing.

0:32:45	SPEAKER_02
 For most part, it's Gaussian mixed using.

0:32:47	SPEAKER_00
 Okay.

0:32:48	SPEAKER_01
 Just the HTML.

0:32:49	SPEAKER_01
 Gaussian mixed with momentum.

0:32:50	SPEAKER_00
 Gaussian mixed with momentum.

0:32:51	SPEAKER_02
 Yeah, the SVM thing was an HTML also.

0:32:54	SPEAKER_02
 Yeah, this is a hybrid.

0:32:57	SPEAKER_05
 Yeah.

0:32:58	SPEAKER_05
 So just so that I understand they're providing scripts and everything so that basically you push a button and it does training and then it does test and everything.

0:33:08	SPEAKER_05
 Is that the idea?

0:33:09	SPEAKER_01
 I think, yeah, I guess something like...

0:33:12	SPEAKER_01
 It's like...

0:33:14	SPEAKER_01
 As painless as possible is work.

0:33:18	SPEAKER_01
 Do they provide all the scripts and everything and then...

0:33:21	SPEAKER_01
 Yeah, there's books to put your features out.

0:33:28	SPEAKER_02
 Yeah, in fact, I mean, if you look into it a little bit, it might be reasonable, you know, Joe, right?

0:33:39	SPEAKER_02
 Yeah, just to sort of ask him about the issue of different features having different kinds of scaling, characteristics and so on.

0:33:49	SPEAKER_02
 So that, you know, possibly having entirely different optimal values for the usual twittles, factors and what's the plan about that?

0:34:00	SPEAKER_01
 Should we like add check all through to the mailing list?

0:34:04	SPEAKER_01
 Maybe better, I mean, in that case, if he's going to...

0:34:07	SPEAKER_01
 Yeah.

0:34:08	SPEAKER_05
 So there's a mailing list for this?

0:34:09	SPEAKER_05
 Yeah, that'd be great.

0:34:10	SPEAKER_01
 Yeah, I guess maybe Harry or Heneke, one of them has to send a mail to Joe.

0:34:15	SPEAKER_01
 Or maybe if you...

0:34:17	SPEAKER_01
 I could send it.

0:34:19	SPEAKER_01
 Yeah, I know, maybe.

0:34:20	SPEAKER_01
 I know, really.

0:34:21	SPEAKER_01
 Yeah, so that's just fine.

0:34:23	SPEAKER_01
 So...

0:34:24	SPEAKER_02
 Yeah, and just maybe...

0:34:26	SPEAKER_02
 You have Harry's...

0:34:27	SPEAKER_02
 Have Harry's?

0:34:28	SPEAKER_02
 Yeah, so maybe just CC Harry and say that you've just been asked to handle the larger vocabulary part here.

0:34:33	SPEAKER_02
 And, you know...

0:34:34	SPEAKER_05
 Would it be better if I asked Harry to ask Joe?

0:34:39	SPEAKER_02
 Why don't you just ask Joe but CC Harry and then in the notes say Harry, hopefully this is okay with you.

0:34:45	SPEAKER_02
 And then if Joe feels like he needs a confirmation, Harry can answer it.

0:34:50	SPEAKER_02
 That way you can get started asking Joe quickly while he's maybe still putting in nails and screws and do it.

0:34:58	SPEAKER_01
 And there is an archive of all the mails that has been...

0:35:10	SPEAKER_01
 That has gone between these people, among these people.

0:35:13	SPEAKER_01
 So, just you can see all those mails in the ISIP website.

0:35:18	SPEAKER_01
 Okay.

0:35:19	SPEAKER_01
 This is the website.

0:35:20	SPEAKER_01
 Is that a password?

0:35:21	SPEAKER_01
 Yeah, it's password-productive.

0:35:22	SPEAKER_01
 So, like...

0:35:23	SPEAKER_01
 It's...

0:35:24	SPEAKER_01
 Like...

0:35:44	SPEAKER_02
 What do you think about how long would be most useful for you to go up to OJ?

0:35:54	SPEAKER_03
 I don't know.

0:35:56	SPEAKER_03
 We can.

0:35:59	SPEAKER_03
 For September we can sit up.

0:36:03	SPEAKER_03
 Work schedule.

0:36:07	SPEAKER_03
 At some point, maybe we better...

0:36:12	SPEAKER_02
 Oh, so you're imagining more that you would come back here first for a while and then go up there.

0:36:18	SPEAKER_02
 I mean, it's up to you guys, are you?

0:36:21	SPEAKER_02
 Well, anyway, you don't have to decide the second.

0:36:23	SPEAKER_02
 But think about it, about what you think would be the best way to work it all supported either way.

0:36:30	SPEAKER_02
 Okay.

0:36:34	SPEAKER_02
 Anything to tell us?

0:36:39	SPEAKER_00
 Well, I've been reading some literature about clustering of data.

0:36:46	SPEAKER_00
 Just...

0:36:47	SPEAKER_00
 I guess, let me put it in context.

0:36:50	SPEAKER_00
 Okay.

0:36:51	SPEAKER_00
 So, we're talking about discovering intermediate categories to classify.

0:36:58	SPEAKER_00
 And I was looking at some of the work that San Gita was doing on these traps things.

0:37:04	SPEAKER_00
 So, she has... she has temporal patterns for a certain set of phonemes from Timmit, right?

0:37:14	SPEAKER_00
 The most common phonemes.

0:37:16	SPEAKER_00
 Each one of them has a nice pattern over time, one second window, and it has these patterns.

0:37:25	SPEAKER_00
 So, she has a trap for each one of the phonemes times 15 for each of the 15 critical bands.

0:37:36	SPEAKER_00
 And she does this agglomerative hierarchical clustering, which basically is a clustering algorithm that starts with many, many, many different points, many different clusters corresponding to the number of data patterns that you have in the data.

0:37:57	SPEAKER_00
 And then you have this distance metric, which measures how closely related they are.

0:38:04	SPEAKER_00
 And you start by merging the patterns that are most closely related.

0:38:12	SPEAKER_00
 You created three.

0:38:17	SPEAKER_05
 Yeah, yeah, yeah, a dendrogram tree.

0:38:19	SPEAKER_05
 You can think of values anywhere along that tree to fix your set of clusters.

0:38:23	SPEAKER_00
 Right.

0:38:24	SPEAKER_00
 Usually, it's when the similarity measures don't go down as much.

0:38:32	SPEAKER_00
 And so, so you stop at that point.

0:38:35	SPEAKER_00
 And what she found was that there were five broad categories corresponding to things like fricatives and vocalic and stops and one for silence and another one for schwa sounds.

0:38:59	SPEAKER_00
 And I was thinking about ways to generalize this because it's not a completely automatic way of clustering because beforehand you have these traps, you're saying that these frames correspond to this particular phonemes.

0:39:20	SPEAKER_00
 And that's constraining your clustering to the set of phonemes that you already have.

0:39:27	SPEAKER_00
 Whereas, maybe we want to just take a look at arbitrary windows in time, a varying length, and cluster those.

0:39:40	SPEAKER_00
 And I'm thinking if we do that, then we would probably, at some point in the clustering algorithm, find that we've clustered things like, okay, this is a transition, this is a relatively stable point.

0:39:57	SPEAKER_00
 Now, hoping to find other things of similarity and maybe use these things as the intermediate categories that later classify.

0:40:11	SPEAKER_02
 Are you looking at this in their own bands?

0:40:14	SPEAKER_00
 Right.

0:40:16	SPEAKER_00
 I guess what you're going to be using. Yeah, I've been exactly figured out the exact details for that.

0:40:24	SPEAKER_00
 But the representation of the data that I was thinking of was using critical band energies over different lengths of time.

0:40:39	SPEAKER_02
 Yeah, I mean, it seems somehow that needs to, there's a couple things that I wonder about with this. So one is, again, looking at the same representation.

0:40:48	SPEAKER_02
 I mean, if you're going for this sort of thing where you have little detectors that are looking at narrow bands, then what you're going to be looking for should be some category that you can find with the narrow bands.

0:41:02	SPEAKER_02
 That seems to be kind of fundamental to it.

0:41:06	SPEAKER_02
 And then the other thing is that I wonder about with it and don't take this in the wrong way like I know what I'm doing or anything.

0:41:16	SPEAKER_02
 But I mean, just wondering, really, the sort of standard answer about this sort of thing is that if you're trying to find the right system in some sense, whether you're trying to categorize or parameters.

0:41:33	SPEAKER_02
 And your goal is discrimination. Then having choices based on discrimination as opposed to unsupervised nearness of things is actually better.

0:41:48	SPEAKER_02
 And I don't know if that means since you're dealing with issues for busness, you know, maybe this isn't right. But it'd be something I'd be concerned about because, for instance, you can imagine.

0:42:02	SPEAKER_02
 If you remember from your quarrels, John O'Halla saying that Bon Pa differed, not really because of voicing, but because of aspiration.

0:42:13	SPEAKER_02
 I mean, as far as what's really there in the acoustics.

0:42:16	SPEAKER_02
 So if you looked, if you're doing some coarse clustering, you probably would put those two sounds together. And yet I would guess that many of your recognition errors were coming from screwing up on this distinction.

0:42:37	SPEAKER_02
 So in fact, it's a little hard because recognizers to first order sort of work. And the reason we're doing the things we're doing is because they don't work as well as we'd like.

0:42:46	SPEAKER_02
 And since they sort of work, it means that they are already doing, if you go and take any recognizer that's already out there, and you say, how well is it distinguishing between schwa's and stops?

0:43:01	SPEAKER_02
 Boy, I bet they're all doing nearly perfectly on this. So these big categories that differ in huge, obvious ways, we already know how to do.

0:43:12	SPEAKER_02
 So what are we bringing to the party? I mean, in fact, what we want to do is have something that, particularly in the presence of noise, is better at distinguishing between categories that are actually close to one another. And hence would probably be cluster together.

0:43:28	SPEAKER_02
 So that's the hard thing. I mean, I understand that it's this other constraint that you're considering is that you want to have categories that would be straightforward for, say, a human being to mark if you had manual annotation.

0:43:41	SPEAKER_02
 And something that you really think you can pick up. But I think it's also essential that you want to look at what are the confusions that you are making. And how can you come up with categories that can clarify these confusions?

0:44:02	SPEAKER_02
 So I mean, the standard sort of way of doing that is take a look at the algorithms, you're looking at them, throw in some discriminative aspect to it. This is more like, how does LDA differ from PCA?

0:44:13	SPEAKER_02
 I mean, the same sort of thing, they're both authorizing, but, you know, and this is a little harder because you're not just trying to find parameters, you're actually trying to find the categories themselves.

0:44:26	SPEAKER_02
 A little more like brain surgery, I think, on yourself.

0:44:33	SPEAKER_02
 So, anyway, that's my thought.

0:44:41	SPEAKER_02
 Okay.

0:44:44	SPEAKER_02
 You've been thinking about this for a long time, actually, I mean, well, actually you stopped thinking about it for a long time, but you used to think about it a lot.

0:44:51	SPEAKER_02
 You were thinking about it more now. Yeah. Yeah. It's categories.

0:44:57	SPEAKER_05
 I guess, I don't, I don't, it's not clear to me how to reconcile, you know, what you're saying, which I think is right, with the way I've been looking at it, it's, it's all not very clear to me.

0:45:08	SPEAKER_05
 But it seems to me that the desire, the desirable feature to have is something that is bottom up.

0:45:18	SPEAKER_05
 Now, however we do that, and so, I guess what I don't understand is how to do that and still be discriminative because to be discriminative, you have to have categories, and the only categories that we know up to use are, sort of, these human, human-significant categories that are significant to humans, like phonemes, things like that.

0:45:41	SPEAKER_02
 But that's sort of what you want to avoid. Well, here's a, here's a, here's a generic and possibly useless thought, which is, what do you really, I mean, in a sense, the only systems that make sense are ones that have something from top down in them.

0:46:05	SPEAKER_02
 Right, because if even the smallest organism is trying to learn to do anything, if it doesn't have any kind of reward for, or penalty for doing anything, then it's just going to behave randomly.

0:46:16	SPEAKER_02
 So whether you're talking about something being learned through evolution or being learned through experience, it's got to have something come down to it that gives its reward, or at least some sort of reinforcement.

0:46:25	SPEAKER_05
 So the question is how far down, and stop at words, but we don't, right, we go all the way down to phonemes.

0:46:31	SPEAKER_02
 Right, but I think it maybe in some ways, part of the difficulty is trying to deal with these phonemes.

0:46:38	SPEAKER_02
 And it's almost like you want categories, if our metric of goodness, or correction, if our metric of badness is word error rate, then maybe we should be looking at words.

0:46:58	SPEAKER_02
 I mean, for very nice reasons, we've looked, well, it's syllables, and they have a lot of good properties.

0:47:04	SPEAKER_02
 But if you go all the way to words, I mean, that's really, I mean, in many applications, you want to go further, you want to go to concepts or something.

0:47:12	SPEAKER_02
 Yeah, I have concepts, actions, the sort of thing.

0:47:15	SPEAKER_02
 Words aren't bad, yeah.

0:47:17	SPEAKER_05
 So the common, right, the common wisdom is you can't do words because there's too many of them, right? So you have to have some smaller set that you can use.

0:47:29	SPEAKER_05
 And so everybody goes to phonemes. But the problem is that we build models of words in terms of phonemes, and these models are really cartoonish, right?

0:47:39	SPEAKER_05
 So when you look at conversational speech, for example, you don't see the phonemes that you have in your word models.

0:47:45	SPEAKER_02
 But we're not trying for models of words here. See, so here's maybe where, if the issue is that we're trying to come up with some sort of intermediate categories, which will then be useful for later stuff, then maybe it doesn't matter that we can't have enough.

0:48:06	SPEAKER_02
 I mean, what you want to do is build up these categories that are best for word recognition. And somehow if that's built into the loop of what the categories, I mean, we do this every day in this very gross way of running over a thousand experiments because we have asked computers picking the thing that has the best word error, right?

0:48:27	SPEAKER_02
 In some way, I mean, we derive that all the time. In some ways, that's not a bad thing to do because it tells you, in fact, how your adjustments at the very low level affect the final goal.

0:48:40	SPEAKER_02
 So maybe there's a way to even put that in a much more automatic way, where you take something about the error at the level of the word or some other, it could be so, but it's some large unit.

0:48:53	SPEAKER_02
 And, yeah, you may not have word models, you may have phone models, whatever, but you just sort of don't worry about that. And just somehow feed it back through.

0:49:04	SPEAKER_05
 So that's what I call a useless comments because I'm not really telling you how to do it. But I mean, it's, it's, it's, you know, I think the important part is there is that, you know, if you want to be discriminative, you have to have, you know, categories.

0:49:19	SPEAKER_05
 And I think this, the important categories are the words. Yeah.

0:49:24	SPEAKER_05
 Not the phones, maybe. And so, right, if you can put the words in to the loop, somehow for determining goodness of your sets of clusters.

0:49:39	SPEAKER_02
 Now, that being said, I think that, that if you have something that is, once you start dealing with spontaneous speech, all the things you're saying are really true.

0:49:49	SPEAKER_02
 If you have read speech that's been manually annotated like Tim at, yeah, then, you know, the phones are going to be right, actually, yeah, for the most part.

0:50:00	SPEAKER_02
 So, it doesn't really hurt them to, to do that, to put in discrimination at that level. If you go to spontaneous speech, then it's, it's trickier. And, and the phones are, you know, it's going to be based on bad pronunciation models that you have.

0:50:21	SPEAKER_05
 And it won't allow for the overlapping phenomena. So, it's almost like there's this mechanism that we have that, you know, when, when we're hearing read speech and all the phones are there, you know, we deal with that.

0:50:34	SPEAKER_05
 But, when we go to conversational and all of a sudden, not all the phone names are there, it doesn't really matter that much to us as humans, because we have some kind of mechanism that allows for these word models, whatever those models are to be.

0:50:50	SPEAKER_05
 And it doesn't really hurt them.

0:51:00	SPEAKER_05
 I'm not sure how, how to build that in.

0:51:08	SPEAKER_02
 Yeah, I mean, I guess the other thing is, is to think a little bit, when you, when you start looking at these kind of results, I think it usually is, is pretty intuitive. But, start looking at what are the kinds of confusions that you do make, you know, between words if you want or, or even between phones in, in, in red speech, say, when there is noise.

0:51:36	SPEAKER_02
 You know, so, is it more across place or more across manor or is it court, you know, is it, I mean, I know one thing that happens is that you, you, you lose low energy phones.

0:51:52	SPEAKER_02
 I mean, if it's added noise, then low energy phones sometimes don't get heard. And if that, if that is, if it's, if that turns it into another word or, or different, you know, another pair of words or something, then it's more likely to happen.

0:52:06	SPEAKER_02
 But, I don't know, I would, I would guess that you, I don't know, anyway, that's.

0:52:15	SPEAKER_05
 I think part of the difficulty is that a lot of the robustness that we have is probably coming from a much higher level, you know, we understand the context of the situational work, having conversation.

0:52:28	SPEAKER_05
 And so, there's noise in there, you know, our brain fills in.

0:52:32	SPEAKER_00
 Well, that's what, what should be the prediction?

0:52:35	SPEAKER_02
 Oh, sure, that's really big. But, I mean, even if you do diagnostic rhyme tests, kind of things, you know, where there really isn't any information like that, people are still better in noise than they, than they are in, then the machines are.

0:52:56	SPEAKER_02
 So, I mean, that's, right, we can't, we can't get it at all without any language models, language models are there and important. But, but, if we're not working on that, then we should work on something else and improve it, but, especially if it looks like the potential is there.

0:53:16	SPEAKER_02
 Should we just do this? Yeah. So, that's right here.

0:53:26	SPEAKER_02
 Okay, transcript, L-338.

0:53:36	SPEAKER_02
 86556-481-5134-2727-1998-2524-8858-0302-7580-0105-992-945-8519-69249-692-497249-339-07342-89.

0:54:05	SPEAKER_02
 734330 20417517

0:54:13	SPEAKER_03
 Let's click L-389 8892 640700 1759 8489 284 851 551 671 09 5065 288 895 282 793 078 707 079 36 2614 9813 8997 4467 0405

0:54:56	SPEAKER_05
 Transcript L-333 6370 690 60028327 777607174 7381141066 957431990 440680058 081543724 527481348

0:55:29	SPEAKER_00
 Transcript L-336 760149538 179649399 890002238 1195436059 0477569867 303895392 861464648 638406072019

0:56:07	SPEAKER_01
 Transcript L-334 1374091804 4794665647 1248047514 8221735705 9106363594 3960392838 0691690 238458830 Preserved

0:56:45	SPEAKER_02
 Exactly

0:57:05	None
 1000

