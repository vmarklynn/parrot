The participants discussed results from the experiments that had been conducted. Switching between tasks in the same language had smaller errors than multilingual models. The professor thought that increasing the parameters of the net for larger multi-lingual models would be helpful. The team decided that they should experiment further with different linguistic features. They also discussed how they could speed up their work by relying on greater computational resources.