Speaker G: So, okay, it doesn't look like a crash, that's great.
Speaker I: So I think maybe what's causing it to crash is I keep starting it and then stopping it to see if it's working.
Speaker I: And so I think starting it and then stopping it and starting it again causes it to crash.
Speaker I: I won't do that anymore.
Speaker C: And it looks like you've found a way of mapping the location to that without having people have to give their names each time.
Speaker C: It's like you have the...
Speaker C: No.
Speaker C: So you know that...
Speaker C: I mean, are you going to write down that I said here?
Speaker I: I'm going to collect the digit forms and write it down.
Speaker I: So they should be right with what's on the digit forms.
Speaker I: Okay, so I'll go ahead and start with the digits.
Speaker I: Reading transcript.
Speaker I: 1, 2, 5, 1, dash, 1, 2, 7, 0.
Speaker I: 7, 5, 3, 9, 1, 2, 0, 1, 2, 7, 3, 4, 5, 2, 6, 9, 6, 3, 9, 3, 0, 6, 4, 7, 8, 2, 0, 0, 6, 3, 0, 9, 0, 2, 9, 3, 4, 9, 5, 0, 4, 5, 4, 6, 7, 8, 0, 4, 2, 2, 2, 1.
Speaker I: And I should say that you just read each line and then pause, really.
Speaker I: Okay.
Speaker G: Start by giving the transcript.
Speaker A: OK.
Speaker A: Number 1, 9, 1, dash, 1, 2, 1, 0, 8, 0, 1, 1, 0, 9, 7, 4, 0, 2, 6, 1, 6, 2, 8, 4, 8, 3, 2, 7, 3, 4, 5, 0, 5, 0, 8, 5, 6, 7, 3, 8, 8, 2, 9, 3, 9, 7, 8, 4, 0, 8, 6, 3, 0, 9, 0 9 4 9 7 4 4 1 2 0 8 4 1 5 4 8 4 0 6 8 3 0 3 8 7 7 8
Speaker G: Transcript 1 2 1 1 dash 1 2 3 0 9 0 1 5 2 3 1 2 5 9 1 3 7 0 0 4 5 0 1 4 5 3 5 6 7 9 4 1 9 0 0 0 2 7 0 5 1 4 2 3 0 2 4 3 8 6 2 4 7 4 9 8 4 1 8 7 5 0 9 6 0
Speaker D: Transcript 9 5 1 9 7 0 9 0 0 0 6 2 0 1 0 6 1 4 9 5 3 5 0 4 2 0 5 6 8 7 9 8 5 8 9 0 1 0 2 9 9 0 0 5 9 1 6 0 0 2 6 6 2 0 0 6 3 9 3 1 0 4 5 6 0 7 7 0 9 1 4 3 9 2
Speaker H: Transcript 1 2 3 1 dash 1 2 5 0 0 0 1 0 0 0 1 3 2 4 4 5 3 6 4 5 5 6 8 0 6 7 8 9 0 5 0 2 9 1 0 3 7 0 1 6 5 9 9 2 9 8 1 1 2 7 3 6 4 5 6 0 5 7 7 8 0 8 1 3 6 2 9 2 1 0 0 0 0
Speaker C: Transcript number 1 1 3 1 dash 1 1 5 0 6 5 2 9 7 8 8 9 0 0 1 1 8 2 4 9 2 3 5 7 8 0 4 5 0 2 5 6 8 6 4 6 7 9 9 9 686-867-914-062-068-19829-234-6106059
Speaker J: Transcript 1151-117-0, 73868-936-02002-10329-6068-4300-56508-790-638-902225-01515-2535-345-6
Speaker E: Transcript 971-919-436-0790-5403-120033-305-51915-657-2790-89343-0090-0, 0000927-213-01002-103, 00003-6505-6505-660810-617-9405-6505-6802-103-103305-6405-8405-6405-6805-6405-6405-6505-8406-710-8405-6405-6605-6405-6405-6405-6805-6405-6405-6405-6405-6405-6405-6405-6405-6405-6405-6405-6405-6405-6405-6405- IS-M-198-444-5מיםcyr Mysticor Over篦
Speaker G: Commнибудь
Speaker I: We should add a feel to the form here for native language.
Speaker G: You know, it doesn't seem like a bad idea. I think I've probably forgot that.
Speaker I: But I think that would be a good thing.
Speaker I: After I just printed out a Zillion of them.
Speaker G: Yeah, well.
Speaker G: So I do have a agenda suggestion.
Speaker G: I think the things that we talk about in this meeting tend to be a mixture of procedural mundane things and research points.
Speaker G: And I was thinking, I think it was a meeting a couple of weeks ago that we spent much of the time talking about the mundane stuff because that's easier to get out of the way.
Speaker G: And then we sort of drifted into the research and maybe five minutes into that.
Speaker G: Andreas had to leave.
Speaker G: So I suggest we turn around.
Speaker G: And sort of we have, anyway, has some mundane points that we could send in an email later, hold them for a bit, and let's talk about the research, kind of, things.
Speaker G: So the one thing I know that we have on that is we had talked a couple of weeks before about the stuff you were doing with attempting to locate events.
Speaker G: We had little go around trying to figure out what you meant by events.
Speaker G: But I think what we had meant by events, I guess, was points of overlap between speakers.
Speaker G: But I gathered from our discussion a little earlier today that you also mean interruptions with something else like some other noise.
Speaker G: Yes?
Speaker G: You mean that is an event also?
Speaker G: Senator, you have done some work on that.
Speaker G: And then the other thing might be nice to have a preliminary discussion of some of the other research areas that we're thinking about doing.
Speaker G: I think, especially since you haven't been, and this means a little bit, maybe, in some discussion of some of the plausible things to look at how we're starting to get data.
Speaker G: And one of the things I know that also came up is some discussions that Jane had with Lucandra about some work about.
Speaker G: I don't want to try to say it, because I'll say it wrong.
Speaker G: But anyway, some potential collaboration there about the working with these data.
Speaker G: Oh, sure.
Speaker G: So don't around.
Speaker G: I don't know if this is sort of like everybody has something contribute sort of thing.
Speaker G: I think there's just a couple of people primarily.
Speaker G: But why not?
Speaker G: Actually, I think that last one I just said we could do fairly quickly.
Speaker G: So when you start with that.
Speaker G: OK.
Speaker C: Child.
Speaker C: Yeah, just explain a little more.
Speaker C: So he was interested in the question, relating to the research that he presented recently, of inference structures, and the need to build in this sort of mechanism for understanding language.
Speaker C: And he gave the example in his talk about how, I'm remembering it just off the top of my head right now, but it's something about how Joe Slip, John had washed the floor or something like that.
Speaker C: And I don't have it quite right, but that kind of thing, where you have to draw the inference that, OK, this time sequence, but also the causal aspects of the floor and how it might have been the cause of the fall, and that it was the other person who fell, and the one who cleaned it, and these sorts of things.
Speaker C: So I looked through the transcript that we had so far, and found identified a couple different types of things of that type.
Speaker C: And one of them was something like, during the course of the transcript, we had gone through the part where everyone said which channel they were on and which device they were on.
Speaker C: And the question was raised, well, should we restart the recording at this point?
Speaker C: And Daniela said, well, we're just so far ahead of the game right now, we really don't need to.
Speaker C: Now, how would you interpret that without a lot of inference?
Speaker C: So the inferences that are involved are things like, so how do you interpret ahead of the game?
Speaker C: So it's metaphorically.
Speaker C: What you draw, the conclusions that you need to draw are that space is involved in recording, that we have enough space, and he continued.
Speaker C: It's like we were so ahead of the game, because now we have built-in down sampling.
Speaker C: So you have to get the idea that ahead of the game is speaking with respect to space limitations that in fact down sampling is gaining us enough space, and that therefore we can keep the recording we've done so far.
Speaker C: But there are a lot of different things like that.
Speaker I: So do you think his interest is in using this as a data source or training material or what?
Speaker G: Well, I should have maybe interject, because this started off with a discussion that I had with him.
Speaker G: So we were trying to think of ways that his interest could interact with our resume.
Speaker G: And I thought that if we were going to project into the future when we had a lot of data and such things might be useful for that, in order before we invested too much effort into that, you should have looked into some of the data that we already have, and see, is there anything to this at all?
Speaker G: Is there any point to which you think that you could gain some advantage and some potential use for it?
Speaker G: Because it could be that you looked through it and you'd say, well, this is just the wrong task for him to pursue his.
Speaker G: And I got the impression from your mail that in fact there was enough things like this, just a little sample that you looked at that it's possible at least.
Speaker C: It's possible.
Speaker C: You know, we met and he was going to go and look through them more systematically, and then meet again.
Speaker C: So it's not a matter.
Speaker C: Yeah.
Speaker C: Yeah, I think.
Speaker G: Anyway, that's quite different than anything we've talked about that might come out from this.
Speaker J: So he gave me his text.
Speaker J: I mean, that's his major.
Speaker J: That's his major.
Speaker C: Just using text.
Speaker C: I mentioned several that had to do with implications drawn from international contours.
Speaker C: And that wasn't as directly relevant to what he's doing.
Speaker C: He's interested in these knowledge structures, inferences that you draw from.
Speaker G: I mean, he certainly could use text.
Speaker G: We were, in fact, looking to see if there is there something in common between our interested meetings and his interest in this stuff.
Speaker G: So.
Speaker I: And I imagine that transcripts of speech, text that his speech probably has more of those than sort of prepared writing.
Speaker I: I don't know whether or not that it means.
Speaker G: Probably depends on what the prepared writing was.
Speaker C: Yeah, I don't think I would make that leap.
Speaker C: Because in narratives, you know, I mean, if you spell out everything in a narrative, it could be really tedious.
Speaker I: Yeah, I'm just thinking, you know, when you're face to face, you have a lot of back channel.
Speaker I: And oh, that aspect.
Speaker I: Yeah.
Speaker I: And so I think it's just easier to do that sort of broad inference-drumping if it's face to face.
Speaker I: I mean, so if I just read that Dan was saying we're ahead of the game in that context, I might not realize that he was talking about discuses and opposed anything else.
Speaker C: I had several that had to do with back channels.
Speaker C: And this wasn't one of them.
Speaker C: This one really does make you leap from, so he said, we're ahead of the game, we have built in down sampling.
Speaker C: And the inference, if you had it written down, would be, but there are others that have back channels.
Speaker C: It was less interested in those.
Speaker D: Sorry to interrupt.
Speaker D: A minute, seven minutes ago, I briefly was not listening.
Speaker D: And so who is he in those context?
Speaker D: Yeah, there's a lot of people.
Speaker D: OK, so I was just realizing, you guys have been talking about E for at least three, three, four minutes without ever mentioning the person's name again.
Speaker D: So this is going to be a big, big problem if you want to later do indexing or speech understanding of any sort.
Speaker D: I wrote this down.
Speaker D: You guys know this?
Speaker J: As Morgan will say, well, you had some ideas.
Speaker J: And he never said, he looked.
Speaker I: Well, I think he's doing that intentional.
Speaker I: Right, yes, great.
Speaker J: So this is really great because the thing is, because he's looking at the first, even for addresses in the conversation, I bet you could pick that up in the acoustics just because your gaze is also correlated with the directionality of your voice.
Speaker I: Oh, that would be interesting.
Speaker J: Yeah, so that, I mean, to even know, when, yeah, if you have the PZM, you should be able to pick up what a person is looking at from their voice.
Speaker I: Well, especially with Morgan, with the way we have the microphones arranged, I'm sort of right on axis.
Speaker I: And it would be very hard to tell.
Speaker J: Right.
Speaker C: But you have things like this.
Speaker C: You'd have Fainter.
Speaker C: Wouldn't you get Fainter reception out here?
Speaker I: Sure, but I think if I'm talking like this, right now I'm looking at Jane and talking now.
Speaker I: I'm looking at Chuck and talking.
Speaker I: I don't think the microphones would pick up that difference.
Speaker I: But you don't have this problem.
Speaker G: Morgan is someone who does.
Speaker I: So if I'm talking to you, or I'm talking to you.
Speaker G: I've probably been affected by too many conversations where we were talking about lawyers and talking about concerns about, oh, I'm going to say something bad and so on.
Speaker G: And so I'm tending to stay away from people's names, even though.
Speaker J: Even though you could pick up later on just from the acoustic.
Speaker J: Who you really did mention who he was.
Speaker D: But I missed it.
Speaker D: Can I say it?
Speaker G: Yeah, no, no, no, it isn't sensitive at all.
Speaker G: I was overreacting just because we've been talking about it.
Speaker C: And in fact, it is sensitive.
Speaker C: I came up with something from the Kimmer's Abjects People that I wanted to mention.
Speaker C: I mean, it fits into the area of Monday.
Speaker C: And but they did say, I asked her very specifically about this cause of how it says, no individuals will be identified in any publication using the data.
Speaker C: OK, well, individuals being identified.
Speaker C: Let's say you have a snippet that says, Joe thinks such and such about this field, but I think he's wrong-headed.
Speaker C: Now, I mean, we're going to be careful not to have the wrong-headed part in there.
Speaker C: But let's say we say Joe used to think so and so about this area.
Speaker C: And in his publication, he says that, but I think he's changed his mind or whatever.
Speaker C: Then the issue of being able to trace Joe because we know he's well known in this field and all this and tie it to the speaker, whose name was just mentioned a moment ago, can be sensitive.
Speaker C: So I think it's really kind of adaptive and wise to not mention names anymore of them.
Speaker C: We have to because if there's a slander's aspect to it, then how much do we want to be able to have to remove?
Speaker G: Yeah, well, there's that.
Speaker G: But I mean, I think also to some extent it's just educating the human subjects people in a way.
Speaker G: Because if there's court transcripts, there's transcripts of radio shows.
Speaker G: I mean, people say people's names all the time.
Speaker G: So I think it can't be bad to say people's names.
Speaker G: It's just that, I mean, you're right that there's more potential.
Speaker G: If we never say anybody's name, then there's no chance of slandering anybody.
Speaker G: But then it won't.
Speaker G: It's not me.
Speaker J: If we, yeah, I mean, we should do whatever is natural in a meeting if we weren't being recorded.
Speaker G: Right.
Speaker G: So my behavior is probably not natural and so.
Speaker C: I'm going to ask, my feeling on it wasn't really important who said it.
Speaker D: Well, since you have to go over the transcripts later anyway, you could make it one of the jobs of the people who
Speaker I: do that to mark about this during an anonymization. If we wanted to go through and extract from the audio and the written every time someone says a name.
Speaker I: And I thought that our conclusion was that we didn't want to do that.
Speaker G: Yeah, we really can't.
Speaker G: But actually, I'm sorry, I really would like to push.
Speaker C: How did you say?
Speaker C: No, I just was suggesting that it's not a bad policy for potentially.
Speaker C: So we need to talk about this later.
Speaker G: Yeah, I didn't tend to this policy.
Speaker G: It was just unconscious.
Speaker G: Well, semi-conscious behavior.
Speaker G: I sort of knew who he is.
Speaker J: I remember who he is.
Speaker J: No, I didn't say you still know who he is.
Speaker G: With that presence.
Speaker G: We were talking about Dana one point.
Speaker G: We were talking about Lucindra, another point.
Speaker G: And I remember which part.
Speaker G: I don't know.
Speaker D: Well, the difference was Lucindra.
Speaker D: OK, that makes sense.
Speaker J: Yeah.
Speaker J: Down trembling.
Speaker J: Yeah.
Speaker F: Good.
Speaker F: Yeah.
Speaker F: Yeah, you can do all these inferences.
Speaker F: Yeah.
Speaker G: Yeah.
Speaker G: I would like to move it into what Jose has been doing.
Speaker G: He's actually doing something.
Speaker E: He's supposed to the rest of us.
Speaker E: OK.
Speaker E: I remember that my first objective in the projects is to study different parameters.
Speaker E: To find a good solution.
Speaker E: To detect the overlapping zone in speech record.
Speaker E: But in that way, I am speaking to study and to analyze the different sessions.
Speaker E: To find, to locate, to mark, to different overlapping zones.
Speaker E: So I was, I had transcluing the first session.
Speaker E: And I had found 1,000 acoustic events.
Speaker E: Besides the overlapping zone, I mean the spreads, expression, tag, club.
Speaker E: I don't know what is the difference.
Speaker E: You used to name the.
Speaker I: Landspeach zone.
Speaker I: Which.
Speaker I: I don't think we've been doing it at that level of detail.
Speaker I: So.
Speaker E: Yeah.
Speaker E: I don't need to level the different acoustic.
Speaker E: I prefer because I would like to study.
Speaker E: I will find a good parameter to detect the overlapping.
Speaker E: I would like to test this parameter with another acoustic events.
Speaker E: To find what is the false.
Speaker E: The false hypothesis which I produced that when we use this parameter, a big difference.
Speaker H: You know, so I think some of these that are the non-speech overlapping events may be difficult even for humans to tell what there's to there.
Speaker H: If it's a tapping sound, you wouldn't necessarily or something like that.
Speaker H: It might be hard to know that it was two separate events.
Speaker I: You weren't talking about just overlaps, or you were just talking about acoustic events.
Speaker E: Someone started, someone stopped.
Speaker E: I talked about acoustic events in general.
Speaker E: Yeah.
Speaker E: But my objective will be to study overlapping zones.
Speaker G: How many overlaps were there?
Speaker E: In 12-15 minutes, I found 1,000 acoustic events.
Speaker E: No, no.
Speaker E: How many of them were the overlaps of speech, though?
Speaker E: How many are most 300 in one session?
Speaker E: In fight in 45 minutes?
Speaker E: 300 overlapping.
Speaker E: 300 overlapping.
Speaker E: Overlapped speech with different duration.
Speaker C: Sure.
Speaker C: So if you had an overlap involving three people, how many times was that counted?
Speaker E: Yeah, three people to people.
Speaker E: I would like to consider one people with different noise in the background.
Speaker G: No, no.
Speaker G: I think what she's asking is, if at some particular stretch, you had three people talking instead of two, did you call that one event?
Speaker E: I consider one event for all the songs.
Speaker E: Well, I consider an acoustic event.
Speaker E: The overlapping songs, the period where three speakers are talking together.
Speaker I: So let's say me and Jane are talking at the same time, and then Liz starts talking also overall of us.
Speaker I: How many events would that be?
Speaker E: Should they be?
Speaker I: So two people are talking.
Speaker I: And then a third person starts talking.
Speaker I: Is there an event right here?
Speaker E: No.
Speaker E: For me, is there overlapping songs?
Speaker E: So if two or more people are talking?
Speaker E: You have more voice, if they're using them in moments.
Speaker G: Yeah, so I think we just wanted to understand how you're defining it.
Speaker G: So then in the region, since there is some continuous region, in between regions where there is only one person speaking, and one continuous region like that, you're calling an event.
Speaker G: Is it, are you calling the beginning or the end of it the event, or are you calling the entire length of it the event?
Speaker E: I consider the entire, all the time where the voices are overlapping.
Speaker E: But I don't distinguish between the numbers of speakers.
Speaker E: I'm not considering the fact of, for example, what you say, first two jokers are speaking, and third person joined to that.
Speaker E: For me, it's all that song with several numbers of speaker is the same acoustic event.
Speaker E: But without any mark between the song or the overlapping song, with two speaker speaking together, the song with the three speakers.
Speaker C: That would just be one.
Speaker E: One.
Speaker E: With the beginning mark and the ending mark.
Speaker E: Because for me, it's a song with some kind of distortion in the special.
Speaker E: Well, by the moment, by the moment.
Speaker I: But you could imagine that three people talking has a different spectral characteristic.
Speaker E: Yeah, good.
Speaker E: I have to start somewhere.
Speaker E: Yeah, we have to start somewhere.
Speaker E: We're just right away.
Speaker E: I don't know what we're talking about.
Speaker E: Yeah.
Speaker G: So again, that's three hundred in 45 minutes that are speaker, just speakers.
Speaker G: OK, yeah.
Speaker G: So that's about eight per minute.
Speaker C: For 1,000 events in 12 minutes, that's that can actually be tapped.
Speaker C: Well, 1,000 taps in eight minutes is a lot of fun.
Speaker E: I consider acoustic events the silent two.
Speaker E: Silence, starting or silent two things.
Speaker E: To detect because I consider acoustic events, all the things are not speech.
Speaker E: You're in the general point of view.
Speaker E: OK, so how many of the speech?
Speaker D: That speech or too much speech.
Speaker D: That's it.
Speaker G: So how many of the 1,000 were silent?
Speaker G: Silence, actually.
Speaker E: This is silent.
Speaker E: I haven't.
Speaker E: I would like to do a statistic study with you with a report from the study from the session, one session.
Speaker E: And I found another thing.
Speaker E: When I was a look at the difference speech file, for example, we use the Mrs. file to transcribe the events and the words.
Speaker E: I saw that the speech signal collected by this kind of mic or this kind of mic are different from the Mrs.
Speaker E: signer we collect by a microphone.
Speaker E: Right.
Speaker E: It's right.
Speaker E: But the problem is the following.
Speaker E: I knew that the signal will be different.
Speaker E: But the problem is we detected difference events in the speech file collected by a mic compared it with the Mrs. file.
Speaker E: And so if you try to crack only using the Mrs. file, it's possible if you use the transcription to evaluate a different system, it's possible.
Speaker E: And you use the speech file collected by the Fed mic to do experiments with the system if possible to evaluate or to consider acoustic events that which you marked in the Mrs. file at the donor pure in the speech signer collected by.
Speaker I: The reason that I generated the mix file was for IBM to do word level transcription.
Speaker I: It's a double the VAT transcription.
Speaker I: So I agree that if someone wants to do speech event transcription that the mix signals here, I mean, if I'm tapping on the table, it's not going to show up on any of the mics.
Speaker I: But it's going to show up rather loudly on the PZM.
Speaker E: So I say that this only because I, in my opinion, it's necessary to put the transcription on the speech file collected by the objective signer.
Speaker E: I mean the signer collected by the real mic in the future, the prototype, to correct the initial segmentation with the real speech you have to analyze, you have to process.
Speaker E: Because I found it a difference.
Speaker G: Yeah, well, just in that one 10 second or whatever was example that Adam had that we passed on to others a few months ago, there was that business where, I guess, was Adam and Jane were talking at the same time.
Speaker G: And in the close talking mics, you couldn't hear the overlap.
Speaker G: And then the distant mic, you're good.
Speaker G: So yeah, it's clear that if you want to study, if you want to find all the places where they're overlap, it's probably better to use a distant mic.
Speaker G: On the other hand, there's other phenomena that are going out at the same time before which it might be useful to look at the close talking mic.
Speaker J: So it's...
Speaker J: But why can't you use the combination of the close talking mic?
Speaker I: If you use the combination of the close talking mics, you would hear Jane interrupting me, but you wouldn't hear the paper rustling.
Speaker I: And so if your interest is...
Speaker G: So have it's masking, Matt.
Speaker J: If you're interested in speakers, you're working on those things.
Speaker J: And not the other kind of non speech.
Speaker I: Right.
Speaker I: Right.
Speaker I: So all of the other issue is that the mixed close talking mics, I'm doing weird normalizations and things like that.
Speaker J: But it's known.
Speaker J: Yep.
Speaker J: I mean, the normalization you do is over the whole conversation.
Speaker J: Right.
Speaker J: Over the whole meeting.
None: Yep.
Speaker J: So if you wanted to study people overlacking people, that's not a problem.
Speaker F: Right.
Speaker E: I saw the...
Speaker E: But I have a...
Speaker E: In your response, I saw this pitchfai...
Speaker E: I was really collected by the fed mic.
Speaker E: And the signal to noise, a relation is low.
Speaker E: It's very low.
Speaker E: It's very...
Speaker E: We compare it with the headphone.
Speaker E: Yep.
Speaker E: I found that...
Speaker E: Probably, in not sure by the moment.
Speaker E: But this is probably that a lot of...
Speaker E: For example, in the overlapping song, and in several parts of the files where you can find a smooth speech from one talking in the meeting, is probably that those files, you cannot find.
Speaker E: You cannot project because it confuses with noise.
Speaker E: And there are a lot of...
Speaker E: I see.
Speaker E: I have to study with more detail.
Speaker E: But my idea is to process only this...
Speaker E: This is the most of the speech.
Speaker E: The fact that it is more realistic, it's more realistic, but it'll be a lot harder.
Speaker G: Well, it'll be hard, but on the other hand, as you point out, if your concern is to get the...
Speaker G: Overliving people, people's speech, you will get that.
Speaker G: It's more better.
Speaker G: Are you making any use?
Speaker G: You were working with the data that had already been transcribed.
Speaker G: Does it?
Speaker G: Yes.
Speaker G: Now, did you make any use of that?
Speaker G: Because we have these 10 hours of other stuff that is not yet transcribed.
Speaker E: The tradition by Jane, I want to use to put...
Speaker E: It's a reference for me.
Speaker E: But the tradition, for example, I don't...
Speaker E: I'm not interested in the words, the tradition, the words, for the speech file.
Speaker E: But Jane, for example, puts a mark at the beginning of each talk in the meeting.
Speaker E: She includes information about the song where there is a overlapping song.
Speaker E: And there is any mark, time, temporal mark, to...
Speaker E: To...
Speaker E: To...
Speaker E: To Laver.
Speaker E: Right, so she is...
Speaker E: I think we need this information to...
Speaker G: Right.
Speaker G: So the 12 hours...
Speaker G: Of course, this included maybe some time where you were learning about what you wanted to do.
Speaker G: But...
Speaker G: But the talk is something that 12 hours marked the 45 minutes.
Speaker G: 12 minutes.
Speaker G: 12 minutes.
Speaker G: 12 minutes.
Speaker G: 12 minutes.
Speaker E: I thought you did 45 minutes.
Speaker E: No, 45 minutes is the session.
Speaker E: All the session.
Speaker E: Oh, you haven't done the whole session.
Speaker E: This is just 12 minutes.
Speaker E: Oh.
Speaker E: 12 hours of work.
Speaker E: Do... to segment a level, 12 minutes processes.
Speaker E: So let me back up again.
Speaker G: So when you said there were 300 speaker overlaps, that's in 12 minutes.
Speaker E: No, no, no.
Speaker E: I consider all the session because I count the overlapping's marked by...
Speaker E: Oh, okay.
Speaker E: In the...
Speaker E: In the 45 minutes.
Speaker G: So it's 345 minutes, you have... you have time marked 12 minutes.
Speaker G: The... the...
Speaker G: The...
Speaker G: Overlaps in 12 minutes.
Speaker G: Got it.
Speaker G: So...
Speaker D: Can I ask...
Speaker D: Can I ask whether you found...
Speaker D: You know how accurate...
Speaker D: James...
Speaker D: Labels were as far as...
Speaker D: You know, did you miss some overlaps or did you...
Speaker E: By the moment, I...
Speaker E: I don't computer my...
Speaker E: Temporal Mark with James.
Speaker E: I want to do it because...
Speaker E: Perhaps I have errors in the marks.
Speaker E: If I... I compare with James, it's probably... I can correct...
Speaker E: To get more...
Speaker E:...create the...
Speaker E:...tractition.
Speaker I: Also, James was doing work level.
Speaker I: Yeah.
Speaker I: So we weren't very...
Speaker J: Right, right.
Speaker D: I'm not expecting...
Speaker J: I'm not in work level, but actually...
Speaker J: No.
Speaker J: I didn't need to...
Speaker J:...show the exact point of interruption.
Speaker J: You just were showing at the level of the phrase...
Speaker J: Or the level of the speech spurt or...
Speaker C: Well, yeah, I would say time been.
Speaker C: So my goal was to get words with reference to a time been...
Speaker C: Beginning and end point.
Speaker C: And sometimes, you know, I was like, You could have an overlap where someone said something in the middle.
Speaker C: But it was just wasn't important for our purposes to have it that...
Speaker C: Disrupt that unit in order to have, you know, the words in the order in which they were spoken.
Speaker C: It would have been hard with the interface that we have.
Speaker C: Now, my app...
Speaker C: I'm working on course, and I realized...
Speaker C: It's an overlapping interface, but...
Speaker E: You said we'd work, but I think we need to...
Speaker E: No, of course.
Speaker D: I expected to find more overlap than...
Speaker D: No.
Speaker D:...because you're looking at it at a much more detailed level.
Speaker E: I want to computer it.
Speaker E: I hope 60 to 1.
Speaker G: Well, but I have a suggestion about that.
Speaker G: Obviously, this is very, very time consuming...
Speaker G:...and you're finding lots of things which I'm sure...
Speaker G:...are going to be very interesting.
Speaker G: But in the interest of making progress...
Speaker G:...my name is...
Speaker G:...how would it affect your time if you only marked the speaker overlaps?
Speaker G: Only.
Speaker G: Yes. Do not mark any other events, but only marked speaker.
Speaker G: Do you think that would speed it up quite a bit?
Speaker G: Do you think that would speed it up?
Speaker G: Speed up your marking?
Speaker E: I... I...
Speaker E: I wanted to...
Speaker E: I don't understand the...
Speaker G: It took you a long time to mark 12 minutes.
Speaker G: Oh, yeah.
Speaker G: Now, my suggestion was for the other 33...
Speaker E:...only to mark only 12 minutes.
Speaker G: Yeah, and my question is, if you did that...
Speaker G:...if you followed my suggestion...
Speaker G:...would it take much less time?
Speaker E: Oh, yeah. Sure.
Speaker E: Yeah, okay.
Speaker E: That I think it's a good idea.
Speaker E: Sure.
Speaker E: That I think it's a good idea because...
Speaker E: I need a little time to put the label on to...
Speaker G: Yeah, I mean, we know that there's noise.
Speaker G: There's continual noise from fans and so forth.
Speaker G: And there is more impulsive noise from taps and so forth.
Speaker G: And something in between with paper rustling.
Speaker G: We know that all of that's there and it's a worthwhile thing to study.
Speaker G: But obviously, it takes a lot of time to mark all of these things.
Speaker G: Whereas, I would think that we can study more or less as a distinct phenomenon...
Speaker G:...the overlapping of people talking.
Speaker G: Okay, so then you can get...
Speaker G:...because you need...
Speaker G:...if it's 300...
Speaker G:...it sounds like you probably only have 50 or 60 or 70...
Speaker G:...events right now that are really...
Speaker G:...and you need to have a lot more than that to have any kind of...
Speaker G:...even visual sense of what's going on...
Speaker G:...much less than any kind of reasonable statistics.
Speaker J: Now, why do you need to mark...
Speaker J:...speaker overlap by hand if you can infer it from the relative energy...
Speaker I:...that's why I was going to bring up.
Speaker J: You shouldn't need to do this completely.
Speaker G: Okay, yeah, so let's back up because you went here for an earlier conversation.
Speaker G: So the idea was that what he was going to be doing...
Speaker G:...was experimenting with different measures...
Speaker G:...such as the increase in energy...
Speaker G:...such as the energy and the LPC residuals...
Speaker G:...I mean, there's a bunch of things...
Speaker G:...I mean, increased energy is sort of an obvious one.
Speaker G: Yeah.
Speaker G: And it's not obvious.
Speaker G: I mean, you could do the dumbest thing and get it 90% of the time.
Speaker G: But when you start going past that and trying to do better...
Speaker G:...it's not obvious what combination of features...
Speaker G:...is going to give you the right detector.
Speaker G: So the idea is to have some ground truth first.
Speaker G: And so the idea of the manual marking was to say,...okay, it's really here.
Speaker H: But I think Liz is saying why not get it out of the time...
Speaker J: Get it from the close talking mics.
Speaker J: Yeah, or get it first pass.
Speaker J: We talked about that.
Speaker J: And then go through sort of a lot better.
Speaker G: We talked about that.
Speaker G: So it's a bootstrapping thing.
Speaker G: The idea was we thought it would be useful for him to look at the data anyway.
Speaker G: And then whatever he could mark would be helpful.
Speaker G: And it's a question of what you bootstrapped from.
Speaker G: You know, do you bootstrapped from a simple measurement...
Speaker G:...which is right most of the time and then you do better...
Speaker G:...or do you bootstrapped from some human being looking at it...
Speaker G:...and then do your simple measurements from the close talking mic.
Speaker G: Even with a close talking mic, you're not going to get it right all the time.
Speaker J: Well, that's what I wonder because...
Speaker I:...or how bad it is.
Speaker I: I'm working on a program to do that.
Speaker J: Because that would be interesting, especially because the bottleneck is the transcription.
Speaker J: Right?
Speaker J: We've got a lot more data than we have the solutions.
Speaker J: We have the auto-experts.
Speaker J: We have the close talking mic.
Speaker J: So I mean, it seems like one kind of project is not perfect.
Speaker J: But that you can get the training data for pretty quickly is...
Speaker J:...if you infer from the close talking mics where the on-off points are, of speech...
Speaker J:...we discuss that.
Speaker J: And how can we detect that from a far film?
Speaker I: I've written a program to do that.
Speaker I: And sorry, I'm in it.
Speaker I: It's okay.
Speaker I: But it's doing something very, very simple.
Speaker I: It just takes a threshold based on...
Speaker D: Or you can set the threshold low and then we'd out the false alarms by hand.
Speaker I: And then it does a median filter and then it looks for runs.
Speaker I: And it seems to work. I'm sort of fiddling with the parameters to get it to actually generate something.
Speaker I: And I haven't...
Speaker I: I don't...
Speaker I: What I'm working on, what I was working on was getting it to a form where we can import it into the user interface that we have into transcriber.
Speaker I: And so I told...
Speaker I: I said it would take about a day.
Speaker I: I've worked on it for about half a day.
Speaker I: So give me another half day and I will have something we can play with.
Speaker G: See, this is where we really need the meeting record to query stuff to be working.
Speaker G: Because we had these meetings and we had this discussion about this and I'm sort of remembering a little bit about what we decided.
Speaker G: But I could remember all of it.
Speaker G: So I think it was partly that...
Speaker G: You know, give somebody a chance to actually look at the data and see what these are like.
Speaker G: Partly that we have some ground truth to compare against when he gets his thing going.
Speaker J: It was definitely good to have somebody look at us thinking as a way to speed up.
Speaker G: But that was exactly the notion that we discussed.
Speaker C: Another thing we discussed was that...
Speaker C: I think that's the idea.
None: I think that's the idea.
Speaker C: The idea was that there was this already a script, I believe, that Dan had written, that handles bleed through.
Speaker C: I mean, because you have this close...
Speaker C: You have contamination from other people who speak loudly.
Speaker I: Yeah, and I haven't tried using that.
Speaker I: It would probably help the program that I'm doing to first feed it through that.
Speaker I: It's a cross-correlation filter.
Speaker F: Yeah.
Speaker I: So I haven't tried that.
Speaker I: So it might be something...
Speaker I: It might be a good way of cleaning it up a little.
Speaker C: Having that be a pre-processor and then run it through yours.
Speaker C: But that's a refinement.
Speaker G: I think we want to see try the simple thing first because you have this complex thing up afterwards that does something good.
Speaker G: You sort of want to see what the simple thing does first.
Speaker G: But having somebody have some experience again with marking it from a human standpoint...
Speaker G: I don't expect Jose to do it for 50 hours of speech.
Speaker G: But I mean, if he could speed up what he was doing by just getting the speaker overlapped so that we had, say, for 45 minutes, then at least we'd have 300 examples of it when Adam was doing his automatic thing.
Speaker G: He could then compare it to that and see what it was doing.
Speaker H: I did something almost identical to this at one of my previous jobs.
Speaker H: And it works pretty well.
Speaker H: I mean, almost exactly what you described, an energy detector with a biggie and filter, you look for runs.
Speaker H: And you think like the right thing to do.
Speaker H: Yeah, I mean, you can get...
Speaker H: I mean, you get them pretty far with the literature, sir.
Speaker H: And so I think doing that to generate these possibilities and then going through and saying yes or no on them would be a quick way to...
Speaker I: That's good validation.
Speaker I: Yeah.
Speaker B: Is this proprietary?
Speaker I: If you have a patent.
Speaker F: No.
Speaker H: This one I was working for the government.
Speaker H: Nicey.
Speaker C: Oh, then everybody owns it.
Speaker C: Is it something that we could just co-op to?
Speaker G: Well, he's pretty close.
Speaker G: Yeah, anyway.
Speaker C: I just thought if it was tried and true, then he's gone through additional models.
Speaker I: Although, if you have some parameters like what's a good window size for the median filter?
Speaker H: I have to remember.
Speaker H: I'll think about it.
Speaker D: And it might be different for government people.
Speaker I: I didn't know for government work, because they say different bandwidth.
Speaker I: I was doing pretty short, you know, 10th of a second.
None: Sort of numbers.
Speaker G: Okay.
Speaker G: I don't know.
Speaker G: If we want to...
Speaker G: So, maybe we can move on to other things in the meantime.
Speaker C: One question about statistics.
Speaker C: 12 minutes.
Speaker C: If we took 300 and divided it by 4, which is about the length of 12 minutes, I'd expect, like, to be 75 overlaps.
Speaker C: Did you find more than 75 overlaps in that period?
Speaker C: More than?
Speaker C: More than how many overlaps in your 12 minutes?
Speaker E: Not even.
Speaker E: All the...
Speaker E: I skype only 12 minutes from the...
Speaker E: I don't count the...
Speaker E: I consider...
Speaker E: I consider to be...
Speaker I: I bet there more, because the beginning of the meeting had a lot more overlaps than...
Speaker I:...the middle ran.
Speaker I: Because we're dealing with the...
Speaker I: In the early meetings, we're recording while we're saying, who's talking on what microphones and things like that.
Speaker I: And that seems to be a lot of overlap.
Speaker C: I think it's an empirical question.
Speaker C: I think we could find that out.
Speaker C: I'm not sure that the beginning had more.
Speaker G: So, I was going to ask, I guess, about any other things that...
Speaker G: That you do want to talk about, especially since...
Speaker G:...I'm very misleading in five minutes.
Speaker G: But...
Speaker J: I just asked about the data, like, very straightforward questions, where we are on the amount of data and the amount of transcribed data, just because I...
Speaker J: I wanted to get a feel for that to sort of be able to know what...
Speaker J:...can be done for us.
Speaker J: Right, so there's this...
Speaker J: How many meetings are we recording?
Speaker G: There's this 45-minute piece that Jane transcribed.
Speaker G: That piece was then sent IBM.
Speaker G: So they could transcribe as we have some comparison points.
Speaker G: Then there's a larger piece that's been recorded and...
Speaker G:...put on CD-ROM and sent IBM.
Speaker G: Right?
Speaker G: And then...
Speaker G: We don't know.
Speaker G: What's that?
Speaker G: That was about 10 hours and it was about...
Speaker G: Like, 10 meetings?
Speaker J: Yeah, something like that.
Speaker I: And then 10 meetings that have been sent to IBM.
Speaker I: Well, I haven't sent them yet because I was having this problem with the missing files.
Speaker I: Oh, that's right.
Speaker G: That has...
Speaker G:...those have not been sent.
Speaker H: How many total have we recorded now?
Speaker H: All together?
Speaker G: It's saying about...
Speaker G: About 12...
Speaker G: 12 or 12 or 13.
Speaker J: So we're recording only this meeting, like, continuously, we're only...
Speaker J: No.
Speaker G: No, no.
Speaker G: So that's the morning one.
Speaker G: That's the biggest one, chunk so far.
Speaker G: But there's at least one meeting recorded of the...
Speaker G:...natural language guys.
Speaker G: Do they mean every week?
Speaker G: They do.
Speaker G: And we talked to them about recording some more and we're going to...
Speaker G: We started having a morning meeting today, starting a week or two ago...
Speaker G:...on the front-end issues.
Speaker G: And we're recording those.
Speaker G: Okay.
Speaker G: There is a network services and applications group here who's agreed to have their meetings recorded.
Speaker G: And we're going to start recording them.
Speaker G: They're meeting on Tuesdays.
Speaker G: We're going to start recording them next week.
Speaker G: So actually we're going to start having a pretty significant chunk.
Speaker G: And so, you know, Adam's sort of struggling with trying to get things to be less buggy...
Speaker G:...and come up quicker when they do crash and stuff like that.
Speaker G: Now that the things are starting to happen.
Speaker G: So right now, I'd say the data is predominantly meeting meetings.
Speaker G: But there are scattered other meetings in it and that amount is going to grow...
Speaker G:...so that the meeting meetings will probably ultimately...
Speaker G:...if we collect 50 or 60 hours, the meeting meetings will probably be 20 to 30 percent of it.
Speaker J: So there's probably...
Speaker J:...there's three to four a week.
Speaker I: That's what we're aiming for.
Speaker J: That we're aiming for.
Speaker J: And they're each about an hour.
Speaker I: Yeah, although we'll find out tomorrow whether we can really do this or not.
Speaker G: Yeah, and the other things I'm not paused.
Speaker G: I'm sort of thinking as we've been through this a few times...
Speaker G:...that I really don't know.
Speaker G: Maybe you want to do it once for the novelty.
Speaker G: But I don't know if in general we want to have meetings...
Speaker G:...that we record from outside this group to do the digits.
Speaker G: Because it's just an added bunch of weird stuff.
Speaker G: And we're highly motivated.
Speaker G: In fact, the morning group is really motivated because they're working on connected digits.
Speaker I: So it's something I wanted to ask.
Speaker I: I have a bunch of scripts to help with the transcription of the digits.
Speaker I: We don't have to hand-transcribe the digits because we're reading them and I have those.
Speaker I: So I have some scripts that let you very quickly extract the sections of each utterance.
Speaker I: But I haven't been doing that.
Speaker I: If I did that, is someone going to be working on it?
Speaker G: Definitely something of interest.
Speaker G: Absolutely.
Speaker G: Whoever we have working on the acoustics for the meeting recording...
Speaker G: I'm interested in that.
Speaker I: I just don't have time to do it now.
Speaker D: I'm sure someone thought of this, but this reading of the numbers...
Speaker D:...would be extremely helpful to do adaptation.
Speaker D: Yep.
Speaker I: I would really like someone to do adaptation.
Speaker I: So if we got someone interested in that, I think it would be great for meeting recorder.
Speaker G: I mean, one of the things I wanted to do...
Speaker G: I talked to Don about one of the possible things you could do...
Speaker G:...or us, we have someone else do it...
Speaker G:...is to do block echo cancellation to try to give it some of the effects of the particle effects.
Speaker G: I mean, we have...
Speaker G: The party line has been that echo cancellation is not the right way to handle the situation...
Speaker G:...because people move around.
Speaker G: And if it's not a simple echo, like, a cross-talk kind of echo...
Speaker G:...but it's actually room acoustics.
Speaker G: You can't really do inversion.
Speaker G: And even echo cancellation is going to be something...
Speaker G:...someone may be moving enough that you are not able to adapt quickly.
Speaker G: And so the tack that we've taken is more...
Speaker G:...let's come up with feature approaches and multi-stream approaches and so forth...
Speaker G:...that will be robust to it for the recognizer...
Speaker G:...and not try to create a clean signal.
Speaker G: That's the party line.
Speaker G: But it occurred to me a few months ago that party lines are always sort of dangerous...
Speaker G:...and it's good to sort of test them, actually.
Speaker G: And so we haven't had anybody try to do a good serious job on echo cancellation...
Speaker G:...and we should know how well that can do.
Speaker G: So that's something I like somebody to do at some point.
Speaker G: Just take these digits, take the far field signal...
Speaker G:...and apply really good echo cancellation.
Speaker G: There was a nice talk recently by Lucen.
Speaker G: The block echo cancellation particularly appealed to me.
Speaker G: I'm not trying to change it sample by sample, but you have some reasonable sized blocks.
Speaker H: What is the artifact you've tried to recognize?
Speaker G: So you have a direct...
Speaker G:...what's the difference in...
None:...if you were trying to recognize the familiar filter...
Speaker G:...that was signing off.
Speaker G: That would subtract off the parts of the signal...
Speaker G:...that were the aspects of the signal that were different between the close talk and the distant.
Speaker G: So I guess the most echo cancellation...
Speaker G:...you've given that...
Speaker G:...you're trying to...
Speaker G:...there's a distance between the close and the distant mic...
Speaker G:...so there's a time delay there.
Speaker G: And after the time delay there's these various reflections.
Speaker G: And if you figure out what's the...
Speaker G:...there's a least-grays algorithm that adjusts itself...
Speaker G:...or adjust the weight so that you try to subtract...
Speaker G:...essentially subtract off different reflections.
Speaker G: So let's take the sample case where you just had...
Speaker G:...you had some delay in a satellite connection or something...
Speaker G:...and then there's an echo.
Speaker G: And you want to adjust this filter so that it will maximally reduce the effect of this echo.
Speaker H: So that would mean like if you were listening to the data that was recorded on one of those...
Speaker H:...just the raw data.
Speaker H: You might hear kind of an echo...
Speaker H:...and then this noise cancellation.
Speaker G: Well, I'm saying that's a simplified version of what's really happening.
Speaker G: What's really happening is...
Speaker G: Well, when I'm talking to you right now...
Speaker G:...you're getting the direct sound from my speech...
Speaker G:...but you're also getting the indirect sound that's bounced around the room a number of times.
Speaker G: Okay.
Speaker G: So now if you try to completely remove the effect of that...
Speaker G:...it's sort of impractical for a number of technical reasons.
Speaker G: But not to try to completely remove it that is invert the room response...
Speaker G:...but just to try to eliminate some of the effect of some of the echoes.
Speaker G: A number of people have done this...
Speaker G:...so that if you're talking to a speaker phone...
Speaker G:...it makes it more like it would be if you were talking right up to it.
Speaker G: So this is sort of the straight forward approach.
Speaker G: You say, I want to use this item...
Speaker G:...but I want to just track it off various kinds of echo.
Speaker G: So you construct a filter...
Speaker G:...and you have this filtered version of the speech...
Speaker G:...get subtracted off from the original speech...
Speaker G:...and you try to minimize the energy in some sense.
Speaker G: And so...
Speaker G: It's kind of a cleanup thing.
Speaker G: It's a cleanup thing, right?
Speaker G: So echo canceling is commonly done in Tollophany...
Speaker G:...and it's sort of the obvious thing to do in this situation...
Speaker G:...if you know you're going to be talking some distance from the mic.
Speaker H: In fact, when I would have meetings with the folks in Cambridge...
Speaker H:...when I had the BDN over the phone...
Speaker H:...they had some kind of a special speaker phone...
Speaker H:...and when they would first connect me...
Speaker H:...it would hear all this noise.
Speaker H: And then it would come on and it was very clear.
Speaker G: So it's taking samples, it's doing adaptations, adjusting weights...
Speaker G:...and then it's getting some.
Speaker G: So...
Speaker G:...anyway that's kind of a reason for something like that somebody tries...
Speaker G:...somebody like...
Speaker G:...and the digits would be a reasonable thing to do that with...
Speaker G:...I think there'd be enough data to do it with...
Speaker G:...and for that sort of task you wouldn't care...
Speaker G:...but it was largely a vocabulary speech or anything.
Speaker C: Is Brian King's worries work related to that?
Speaker C: There's a different type of evaluation.
Speaker G: Brian King's worries work is an example of what we did...
Speaker G:...from the opposite dogma, right?
Speaker G: And what I was calling a party line, which is that...
Speaker G:...doing that sort of thing is not really what we want.
Speaker G: We want something more flexible...
Speaker G:...where people might change their position...
Speaker G:...and there might be...
Speaker G:...there's also...
Speaker G:...oh yeah, noise.
Speaker G: So that echo cancellation does not really allow for noise.
Speaker G: If you have a clean situation but you just have some delays...
Speaker G:...then we'll figure out the right set of weights for your taps...
Speaker G:...for your filter in order to reduce the effect of those echoes.
Speaker G: But if there's noise, then the very signal that it's looking at...
Speaker G:...is corrupted so that it's decision about what the right...
Speaker G:...right delays are is in correct.
Speaker G: And so in a noisy situation, also in a situation...
Speaker G:...that's very, very, very long reverberation times...
Speaker G:...really long delays, it's sort of typically impractical.
Speaker G: So for those kind of reasons...
Speaker G:...and also a complete inversion.
Speaker G: If you actually, I mentioned that it's kind of hard to really do...
Speaker G:...the inversion of the room acoustics.
Speaker G: That's difficult because...
Speaker G:...often times the...
Speaker G:...the system transfer function is such that when it's inverted...
Speaker G:...you get something that's unstable.
Speaker G: And so if you do your estimate of what the system is...
Speaker G:...then you try to invert it, you get a filter that actually...
Speaker G:...rangs and goes to infinity.
Speaker G: So there's that sort of technical reason...
Speaker G:...and the fact that things move, there's error currents...
Speaker G:...I mean there's all sorts of reasons why that's not really practical.
Speaker G: So for all those kinds of reasons...
Speaker G:...include we didn't want to do inversion...
Speaker G:...and we even pretty skeptical of echo cancellation...
Speaker G:...which isn't really inversion.
Speaker G: And we decided to do this approach of taking...
Speaker G:...just picking features...
Speaker G:...which will give you something more stable...
Speaker G:...in the presence of or absence of room reverberation...
Speaker G:...and that's what Brian was trying to do.
Speaker G: So let me just say a couple things...
Speaker G:...that I was going to bring up.
Speaker G: Let's see, I guess you actually already said...
Speaker G:...this thing about the consent forms...
Speaker G:...which was that we now don't have to.
Speaker G: So this was the human subject's focus, you said this?
Speaker C: Apparently, we're going to do a revised form, of course.
Speaker C: But once a person is signing it once...
Speaker C:...then that's valid for a certain number of meetings.
Speaker C: She wanted me to actually estimate how many meetings...
Speaker C:...and put that on the consent form.
Speaker C: I told her that would be a little bit difficult to say.
Speaker C: So I think from a practical standpoint...
Speaker C:...maybe we could have them do it once every 10 meetings...
Speaker C:...or something that won't be that many people who do it that often...
Speaker C:...but just, you know, something else...
Speaker C:...they don't forget that they've done it, I guess.
Speaker G: Okay.
Speaker G: Back on data thing...
Speaker G:...so there's this sort of one hour, ten hour, a hundred hours sort of thing...
Speaker G:...that we have...
Speaker G:...we have an hour...
Speaker G:...that is transcribed.
Speaker G: We have 12 hours that's recorded, but not transcribed.
Speaker G: And at the right we're going by the end of the semester...
Speaker G:...we'll have, I don't know, 40 or 50 or something...
Speaker G:...if this really...
Speaker G:...but we have that one, so see what happens.
Speaker J: It's three to four per week.
Speaker G: So, eight weeks...
Speaker G:...not a lot of hours.
Speaker G: Eight weeks, ten to three, so it's 24.
Speaker G: So that's, yeah, so like 30 hours?
Speaker J: I mean, is there, I know this sounds tough, but we've got the room set up.
Speaker J: I was starting to think of some projects where you would use...
Speaker J:...well, similar to what we talked about with the energy detection...
Speaker J:...on the close talking mic.
Speaker J: There are a number of interesting questions that you can ask...
Speaker J:...about how interactions happen in the meeting.
Speaker J: They don't require any transcription.
Speaker J: So what are the patterns of the energy patterns over the meeting?
Speaker J: And I'm really interested in this.
Speaker J: But we don't have a lot of data.
Speaker J: So I was thinking, you know, we've got the room set up.
Speaker J: And you can always think of also for political reasons if the XC collected, you know, 200 hours...
Speaker J:...that looks different than 40 hours, even if we don't transcribe it ourselves.
Speaker G: But I don't think we're going to stop at the end of the semester.
Speaker G: So I think that if we are able to keep that up for a few months...
Speaker G:...we are going to have more like 100 hours.
Speaker J: Are there any other meetings here that we can record, especially meetings...
Speaker J:...that have some kind of conflict in them or some kind of...
Speaker J:...that are less...
Speaker J:...that have some more emotional aspects to them or...
Speaker J: We had some good ones earlier.
Speaker J: There is laughter.
Speaker J: I'm talking more about strong differences of the meeting...
Speaker J:...maybe with manager types or...
Speaker I: I think it's hard to record this.
Speaker C: To be allowed to record.
Speaker C: It's also a lot of people cancel out afterwards.
Speaker C: But I wonder if they can keep AID anyway.
Speaker I: Yeah, I was going to mention that.
Speaker I: That's a good idea. That would be a good match.
Speaker G: Yeah, so I'd mention to Adam and...
Speaker G:...that was not the thing I was going to talk about.
Speaker G: I'd mention to them before that...
Speaker G:...it occurred to me that we might be able to get some additional data...
Speaker G:...by talking to acquaintances and local broadcast media.
Speaker G: Because we had talked before about the problem...
Speaker G:...but using found data that it's just set up...
Speaker G:...however they haven't set up.
Speaker G: They don't have any say about it.
Speaker G: It's typically one microphone.
Speaker G: And so it doesn't really give us the character six we want.
Speaker G: And so I do think we're going to continue recording here...
Speaker G:...and record what we can.
Speaker G: But it did occur to me that we could go to friends and broadcast media...
Speaker G:...and say, hey, you have this panel show...
Speaker G:...or this discussion show.
Speaker G: And can you record multi-channel?
Speaker G: And they may be willing to record it with...
Speaker G: Tell them I could.
Speaker G: Well, they probably already used the PAL...
Speaker G:...but they might be able to have it...
Speaker G:...it wouldn't be that weird for them to have another mic that was somewhat distant.
Speaker G: It wouldn't be exactly this setup, but it'd be that sort of thing.
Speaker G: And what we were going to get from UW, assuming they start recording,
Speaker J:...is also not going to be this exact setup.
Speaker G: No, I think that would be great. So I was thinking of looking into that.
Speaker G: And the answer we had that discussion, in fact, is that it's even possible...
Speaker G:...since, of course, many radio shows are not live...
Speaker G:...that we could invite them to record some of their shows here.
Speaker J: Wow.
Speaker J: The thing is, they're not as averse to wearing one of these.
Speaker J: I mean, they're on the radio, right?
Speaker J: Right.
Speaker J: I think that would be fantastic, because those kind of panels and those have interest in.
Speaker J: Yeah.
Speaker J: That's a side of a style that we're not collecting here.
Speaker G: And the other side to it, which is where we're coming from, I'll talk to you more about later, is that there's...
Speaker G:...the radio stations and television stations already have stuff worked out presumably related to illegal issues and permissions and all that.
Speaker G: I mean, they already do what they do.
Speaker G: So it's another source.
Speaker G: So I think it's something we should look into. We'll collect what we collect here.
Speaker G: Hopefully, they will collect more UW also.
Speaker G: And maybe we have this other source, but yeah, I think it's not unreasonable to aim at...
Speaker G:...getting significantly in excess of 100 hours.
Speaker G: I mean, that was sort of our goal.
Speaker G: The thing was, I was hoping that we could...
Speaker G:...in the under this controlled situation, we could at least collect, you know, 30 to 50 hours.
Speaker G: And if the rate we're going, we'll get pretty close to that, I think, this semester.
Speaker G: And if we continue to collect some next semester, I think we should...
Speaker J: Right, yeah, I was mostly trying to think, okay, you start a project within, say, a month.
Speaker J: How much data do you have to work with?
Speaker J: You want to sort of freeze your data for a while.
Speaker J: So right now, and we don't have the transcripts back yet from IBM.
Speaker J: Well, we don't have it for this, you know, 45 minutes that way.
Speaker J: So not complaining, I was just trying to think, what kinds of projects can you do now,...versus six months from now, and they're pretty different.
Speaker G: Yeah, so I've seen it right now. It's sort of this exploratory stuff where you look at the data, you do some primitive measures, and get a feeling for what the scatter plots look like.
Speaker G: Right, right.
Speaker G: And meanwhile, we collect, and then it's more like, yeah, three months from now or six months from now, you can do a lot more.
Speaker J: Because I'm not actually sure just logistically that I can spend...
Speaker J: I don't want to charge the time that they have on the project too early before there's enough data to make good use of the time.
Speaker J: And especially with the student, for instance, this guy who seems to...
Speaker J: Anyway, I shouldn't say too much, but if someone came that was great, and wanted to do some real work, and they have to end by the end of the school year in the spring, how much data will I have to work with that person?
Speaker J: Right.
Speaker G: Yeah, so I would think exploratory things now.
Speaker G: Three months from now, I mean, the transcriptions are...
Speaker G: I mean, the transcriptions, I think, are a bit unknown, because we haven't gotten those back yet, as far as the timing.
Speaker G: But I think, as far as the collection, it doesn't seem to me unreasonable to say that, in January, roughly, just roughly three months from now, we should have at least something like 25, 30 hours.
Speaker G: So that's...
Speaker J: And you just don't know about the transcription part of that.
Speaker J: And we need to...
Speaker C: I think that there's the possibility that the transcript will need to be adjusted after words and...
Speaker C: especially since these people won't be used to dealing with multi-channel transcription.
Speaker C: So I think that we'll need to adjust some...
Speaker C: And also, if we want to add things like...
Speaker C: well, more refined coding of overlaps than definitely, I think we should count on having extra pass through.
Speaker C: I wanted to ask another aspect of the data collection.
Speaker C: There'd be no reason why a person couldn't get together several, you know, friends and come and argue about a topic if they wanted to, right?
Speaker G: If they really have something they want to talk about as opposed to something...
Speaker G: I mean, what we're trying to stay away from was artificial constructions, but I think if it's a real...
Speaker G: Why not?
Speaker G: I'm thinking...
Speaker G: Stakes in political debates?
Speaker J: Well, yeah, or just if you're...
Speaker J: If you have...
Speaker J: There are meetings here that happen that we can record, even if we don't...
Speaker J: have them do the digits, or maybe have them do a shorter digit thing.
Speaker J: Like, you know...
Speaker I: We don't have to do the digits at all if we don't want to.
Speaker J: One string of digits is something that probably will indeed.
Speaker J: Then having the data is very valuable, because I think it's politically better for us to say we have as many hours of audio data, especially with the ITR, if we put in a proposal, it'll just look like EXU's collected a lot more audio data, whether it's transcribed or not, is another issue, but there are research questions you can answer without the transcriptions, or at least that you can start to answer.
Speaker B: It seems like you could hold some meetings, you know, and maybe you could hold some additional meetings.
Speaker H: Would it help at all?
Speaker H: I mean, we're already talking about sort of two levels of detail, and meetings.
Speaker H: One is without doing the digits...
Speaker H: I guess the full-blown one is where you did the digits and everything, and then talk about doing it without digits.
Speaker H: What if we had another level just to collect data, which is without the headsets, and we just did the table amount.
Speaker H: We need the close-talking line.
Speaker J: I mean, absolutely.
Speaker I: Yeah, I'm really scared.
Speaker I: It seems like it's a big part of this corpus, is that what it was like?
Speaker J: Or at least, like me personally, I couldn't use that data.
Speaker C: Okay, and Murray also, we had this camera-bunship issue here, that's important.
Speaker J: Yeah.
Speaker J: So it's a great idea, and if it were true, then I would just do that, but it's not that bad.
Speaker J: Like, the room is not the bottleneck, and we have enough time in the room, and it's getting the people to come in and put on the...
Speaker G: Okay, by the way, I don't think the transcriptions are actually, in the long run, such a big bottleneck.
Speaker G: I think the issue is just that we're blazing that path.
Speaker G: And do you have any idea when you'd be able to send the...
Speaker I: Well, I've been burning two CDs a day, which is about all I can do with the time I have.
Speaker I: Yeah.
Speaker I: So it'll be early next week.
Speaker G: Yeah, okay.
Speaker G: So early next week is sent it to them, and then we check with them to see if they've got it, and we start asking about timing for it.
Speaker G: So I think once they get sorted out about how they're going to do it, which I think they're pretty well long on, because they were able to read the files and so on, right?
Speaker G: Yeah, but...
Speaker G: Well...
Speaker G: Yeah, when those were, they aren't.
Speaker G: Have they ever responded?
Speaker G: No.
Speaker G: Yeah, but, you know, so they have, you know, they're volunteering at time, and they have a lot of other things to do, right?
Speaker G: Yeah, they have a lot of other things to do, right?
Speaker G: But anyway, though, I think once they get that sorted out, they're making cassettes there, and then they're handing it to someone who is doing it, and I think it's not going to be...
Speaker G: I don't think it's going to be that much more of a deal for them to do 30 hours than to do one hour.
Speaker G: Yeah, it's not going to be 30- So it's the amount of...
Speaker G: It's just getting it going.
Speaker I: It's pipeline, pipeline issue.
Speaker I: So what's the pipeline?
Speaker I: What about these lunch meetings?
Speaker J: I mean, I don't know.
Speaker J: If there's any way without too much more overhead, even if we don't ship it right away to IBM, even if we just collected here for a while to record, you know, two or three more meetings a week, just to have the data, even if they're not doing the digits, but they do wear the...
Speaker G: But the lunch meetings are pretty much one person getting up.
Speaker J: No, I meant...
Speaker J: Sorry, the meetings where people eat their lunch downstairs, maybe they don't want to be recorded, but...
Speaker I: Oh, and we're just chatting?
Speaker I: Yeah, we have a lot of the things.
Speaker J: Actually, I actually think that's useful data.
Speaker I: Yeah, the problem with that is...
Speaker I: I think I would feel a little constrained to...
Speaker I: Okay, you know, some of them are soccer ball meetings.
Speaker I: I guess none of you were there for a soccer ball meeting.
Speaker J: Throw it out there with anyone knows of one more or two more meetings per week that happen at XC that we can record.
Speaker J: I think it would be worth it.
Speaker G: Yeah, well we should also check with Maria again, because they were really intending, maybe it just didn't happen, but they were really intending to be duplicating this in some level.
Speaker G: So then that would double what we had.
Speaker G: And there's a lot of different meetings that UW mean really a lot more than we have here, because we're not right on campus.
Speaker H: Is the notion of recording any of Chuck's meetings dead in the water?
Speaker H: They seem to have some problems,
Speaker G: whether we can talk about that later. But again, Jerry's open.
Speaker G: So I mean, we have two speech meetings, one network meeting.
Speaker G: Jerry was open to it, but I...
Speaker G: One of the things that I think is a little bit of a limitation there, is I think when people are not involved in our work, we probably can't do it every week.
Speaker G: I think that people are going to feel...
Speaker G: are going to feel a little bit constrained.
Speaker G: I might get a little better if we don't have them do the digits all the time.
Speaker G: Yeah.
Speaker G: And so then they can just really sort of chart you, put the mics on, they just charge in.
Speaker J: What if we give people, you know, we cater a lunch in exchange for them having their meeting here?
Speaker C: I do think eating while you're doing a meeting is going to be increasing my rights.
Speaker C: I had another question, which is, you know, in principle, I know that you don't want artificial topics, but it does seem to me that we might be able to get subjects from campus to come down and do something that wouldn't be too artificial.
Speaker C: I mean, we...
Speaker C: Political discussions or something, rather.
Speaker C: And, you know, people who are...
Speaker C: Because, you know, there's also this constraint.
Speaker C: It's like, you know, the...
Speaker C: Goldy bars, Goldy blocks.
Speaker C: It's like, you don't want meetings that are too large, but you don't want meetings that are too small.
Speaker C: And it just seems like maybe we could exploit human subjects in the positive sense of...
Speaker H: Well, even, I mean, coming down from campus is sort of a big thing.
Speaker H: But what about...
Speaker H: Could pay subjects.
Speaker H: Or what about people in the building?
Speaker B: Yeah, I don't get it.
Speaker B: They need credit.
Speaker H: Yeah, I was saying there's only other people.
Speaker H: And, you know, there's a lot of people in California downstairs.
Speaker I: And I just really doubt that any state of California meetings would be recordable and then really so both of the general public.
Speaker I: So, I mean, I talked with some people at the Hoss Business School who are interested in speech recognition.
Speaker I: And they sort of hummed and said, well, maybe we could have some meetings down here, but then I got a email from them and said, no, we decide we're not really interested, and we don't want to come down to hold meetings.
Speaker I: So, I think it's going to be a problem to get people regularly.
Speaker G: But, yeah, I can maybe he can...
Speaker G: Yeah, we can get some scattered things from this and that.
Speaker G: And I do think that maybe we can get somewhere with the radio.
Speaker G: I better context radio.
Speaker G: You can get a lot of lively discussions from those radio.
Speaker J: Well, and they're already...
Speaker J: Yeah.
Speaker J: These things are already recorded.
Speaker J: We don't have to ask them to.
Speaker J: Even, and I'm not sure how they recorded, but they must need some individual.
Speaker G: No, I'm not talking about ones that are already recorded.
Speaker G: I'm talking about new ones, because we would be asking them to do something different.
Speaker J: Well, we can find out...
Speaker J: I know, Princess Mark, living in this interested in L.D.C.
Speaker J: getting data...
Speaker G: Right, that's the found data idea.
Speaker G: But what I'm saying is, if I talk to people that I know who do these and who produce these things, we could ask them if they could record an extra channel, let's say, of a distant mic.
Speaker G: And I think routinely they would not do this.
Speaker G: So, since I'm interested in the distant mic stuff, I want to make sure that there is at least that somewhere.
Speaker G: But if we ask them to do that, they might be intrigued enough by the idea that they...
Speaker G: I might be able to talk them into it.
Speaker I: We're getting towards the end of our disc space, so we should think about...
Speaker I: Okay, well, why don't we...
Speaker G: When we...
Speaker I: Okay, leave them on for a moment until I turn this off, because that's what I mean.
Speaker I: Crash last time.
Speaker G: Turning off the microphone and crash.
Speaker G: Yeah.
Speaker B: Let's question them.
Speaker G: Okay.
