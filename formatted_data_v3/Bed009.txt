None: Okay.
Speaker D: Testing channel 2.
Speaker D: Two.
Speaker D: Two.
Speaker C: Oh.
Speaker E: Hmm?
Speaker E: There.
Speaker E: Wow.
Speaker E: So, rough and terminate here.
Speaker E: Great.
Speaker E: Great.
Speaker D: Made it safety.
Speaker D: So, what we have been doing is they would like us all to read these digits.
Speaker D: But we don't already.
Speaker D: A couple people read it.
Speaker D: When it gives them all German accents.
Speaker E: Okay.
Speaker E: The way you do it is you just read the numbers not as each single.
Speaker E: So, just like I do it.
Speaker E: First you read the transcript number.
Speaker E: My transcript number is L95.
Speaker E: 3230977352214082115160087096440 64404562850593 5261 358105 624 468 48551 4229 05756 07 32
Speaker B: Okay. What's my transcript number is L91 141628613157 0395 8 06622 0316143416171340652105 9821408492 126586666 866161311102066654159
Speaker A: Okay. My transcript number is L92 85034213760632 4970 6068 636 564 9306 641 8706 807 3 1770 7556 445660 4510 845 841 1037 1072 6774 1700
Speaker C: Okay. Let's be done with this. Okay. This is Mommy.
Speaker C: Come on in.
Speaker C: Okay. So, we're going to try to finish by five.
Speaker D: So, people who want to go here, Nancy Chang's talk downstairs.
Speaker D: And you guys are giving talks on tomorrow and Wednesday much.
Speaker C: That's great. Okay. So, you know what we're going to do?
Speaker E: I thought two things we'll introduce ourselves.
Speaker E: What we do. And we already talked with Andreas Tilo and David and some lines of code were already written today and almost tested.
Speaker E: And just going to say we have again the recognizer to pass the thing where we're working on and that should be no problem.
Speaker E: And then that can be sort of developed as needed when we enter the tourism domain.
Speaker E: We have talked this morning with Tillman about the generator.
Speaker E: And they are one of our diligent workers has to sort of volunteer to look over Tillman's shoulder while he is changing the grammar to English because we have we face two ways.
Speaker E: Either we do a simple concatenating grammar for the English generation which is sort of starting from scratch and doing it the easy way.
Speaker E: Always simply adopt the more in-depth style that is implemented in the German system.
Speaker E: And are then able not only to produce strings but also the syntactic parts, not parts in the syntactic tree that is underneath the syntactic structure.
Speaker E: Which is the way we decided we were going to go because it's easier in the beginning.
Speaker E: And that's required some knowledge of those grammars and some linguistic background.
Speaker E: But it shouldn't be a problem for anyone.
Speaker C: Okay, so that's the answer.
Speaker C: You're going to have some time to do that with these guys.
Speaker E: Sure.
Speaker D: Because you're the grammar major.
Speaker D: Okay.
Speaker C: I mean it makes sense doesn't it?
Speaker D: Yeah.
Speaker D: Okay, so I think that's probably the right way to do that.
Speaker D: And yeah, so I actually want to find out about it too but I may not have time to...
Speaker E: The ultimate goal is that before they leave we can run through the entire system input through output on at least one or two simple things.
Speaker E: And by virtue of doing that, then in this case, John will have acquired the knowledge of how to extend it at infinitum.
Speaker E: When needed, if needed, when wanted.
Speaker E: So for...
Speaker C: Okay, that sounds great.
Speaker E: And also, Ralph has hooked up with David and you're going to continue either all through tonight or tomorrow and whatever to get the password interface working.
Speaker E: They're sending out and ticking out lattices and doing this kind of stuff to see what works best.
Speaker D: So you guys enjoy your weekend?
Speaker D: Yes, yeah, I'm sorry.
Speaker D: You ever got to put the work?
Speaker D: Okay, so that's sort of one branch is to get us caught up on what's going on.
Speaker D: Also of course would be really nice to know what the plans are in addition to what's already in code.
None: And we can...
Speaker D: I don't know what was or the time when we were set up to do that.
Speaker D: It probably will work better if we do it later in the week after we actually understand better what's going on.
Speaker D: So when do you guys leave?
Speaker A: We're here through Sunday.
Speaker A: Oh, okay, so...
Speaker D: So we'll find a time later in the week to get together and talk about your understanding of what smart comp plans are and how we can change it.
Speaker E: So we already said a day for that.
Speaker E: Might be a bit official while we're all here.
Speaker C: Okay.
None: What does not work for me is Thursday afternoon.
Speaker D: I can do earlier than day on Thursday or most of the time on Friday.
Speaker E: Thursday morning sounds fine?
Speaker E: What are your constraints?
Speaker E: Thursday afternoon doesn't work for me, but...
Speaker E: It's either Thursday morning, no.
Speaker C: Thursday morning should be fine.
Speaker C: 11?
None: 11 on Thursday.
Speaker C: I was just thinking I will 11 by 11.
Speaker D: This is a different to our morning people.
Speaker A: So he's there.
Speaker A: Third Sunday live.
Speaker D: And actually we could invite Andreas as well.
Speaker D: He will be in Washington.
Speaker D: That's true.
Speaker D: He's off the office trip already.
Speaker E: But David is here and he's actually...
Speaker E: Those everything about the smart comp plans.
Speaker C: Okay, we'll see if David can make it out.
Speaker E: Okay, so facing to what we've been doing here.
Speaker E: One thing we're also using this room to collect data.
Speaker E: Not this type of data, not meeting data, but sort of our version of a wizard experiment, not like the ones in Munich, but pretty close to it.
Speaker E: The major difference to the Munich ones is that we do it...
Speaker E: We add the telephone, even all the recording is done here.
Speaker E: And so it's sort of a computer call system that gives you tourist information to get places.
Speaker E: And it breaks halfway through the experiment and a human operator comes on.
Speaker E: And part of that is sort of try to find out whether people change their linguistic verbal behavior when first thinking they speak to a machine or then to a human.
Speaker E: And we're setting it up so that we can...
Speaker E: We hope to implant certain intentions in people, for example.
Speaker E: We have first looked at a simple sentence that...
Speaker E: How do I get to the powder tower?
Speaker E: Okay, so you have that castle of idle work and there is a tower and it's called powder tower.
Speaker E: And so what do you parse out of that sentence?
Speaker E: Probably something that we specified in M3L that is...
Speaker E: Action, go to whatever domain object, whatever, powder tower.
Speaker E: And maybe some model will tell us some GPS module in a mobile scenario where the person is at the moment.
Speaker E: And we've sort of gone through that once before in the DeepMap project.
Speaker E: And we noticed that first of all, what are...
Speaker E: I should have brought some slides.
Speaker E: But what are...
Speaker E: So here's the tower.
Speaker E: Think of this as a two-dimensional representation of the tower.
Speaker E: And our system that people here, to a point where they were facing a wall from the tower, there's no entrance here.
Speaker E: But it just happens to be the closest point of the road network to the geometric center.
Speaker E: And it just says how the algorithm works.
Speaker E: So we took out that part of the road network as a heck, and then it followed actually the way to the entrance, which was now the closest point of the road network to geometric center.
Speaker E: But what we actually observed in idle work is that most people, when they want to go, they actually don't want to enter.
Speaker E: Because it's not really interesting.
Speaker E: They want to go to a completely different point where they can look at it and take a picture.
Speaker E: So, let's say a simple parse from an utterance won't really give us, is what the person actually wants.
Speaker E: Does he want to go there to see it?
Speaker E: Does he want to go there now?
Speaker E: Later?
Speaker E: How does the person want to go there?
Speaker E: Is that person more likely to want to walk there, walk a scenic route, and so forth?
Speaker E: There are all kinds of decisions that we have identified in terms of getting to places and in terms of finding information about things.
Speaker E: And we are constructing, and then we've identified more or less the extra linguistic parameters.
Speaker E: It may play role, information related to the user and information related to the situation.
Speaker E: And we also want to look closely on the linguistic information, what we can get from the utterance.
Speaker E: That's part of why we implant these intentions in the data collection to see whether people actually are facing differently, whether they want to enter in order to buy something, or whether they just want to go there to look at it.
Speaker E: And so, the idea is to construct suitable interfaces and a belief net for a module that actually tries to guess what the underlying intention was.
Speaker E: And then, enrich or augment the M3L structures with what I thought, what more it sort of got out of that utterance.
Speaker E: So, if it can make a good suggestion, hey, that person doesn't want to enter.
Speaker E: That person just wants to take a picture, because he just bought a film, or that person wants to enter, because he discussed the admission fee before, or that person wants to enter, because he wants to buy something, and that you usually do inside of buildings and so forth.
Speaker E: These types of additional information are going to be embedded into the M3L structure, in a sort of subfield that we have reserved.
Speaker E: And if the action planner does something with that grade, if not, then that's also something that we can't really, at least we want to offer the extra information, we don't really, we're not too worried.
Speaker E: I mean, ultimately, if you have, if you can offer that information, somebody's going to do something with it sooner or later, that's sort of part of our belief.
Speaker E: For example, right now, I know the GIS from email is not able to calculate these viewpoints.
Speaker E: So, that's a functionality that doesn't exist yet, to do that dynamically.
Speaker E: But if we can offer that distinction, maybe somebody will go ahead and implement it.
Speaker E: Surely nobody is going to go ahead and implement it, if it's never going to be used.
Speaker E: What have I forgotten about?
Speaker D: Yeah, I'm happy to do it.
Speaker D: It's a good time to pause.
Speaker D: I see questions on people's faces.
Speaker A: What would the office want to be if you envision this as a module within SmartCom?
Speaker E: So far, I've sort of it sort of adding it on to the model and knowledge module.
Speaker E: So, this is one that already adds additional information to the, but it could sit anywhere in the attention recognition.
Speaker E: I mean, basically, this is what attention recognition literally sort of can.
Speaker E: That's why it should be.
Speaker A: Well, from my understanding of what the people at TIPS were originally trying to do, doesn't seem to quite fit into SmartCom currently.
Speaker A: So what they're really doing right now is only selecting among the alternatives, the hypothesis that they're given and enriched by the domain knowledge and the dismalarist modeler and so on.
Speaker A: So if this is additional information, that could be merged in with them.
Speaker A: And then it wouldn't be available to action planning and others.
Speaker D: Okay, that was one question.
Speaker D: Are there other things that, because we want to not pass over any questions or concerns that you have?
Speaker A: Whether they're two levels of giving an answer, I guess on both levels.
Speaker A: I don't have any further questions. The two levels of being, as far as I'm concerned, is standing here for the generation module and the other is my understanding of what SmartCom is supposed to be.
Speaker D: So, let me explain that a little bit from the point of view of the generation.
Speaker D: So the idea is that we've actually got this all laid out and we could show it to you.
Speaker D: I think Robert didn't bring it today, but there's a belief net, which is, there's a first cut of the belief net that doesn't, isn't fully instantiated in particular.
Speaker D: Some of the combination rules and ways of getting additional probabilities aren't there.
Speaker D: But we believe that we have laid out the fundamental decisions in this little space and the things that influence them.
Speaker D: So, one of the decisions is what we call this ABE.
Speaker D: You want to access view or enter.
Speaker D: So that's a discrete decision. There are only three possibilities.
Speaker D: And what we would like is for this knowledge modeling collection to add which of those it is and give it to the player.
Speaker D: But the current design suggests that if it seems to be an important decision and if the belief net is equivocal so that it doesn't say that one of these is much more probable than the other, then an option is to go back and ask for the information you want.
Speaker D: There are two ways one can imagine doing that. For the debugging, we'll probably just have a drop down menu and while you're debugging, you're just mucking.
Speaker D: But for a full system, then one might very well formulate a query, give it to the dialogue planner and say, are you planning to enter or whatever it might be. So that's under that model, then there would be a loop in which this thing would formulate a query, presumably give it to you that would get expressed and hopefully you get an answer back.
Speaker D: And that would of course, the answer would have a harsh two. You probably won't do this early on because the current focus is more decision making and stuff like that.
Speaker D: But while we're on the subject, I just wanted to give you a heads up.
Speaker D: It could be that some months from now, we said, okay, we're now ready to try to close that loop in terms of querying about some of those decisions.
Speaker A: So my suggestion then is that you look into the currently ongoing discussion about how the action plans are supposed to look like.
Speaker A: And they're currently agreeing or in the process of agreeing on an exemplification of something like a state transition network of how dialogues would proceed.
Speaker A: And these transition networks will be what the action plan of the next interprets in a sense.
Speaker C: You know this, honey?
Speaker A: And Mikhail is doing that right? Well, Markus is actually implementing that stuff and Markus and Michele together are leading the discussion there.
Speaker D: Okay. So we have to get it on that because partly those are like excements, the transition backgrounds.
Speaker D: And it may be that we should early on make sure that they have flexibility to be weak.
Speaker E: But they have understood this right? They govern more or less the dialogue behavior or the action.
Speaker E: It's not really what you do with the content of the dialogue, but it's.
Speaker D: I mean, there is this nice. So there's a. So the word action. Okay. Is what's ambiguous here. So one thing is there's an actual planner that tells the person first of me.
Speaker D: Where it tells the person how to go first go here first go there. Take a bus, whatever it is. So that's that form of planning and action and a round planner and GIS also to stuff.
Speaker A: But I think that isn't what you know. No, no, in smart home terminology that's called a function that's modeled by a function modeler.
Speaker A: And it's that that's completely encapsulated from the dialogue system. That's simply a functionality that you give data is in a query.
Speaker A: And then you get back from that functioning model, which might be a planner or a VCR or whatever. Some result. And that's then.
Speaker D: Okay. So that's what I thought. So action action here means that I have speech. Yeah. Dialogue.
Speaker D: Okay. I think that I think it's not going to. I think it's not going to be good enough. I don't know what I meant by that.
Speaker D: So I think the idea of having a transition diagram or the grammar of conversations is a good idea.
Speaker D: Okay. And I think we do have to get in on it. But I think that when so when you get to the tourist domain.
Speaker D: It's not just an information retrieval system. Right. So this is where I think people are going to have to think this to a bit more carefully.
Speaker D: So if it's only like in the film and TV thing, okay, you can do this. You just get information and give it to people.
Speaker D: But what happens when you actually get them moving and so forth and so on.
Speaker D: I think the notion of this is a self contained module. The functional module that interacts with where the tourist domain is.
Speaker D: Probably is too restrictive. I don't know how much people have thought ahead to the tourist domain.
Speaker A: Probably not another. Another more basic point there is that the current tasks and therefore the concepts of this.
Speaker A: What's called the action plan. It's really a dialogue manager is based on slots that have to be filled.
Speaker A: The kind of values in these slots would be fixed things like a time or a movie time setting like this.
Speaker A: Whereas in the tourist domain might be an entire route.
Speaker A: It's a very complex structure information in these slots. Not sure if complex slots of that type are really being taken into consideration.
Speaker A: So that's really something.
Speaker A: We need to be settled there. So this is really an ongoing discussion.
Speaker E: We have faced and implemented those problems once already.
Speaker E: Maybe we can even shovel some know-how from there to Markus and Micheal.
Speaker E: I'll talk to Micheal. How far is the M3L specification for the natural language input gone?
Speaker E: I haven't seen anything for the tourist path.
Speaker B: It's not defined yet.
Speaker E: You are probably also involved in that.
Speaker B: We'll meet next week.
Speaker E: Those are the two key issues. How does the input pipeline look like and what the action planner does with it?
Speaker E: I think of the internal working of the action planner and the function model as relevant.
Speaker E: That can be as detailed or as crude as you want it to be.
Speaker E: The internal workings of the action planner and the work with the state.
Speaker E: That shouldn't really matter too much.
Speaker E: It does have to keep track of your bare-on-part six of a route that consists of eight steps.
Speaker D: I think there are a lot of reasons why it matters.
Speaker D: The user says that the action planner told it if the parser and the language end doesn't know what the person has been told.
Speaker D: The person says that the planner says that the planner doesn't know that.
Speaker D: There are all sorts of dialogues that won't make any sense.
Speaker A: The point has been realized that it's not really defined yet.
Speaker A: There's going to be some kind of feedback from the action planner into all the analysis modules telling them what to expect, what the current state of the discourse is beyond what's currently being implemented.
Speaker D: This is not just the state of the discourse, this is actually the state of the plan.
Speaker D: It's great if people are already taking that into account.
Speaker D: The specifics are in this room.
Speaker D: The question is, can you put in this need a fair amount of feedback from planning it in these things which are much more continuous than the dialogue over movies and stuff?
Speaker A: The action planner needs to be able to have an expressive power that can deal with these structures.
Speaker D: The next question is, can you put in a fair amount of feedback from the action planner?
Speaker D: It ought to be called a dialogue manager.
Speaker D: What would happen if we said, we've talked about this and we've changed this.
Speaker A: Probably the most impossible.
Speaker A: Who you talk to, how we'll see.
Speaker A: I think this is just for historical reasons within the preparation phase of the project and not because somebody actually believes it ought to be action funded.
Speaker D: If that persists, then we're going to need another term for the thing that actually does the planning of the routes and whatever we're doing for the tourist.
Speaker E: That's external services.
Speaker D: That has all the wrong connotations.
Speaker D: It sounds like it's standalone, it does interact, it doesn't.
Speaker D: That's something I think you can't. It's fine for looking up when the show is on TV.
Speaker D: I think it's really wrong headed for something that has a lot of state it's going to interact in a complicated way with understanding the board.
Speaker E: I think just the spatial planner and the route planner, I showed you once the interaction between them among them in the deep map system.
Speaker E: A printout of the communication between those two fills up how many pages.
Speaker E: That's just part of how do I get to one place.
Speaker E: So this is definitely a good point to get into the discussion or to enter his discussion actually.
Speaker E: Is he new in the...
Speaker A: Yes.
Speaker A: He started, like, January.
Speaker A: He's going to be responsible for the interpretation of this action plan.
Speaker E: He's going to continue with the old thing.
Speaker E: Yes, I was just wondering the next question, we're going to stick to ProLoc or not.
Speaker E: But I do think the function modeling concept has a certain...
Speaker E: It makes sense in a certain light because the action planner should not be or the dialogue manager in that case should not...
Speaker E: We have to worry about whether it's interfacing with something that does route planning in this way or that way.
Speaker D: I agree. There is a logic to dialogue which is separable.
Speaker E: And it can sort of formulate what it wants in a rather abstract way.
Speaker E: Find me a good route for this. It doesn't really have to worry about how route planner AO or route planner B actually wants it.
Speaker E: So this seems like a good idea.
Speaker D: It's tricky because one could well imagine, I think it will turn out to be the case that this thing we're talking about, and the extended knowledge modeler will fill in some parameters about what the person wants.
Speaker D: One could well imagine that the next thing that's trying to fill out the detailed route planning, let's say, will also have questions that it would like to ask the user.
Speaker D: You could well imagine you get to a point where it's got a choice to make and it just doesn't know something.
Speaker D: So you would like it also be able to formulate a query and to run that back through the dialogue manager and to the output module and back around.
Speaker D: And a good design would allow that if you can't make it happen.
Speaker A: So that doesn't necessarily contradict an architecture where there really is a person that you will define the interface.
Speaker D: I totally agree. But what it needs, the point is, in that case the dialogue manager is sort of a vent driven.
Speaker D: So dialogue manager may think it's in a dialogue state of one sort.
Speaker D: And this one of these planning modules comes along and says, hey, right now we need to ask a question.
Speaker D: So that forces the dialogue manager to change state.
Speaker A: Okay, it can be true. Yeah, yeah, I think that's the concept of people.
Speaker A: And then the underlying idea, of course, is that there is something like kernel modules with kernel functionality that can pluck certain applications like tourist information or the whole scenario of controlling a VCR install.
Speaker A: And then extend it to arbitrary number of publications.
Speaker A: So that's an additional reason to have this well defined interface.
Speaker A: Keep these things like tourist information external.
Speaker E: Of course, there is another philosophical issue that I think you can debate.
Speaker E: But this makes sense to me that sooner or later a service is going to come and describe itself to you.
Speaker E: And that's sort of what Srini is working on in the Dumbled project where you find a GIS about that gives you information on Berkeley.
Speaker E: And it's going to be there and tell you what it can do and how it wants to do things.
Speaker E: And so you can actually interface to such a system without ever having met it before.
Speaker E: And the function modeler and the self description of the external service, handle it out.
Speaker E: And you can use the same language core understanding core to interface with planner a planner B planner C and so forth, which is, you know, a utopian completely utopian at the moment.
Speaker E: But slowly getting into the realm of the contingent.
Speaker E: But we are facing, of course, much more realistic problems and language input, for example, is of course crucial.
Speaker E: And also when you do the sort of deep understanding analysis that we envision, then of course, the, you know, what is the property of the stimulus, the last we get of that, the better.
Speaker E: And so we were thinking, for example, how much syntactic analysis actually happens already in the parser and whether one could interface to that potentially.
Speaker B: Currently, it's no syntactic analysis. But in the next release, and it's kind of, so we looked at the current pattern matching.
Speaker D: And as you say, it's just the surface pattern matching. So what are the plans roughly?
Speaker B: To integrate and syntactic analysis and some more features like segmentation. So then more than one utterance is there.
Speaker D: And this is all done, a pause between it, segmentation across. So the idea is to have a particular, particular parser in mind.
Speaker D: And if you thought through, is it an HBSG parser? Is it a, whatever? No, no, I think it's complicated for.
Speaker B: Okay. One person has to. Oh, you have to do it. Yeah. So things must be simple. I see. So.
Speaker D: But yeah, the syntactic analysis. People in finite state trans-susers. People at DFK, I have written a fair number of parsers. Other people over the years have written various parsers in DFK. None of them are suitable. I'm asking.
Speaker B: Yeah, the problem is that it has to be very fast because if you want to for more than one path and what's in the lattice from a speed track or not, so it's speed is crucial.
Speaker B: Not fast enough. It also has to be very robust cause of speed track recognition. I don't know. So there was a chunk parser in verbobile.
Speaker D: There was one of the branches. You know, I do, there were these various competing syntax modules. And I know one of them was a chunk parser. And I don't remember who did that.
Speaker B: I think that a tubing and I thought. I didn't know. Well, do you know something about it? Tubing was at least involved in putting the chunks together.
Speaker A: I can't quite recall whether they actually produced the chunks in the first place.
Speaker D: That's right. They had just done with a two-phase thing where the chunk parser itself was pretty stupid. And then there was a kind of trying to fit them together that used more context.
Speaker A: And especially you did some, was a learning based approach, which you learned from a big corpus of trees. And yes, the chunk parser was a financial machine that Mark Leidritch worked on and wasn't tubing them.
Speaker A: And somebody else was tubing that up, so it was done and tubing.
Speaker B: But is that the kind of thing you were thinking of? Yeah. It sounds like the star action. What? It's in this direction.
Speaker E: From Micheal Stubach, I've heard very good stuff about the chunk parser that is done by four-vice riches in embassy doing the parsing. So this sort of came as a surprise to me that embassy is featuring a nice parser.
Speaker E: But it's what I hear one could also look at that and see whether there is some synergy possible. And they're doing chunk parsing.
Speaker E: I can give you the names of the people who do it there. But then there's of course more ways of parsing things.
Speaker D: Of course, but given the constraints that you wanted to be small and fast and so forth, my guess is you're probably into some kind of chunk parsing.
Speaker D: And I'm not a big believer in this statistical cleaning up. That seems to be kind of a last resort if you can't do it any other way.
Speaker D: But I don't know. Maybe that's what you guys finally decided to do.
Speaker D: And if you looked just again for context, there's this one that they did at SRI some years ago, fastest pace.
Speaker B: Yeah, I've looked at that. But there's not much information available. But it's also finance Tetrance. It is. Yeah, it was pretty ambitious.
Speaker B: And of course it was English oriented. And fully finance Tetrance, I'm not so good for German.
Speaker D: Yeah, I guess that's the point is all the morphology and stuff. In English is all word order and it makes a lot more sense.
Speaker B: Yeah, okay. Good point. So in German, you've got most of this. So it's a choice between risk processing and set processing and template.
Speaker B: So what about like morphics? You've got stemmers or is that something? Yeah, but all in the in the lexicon.
Speaker B: But you have that. Yeah, information is a lot of that.
Speaker D: Okay, I see. So, but so you just connect to the lexicon. Yeah, at least for German, you have all of the stemming information.
Speaker B: Yeah, we can. We have knowledge passes from from Rappmökels. Yeah.
Speaker D: But it doesn't look like it you're using it. I didn't see it being used in the current template parser. I didn't see any.
Speaker B: Which we actually only look at the English. But it's used for stem forms.
Speaker A: I think there's some misunderstanding. Morphics is not used online. So the lexicon might be derived by morphics, but what's happening online is just retrieving from the lexicon, which we call the stemming information.
Speaker A: So it will be a full form lexicon. That's what you have. Yeah.
Speaker E: We threw out all the forms. We threw out all the forms because English.
Speaker D: Oh, okay. So, yeah, so I thought I so in German, then you actually do case matching and things like that in the in the pattern matcher or not.
Speaker D: Not yet. I didn't. Okay.
Speaker D: I didn't think I saw it. Yeah. Getting it from the lexicon is just fine.
Speaker C: Yeah.
Speaker D: Yeah. Here's the case where the English and the German might really be significantly different in terms of if you're trying to build some fast parser and so forth. You really might want to do it in a significantly different way.
Speaker D: So you guys have looked at this also in terms of, you know, if you're doing this for English as well as Germans, you think now that it would be this similar way?
Speaker B: Yeah. I think it's possible to do list processing. And maybe it's more adequate for English and German set processing.
Speaker B: Maybe some extensions have to be made for English version.
Speaker E: I'm sure there's going to be more discussion on that after your talk. We're just going to foreshadow.
Speaker D: Now actually, are you guys three of five? Do you have to go somewhere at five o'clock tonight? No. I think I was just talking.
Speaker D: I'm just going to practice talk. Great. So you're going to. Yeah. That's good. Because that will tell you a fair amount about the form of semantic construction grammar that we're using.
Speaker D: So I think that's probably as good an introduction as you get to the form of conceptual grammar that will be having mind.
Speaker D: So I won't talk particularly about how that relates to what Robert was saying at the beginning. Let me give you a very short version of this. So we talked about the fact that they're going to be a certain number of decisions that you want the knowledge modeler to make that we then fed to the function module.
Speaker D: So they're these decisions. And then one half of this we talked about a little bit is how if you had the right information, if you knew something about what was said and about something about was the agent, a tourist or a native or a business person or a younger role, whatever.
Speaker D: So we're also about the what we're calling the entity is that a castle is it a bank is it a town square is a statue, whatever. So all that kind of information could be combined into decision networks and decisions.
Speaker D: So the other half of the problem is how would you get that kind of information from the parsed input. So what you might try to do is just build more templates saying we're trying to build a template, you know, build a template somehow would capture the fact that you want to take a picture.
Speaker D: And we could you could do this and it's a small enough domain that probably.
Speaker D: But from our point of view, this is also a research project and there are a couple of people not here. The various reasons we're doing Dr. of the citations on this. And the idea that we're really after is a very deep semantics based on cognitive linguistics and the notion that there are a relatively small number of primitive conceptual schemas that characterize a lot of activity.
Speaker D: So a typical one in this formulation is a container.
Speaker D: And the notion is that all sorts of physical situations are characterized in terms of container point in and out of portals.
Speaker D: But also importantly for lay coffin these guys is also a metaphorical picture also characters this way you get in trouble.
Speaker D: So what we're really trying to do is to map from the discourse to the conceptual semantics level and from there to the appropriate decisions.
Speaker D: So another one of these primitive what are called image schemas is goal seeking.
Speaker D: There's an ocean of the source, path goal, trajectory possibly obstacles. The idea is this is another conceptual primitive.
Speaker D: And that all sorts of things particularly in the tourist domain can be represented in terms of source, path goal. So the idea would be could we build and analyze it, we'd take an utterance and say, aha, this utterance is talking about an attempt to reach a goal.
Speaker D: The goal is this, the person, the traveler is that, the sort we are now is this, they've mentioned possible obstacles, et cetera.
Speaker D: And this is an attempt to get very wide coverage. So if you can do this then the notion would be that across a very large range of domains you could use this deep conceptual basis as the interface.
Speaker D: And then the processing of that both on the input end recognizing that certain words in a language talk about containers or goals, et cetera.
Speaker D: And on the output end given this kind of information you can then make decisions about what actions to take provides they claim a very powerful general notion of deep semantics.
Speaker D: And we're really, Nancy is going to her talk is going to be not about using this in applications, but about modeling how children might learn this kind of deep semantic grammar.
Speaker A: And how do you envision the deep semantic to be worked with would it be highly ambiguous. And then there would be another module that takes that highly underspecified deep semantic construction and map it onto the current context to find out what the person really was talking about in that context.
Speaker D: Well, that's that's where the belief that comes in. So the idea is let's take this business not going to the powder tower. So part of what you'll get out of this will be the fact that if it works right.
Speaker D: Okay, that this is an agent that wants to go to this place and that's their goal. And there'll be additional situational information.
Speaker D: Okay, part of comes to the ontology the tower is this kind of part of it comes with the user. And the idea of the belief that is it combines the information from the dialogue which comes across in this general way.
Speaker D: You know, this is this is a goal seeking behavior along with specific information from the ontology about the kinds of objects involved about the situation about is raining. I don't know, whatever it is. And so that's the belief that we've laid out.
Speaker D: And so the coupling to the situation comes in this model from at the at the belief net company evidence from the dialogue with the ontology with the situation.
Speaker D: Nancy isn't going to talk about that just about the first steps. Right, the construction grammar.
Speaker E: And she's going to start in a minute.
None: Yeah, I didn't want to give you a little.
None: Okay.
