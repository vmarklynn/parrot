Speaker G: Yeah, yeah, okay.
Speaker G: We're on again, okay.
Speaker G: That is okay.
Speaker H: So if anyone hasn't signed the consent form, please do so.
Speaker H: The new consent form.
Speaker H: The new information form.
Speaker H: I mean, that's the one that we're going to bring to you back.
Speaker H: Okay.
Speaker H: And shall I go ahead and do some digits?
Speaker G: We're going to do that at the end, remember?
Speaker G: Okay, whatever you want.
Speaker G: Yeah, just to be consistent from you around and at least to the end.
Speaker G: It's a, yeah, it doesn't matter, okay.
Speaker G: Okay.
Speaker G: Well, it just, I mean, it might be that someone here has to go.
Speaker G: That was the other sort of the point.
Speaker G: So I had asked, actually, anybody who had any ideas for an agenda to send it to me and no one did.
Speaker G: So that was an over-guy.
Speaker E: From last time I wanted an issue.
Speaker E: Right.
Speaker E: From last time.
Speaker G: Okay, so one item for Denda is Jane has some, some research to talk about, research issues.
Speaker G: And I have some short research issues.
Speaker G: And I'm going to have some short research issues.
Speaker G: I have a list of things that I think were done over the last three months.
Speaker G: I was supposed to send off.
Speaker G: And I sent a note about it to Adam and Jane, but I think I'll just run through it also and see if someone thinks it's inaccurate or...
Speaker G: A list you have to send off to...
Speaker G: Oh.
Speaker G: Okay, you know.
Speaker G: So, so I'll go through that.
Speaker G: And...
Speaker G: Anything else?
Speaker G: Anything else to talk about?
Speaker I: No.
Speaker I: What about the new trip?
Speaker G: The next day.
Speaker G: Sort of off topic, I guess, because I was all about the...
Speaker G: I can chat with you about that.
Speaker G: Fine, that's another thing.
Speaker G: And...
Speaker G: Anything else?
Speaker G: Anything else?
Speaker G: There's a...
Speaker G: I mean, there is a...
Speaker G: A telephone call tomorrow, which would be a conference call.
Speaker G: Some of us are involved in...
Speaker G: For a possible proposal.
Speaker G: We'll talk about it next week.
Speaker H: Do you want me to give that?
Speaker H: I know you.
Speaker H: CC me, but I wasn't actually recipient.
Speaker H: I didn't quite know what to make of that.
Speaker H: Well, we'll talk about that after.
Speaker G: Okay.
Speaker G: Okay, so it sounds like the three main things that we have talked about are this list, Dean and Dean Adam have a series of items, and other than that, anything as usual, and if it goes beyond that.
Speaker G: Okay, Dean, since you were sort of cut off last time when we start with yours, make sure we get to it.
Speaker E: It's very brief.
Speaker E: I just want to just have these out.
Speaker H: This is the same as the email or different.
Speaker E: It's slightly just...
Speaker E: It's basically the same idea.
Speaker E: Same idea.
Speaker E: So I feel like that is using it before.
Speaker E: So basically, as you know, part of the encoding includes a mark that indicates that an overlap.
Speaker E: It's not indicated with a type precision.
Speaker E: It's just indicated that...
Speaker E: Okay, so...
Speaker E: It's indicated to some of the people know what parts of speech...
Speaker E: which stretches the speech were in the clear versus being overlap by others.
Speaker E: So I've used this mark and divided the enrol script, which divides things into individual minutes, which ended with 45 and a little bit.
Speaker E: And, you know, minute zero, of course, is the first minute up to 60 seconds.
Speaker E: And what you can see is the number of overlaps.
Speaker E: And then to the right, whether they involve two speakers, three speakers and one and three speakers.
Speaker E: And what I was looking for, specifically, was the question of...
Speaker E: whether they distributed evenly throughout or whether they're averse of them.
Speaker E: And it looked to me as though...
Speaker E: You know, this is just...
Speaker E: This is not specifically verified, but it did look to me as though they're averse throughout, rather than being unlocalized to a particular region.
Speaker E: So, part down there where the maximum number of overlaps is the area where we were discussing whether or not it was useful to code stress, set and stress as possible, indication of information and treatment.
Speaker E: So it's like, you know, rather lively discussion there.
Speaker G: What's the parenthesis stuff that says...
Speaker G: Like the first one says six overlaps and then 2.8?
Speaker E: That's the percent.
Speaker E: So, six is 2.8% of the total number of overlaps in that session.
Speaker E: So, here we end.
Speaker E: This is when people were, you know, packing up to go basically to this final stuff.
Speaker E: I don't remember where the digits felt.
Speaker E: I had to look at that.
Speaker E: But the final three there are no overlaps at all.
Speaker E: And a couple times there.
Speaker E: So it seems like it goes through verse.
Speaker E: That's going to be...
Speaker E: Now, another question is, are there individual differences in whether you're likely to be overlapped with or to overlap with others?
Speaker E: And again, I want to emphasize is just one particular meeting and also it's been a statistical testing involved.
Speaker E: But I took the coding of the...
Speaker E: You know, I had the script figure out who was the first speaker who was the second speaker involved in a two person overlap.
Speaker E: I didn't look at the ones involved in three or more.
Speaker E: And this is how it ranks down in the individual cells.
Speaker E: Who tended to be overlapping most often with who else?
Speaker E: And if you look at the marginal totals, which is the ones on the right side, across the bottom, you get the totals for an individual.
Speaker E: So, if you look at the bottom, those are the numbers overlaps in which Adam was involved as the person doing the overlap thing.
Speaker E: And if you look... I'm sorry, but you're alphabetical as my question is.
Speaker E: And then if you look across the right, then that's where he was the person who was the first speaker in the pair.
Speaker E: And he got overlapped with by somebody.
Speaker E: And then if you look down on that summary table, then you see that there are differences in whether a person overlap with or overlap.
Speaker H: Is this just raw counts or is it...?
Speaker H: Raw counts.
Speaker H: So it would be interesting to see how much each person spoke.
Speaker E: Yes, very true.
Speaker E: Very true.
Speaker E: We could normalize through that now in the table.
Speaker E: I did take one step toward away from the raw frequencies by putting percentages.
Speaker E: So the percentage of time, other times that the person spoke, what percentage...
Speaker E: Other times the person spoke and furthermore was involved in a two-person overlap.
Speaker E: What percentage of the time were they the overlap or what percent of the time were they the overlap be?
Speaker E: And there it looks like you see some differences.
Speaker E: That some people tend to be overlapped with more often than they're overlapped.
Speaker E: Of course, this is just one meeting. There's no statistical testing involved and that would be required for an in-line.
Speaker G: So it would be statistically incorrect to conclude from this that Adam talked too much?
None: No actually, it's still incorrect.
Speaker E: Yeah, that's right.
Speaker E: I don't see a point in signaling people out.
Speaker E: Now this is a kiss for obviously...
Speaker E: But the numbers for people themselves, that's right.
Speaker E: So I'm not saying on the tape who did better or worse because I think that...
Speaker E: And then here's a case where of course human subjects people would say, be sure that you anonymize results.
Speaker E: This is what...
Speaker H: This is actually when Jane sent this email first, it's what caused me to start thinking about anonymizing the data.
Speaker H: Well, fair enough.
Speaker E: And actually, the point is not about an individual. It's a point about tendencies toward different styles, different speakers.
Speaker E: Oh, sure.
Speaker E: It would be, you know, of course, there's also the question of what type of overlap was this and were they?
Speaker E: And I know that I can distinguish at least three types and probably more.
Speaker E: I mean, the general cultural idea, which the conversation analyst originally started with in the 70s, was that we had this strict model where politeness involves that you let person finish before you start talking.
Speaker E: And, you know, I mean, we know that...
Speaker E: And they've loosened up on that too, in the intermeaning time.
Speaker E: That that's viewed as being a culturally relative thing.
Speaker E: You have the high involvement style from the East Coast where people will overlap often as an indication of interest in what they are person saying.
Speaker E: And, you know, exactly, they're the same, fine?
Speaker E: And, you know, in contrast, and also, Divertannis, these, as she talked about differences in these types, that they're just different styles.
Speaker E: And you can impose a model of the ideal being, no overlaps in conversation.
Speaker E: And, you know, it's also bringing advances in the university, and I agree with that.
Speaker E: And, and also, I can't say university, but anyway, the people who used to say it was strict, now, don't.
Speaker E: I mean, they also acknowledge the influence of subcultural norms and cross cultural norms and things.
Speaker E: So, then it be kind of...
Speaker E: So, just superficially, you give a couple ideas of the types of overlaps involved.
Speaker E: I have the bottom several that I know. So, they're backchats, like, what I'm just now anticipating the end of a question.
Speaker E: And, simply answering it earlier. And, there are several of those in this in these days, where, because we're people who've talked to each other, we know basically what the topic is, what the possibilities are, and we've spoken with each other.
Speaker E: So, we know basically what the other person's style is likely to be.
Speaker E: And, so, and there are a number of places where someone just answered early.
Speaker E: And, places also, which I thought were interesting, where two or more people gave exactly the same answer in unison.
Speaker E: Different words, of course, but, you know, the basically, you know, everyone's saying yes, or, you know, or even more specific than that.
Speaker E: So, the point is that overlaps not necessarily bad thing, and that it would be useful to subdued by these further and see if their individual differences in styles, and respect the types involved.
Speaker E: And, that's all I want to say on that.
Speaker G: Thank you. Well, of course, the biggest result here, which is when we've talked about many times, and this is new to us, but I think would be interesting to show someone who isn't familiar with this.
Speaker G: It's just the sheer number of overlaps. See that, right? That, that, that, here's a relatively short meeting.
Speaker G: So, 40, 40 plus minute meeting, and not only were there 215 overlaps, but, I think there's one, one minute there.
Speaker G: Where, where, where there wasn't any overlap, I mean, it's throughout this thing.
Speaker E: Well, at the bottom, we have the bottom three. So, four, four minutes altogether.
Speaker G: Oh, so the bottom three did have stuff going on.
Speaker G: Yes, but just no overlaps.
Speaker I: Okay, so it's interesting to see what the total amount of time is in the overlap.
Speaker I: Yes, exactly. That's where Jose is.
Speaker B: I have this, that's where he comes in.
Speaker B: I have that information.
Speaker B: No. No, about how much is it?
Speaker G: Which is the duration of the, of each of the overlaps? What's the, what's the average?
Speaker B: I, I have in the average now, but I will, I will do the, the study of the, with the, with the, with the problem, with the, the, the different distribution of the duration of the overlap.
Speaker G: Okay, you, you don't have a feeling for roughly how much.
Speaker B: Because the budget is a good, the duration is the variation, the variation of the duration is the very, very...
Speaker E: I suspect that we'll also differ depending on the type of overlap.
Speaker B: Yeah, I'm sure.
Speaker B: Because are yourself a, a, a, a son of overlapping with duration, a, a, a, a overlap and another very, very short.
Speaker B: I probably is very difficult to, to speak, because the overlap is the only, the, the final S, the, the, the, the, the, the, the, the end, the end of the war, or the previous speaker, with the, the next word of the, the new speaker.
Speaker B: And I consider that son overlap, but it's very short, and X, with the, and the idea is probably, when, when we study the, that song, we have a, a, a, confusion with noise, with that, the effective sounds.
Speaker B: But, yeah, I have an information, but I have to,
Speaker C: use blip as by minute, sorry for the overlap, the strategy, the boundary between two minutes, that comes towards both of those.
Speaker E: Actually, actually not. So, it was, think about the case where A, start speaking, and then B, overlaps with A, and then the minute boundary happens. And let's say that, after that minute boundary, B is still speaking, and A overlaps with B, that would be a new overlap.
Speaker E: But otherwise, let's say B comes to the conclusion of that turn without anyone overlapping with him in which case, there would be no overlap counted in the second.
Speaker C: So most of them, talk simultaneously, both important moments, and one, and the other question to you.
Speaker E: Okay, in that case, my, the coding that I was using, since we haven't incorporated Adams coding on the lap, yes, the coding of, yes, not over.
Speaker E: So if we haven't incorporated Adams method of handling over, overlaps yet, then that would have fallen through the crack, cracks, it would be an underestimate of the number of overlaps, because I, I wouldn't be able to pick it up from the way it was encoding so far.
Speaker E: We just haven't done that. The precise second to second, you know, second to second coding.
Speaker G: I'm, I'm confused now. So, let me restate what I thought Andrew has been saying and, and see.
Speaker G: Let's say that in, in second, 57 of one minute, you start talking and I start talking, and we ignore each other and keep on talking for six seconds.
Speaker G: So we go over, so we were, we were talking over one another, and it's just, in each case, it's just sort of one interval, right?
Speaker G: So, we talked over the minute boundary. Is this considered, is one overlap in each of the minutes, the way you have done this?
Speaker E: No, it wouldn't. It would be considered as an overlap in the first one.
Speaker G: Okay, so that's good, I think, in the sense that I think Andrew has meant the rest of you.
Speaker E: I should also say I did a simplifying count in that, if A was speaking, B overlapped with A, and then A came back again, and overlapped with B again, I, I didn't count that as a three person overlap, I counted that as a two person overlap, and it was A being overlapped with by D.
Speaker E: Because the idea was the first speaker had the floor, and the second person started speaking, and then the first person re-ocerted the floor kind of thing.
Speaker E: These are simple, not an assumption. It didn't happen very often, there may be like three overlaps in that way in the long day.
Speaker H: I want to go back and listen to minute 41.
Speaker H: Yeah, yeah.
Speaker H: Because, yeah.
Speaker H: And I think that by interesting that there were a large number of overlaps and they were all two speaker. I mean, what I thought would have thought is that when there were a large number of overlaps, because everyone was talking at once, but apparently not, that's really neat.
Speaker H: Yeah, there's a lot of background.
Speaker F: Yeah, it is. I think it's really interesting though, before saying yes, meetings have a lot of overlaps, it's to actually find out how many more we have than two party.
Speaker F: And if you have a party conversation, like switchboard, does it offer a lot too? If you just look at the back channel, if you consider those overlaps, it's also very huge.
Speaker F: It's just that people haven't been looking at that because they've been doing single channel processing.
Speaker F: So the question is, how many more overlaps do you have of say the two person type by adding more people to a meeting?
Speaker F: And it may be a lot more, but it may not be.
Speaker G: Well, but see, I find it interesting, even if it wasn't anymore, because since we were dealing with this full duplex sort of thing in switchboard, where it was just all separated out, we just, everything was just nice.
Speaker G: So the issue is in a situation where that's...
Speaker F: It's really nice, it depends what you're doing.
Speaker F: So if you were actually having, depends what you're doing.
Speaker F: Right now, we're doing, we have individual mics on the people in this meeting.
Speaker F: And the question is, are there really more overlaps happening than there would be in a two person?
Speaker G: Let me rephrase what I'm saying, because I don't think I'm getting across.
Speaker G: But shouldn't these words like nice, because we're doing it precise.
Speaker G: What I mean is that in switchboard, despite the many other problems that we have, one problem that we're not considering is overlap.
Speaker G: And what we're doing now is, aside from the many other differences in the task, we are considering overlap.
Speaker G: And one of the reasons they were considering it, one of them, one of them is that, at least I'm very interested in the scenario in which both people talking here are pretty much equally audible in from a single microphone.
Speaker G: And so in that case, it does get mixed in, and it's pretty hard to just ignore it, to just do processing on one and on the other.
Speaker F: I agree that it's an issue here, but it's also an issue for switchboard. And if you think of meetings being recorded over the telephone, which I think, you know, this whole point of studying meetings isn't just at people in a room, but to also have meetings over different phone lines.
Speaker F: Maybe far, feel like people wouldn't be interested in that, but all the dialogue issues still have.
Speaker F: So each of us was calling and having a meeting that way, you know, a conference call.
Speaker F: And just the question is, you know, in switchboard, you would think that's the simplest case of a meeting, a more than one person.
Speaker F: I'm wondering how much more overlap of the types that, that you described happen with more people present. So it may be that having three people is very different from having two people or it may not be.
Speaker G: That's an important question to ask. I think what I'm certainly saying is that I don't think we were considering that switchboard. Not you, maybe.
Speaker F: Were you measuring it? I mean, there is actually to tell you the truth, the reason why it's hard to measure is because of, so from the point of view of studying dialogue, in which Dan Draskin and Dresden, I had some projects on.
Speaker F: I know the sequence of terms. So what happens is if you're talking and I have a back channel in the middle of your turn, and then you keep going, what it looks like in a dialogue model is your turn and then my back channel, even though my back channel occurred completely inside your turn.
Speaker F: Yeah.
Speaker F: So for things like language modeling or dialogue modeling, we know that that's wrong in real time. But because of the acoustic segmentations that were done and the fact that some of the acoustic data and switchboard were missing, people couldn't study it.
Speaker F: But that doesn't mean in the real world that people don't talk that way.
Speaker G: Yeah, I wasn't saying that. Right. I was just saying that now we're looking at it.
Speaker G: You maybe wanted to look at it before, but for these various technical reasons, in terms of how the data was, you weren't. So that's why it's coming to us as new, even though it may well be.
Speaker G: If you're hypothesis, you're offering, right, if it's the null hypothesis, and if actually you have as much overlap in the two person, we don't know the answer to that. The reason we don't know the answer to is because it wasn't studied and wasn't studied because it was a set of.
Speaker F: And if you're asking the question from the point of view of what's different from out of meeting, studying meetings of say more than two people versus what kinds of questions you can ask what the two person meeting.
Speaker F: It's important to distinguish that, you know, this project is getting a lot of overlap, but other projects for two, but we just couldn't study them.
Speaker F: May have been.
Speaker F: Well, there is a high rate, but I don't know how high. I have a question.
Speaker G: My point was just if you wanted to say to somebody, what do we learn about overlaps here? Just never mind comparison to something else.
Speaker G: What we've learned about is overlaps in this situation is that the first order thing I would say is that there's a lot of them.
Speaker G: In the sense that if you said, I guess what I'm comparing to is more the common sense notion of how much people overlap.
Speaker G: The fact that when Adam was looking for a stretch of speech before that didn't have any overlaps and he was having such a hard time.
Speaker G: And now I look at this and I go, well, I can see why he was having such a hard time.
Speaker F: That's also been a fish for.
Speaker G: I wasn't saying it wasn't. Right?
Speaker G: I was commenting about this.
Speaker G: I was saying if I have this complicated thing in front of me, which we're going to get much more sophisticated about when we get lots more data.
Speaker G: But then if I was going to describe somebody, what did you learn right here about the modest amount of data that was analyzed?
Speaker G: I'd say, well, the first order thing was there's a lot of overlaps. In fact, it's not just a bunch of overlap.
Speaker G: Second order thing is it's not just a bunch of overlaps in one particular point, but that there's overlaps throughout the thing.
Speaker F: And that's interesting. I agree with that. I'm just saying that the reason you get overlaps may or may not be due to the number of people in the meeting.
Speaker F: Yeah. Yeah. I wasn't making any statement about that.
Speaker F: And it would actually be interesting to find out because some of the data say switchboard, which is an exactly the same kind of contact.
Speaker F: And these are two people who don't know each other.
Speaker F: But we should still be able to somehow say what is the added contribution to the sort of overlap time of each additional person.
Speaker F: Yeah, that would be good to know, but we need the way.
Speaker E: Yeah, I agree with that. And the reason is because I think there's a limit.
Speaker E: There's an upper bound on how many you can have simply from the standpoint of audibility when we speak.
Speaker E: We do make a judgment as adults. I mean children don't adjust so well.
Speaker E: If a truck grows rolling past, adults will, depending, but mostly adults will hold off to what to finish the end of the sentence until the noise is passed.
Speaker E: And I think we generally do monitor things like that. Whether we, whether our utterance will be in the clear or not.
Speaker E: And partly it's related to rhythmic structure and conversation. So, you know, you, you, you, you, you, you, stop.
Speaker E: So people tend to time their, their, their, when they come into the conversation based on the overall rhythmic ambient thing.
Speaker E: So you don't want to be cross cutting and just to finish this that, that I think that there may be an upper bound on how many overlaps you can have simply from the standpoint of audibility and how loud the other people are who are already in the break.
Speaker E: But I, you know, I've certain types. Now, if it's just back channels, people may be doing that with less intention of being heard just sort of spontaneously doing back channels.
Speaker E: In which case that those might, there may be no upper bound.
Speaker C: I have this feeling that back channels which are the vast majority of overlaps in switchboard.
Speaker C: I didn't play it as big a role here because it's very unnatural.
Speaker C: I think to back channel in a multi audience, you know, in a multi person.
Speaker F: If you can see them actually. So if you watched people are going like, right, like this here, but they may not be the case.
Speaker C: But instead of audition, one person speaking and everybody's listening.
Speaker G: Actually, I think I've done it a fair number of times today.
Speaker G: I thought it had none.
Speaker H: Yeah, we need to put trackers on that.
Speaker I: In two person.
Speaker C: Yeah, so actually that's in part because the nodding, if you have very old contact, the nodding has the same function, but on the phone is switchboard.
Speaker C: You, that would work.
Speaker C: So you need to use the message here.
Speaker I: So in the two person conversations, when there's back channel, is there a great deal of overlap?
Speaker I: The speech or because I impression is sometimes it happens when there's a pause.
Speaker I: You know, like you get a lot of back channel when somebody's pausing.
Speaker E: She's doing that.
Speaker I: Sorry about what you're saying.
Speaker I: Talk to your both.
Speaker I: No, when there's back channel, I mean, just listening, when there's two people talking and there's back channel, it seems like the back channel happens when the pitch drops and the first person.
Speaker I: And a lot of times the first person actually stops talking and then there's a back channel and then they start up again.
Speaker I: So I'm wondering about, I just wonder how much overlap there is.
Speaker I: Is there a lot?
Speaker F: I think there's a lot of the kind that Jose was talking about where in the Scult position timing, conversation happens where they come in overlapping.
Speaker F: But at a point where the information is mostly complete.
Speaker F: So all you're missing is some last syllables or something, the last word, some highly predictable words.
Speaker F: So technically it's an overlap.
Speaker I: But maybe it's just a small overlap.
Speaker F: From the information flow point of view, it's not an overlapping.
Speaker I: I was just thinking more in terms of alignment overlap.
Speaker H: Language model prediction of overlap that would be really interesting.
Speaker F: Well, that's exactly why we wanted to study the pre-sized writing of overlapses in switchboard.
Speaker C: So here's a first interesting labeling task to distinguish between say back channels, precision timing, sort of, you know, benevolent overlaps and add, and pick it up and work for pants.
Speaker C: I don't know, I'll slide over to someone else's side over that before it's chaos.
Speaker C: That might be interesting from just to take over.
Speaker E: I think that in this meeting I really had the feeling that wasn't happening, that the hostile type.
Speaker E: These were benevolent types, as people finishing each other's sense.
Speaker C: I could imagine that there's a fair number of cases where this is not really hostile, but sort of competitive.
Speaker C: What person is finishing something and you have like two or three people trying to grab the next turn.
Speaker C: And so it's not against the person who talks first, because they're actually all waiting for that person to finish.
Speaker G: But they all are next.
Speaker G: I have a feeling most of these things that are not benevolent kind are competitive as opposed to really hostile.
Speaker I: I'm doing what determines who gets the floor.
Speaker G: I mean, vote in Florida.
Speaker G: What do you remember?
Speaker G: One thing I remember, or you can tell a good joke and then everybody's laughing and you get a chance to break in.
Speaker G: But the other thing I was thinking was that all these interesting questions are, of course, pretty hard to answer with a small amount of data.
Speaker G: So I wonder if what you're saying suggests that we should make a conscious attempt to have a fair number of meetings with a smaller number of people.
Speaker G: Most of our meetings are meetings currently with a 5, 6, 7, 8 people.
Speaker G: Should we really try to have some two person meetings or some three person meetings and record them just to beef up the statistics on that?
Speaker E: Well, it seems like there are two possibilities.
Speaker E: I mean, it seems like if you have just two people, it's not really like a meeting.
Speaker E: It's not as similar as the rest of the sample.
Speaker E: It depends on what you're after, of course. But it seems like that would be more in case of the control condition compared to an experimental condition with more than two.
Speaker G: Well, this was raising the question of whether it's the number.
Speaker G: There's a relationship between the number of people and the number of overlaps of type of overlaps.
Speaker G: And if you had two people meeting in this kind of circumstance, then you'd still have the visual.
Speaker G: So you wouldn't have that difference also that you have in the scenes which are poor data.
Speaker E: I'm just thinking that'd be more like a control condition.
Speaker H: But from the acoustic point of view, it's all good.
Speaker H: It's the same. The acoustic is fine.
Speaker C: If the goal were to just look at overlap view, what you could say of yourself saved yourself a lot of time, and not even transparent the words.
Speaker F: I was thinking you should be able to do this from the acoustic on the close track in my experience.
Speaker H: Well, that was my status for Florence.
Speaker H: I've never done with this type of discussion.
Speaker F: I don't think you would be able to have any kind of apology on the next one, but you get some rough statistics.
Speaker G: But what do you think about that? Do you think that would be useful?
Speaker G: I'm just thinking of as an action item, whether we should try to record some two words of meeting.
Speaker F: I guess my first comment was only that we should not attribute overlaps only to meetings, but maybe that's obvious.
Speaker F: Maybe anybody knew that.
Speaker F: In normal conversation with two people, there's an awful lot of the same kinds of overlap, and that it would be interesting to look at whether or there are these kinds of constraints that Jane mentioned, that maybe the additional people add to this competition that happens right after a turn.
Speaker F: You can have five people trying to grab a turn, but pretty quickly they back off and we go back to the sort of one person at a time with one person.
Speaker F: I don't know to answer your question.
Speaker F: I don't think it's crucial to have controls, but I think it's worth recording all the meetings we can.
Speaker F: I have a lot of that.
Speaker F: I would not record on the two person meeting because it only has a few.
Speaker C: Could we have the past and continue to have a fair number of phone calls?
Speaker C: We talked about this repeatedly.
Speaker C: We can see what happens in terms of role that way.
Speaker C: We have to set up for it.
Speaker G: We recorded this meeting so regularly.
Speaker H: We can look at each other.
Speaker H: Turn off the lights.
Speaker G: Let me take a picture.
Speaker G: That was the other thing.
Speaker G: Were we going to take a picture to the beginning of each of these meetings?
Speaker H: What I thought we were going to do was just take pictures of the whiteboards rather than take pictures of the meeting.
Speaker E: It's a head nodding here.
Speaker E: Why do we want to take pictures of the meeting?
Speaker E: Because you said the spatial relationship of the speech.
Speaker H: You could do that by just noting on the role.
Speaker H: I'll do that on the next set of forms.
Speaker B: I finally remembered to put the name of the speech.
Speaker H: We figured out from the mic.
Speaker H: No.
Speaker H: The wire was once.
Speaker H: I mean, I'm sitting here and the jack is over here.
Speaker F: Probably from the evening.
Speaker H: It would be another task.
Speaker H: Having ground to proof would be nice.
Speaker H: You could get it.
Speaker H: The game forming during the digit.
Speaker H: So I'm going to put the labels on all the chairs with the seat number.
Speaker H: That's a good idea.
Speaker C: But the chairs are in the same level.
Speaker C: Put them on the table.
Speaker E: But you know, the linguistic anthropologists would say it would be good to have a digital picture anyway.
Speaker E: Because you get a sense of a posture.
Speaker E: You could block out a person's face or whatever.
Speaker E: But these are important cues.
Speaker G: But from one picture, I don't know that you really get that.
Speaker G: You can be better than nothing.
Speaker E: You can just from a synch picture.
Speaker E: I think you can come up with some aspects.
Speaker E: I mean, I could tell you, if I'm in certain meetings, I really do the body language.
Speaker E: It's very interesting in terms of the dumbness.
Speaker C: That's funny.
Speaker C: Yeah.
None: I mean, you could block out the person's face.
Speaker H: You agree.
Speaker H: Of course, where we sit at the table, I find it's very interesting that we do tend to gravitate to the same place each time.
Speaker H: And it's somewhat coincidental.
Speaker H: I'm sitting here so I can run into the room if the hardware starts catching fire.
Speaker H: You'd like to be at charge.
Speaker G: I can start off at the head of the table.
Speaker G: Take control.
Speaker G: Speaking of taking control, you said you hid some research.
Speaker H: Yeah, I've been playing with using the close talking mic to try to figure out who's speaking.
Speaker H: So my first attempt was just using thresholding and filtering that we talked about about two weeks ago.
Speaker H: And so I play with that a little bit.
Speaker H: And it works okay, except that it's very sensitive to your choice of your filter width and your threshold.
Speaker H: So if you fiddle around with it a little bit and you get good numbers, you can actually do a pretty good job of segmenting when someone's talking and when they're not.
Speaker H: But if you try to use the same parameters on another speaker, it doesn't work anymore.
Speaker H: Even if you normalize it based on the absolute loudness.
Speaker F: It does work for that one's feature output meeting.
Speaker H: It does work for the one's feature output meeting.
Speaker H: Pretty well.
Speaker H: How did you do it then?
Speaker H: How did I do it?
Speaker I: What do you mean?
Speaker H: The algorithm was take every frame that's over the threshold and then median filter it and then look for runs.
Speaker H: So there was a minimum run length.
Speaker H: Every frame that's over what threshold?
Speaker I: A threshold that you pick.
Speaker I: In terms of energy?
Speaker I: Yeah.
Speaker I: Okay.
Speaker E: Say that again.
Speaker H: Okay.
Speaker H: So if you take each frame and you compute the energy and if it's over the threshold you set it to one.
Speaker H: And if it's under the threshold you set it to zero.
Speaker H: So now you have a bit stream.
Speaker H: That's zero's and once.
Speaker H: And then I median filtered that using a fairly long filter length.
Speaker H: Well, actually I guess it depends on what you mean by long.
Speaker H: You know, 10th of a second, source of numbers.
Speaker H: And that's to average out pitch, you know, the pitch converse and things like that.
Speaker H: And then look for long runs.
Speaker H: And that works okay if you filter if you tune the filter parameters, if you tune how long your median filter is and how high you're looking for your thresholds.
Speaker I: Did you ever try running the filter before you pick a threshold?
Speaker H: No.
Speaker H: Certainly could though.
Speaker H: But this was just I had the program mostly written already.
Speaker H: So it was easy to do.
Speaker H: Okay.
Speaker H: And then the other thing I did was I took, I took a few years speaker change detector, acoustic change detector and I implemented that with the closed talking mics.
Speaker H: And unfortunately that's not working real well and it looks like it's the problem is he does it in two passes.
Speaker H: The first pass is to find candidate places to do a break.
Speaker H: And he does that using a neural net doing broad phone classification and he has the one of the phone classes is silence.
Speaker H: And so the possible breaks are where silence starts and ends.
Speaker H: And then he has the second pass which is a modeling a Gaussian mixture model looking for whether it improves or degrades to split at one of those particular places.
Speaker H: And what looks like it's happening is that the even on the closed talking mic, the broad phone class classifiers doing a really bad job.
Speaker H: What was it trained on?
Speaker H: I have no idea. I don't remember. Does anyone do you remember Morgan? Was it broadcast news?
Speaker H: I think so, yeah.
Speaker H: So I didn't rate my next attempt which I am in the midst of and having quite finished yet was actually using the thresholding as the way of generating the candidates.
Speaker H: Because one of the things that definitely happens is if you put the threshold low, you get lots of breaks, all of which are definitely acoustic events.
Speaker H: They're definitely someone talking. Like it could be someone who isn't the person here, but the person over there or it could be the person breathing.
Speaker H: And then feeding that into the acoustic change detector.
Speaker H: And so I think that might work. I haven't gotten very far on that.
Speaker H: But all of this is closed talking mic.
Speaker H: Just trying to get some ground truth.
Speaker B: I think there is a good difference in the same thing.
Speaker H: Oh, absolutely. So my attention to this is as an aid for ground truth.
Speaker B: I mean that in the Mr. File you can find some with a great different level of energy.
Speaker B: I think for a minimum basic energy, more or less like a fair sign and detector.
Speaker B: Say it again. When you detect the fairs at the end of the detector of the name and the English, the detector of a war in the isolated war.
Speaker B: I'm not a launcher, but you're saying contract.
Speaker H: And you use an outside detector.
Speaker B: I think it's probably to war well because you have in the Mr. File it's a level of energy and a great difference between the speaker.
Speaker B: And probably it's not so easy when you use the PDA because the signal is the energy level in that speech file is more similar between the different speakers.
Speaker B: I think it will be in my opinion. It will be more difficult to detect basic energy, the chain.
Speaker H: In the PDA. Absolutely. No question. It will be much harder.
Speaker B: Another question. When I review the work of Javier, I think the idea of using neural network to get a broad class phonetic from the speaker.
Speaker B: If you have a, I'm considering only because Javier only consider like candidate the silence because this is the only model he used to detect the possibility of a chain between the speaker.
Speaker B: And another research in different groups working on broadcast news prefer to consider hypothesis between each 40 when the phone changes.
Speaker B: Because I think it's more realistic that only consider the silent between speaker. There is a seat silent between speaker is acoustic event important to consider.
Speaker B: I found that silent in many occasions in the speech file. But when you have to speak together with enough silent between the end, I think it's better to use the acoustic chain detector.
Speaker B: I, I, I, X or bike, the criteria for consider all the friends in my opinion.
Speaker G: The reason that he just used silence was not because he thought it was better. It was, it was the place he was starting. So I was trying to get something going. And as, as in your case, if you're here for on the amount of number of months, you try to get the holistic goal.
Speaker B: But his, his goal was always to proceed from there to then allow broad category change also. But do you think that if you consider all the friends to apply the, the bike, to the date, the different acoustic chain between speaker without and with silence or with overlapping.
Speaker B: I think like a general way of process the acoustic chain in the first step, I mean. And then with that, considering the, you, you can consider the energy like another parameter in the, in the future.
Speaker B: Absolutely. This is the idea. And if you do that with a bike, to tell you for example, or with another kind of a, of this time in the first step. And then you, you get the hypothesis to the, this chain acoustic.
Speaker B: Process, right. Because probably you, you can find the small gap of silence between speaker with a small duration less than 200 seconds. For example, and apply another, another algorithm, another approach like the texture of an, the texture, the basic energy to, to consider that, that, the sound of small silence between speaker or another algorithm to, to process the, the segment between marks, founded by the, the bike, the unit applied for, for each thing.
Speaker B: And it will be, and, and, and more general approach. That if we compare with use a neural net or another, a, a, a, a, a, a, a, a, a, with a broad class or, or not broad class because, in my opinion, it's, in my opinion.
Speaker B: If you, if you change the condition of the speech, I mean, if you adjust to your algorithm with the mr speech file and to, to, to, a, that, the neural net, you said by heavier with the mr file, with the, with the mix, mix, mix, sorry. And, and then you, you, you tried to, to apply that, a, a, a, a, a, speaker recognizer to that signal, to the pdA, a, a, a, a, a, a, I think you will have problems with the, a, a, the, a, a, a, you will need to, a, you will need to, to, to, to, retrain.
Speaker G: Look, I think this is a, once, I used to work like a voice, not voice silence detection young, this is this kind of thing.
Speaker G: If you have somebody who has some experience with this sort of thing and they work on it for a couple of months, they can come up with something that gets most of the cases fairly easily.
Speaker G: Then you say, okay, I don't want to just get most of the cases, I want it to be really accurate.
Speaker G: Then it gets really hard to measure what you do.
Speaker G: So the problem is, is that if you say, well, I have to use other data over here that I learn things from either explicit training of neural nets or Gaussian mixture models or whatever.
Speaker G: So, as you don't use any of those things, you say you have looked for acoustic change.
Speaker G: What does that mean?
Speaker G: That means you set some threshold somewhere or something, right?
Speaker G: And so, where do you get your thresholds from?
Speaker G: From something that you looked at.
Speaker G: So you always have this problem, you're going to new data.
Speaker G: How are you going to adapt to whatever you can very quickly learn about the new data if it's going to be different from old data that you have?
Speaker G: I think that's a problem.
Speaker H: Well, also, what I'm doing right now is not intended to be an acoustic change detector for far-field mics.
Speaker H: What I'm doing is trying to use the close talking mic and just use candidates.
Speaker H: Can't just get in and just try to get a first pass at some of the smart things.
Speaker H: And I haven't spent a lot of time on it.
Speaker H: And I'm not intending to spend a lot of time on it.
Speaker C: I'm unfortunately out to run, but I can imagine building a model of speaker change detection that takes into account both the far-field and actually not just the close talk mic for that speaker, but actually for all of the speakers.
Speaker C: If you model the effect that me speaking has on your microphone and everybody else's microphone as well as on that.
Speaker C: And you build basically, I think you would build an HMM that has a state space all of the possible speaker combinations.
Speaker C: And you can control it.
Speaker H: It's not that big actually.
Speaker H: Two to the end.
Speaker H: Two to the number of people in the meeting.
Speaker G: But actually, maybe just something simpler, but the long lines of what you're saying, I was just realizing, you know, the sky used to build mic mixers, automatic mic mixers where, you know, in order to be able to turn up the gain, you know, as much as you can, you lower the gain on the mics of people who aren't talking, right?
Speaker G: And you have some sort of reasonable way of doing that.
Speaker G: But what if you were just looking at very simple measures like energy measures, but you don't just compare it to some threshold overall, but you compare it to the energy in the other
Speaker H: microphones. I was thinking about doing that originally to find out who's the loudest in that person certainly talking, but I also wanted to find threshold, excuse me, overlap.
Speaker H: So not just just loudest.
Speaker B: Sorry.
Speaker B: I found it when I analyzed the speech file from the mic across microphone.
Speaker B: I found sound with a different level of energy, including overlap sound, including because the, depending on the position of the mic, or the feature speaker to get more or less energy in the signal.
Speaker B: And then if you consider energy to detect overlapping, and you process the speech file from the reset signals, the mic signals, I think it's difficult only to end with the energy to consider that in that zone we have a overlapping sound if you process only the energy of each frame.
Speaker G: Well, it's probably harder, but I think what I was noting just when he raised that was that there's other information to be gained from looking at all of the microphones and you may not need to look at very sophisticated things.
Speaker G: Because if most of the overlaps, this doesn't cover C3, but if most of the overlaps say are two, if the distribution looks like there's a couple high ones and an address down below, you know, I mean, there's some information there about the distribution even with very simple measures.
Speaker G: By the way, I had an idea that what I was watching Chuck nodding and a lot of these things is that we could all wear little bells in our heads.
Speaker H: You know that.
Speaker H: Sorry, I'm just going to sleep.
Speaker I: Yeah.
Speaker I: Actually, I saw a woman at the bus stop the other day who was talking on her cell phone speaking Japanese and was bowing, you know, profusely, just kept.
Speaker F: It's very difficult if you try while you're trying to say to convince somebody on the
Speaker D: phone, it's difficult not to move your hands.
Speaker F: If you watch the whole thing, you do things. I still think we should try a meeting or two with the blindfolds.
Speaker F: At least of this meeting that we have lots of recording though.
Speaker F: Yeah, I think.
Speaker F: Maybe for a part of the meeting, we're going to have to do it the whole evening.
Speaker F: I think it's a great idea.
Speaker F: It'll be too hard to make barriers that I was thinking because they have to go all the way.
Speaker F: I can see Chuck even if they're going to go to bed.
Speaker H: I can see that they're just turning out of lights.
Speaker E: I can say I made barriers so that the stuff I was doing was calling.
Speaker E: Which just used this kind of foam board, really inexpensive.
Speaker E: You can mask and tape it together.
Speaker E: These are very large.
Speaker E: We also have tissues.
Speaker F: These are the other things I think.
Speaker F: So we need a barrier that doesn't disturb the long range of life.
Speaker G: That would be good.
Speaker G: Probably we should wait until Adam set up the mics.
Speaker F: The interesting of the camera going.
Speaker F: I think we're going to have to work on the human subjects.
Speaker D: Yeah, that's right.
Speaker D: We did that one with people.
Speaker E: Do you mind being blindfolded while you're doing it?
Speaker G: That's the one that we videotape.
Speaker G: So I want to move this along.
Speaker G: I did have this other agenda item, which is a list which I sent to a couple folks but I wanted to get broader input on it.
Speaker G: So this is the things that I think we did in the last three months.
Speaker G: Obviously, not everything did, but sort of highlights that I can tell some outside person.
Speaker G: What were you actually working on?
Speaker G: In no particular order.
Speaker G: One, ten more hours of meetings recorded.
Speaker G: Something like that from three months ago.
Speaker G: XML formats and other transcription aspects sorted out.
Speaker G: Sent to IBM.
Speaker G: Pilot data put together.
Speaker G: Sent to IBM for transcription.
Speaker G: Next batch of recorded data put together on the CD-ROMs for shipment to IBM.
Speaker G: Hasn't been sent yet.
Speaker G: But it's getting ready.
Speaker G: Human subjects approval on campus and release forms worked out so the meeting participants have a chance to request audio pixelization of selected parts of the speech.
Speaker G: Audio pixelization software written and tested.
Speaker G: Eliminary analysis of overlaps in the pilot data we have transcribed.
Speaker G: And exploratory analysis of long distance inferences for topic coherence.
Speaker G: I was just sure if those were the right way.
Speaker G: That was the right way to describe that.
Speaker G: That was the lecture size that you and look under did.
Speaker G: What was that called?
Speaker G: Well, I'm probably saying this wrong.
Speaker G: But what I said was exploratory analysis of long distance inferences for topic coherence.
Speaker G: Something like that.
Speaker G: So a lot of that was from what you two were doing.
Speaker G: So I sent to you and please mail me corrections or suggestions for changing.
Speaker G: I don't want to make this twice its length, but just improve it.
Speaker H: Is there anything I need to do?
Speaker H: I did a bunch of stuff for supporting of digits.
Speaker G: A bunch of stuff for, okay, maybe send me a sentence.
Speaker G: That's a little bit of a sentence.
Speaker G: That doesn't just say a bunch of stuff.
Speaker H: Stuff is probably bad too.
Speaker H: It's not very technical.
Speaker H: I'll try to phrase it in passive voice.
Speaker H: Yeah, technical stuff.
Speaker G: A range of things.
Speaker G: Yeah.
Speaker G: And I sort of threw in what you did with what Jane did under the preliminary analysis for relapse.
Speaker G: Do you all can you tell us about all the work you've done on this slide?
Speaker G: Last three months.
Speaker G: It's really too complicated.
Speaker A: I didn't get what is audio pixelization.
Speaker G: Audio pixelization.
Speaker G: He did it.
Speaker H: So why don't you explain it quickly?
Speaker H: It's just beeping out parts that you don't want to include it in the meeting.
Speaker H: So you can say things like, well, they should probably not be on the record.
Speaker G: But we spent a fair amount of time early on just talking dealing with this issue about, we realized what people are speaking in an impromptu way.
Speaker G: And they might say something that would embarrass them or others later.
Speaker G: And how did you get around that?
Speaker G: So in the consent form it says, well, we'll look at the transcripts later and if there's something that you're unhappy with.
Speaker G: But you don't want to just totally excise it because, well, you have to be careful about excising how you excise it, keeping the timing right and so forth.
Speaker G: So the moment the idea we're running with is putting the beep.
Speaker H: You can either beep or it can be silence.
Speaker H: I couldn't decide which was the right way to do it.
Speaker H: It's good auditorily. If someone is listening to it, there's no mistake that it's been beeped out.
Speaker H: But for software, it's probably better for it to be silence.
Speaker I: You could make a model of that beep.
Speaker H: I like that.
Speaker H: It's an A low-poss.
Speaker I: It's more obvious that there was something there than it's just silence.
Speaker I: I mean, he's removing the old thing.
Speaker I: Right.
Speaker I: I mean, if you just replace it with silence, it's not clear whether that's really silence.
Speaker E: What question do you do it on all channels?
Speaker E: Of course.
Speaker H: Interesting. I like that.
Speaker H: You have to do it on all channels because it's audible.
Speaker H: It's potentially audible. You could potentially recover it.
Speaker H: You could keep it back door.
Speaker H: I haven't thrown away any of the meetings that I beeped.
Speaker H: Actually, yours is the only one that I beeped and then the ARP, the DARPA meeting.
Speaker H: Sorry.
Speaker H: It's the DARPA meeting I just excised completely.
Speaker F: It's some people who only have beeped their speed.
Speaker G: Very easy to find.
Speaker G: All right.
Speaker G: I think we should go on to the digits.
Speaker E: I have one concept.
Speaker E: I want to say, which is that I think it's nice that you're preserving the time relations.
Speaker E: So you're not just cutting, you're not doing scissors.
Speaker E: Right.
Speaker E: You're keeping the time duration that I've been in.
Speaker E: It's a deleted part.
Speaker H: Okay.
Speaker F: I think the other thing is that I'm saying something unbelievable.
Speaker F: You'll lose it.
Speaker H: There's no way around that.
Speaker G: Before we do the digit I did also want to remind people.
Speaker G: Please do send me thoughts for an agenda.
Speaker G: That would be good.
Speaker G: So that it's kind of stuck on me this week.
Speaker G: Yeah, well the screen.
Speaker F: Okay, and I wanted to say I think this is really interesting.
Speaker F: It's cool stuff.
Speaker F: I was going to say can you do that for the other meetings?
Speaker H: Can you do it for them?
Speaker I: No, actually I thought that's what you were given.
Speaker I: So it was another meeting.
Speaker I: I was like, oh cool.
Speaker E: How long did it take just briefly?
Speaker E: I have the script now.
Speaker E: So I mean it can work off the label.
Speaker E: Okay, so it has to be handled label first.
Speaker E: Well, yeah, because, well, I mean, once his is algorithm is that it works well enough.
Speaker E: Then we could do that way.
Speaker E: Okay, but it's really worked out with my things.
Speaker E: I'm not quite to the point where it was.
Speaker E: What this is caused me.
Speaker E: So this discussion caused me to want to subdivide these further.
Speaker E: I'm going to take a look at the back channel.
Speaker E: So much we have the panel.
Speaker E: I hope to have that.
Speaker H: And my algorithm worked great actually on these.
Speaker H: But when you wear it like that or with the lip hell, or if you have it very far from your face, that's when it starts failing.
Speaker F: Well, I can wear it.
Speaker F: It doesn't matter.
Speaker H: I mean, we wanted to wear it, right?
Speaker H: It's too late.
Speaker H: I don't want to change the way we do to be in it.
Speaker H: It's just a comment on the software, not a comment on the prescriptions on how you wear microphones.
Speaker H: Okay, let's get the bolts.
Speaker H: Let's do digits.
Speaker H: Transcript 16111630.
Speaker H: 5306185750.
Speaker H: Strike that.
Speaker H: 75108.
Speaker H: 8770980091392133442890597809869023857805094650207117529266007234.
Speaker I: Transcript 1851-187046055987681478054064016007000400400416004651222716634.
Speaker I: 5074-725448331-93421-00991241.
Speaker F: Transcript 18311850.
Speaker F: 3608456-83792-948150880301905625353527096520781298893623390060399024, I'm sorry, 2244340.
Speaker G: Transcript 1791-181012005843051665540890035840143692243724756.
Speaker G: 7056-911-0578703811729102.
Speaker A: Transcript 1811-1830230654066547067737890089529709649101032445606864706.
Speaker B: Transcript 1771-1790-005782021348358645205550678041060780410607706.
Speaker B: 41039-0230-C492-01543279340540403271345308258146955708909.
Speaker E: Transcript 1751-1770-011492887897354500604018120276.
Speaker E: 812-0276-923-1518-030-205-0123-0303184-524-64522-851-8900.
Speaker E: The only one that wasn't red is known, so we don't do it properly.
