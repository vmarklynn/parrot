{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yuzzPHd6gIUQ",
    "outputId": "a34fedfd-7340-43a9-90d7-4952f665db1e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import whisper\n",
    "import torch\n",
    "from pyannote.audio import Pipeline\n",
    "from pyannote.core import Segment, Annotation, Timeline\n",
    "import datetime\n",
    "from transformers import BartTokenizer, BartModel, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_suffix(filename):\n",
    "    return filename.replace(\".wav\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7EsxxG36STID"
   },
   "outputs": [],
   "source": [
    "# Taken from https://github.com/yinruiqing/pyannote-whisper\n",
    "class PyanWhisper:\n",
    "    PUNC_SENT_END = ['.', '?', '!']\n",
    "        \n",
    "    def diarize_text(transcribe_res, diarization_result):\n",
    "        timestamp_texts = PyanWhisper.get_text_with_timestamp(transcribe_res)\n",
    "        spk_text = PyanWhisper.add_speaker_info_to_text(timestamp_texts, diarization_result)\n",
    "        res_processed = PyanWhisper.merge_sentence(spk_text)\n",
    "        return res_processed\n",
    "\n",
    "    def get_text_with_timestamp(transcribe_res):\n",
    "        timestamp_texts = []\n",
    "        for item in transcribe_res['segments']:\n",
    "            start = item['start']\n",
    "            end = item['end']\n",
    "            text = item['text']\n",
    "            timestamp_texts.append((Segment(start, end), text))\n",
    "        return timestamp_texts\n",
    "    \n",
    "    def add_speaker_info_to_text(timestamp_texts, ann):\n",
    "        spk_text = []\n",
    "        for seg, text in timestamp_texts:\n",
    "            spk = ann.crop(seg).argmax()\n",
    "            spk_text.append((seg, spk, text))\n",
    "        return spk_text\n",
    "    \n",
    "    def merge_cache(text_cache):\n",
    "        sentence = ''.join([item[-1] for item in text_cache])\n",
    "        spk = text_cache[0][1]\n",
    "        start = text_cache[0][0].start\n",
    "        end = text_cache[-1][0].end\n",
    "        return Segment(start, end), spk, sentence\n",
    "    \n",
    "    def merge_sentence(spk_text):\n",
    "        merged_spk_text = []\n",
    "        pre_spk = None\n",
    "        text_cache = []\n",
    "        for seg, spk, text in spk_text:\n",
    "            if spk != pre_spk and pre_spk is not None and len(text_cache) > 0:\n",
    "                merged_spk_text.append(PyanWhisper.merge_cache(text_cache))\n",
    "                text_cache = [(seg, spk, text)]\n",
    "                pre_spk = spk\n",
    "            elif text[-1] in PyanWhisper.PUNC_SENT_END:\n",
    "                text_cache.append((seg, spk, text))\n",
    "                merged_spk_text.append(PyanWhisper.merge_cache(text_cache))\n",
    "                text_cache = []\n",
    "                pre_spk = spk\n",
    "            else:\n",
    "                text_cache.append((seg, spk, text))\n",
    "                pre_spk = spk\n",
    "        if len(text_cache) > 0:\n",
    "            merged_spk_text.append(PyanWhisper.merge_cache(text_cache))\n",
    "        return merged_spk_text\n",
    "\n",
    "    def write_to_txt(spk_sent, file):\n",
    "        with open(file, 'w') as fp:\n",
    "            for seg, spk, sentence in spk_sent:\n",
    "                line = f'{seg.start:.2f} {seg.end:.2f} {spk} {sentence}\\n'\n",
    "                fp.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"base\", device=\"cuda\")\n",
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization@2.1\",\n",
    "                                    use_auth_token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory = \"../../../Pipeline/sample_input/\"\n",
    "output_directory = \"../../../Pipeline/sample_output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:../../../Pipeline/sample_input/Bdb001.interaction.wav\n",
      "Output:../../../Pipeline/sample_output/Bdb001.interaction\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(input_directory):\n",
    "    audio = os.path.join(input_directory, filename)\n",
    "    text = os.path.join(output_directory, remove_suffix(filename))\n",
    "    print(\"Input:\" + audio)\n",
    "    print(\"Output:\" + text)\n",
    "    result = model.transcribe(audio)\n",
    "    diarization = pipeline(audio)\n",
    "    final_result = PyanWhisper.diarize_text(result, diarization)\n",
    "\n",
    "    with open(text + '.txt', 'w+') as f:\n",
    "        for seg, spk, sent in final_result:\n",
    "            start = str(datetime.timedelta(seconds=int(seg.start)))\n",
    "            line = start + f'\\t{spk}\\n{sent}\\n\\n'\n",
    "            f.write(line)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q1jLEgGmx834"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1vyNc7CSu6r",
    "outputId": "4ab8655c-014d-4c8a-8613-6df0ae2559f9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.8 (pytorch, pyannote, django)",
   "language": "python",
   "name": "whisper_django"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "85be66a78383f87e7b3b7ff9e62c87db4dd1969cd1dbe796cc7f107fbcc8db62"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
