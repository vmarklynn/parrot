{
 "cells":[
  {
   "cell_type":"code",
   "source":[
    "import os\n",
    "import json\n",
    "import glob as glob"
   ],
   "execution_count":1,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"Pu5U1QCNG1Yo4kce4jHRKd",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from huggingface_hub import login\n",
    "\n",
    "# non-blocking login\n",
    "login(token=\"<HUGGINGFACETOKENHERE>\")"
   ],
   "execution_count":2,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid.\n",
      "Your token has been saved to \/home\/datalore\/.cache\/huggingface\/token\n",
      "Login successful\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"hSyOwpESX8Mq2bRHqAwqWB",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from datasets import load_dataset\n",
    "\n",
    "data_files = {\"train\" : \"result.json\"}\n",
    "my_data = load_dataset(\"json\", data_files=data_files)\n",
    "\n",
    "my_data_train_test = my_data[\"train\"].train_test_split(test_size = 0.2)\n",
    "my_data_train_test"
   ],
   "execution_count":3,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Downloading and preparing dataset json\/default to \/home\/datalore\/.cache\/huggingface\/datasets\/json\/default-91b230ce0a827a88\/0.0.0\/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51...\n",
      "Dataset json downloaded and prepared to \/home\/datalore\/.cache\/huggingface\/datasets\/json\/default-91b230ce0a827a88\/0.0.0\/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51. Subsequent calls will reuse this data.\n"
     ],
     "output_type":"stream"
    },
    {
     "data":{
      "application\/vnd.jupyter.widget-view+json":{
       "version_major":2,
       "version_minor":0,
       "model_id":"2d30443ff2fc44b68e35f8f61e4e55f6"
      }
     },
     "metadata":{
      "application\/vnd.jupyter.widget-view+json":{
       "datalore":{
        "widget_id":"SejuKyM5AjbvsX2nVzy1eM"
       }
      }
     },
     "output_type":"display_data"
    },
    {
     "data":{
      "application\/vnd.jupyter.widget-view+json":{
       "version_major":2,
       "version_minor":0,
       "model_id":"dccf2670f0034a77b8ffb2bf3623502a"
      }
     },
     "metadata":{
      "application\/vnd.jupyter.widget-view+json":{
       "datalore":{
        "widget_id":"xT28bOEe4K1IimzF3JRlc8"
       }
      }
     },
     "output_type":"display_data"
    },
    {
     "data":{
      "application\/vnd.jupyter.widget-view+json":{
       "version_major":2,
       "version_minor":0,
       "model_id":"e582889030c0442bbe335b2886f033b0"
      }
     },
     "metadata":{
      "application\/vnd.jupyter.widget-view+json":{
       "datalore":{
        "widget_id":"W9LlEpU4OndWQ5OXRn4WJU"
       }
      }
     },
     "output_type":"display_data"
    },
    {
     "data":{
      "application\/vnd.jupyter.widget-view+json":{
       "version_major":2,
       "version_minor":0,
       "model_id":"f98c7b6021544c17b998676b05d359a8"
      }
     },
     "metadata":{
      "application\/vnd.jupyter.widget-view+json":{
       "datalore":{
        "widget_id":"61zHWT5NAyiPqzJDHpqlc1"
       }
      }
     },
     "output_type":"display_data"
    },
    {
     "data":{
      "text\/plain":[
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['meeting_id', 'summary', 'dialogue'],\n",
       "        num_rows: 135\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['meeting_id', 'summary', 'dialogue'],\n",
       "        num_rows: 34\n",
       "    })\n",
       "})"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"aHIxetyIn8DOWi4lfKFGBZ",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "my_sample = my_data_train_test[\"train\"].shuffle(seed=42).select(range(3))\n",
    "for row in my_sample:\n",
    "    print(f\"\\n'>>> Text: {row['dialogue']}'\")"
   ],
   "execution_count":4,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "\n",
      "'>>> Text: SPEAKER_02: Excellent. So I sent you the agenda that was in the project document, I don't know if you've got a chance to just have a look at it.\n",
      "SPEAKER_02: Anyway, the meeting is going to follow more or less the same structure as last time, so we'll go around each of you in turn and you can give your presentations on what you've been up to.\n",
      "SPEAKER_02: And at the end of that we need to discuss what you've come up with so that we can make a decision on the key remote control concepts.\n",
      "SPEAKER_02: So that's we need to know about the components, properties, materials, the user interface and any trends that the marketing expert has been watching.\n",
      "SPEAKER_02: Okay, do you understand again? Okay. I've got 40 minutes.\n",
      "SPEAKER_00: So I haven't played a PowerPoint. We have a bit of a passion.\n",
      "SPEAKER_00: I thought I'll use the whiteboard instead.\n",
      "SPEAKER_00: I'll put that back in and go down.\n",
      "SPEAKER_00: Okay, so basically I'll start off by, I thought I'll use the whiteboard because we have so many different options.\n",
      "SPEAKER_00: And what we can do is that we can start rubbing off the options that we do not require.\n",
      "SPEAKER_00: I'm putting in the options that are more highlighted and aligning them or something like that.\n",
      "SPEAKER_00: Okay, so I'll start again with a brief introduction to that anyway.\n",
      "SPEAKER_00: Brief introduction to the insides of a mode control and then we can probably discuss the various components.\n",
      "SPEAKER_00: Okay, so what you see here is this is the outside of the remote.\n",
      "SPEAKER_00: If you open it, you have a circuit board here.\n",
      "SPEAKER_00: And this is the chip that I was talking about last time.\n",
      "SPEAKER_00: This basically sends information to a transistor here, which then sends the information to an LED device here.\n",
      "SPEAKER_00: If you flip the printed circuit board, and this is the most important point here, everything else is kind of.\n",
      "SPEAKER_00: Okay, so if you flip the circuit board, this is what it looks like.\n",
      "SPEAKER_00: So you see, for example, a particular button attaches to a particular place on the PCB.\n",
      "SPEAKER_00: And on pressing this button, a circuit completes.\n",
      "SPEAKER_00: The information goes to the chip, which is somewhere here, and the chip then translates the code into an infrared radiation, which goes out through there.\n",
      "SPEAKER_00: So the important point that I read over the website was that the configurations of these printed circuit boards are quite too many.\n",
      "SPEAKER_00: You can get them printed as you want to.\n",
      "SPEAKER_00: So we can have a configuration irrespective of the cost the way we want to have it.\n",
      "SPEAKER_00: So that's the important point here.\n",
      "SPEAKER_00: So these are the different options that we have.\n",
      "SPEAKER_00: Okay, so the batteries, I'll start with the battery.\n",
      "SPEAKER_00: So they can be simple, which is like the normal batteries in our results.\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_00: These are the kind of different kinds of batteries that the company makes.\n",
      "SPEAKER_00: So hand dynamos.\n",
      "SPEAKER_00: Does that mean like a wind up one?\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_00: I don't know if you want to consider this, but these are the different things that the company makes.\n",
      "SPEAKER_00: So they'll come internally from the company.\n",
      "SPEAKER_00: They'll be cheaper.\n",
      "SPEAKER_00: All these options.\n",
      "SPEAKER_00: So the third one is the kinetic energy one.\n",
      "SPEAKER_04: You can make the hand dynamo into an exercise bike and then people could exercise walls, watching TV and charging the remote.\n",
      "SPEAKER_02: Yeah.\n",
      "SPEAKER_04: And still worrying about the whole RSI.\n",
      "SPEAKER_00: It's a good option.\n",
      "SPEAKER_00: So what was the kinetic energy one?\n",
      "SPEAKER_00: The kinetic energy one is that they're usually in modern watches since our hand keeps moving.\n",
      "SPEAKER_00: It keeps the watch ticking.\n",
      "SPEAKER_00: But I don't know if it is a good idea for a remote control because it'll just lie there for a long while sometimes.\n",
      "SPEAKER_00: As soon as you pick it up, it moves and then again it recharges or something.\n",
      "SPEAKER_00: And the fourth option is the solar cells, which are also made by the company.\n",
      "SPEAKER_00: Environment friendly.\n",
      "SPEAKER_00: Okay.\n",
      "SPEAKER_00: So I'll enlist things and then we can come back and discuss what we think from everybody's perspective.\n",
      "SPEAKER_00: There are different cases that can be provided.\n",
      "SPEAKER_00: They can be basically the shape of the cases.\n",
      "SPEAKER_00: They can be flat.\n",
      "SPEAKER_00: They can be curved with one sided curved and one sided flat.\n",
      "SPEAKER_00: And they can be curved with on both the sides.\n",
      "SPEAKER_00: These are the three options.\n",
      "SPEAKER_03: I mean, this would be like the overall shape of the remote control.\n",
      "SPEAKER_03: Yeah.\n",
      "SPEAKER_00: Would it be flat on both the sides?\n",
      "SPEAKER_00: Would it be curved from one side?\n",
      "SPEAKER_00: There are different kinds of supplements available.\n",
      "SPEAKER_00: Like it can be in plastic, rubber, wood or titanium.\n",
      "SPEAKER_00: Okay.\n",
      "SPEAKER_01: Would you say woah?\n",
      "SPEAKER_01: Wood?\n",
      "SPEAKER_01: Wood.\n",
      "SPEAKER_04: Oh.\n",
      "SPEAKER_04: It can be remote.\n",
      "SPEAKER_00: Yeah, you understand why when we get to work with it.\n",
      "SPEAKER_00: So we can use even, titanium is also used in the company to make some space design equipment.\n",
      "SPEAKER_00: So it's kind of, it'll be probably nicer to use because it relates to the overall image of the company.\n",
      "SPEAKER_00: But it cannot be used on a double curved surface.\n",
      "SPEAKER_00: If you choose this, we cannot use titanium.\n",
      "SPEAKER_00: For these two, we can use titanium, wood, rubber or plastic.\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_00: Okay.\n",
      "SPEAKER_00: The interface options now.\n",
      "SPEAKER_00: So we can have push buttons like most remote do.\n",
      "SPEAKER_00: And our company is an expert in making push buttons.\n",
      "SPEAKER_00: We can have scroll wheels like the ones on mouse pointer.\n",
      "SPEAKER_04: And the...\n",
      "SPEAKER_00: So do you actually have a phone?\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_00: Something like that.\n",
      "SPEAKER_00: So, and they have, they can even have an integrated push button inside the scrolling.\n",
      "SPEAKER_00: Okay.\n",
      "SPEAKER_00: The scroll plus push.\n",
      "SPEAKER_00: So this is something that has been recently developed by the company in the last decade.\n",
      "SPEAKER_00: So not too recent.\n",
      "SPEAKER_00: And LCDs.\n",
      "SPEAKER_00: We can have LCDs.\n",
      "SPEAKER_00: These two are recent.\n",
      "SPEAKER_00: And this is quite old.\n",
      "SPEAKER_00: The various electronic options are...\n",
      "SPEAKER_00: So this concerns first of all the chips I showed you that...\n",
      "SPEAKER_00: So there is a chip behind this one, right?\n",
      "SPEAKER_00: The PCB is inexpensive.\n",
      "SPEAKER_00: So we can put in whatever we want.\n",
      "SPEAKER_00: But the various integrated circuit options are...\n",
      "SPEAKER_00: We have either a simple one or a regular or advanced.\n",
      "SPEAKER_00: And the price goes up as we go down, obviously.\n",
      "SPEAKER_00: Okay.\n",
      "SPEAKER_00: So the good thing about why we would want to use advanced...\n",
      "SPEAKER_00: Why we might want to use advanced is that LCDs can only come with the advanced chip.\n",
      "SPEAKER_00: We need regular or advanced for scroll wheels.\n",
      "SPEAKER_00: And the chip basically includes the infrared sender.\n",
      "SPEAKER_00: Besides this, under electronics, also the company has started making a sample sender, which did not explain what it was.\n",
      "SPEAKER_00: But I'm guessing that...\n",
      "SPEAKER_00: So they have a sample sender and a sample speaker.\n",
      "SPEAKER_00: So I'm guessing that the sample speaker is probably something like, you know, as soon as you press a button, it gives you feedback.\n",
      "SPEAKER_00: One, five or whatever.\n",
      "SPEAKER_00: Yeah, on.\n",
      "SPEAKER_00: And I don't know whether a sample sender has to do something with voice recognition or not.\n",
      "SPEAKER_00: But anyway, so these are the different options that we have.\n",
      "SPEAKER_00: Okay.\n",
      "SPEAKER_00: So that's basically...\n",
      "SPEAKER_00: Now I think that we can integrate the user interface and the marketing things in that...\n",
      "SPEAKER_00: To keep taking out things from this and underlining things that are important.\n",
      "SPEAKER_02: Excellent.\n",
      "SPEAKER_02: Do you want to stay somewhere near the board so that if we need to...\n",
      "SPEAKER_00: Yeah, sure.\n",
      "SPEAKER_02: You can sit down, but just...\n",
      "SPEAKER_02: We might need you to leap up.\n",
      "SPEAKER_03: What do you have now?\n",
      "SPEAKER_03: I have some PowerPoint here.\n",
      "None: Okay.\n",
      "SPEAKER_03: Oh, yeah.\n",
      "SPEAKER_02: Can these pens give you a cancer overhand?\n",
      "SPEAKER_04: I suppose we'll come in and click in and say...\n",
      "SPEAKER_00: Yeah, it should do it.\n",
      "None: Right.\n",
      "SPEAKER_02: Interface concept.\n",
      "SPEAKER_03: Okay.\n",
      "SPEAKER_03: To be honest, actually, I mentioned some of the things which could fit under this talk.\n",
      "SPEAKER_03: This time I mentioned the more ID in the previous talk.\n",
      "SPEAKER_03: So, yeah, this time I might not have them on the slides, but I can just mention them again.\n",
      "SPEAKER_03: Okay.\n",
      "SPEAKER_03: So I thought I would also include the definition of using interface.\n",
      "SPEAKER_03: So it's the aspects of a computer system or a program which can be seen by the user.\n",
      "SPEAKER_03: And which the mechanism that the user uses to control is operation and input data.\n",
      "SPEAKER_03: So this would include things like shape and size and buttons and voice recognition as well and color and so on.\n",
      "SPEAKER_03: The method I employed this time was again having a look to related products and mainly on the internet.\n",
      "SPEAKER_03: Then analyzed them from the point of view of user friendliness and also whether their appearance was pleasant.\n",
      "SPEAKER_03: And then this can help us to decide which reaches we want to incorporate in our product.\n",
      "SPEAKER_03: So some findings.\n",
      "SPEAKER_03: So in the case of many user interfaces, they are just so full of buttons that it's actually hard to find the ones you really want to use.\n",
      "SPEAKER_03: And it's just confusing.\n",
      "SPEAKER_03: It takes time to learn.\n",
      "SPEAKER_03: Okay.\n",
      "SPEAKER_03: And I thought I would just quickly show some of them that I found.\n",
      "SPEAKER_03: Okay.\n",
      "SPEAKER_03: Some of them are here.\n",
      "SPEAKER_03: The picture is not very clear.\n",
      "SPEAKER_03: But as you can see there are actually, oh, oh, sorry for that.\n",
      "SPEAKER_03: Let's go back.\n",
      "SPEAKER_03: Oh, please.\n",
      "SPEAKER_03: Okay.\n",
      "SPEAKER_03: So yeah, they are quite big and have many, many buttons.\n",
      "SPEAKER_03: Actually, all these I personally prefer this one because it's the smallest and with least with the smallest number of buttons.\n",
      "SPEAKER_03: And I would say even the appearance of some of them is kind of not so nice.\n",
      "SPEAKER_03: Okay.\n",
      "SPEAKER_03: So let's carry on with this.\n",
      "SPEAKER_03: So other findings.\n",
      "SPEAKER_03: Some new things used.\n",
      "SPEAKER_03: Some of them were mentioned already by our technical designer.\n",
      "SPEAKER_03: Our own company has developed a new user interface.\n",
      "SPEAKER_03: Wait.\n",
      "SPEAKER_03: No, this is not the one.\n",
      "SPEAKER_03: Okay.\n",
      "SPEAKER_03: There is a, we can include voice recognition and it allows.\n",
      "SPEAKER_03: It's possible to record 80 different voice samples on it.\n",
      "SPEAKER_03: So this one was already mentioned, the LC display.\n",
      "SPEAKER_03: Yeah.\n",
      "SPEAKER_03: Another new development is a scroll button, which was also also already mentioned.\n",
      "SPEAKER_03: And our own manufacturing division has designed a new programmable speech.\n",
      "SPEAKER_03: Sorry, a speaker unit, I guess it should be.\n",
      "SPEAKER_03: And this means that once it comes together with a voice recognition, but it's once the, once the, it recognizes the voice of the speaker, there can be a pre-programmed answer.\n",
      "SPEAKER_03: For example, you can pick up the remote control and say something to it like hello and it says hello and your name or whatever.\n",
      "SPEAKER_03: So, I mean, this is also one of the new developments which we might consider if we wanted to.\n",
      "SPEAKER_00: Sorry, can you go back for a second?\n",
      "SPEAKER_00: Are you sure what this means, the spinning wheel with the LC display?\n",
      "SPEAKER_02: It's like the, like you said, no, the scroll button.\n",
      "SPEAKER_03: No, no, the scroll button is a different thing.\n",
      "SPEAKER_03: I have a picture if you, just a moment, I'll show you.\n",
      "SPEAKER_03: I wasn't completely sure myself, but I think it's just like, it's a wheel, it's like not separate buttons.\n",
      "SPEAKER_03: Look, this one here, but I'm not really sure whether you can really turn it around.\n",
      "SPEAKER_03: It's like a press this or this.\n",
      "SPEAKER_04: It's like, you know how you have your mouse and you go around and it's kind of like that and you spin around and it's okay.\n",
      "SPEAKER_00: So instead of going down, you just spin.\n",
      "SPEAKER_04: You just go around and it's a bit weird at first, but it's actually very fast.\n",
      "SPEAKER_04: Like the wheels that click on the side, you get a much slower set.\n",
      "SPEAKER_04: It's quite good if you're like searching quite a lot of stuff.\n",
      "SPEAKER_04: So, you know, if you're looking, you're scrolling through the A to Z and you're looking for something at T, then it's a lot faster than the wheel, but you've got a lot less control over it.\n",
      "SPEAKER_00: I think that you include that here as well as CVs plus spinning.\n",
      "SPEAKER_03: Okay, and the personal preference is pretty much the same as last time.\n",
      "SPEAKER_03: It has to be a small, simple, okay, we decided to include voice recognition.\n",
      "SPEAKER_03: So, the standard major buttons like gone off, the channels and then volume, and then there will be menu on the screen.\n",
      "SPEAKER_03: And I also thought if we want to put small and nice, and actually I quite like the idea of a scrolling button, with voice like, I don't know, like on the movements or something.\n",
      "SPEAKER_03: I think there is no reason why we couldn't do something like this for the remote control.\n",
      "SPEAKER_03: So, yeah, that's it. That's it. Excellent.\n",
      "SPEAKER_02: Okay, straight to trains and then we can discuss it all at once.\n",
      "SPEAKER_01: I can't wait. I have a little bit of a nice, and a little bit of a quick difference.\n",
      "SPEAKER_01: Yeah, if you're too good by stealing it.\n",
      "SPEAKER_01: No, no, no, no.\n",
      "None: It's not the same thing.\n",
      "None: No, no, no, no.\n",
      "SPEAKER_01: No, no, no.\n",
      "None: No, no, no, no, no, no, no, no.\n",
      "None: Oh, no, no, no.\n",
      "SPEAKER_01: Okay, cool.\n",
      "SPEAKER_04: What I always do is search the inserts, come up with market trends, and you know what users are going to be wanting in the near future.\n",
      "SPEAKER_04: Okay.\n",
      "SPEAKER_04: So, the first aspect is about only twice as important as the second aspect, which is twice as important as the third aspect.\n",
      "SPEAKER_04: So, I mean, the easy to use thing is fairly low down on there, which I think given the target group is what you would expect.\n",
      "SPEAKER_04: You know, people want something new, something technologically innovative and different, so the whole idea with the LCDs and the spinning and the colours and the voice recognition is like quite a thing to go for.\n",
      "SPEAKER_04: And yeah, it would still look funny.\n",
      "SPEAKER_00: So, maybe as you're discussing things, is it okay if we just keep highlighting things there?\n",
      "SPEAKER_00: Yeah, yeah.\n",
      "SPEAKER_00: So, so, so, so, so, so probably voice recognition is kind of important, right?\n",
      "SPEAKER_00: Maybe the LCD and spinning.\n",
      "SPEAKER_00: Yeah, okay, I have a point about LCD, I don't know if it is the right point to take it up.\n",
      "SPEAKER_00: LCDs are basically for feedback, right, to the user who is pressing buttons, and the feedback can come through the television itself, so do we need a hand sitting on the remote?\n",
      "SPEAKER_04: It depends how fast your television runs really, don't you think?\n",
      "SPEAKER_04: I only have one of those, tell you where spot is, and you put the number in the remote, and then you wait, and then it goes to the TV, and then you wait, and then it comes, so it actually takes quite a long time.\n",
      "SPEAKER_00: Right.\n",
      "SPEAKER_04: So, if you get the number wrong, then it's a bit of a pain, so I think, you know, a screen on the remote would probably get down the time of that, but like, the roads do tend to get thrown about a bit.\n",
      "SPEAKER_04: Right.\n",
      "SPEAKER_02: It is also quite nice, though, to have something here so you don't interrupt the picture on the screen, so if you're watching something.\n",
      "SPEAKER_02: Yeah, that's true.\n",
      "SPEAKER_04: I think it would be like, I mean, if you can make it integrate with the TV, then it can come up with your information about what's on, and you could just see that on the remote\n",
      "SPEAKER_02: rather than having to interrupt your viewing pleasure.\n",
      "SPEAKER_04: But I think maybe a way to do it would be a similar way to how you have your mobile phone, you know, like you have the slide you want, and you have the flip you want, and then the screen is protected, so it doesn't actually get scratched, so you can have like, what looks like a normal remote control, you know, or like a minimalist remote control, so you got your buttons one to nine, you're on and off, and your volume on that, and then if you want to mess about it, you flip it open, and, yeah.\n",
      "SPEAKER_00: Okay.\n",
      "SPEAKER_00: So we seem to have a consensus that LCDs are definitely the way to go because of style,\n",
      "SPEAKER_04: and yeah, so that kind of decides your whole chip thing.\n",
      "SPEAKER_00: Right. You agree?\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_00: Right.\n",
      "SPEAKER_00: So, okay.\n",
      "SPEAKER_00: LCDs.\n",
      "SPEAKER_00: Definitely.\n",
      "SPEAKER_00: Go on.\n",
      "None: Okay.\n",
      "SPEAKER_04: Okay.\n",
      "SPEAKER_04: Apparently, these are vegetables we'll be providing inspiration, so I discovered your part.\n",
      "SPEAKER_04: So these will be an important feature for clothes, shoes, and furniture.\n",
      "SPEAKER_04: So, I mean, I'm taking this to mean, you know, carviness, you know, because you don't tend to get flat vegetables, you know, possibly even uneven, like, a bit of asymmetry and stuff, but that would be a good way to get in the whole RSI issue in the videos.\n",
      "SPEAKER_04: I mean, if you think most people use the remote control with their right hand, right hand, so you want to, you can't have it so that it's too small for you to use your right hand.\n",
      "SPEAKER_04: Yeah.\n",
      "SPEAKER_04: I'm not quite sure about the relevance of material will be spongy.\n",
      "SPEAKER_02: Something a bit squishy.\n",
      "SPEAKER_02: Yeah.\n",
      "SPEAKER_04: Yeah.\n",
      "SPEAKER_02: We have.\n",
      "SPEAKER_00: It'd be like a robbery.\n",
      "SPEAKER_00: We have a robbery.\n",
      "SPEAKER_00: But, I think it's a good case with using.\n",
      "SPEAKER_04: Well, I suppose you wouldn't get a remote control.\n",
      "SPEAKER_04: Yeah.\n",
      "SPEAKER_02: Yeah.\n",
      "SPEAKER_02: And it'd help if you drop it, to protect it as well.\n",
      "SPEAKER_02: Yeah.\n",
      "SPEAKER_02: Yeah.\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_00: So, if we use latex cases, they won't allow us to use solar cells as an emergency.\n",
      "SPEAKER_00: We could use titanium, food, or plastic.\n",
      "SPEAKER_02: Or if we want to use the latex, then we have to go with one of the other.\n",
      "SPEAKER_02: Yeah.\n",
      "SPEAKER_04: We'll have a nice show.\n",
      "SPEAKER_04: We could get the kinetic energy fairly easily there.\n",
      "SPEAKER_02: From down to down.\n",
      "SPEAKER_02: You can have it as like a little bald.\n",
      "SPEAKER_02: Yeah.\n",
      "SPEAKER_04: Yeah.\n",
      "SPEAKER_04: So, yeah.\n",
      "SPEAKER_00: So, probably double curved surfaces the way to go.\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_00: So, we're curved at one end and flat on the top, because I'm not sure if it is flat on both the sides, then how much easy would it be to reach for buttons, etc.\n",
      "SPEAKER_04: Yeah.\n",
      "SPEAKER_04: Yeah.\n",
      "SPEAKER_04: It depends on the whole.\n",
      "SPEAKER_04: Yeah.\n",
      "SPEAKER_04: It's like how you put your hand on a single side curve.\n",
      "SPEAKER_00: Single side curve, double side curve does not say too much does it?\n",
      "SPEAKER_04: No, I don't think it makes a lot of difference.\n",
      "SPEAKER_04: I have one of those slidey bones and the back is essentially straight, but it's curvy.\n",
      "SPEAKER_04: Besides, you have four sides to a thing.\n",
      "SPEAKER_04: I think it's curved.\n",
      "SPEAKER_04: One side means one side is straight.\n",
      "SPEAKER_04: Right.\n",
      "SPEAKER_04: And curved two sides means the whole thing is just a big curvy thing.\n",
      "SPEAKER_00: Did it say anywhere in your research material about the sliding stuff?\n",
      "SPEAKER_00: Because according to the information that I have, I think the only options that we have with the case is that we used to be.\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_00: We either have a black surface to the case or a curved surface case.\n",
      "SPEAKER_00: It does not say anything about whether technically this stuff is available at all.\n",
      "SPEAKER_04: Yeah.\n",
      "SPEAKER_04: It's more about the protection of the LCD.\n",
      "SPEAKER_04: We have one of the keys where it came on.\n",
      "SPEAKER_04: Yeah.\n",
      "SPEAKER_04: My research didn't tell me anything, which is why we have all the pictures.\n",
      "SPEAKER_04: That's what I had to do with my time.\n",
      "SPEAKER_04: Okay.\n",
      "SPEAKER_04: Cool.\n",
      "SPEAKER_04: What have we got?\n",
      "SPEAKER_04: Combined style with a level of functionality, beauty and practicality.\n",
      "SPEAKER_04: And a piece of functionality.\n",
      "SPEAKER_04: Okay.\n",
      "SPEAKER_02: Yes.\n",
      "SPEAKER_02: So, looking at what we've got, we want to now set it up to display with a spinning wheel.\n",
      "SPEAKER_00: Let's try to rub off things.\n",
      "SPEAKER_00: Rub off some of those.\n",
      "SPEAKER_00: So, hand dynamics are definitely out, right?\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_02: Yeah.\n",
      "SPEAKER_02: That's not streamlined and sexy having a wind up.\n",
      "SPEAKER_00: Um, kinetic energy does seem to have some kind of a appeal, but...\n",
      "SPEAKER_00: It's rather practicality really, isn't it?\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_00: As against a watch, which constantly keeps moving, this thing will have to be tapped every time, which might be very frustrating for the user.\n",
      "SPEAKER_02: Depends how much movement it really needs.\n",
      "SPEAKER_01: I don't have to mention that.\n",
      "SPEAKER_02: Presumably, if they're suggesting it, then we could use it.\n",
      "SPEAKER_00: Okay.\n",
      "SPEAKER_00: Let's keep it off.\n",
      "SPEAKER_00: I'll keep it off.\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_00: Um, the flat, completely flat case is definitely out, right?\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_01: It has to be removed from one side.\n",
      "SPEAKER_00: Not vegetable.\n",
      "SPEAKER_00: Um, okay.\n",
      "SPEAKER_00: We still have all the options.\n",
      "SPEAKER_00: What do you think would be very...\n",
      "SPEAKER_03: What is...\n",
      "SPEAKER_03: I can't...\n",
      "SPEAKER_03: How do you...\n",
      "SPEAKER_03: I mean, you can't keep it really small.\n",
      "SPEAKER_03: You can't make it like thin and...\n",
      "SPEAKER_03: Right.\n",
      "SPEAKER_03: I would think because you need to put all the technology in.\n",
      "SPEAKER_03: So, I mean, if the case, you had the case.\n",
      "SPEAKER_03: Yeah.\n",
      "SPEAKER_00: If it is really...\n",
      "SPEAKER_00: If it is really...\n",
      "SPEAKER_00: If it is really thin, it's like you to break.\n",
      "SPEAKER_00: It's like it's much more...\n",
      "SPEAKER_02: Yeah.\n",
      "SPEAKER_02: Yeah.\n",
      "SPEAKER_02: Given that we're looking at more spongy material preferences, would think maybe rubber or plastic as well.\n",
      "SPEAKER_04: Yeah.\n",
      "SPEAKER_04: That's true.\n",
      "SPEAKER_04: Yeah.\n",
      "SPEAKER_04: It's not a practical...\n",
      "SPEAKER_04: I mean, it's right for a table, but for a micro control, you know?\n",
      "SPEAKER_04: Yeah.\n",
      "SPEAKER_04: And splinters and stuff.\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_04: Okay.\n",
      "SPEAKER_04: What is that?\n",
      "SPEAKER_03: It doesn't make any sense, I think.\n",
      "SPEAKER_03: Yeah.\n",
      "SPEAKER_03: Yeah.\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_00: In the case of remote control, remote really.\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_00: Okay.\n",
      "SPEAKER_00: Now for the really interesting stuff, the interface.\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_00: Right.\n",
      "SPEAKER_00: So, the push buttons is our expertise in the industry.\n",
      "SPEAKER_00: But it seems to be out of trend, you know, no big thing.\n",
      "SPEAKER_04: Yeah, but I have some push buttons.\n",
      "SPEAKER_03: I think for the channel numbers, you still need them, wouldn't you?\n",
      "SPEAKER_04: Yeah.\n",
      "SPEAKER_04: Yeah.\n",
      "SPEAKER_00: Right.\n",
      "SPEAKER_00: So, for channel numbers...\n",
      "SPEAKER_00: If you have LCD displays that opens up a whole world, you know, if you have an LCD display, then you can select almost everything on the LCD display.\n",
      "SPEAKER_03: Yeah, but I think the LCD display is kind of...\n",
      "SPEAKER_03: Yeah, it's faster with...\n",
      "SPEAKER_03: And when we discuss that, we might like the flipping open thing.\n",
      "SPEAKER_03: I mean, you can use it as a normal remote control.\n",
      "SPEAKER_03: Yeah.\n",
      "SPEAKER_03: But if you do want to use LCD, then you flip it open, but it's more time consuming.\n",
      "SPEAKER_04: Yeah.\n",
      "SPEAKER_04: I think this is going back to the graph at the beginning that I made, where, you know, the buttons, the people use all this honey on buttons for them.\n",
      "SPEAKER_04: Yeah.\n",
      "SPEAKER_00: And everything else.\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_00: Many don't.\n",
      "SPEAKER_00: So, in the buttons we have, for the channels also, we have options.\n",
      "SPEAKER_00: Do we enumerate everything from zero to nine?\n",
      "SPEAKER_00: Or do we have just a channel plus channel minus?\n",
      "SPEAKER_03: No, no, I mean, we definitely need the numbers because it's...\n",
      "SPEAKER_03: Otherwise, people don't want to flip through all the channels.\n",
      "SPEAKER_02: Do we need them as buttons or do we need them as LCD?\n",
      "SPEAKER_00: On the LCD we can, you know...\n",
      "SPEAKER_03: Yeah, I would say buttons because it's...\n",
      "SPEAKER_03: Yeah.\n",
      "SPEAKER_04: It's...\n",
      "SPEAKER_04: I think the thing is, if someone just wants to turn on the TV and put on a channel, then it should be easier to use than any other remote.\n",
      "SPEAKER_04: And then if someone wants to, you know, change the contrast on their TV and...\n",
      "SPEAKER_04: Right.\n",
      "SPEAKER_04: They should be able to do that and it should be accessible, but, you know, I mean, most of the time, I mean, there's a limit to how much the biggest technology can spend fiddling with the TV.\n",
      "SPEAKER_04: Right.\n",
      "SPEAKER_04: I think it's the issue here.\n",
      "SPEAKER_00: Okay.\n",
      "SPEAKER_00: So, buttons definitely, but...\n",
      "SPEAKER_00: Shall we try to draw...\n",
      "SPEAKER_02: I think that's what you guys are going to do next.\n",
      "SPEAKER_02: Okay.\n",
      "SPEAKER_02: So, I'm going to put down the key.\n",
      "SPEAKER_00: Okay.\n",
      "SPEAKER_00: So, components.\n",
      "SPEAKER_00: Right.\n",
      "SPEAKER_00: So, what about the scrolling?\n",
      "SPEAKER_03: Yeah, but I'm not completely clear.\n",
      "SPEAKER_03: Yeah.\n",
      "SPEAKER_03: About the spinning wheel.\n",
      "SPEAKER_03: So, I think it doesn't make sense to have both like a scrolling and spinning thing.\n",
      "SPEAKER_03: You cannot include everything in the spinning, if you just spin it.\n",
      "SPEAKER_03: Yeah.\n",
      "SPEAKER_04: I would say the spinning goes at a higher speed to the scrolling wheel.\n",
      "SPEAKER_04: So, you have to decide whether you want to be going so fast or not.\n",
      "SPEAKER_04: But, I mean, the thing with this hole, you're planning on making it out of rubber, and the basis that it's spondy.\n",
      "SPEAKER_04: And I'm not sure how well a scrolling wheel would work.\n",
      "SPEAKER_02: But if you've got a...\n",
      "SPEAKER_02: I mean, you can...\n",
      "SPEAKER_02: If you've got a flip thing, effectively, it's something that's curved on one side and plait on the other side, but you fold a little in half.\n",
      "SPEAKER_04: Yeah, but your spinning wheel tends to go to one side.\n",
      "SPEAKER_02: That would be on one side.\n",
      "SPEAKER_00: I'm not sure it'll be a good idea to construct the whole thing out of rubber.\n",
      "SPEAKER_00: Yeah, I think so too.\n",
      "SPEAKER_00: I mean, the case would be rubber and the buttons.\n",
      "SPEAKER_00: Or at the corner edges, just the edges covered by rubber or something like that, everything else in plastic.\n",
      "SPEAKER_00: Or even titanium if you want to use it.\n",
      "SPEAKER_04: Or maybe like interchangeable cases.\n",
      "SPEAKER_04: Because I know, like, we're going back to eye pods again in the whole spinning wheel, but I have like a...\n",
      "SPEAKER_04: Now, obviously my eye pod is not made of rubber, and then I have a little rubber case that goes over the top of it, and I can change the color.\n",
      "SPEAKER_00: Right.\n",
      "SPEAKER_04: The U.S.A.T. to march my outfit.\n",
      "None: Right.\n",
      "SPEAKER_00: Okay.\n",
      "SPEAKER_00: So that gives us a more trendy look as well.\n",
      "SPEAKER_04: Yeah, I think the spinning wheel is definitely very narrow.\n",
      "SPEAKER_00: Right.\n",
      "SPEAKER_00: Yeah, and we're going more for the trend stand for the usability anyway.\n",
      "SPEAKER_00: That's right.\n",
      "SPEAKER_00: Yeah, after.\n",
      "SPEAKER_00: So, rub that out.\n",
      "SPEAKER_00: And colors can be provided with the case rather than...\n",
      "SPEAKER_00: But we still need to think about the color of our moda such.\n",
      "SPEAKER_03: Yeah, I think it was a requirement that we use our...\n",
      "SPEAKER_03: The colors of our company.\n",
      "SPEAKER_03: So would it be like yellow, gray and black or something?\n",
      "SPEAKER_03: I guess.\n",
      "SPEAKER_04: That doesn't fit in with the whole vegetable thing.\n",
      "SPEAKER_03: Bananas?\n",
      "SPEAKER_03: Bananas?\n",
      "SPEAKER_03: Yellow.\n",
      "SPEAKER_04: Yeah, definitely.\n",
      "SPEAKER_04: I mean, do you think we could incorporate the colors of the company into the buttons and then make the colors the main remote.\n",
      "SPEAKER_04: The color like vegetable colors, you know?\n",
      "SPEAKER_04: So you could have like...\n",
      "SPEAKER_04: I mean, I suppose vegetable colors would be all in green and some reds and maybe purple and that.\n",
      "SPEAKER_04: And then you'd paint the buttons and company colors to match the color.\n",
      "SPEAKER_04: Okay.\n",
      "SPEAKER_00: Okay.\n",
      "SPEAKER_00: Okay.\n",
      "SPEAKER_00: If you go over to the integrated circuits, since we are having LCDs, there's no way that we will be able to.\n",
      "SPEAKER_00: What we do need to consider however is that the price is going up with every such thing that we are considering.\n",
      "SPEAKER_00: But since LCDs seems to be a definite yes.\n",
      "SPEAKER_00: So it seems to be one area where we would want to spend.\n",
      "SPEAKER_00: So I'll rub off the other two.\n",
      "SPEAKER_04: So we're discounting solar energy because rubber is going to be used in there somewhere.\n",
      "SPEAKER_04: Or...\n",
      "SPEAKER_02: That was the...\n",
      "SPEAKER_00: Oh, so the constraint was...\n",
      "SPEAKER_00: We can't have solar panels.\n",
      "SPEAKER_00: Solar panels with rubber.\n",
      "SPEAKER_01: So...\n",
      "SPEAKER_04: Yeah, okay.\n",
      "SPEAKER_04: So you really lose that, I think.\n",
      "SPEAKER_02: Should we go for...\n",
      "SPEAKER_02: If we're going for rubber, we think of it as our case.\n",
      "SPEAKER_02: And then...\n",
      "SPEAKER_03: And the buttons as well.\n",
      "SPEAKER_02: Yeah.\n",
      "SPEAKER_00: I think...\n",
      "SPEAKER_00: We'll have...\n",
      "SPEAKER_00: Using the simple battery will be a safer option as compared to the kinetic energy one.\n",
      "SPEAKER_00: I mean, although it does seem interesting.\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_00: But it does not hold any advantages as that.\n",
      "SPEAKER_00: Yeah, it's just to get it.\n",
      "SPEAKER_04: Yeah.\n",
      "SPEAKER_00: Okay.\n",
      "SPEAKER_00: Okay, so we understand this better now that the speaker is for the feedback, right?\n",
      "SPEAKER_00: It says the things that you type in or something like that.\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_02: So...\n",
      "SPEAKER_02: I think if we can include them not too much extra cost, then I'd put them in...\n",
      "SPEAKER_00: We don't have too much information about it.\n",
      "SPEAKER_03: Yeah, but I think it should be quite cheap because it's from a company company.\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_00: Okay.\n",
      "SPEAKER_00: So this is in as well then.\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_00: So I'm supposed to be good.\n",
      "SPEAKER_02: Okay.\n",
      "SPEAKER_02: And the case is curved on one side but in flat.\n",
      "SPEAKER_02: Flat on the top.\n",
      "SPEAKER_02: Flat. So it's flipped.\n",
      "SPEAKER_02: Into each other.\n",
      "SPEAKER_02: Okay.\n",
      "SPEAKER_02: Can I pull the...\n",
      "SPEAKER_02: Yeah, sure.\n",
      "SPEAKER_02:...the computer.\n",
      "SPEAKER_01: Just so I can...\n",
      "SPEAKER_04: Sorry, Joey.\n",
      "SPEAKER_02: Nothing gets right.\n",
      "SPEAKER_02: I'll just...\n",
      "None: Okay.\n",
      "SPEAKER_04: What is ICSC?\n",
      "SPEAKER_00: ICs, integrated circuits.\n",
      "SPEAKER_04: Okay.\n",
      "SPEAKER_04: So it's advanced integrated circuits?\n",
      "SPEAKER_04: Yeah.\n",
      "SPEAKER_04: Welcome to the...\n",
      "SPEAKER_00: We're definitely going in for voice recognition as well as on CDs.\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_01: Okay.\n",
      "SPEAKER_02: So we've basically worked out that we're going with a simple battery.\n",
      "SPEAKER_02: The advanced chip.\n",
      "SPEAKER_02: And curved on one side case which is folded in on itself.\n",
      "SPEAKER_02: Made out of rubber.\n",
      "SPEAKER_02: And the buttons are also rubber.\n",
      "SPEAKER_02: We're having push buttons on the outside and then on the inside an LCD with spinning wheel.\n",
      "SPEAKER_02: And we're incorporating voice recognition.\n",
      "SPEAKER_02: That's however all contact.\n",
      "SPEAKER_02: And it's going to look sort of digital and be in bright vegetable colours.\n",
      "SPEAKER_03: So would we have the spinning wheel inside with the LCD or would it be on the altar?\n",
      "SPEAKER_03: Imagine being inside.\n",
      "SPEAKER_04: Okay.\n",
      "SPEAKER_04: So actually that could like really cut down your thing.\n",
      "SPEAKER_04: So you've got your outside which is like minimalist and then you open it up and you've got a screen and a spinning wheel which you can incorporate buttons into.\n",
      "SPEAKER_04: So you've still not got like a lot of stuff in there.\n",
      "SPEAKER_04: You've maybe got like if you're modelling on an iPod you've got five buttons and a wheel and fours of it and doing the wheel.\n",
      "SPEAKER_04: And the other one's a little bit inside.\n",
      "SPEAKER_02: Yeah.\n",
      "SPEAKER_02: Sure.\n",
      "SPEAKER_02: Okay.\n",
      "SPEAKER_02: So now we've got 30 minutes before our next meeting.\n",
      "SPEAKER_02: In the meantime the industrial designer over here is going to work on the look and feel design which I presume will work out what that means.\n",
      "SPEAKER_02: The user interface designer will work on the user interface design and the marketing expert is going to work on productive evaluation.\n",
      "SPEAKER_02: And as well as that the two designers are going to work together on our prototype following those instructions that we've just come up with using modelling clay and you will get extra instructions from your personal coach.\n",
      "SPEAKER_02: That all okay.\n",
      "SPEAKER_02: And anyone who hasn't put their presentation in the project documents folder it would be good just so in case we have to refer to it.\n",
      "SPEAKER_04: I'm going to go and sit on my own.\n",
      "SPEAKER_02: Nobody wants to talk to you.\n",
      "SPEAKER_02: I know.\n",
      "SPEAKER_04: I'm plugging in.\n",
      "SPEAKER_04: I've got a bit tangled up in here.\n",
      "SPEAKER_03: Shall I move away first or shall I stay here?\n",
      "SPEAKER_03: I don't know.\n",
      "SPEAKER_03: Maybe.\n",
      "SPEAKER_03: I would care.\n",
      "'\n",
      "\n",
      "'>>> Text: SPEAKER_02: That's usual. Yes\n",
      "SPEAKER_03: I was forgot it was a meeting Oh good 20 minutes ago. Thank you. What did I forget?\n",
      "SPEAKER_01: Scridge how the brain sort of does that\n",
      "SPEAKER_03: And turn all the alarms\n",
      "SPEAKER_01: Okay, so the news from me is a my forthcoming travel plans Yes two weeks from today Yeah, more or less I'll be off to Sicily in Germany for a couple three days\n",
      "SPEAKER_03: And what are you doing there forget?\n",
      "SPEAKER_01: Okay, I'm flying to Sicily basically to drop off Simon There's this great verse and then I'm flying to Germany to go to a Mojo to Athens which is the meeting of all the module responsible people in smart com And represent ici I It myself I guess there and That's the actual reason and then I'm also going up to email for a day and then I'm going to meet the very big boss of convoyster in sub-routine and the system integration people in kaiserslautern And then I'm flying back via Sicily They dropped my son coming here on the 4th of July\n",
      "SPEAKER_02: And a great time to be coming back to the us of a God bless America you see the fireworks from your plane coming in\n",
      "SPEAKER_01: I'm sure all the people at the airport will be happy to work on that day\n",
      "SPEAKER_02: Yeah We're not even better service than usual\n",
      "SPEAKER_03: We're aren't you flying on the tons of them I'll tell you That's not a big deal What you get to the United States it'll be a problem then\n",
      "SPEAKER_01: And That's that bit of news and the other bit of news is we had you know I was visited by my German project manager Who a did like what we did What we're doing here and B is planning to come here either three weeks in July or three weeks in august To actually work on us oh And we sat around and we talked and he came up We came up with a pretty strange idea And that's what I'm going to lay on you now And maybe it might be ultimately the most interesting thing for Eva because he has We know to complain about the fact that the stuff we do here is not weird enough So this is so weird that should even make you happy Okay Imagine if you will That we have a system that does all that understanding that we wanted to do Uh-huh based on utterances It should be possible To make that system produce questions So if you have the knowledge of how to interpret where is x Undergiven conditions situational user discourse on logical Conditions You should also be able to make that same system ask Where is x In a certain way based on certain intentions So instead of just being able to observe phenomenon Um and guess the intention we Might be able just Sort of Give it an intention and make it produce an utterance\n",
      "SPEAKER_03: But like in AI they generally do the Take in and then they also do the generation phase like Nancy's thing or You know in the hand Thing in 182 like not only was able to recognize which is also to generate based upon situations I mean that sort of thing absolutely\n",
      "SPEAKER_01: Once you've done that What we can do is have the system ask It's self An answer Ask something else and enter a dialogue with itself The basic the same idea is having two chess computers take\n",
      "SPEAKER_02: Except this smacks a little bit more of a skits of random computer\n",
      "SPEAKER_01: Yeah, you if you want you can have two parallel I'm asking each other what would that give us would a be something completely weird and strange and be If you look at all the factors We will never observe People Let's say in wheelchairs under you know under all conditions, you know when they say it x And there is a right at the goal and the parking is good. We can never collect enough data It's not possible, right But maybe one could do some learning If you get the system to speak to itself you may find breakdowns and errors And you may be able to learn And make it more robust maybe learn new things and And so there is no no end of potential things one could get out of it if that works And he would like to actually work on that for this\n",
      "SPEAKER_03: So they probably should be coming back a year from now\n",
      "SPEAKER_01: Yeah, I See that the generation bit making the system generate generate something this shouldn't be too hard\n",
      "SPEAKER_03: Well, once the system understands things. Yeah, no problem I just don't think I think we're probably a year away from getting the system to understand things\n",
      "SPEAKER_01: Yeah, well if we can get it to understand one thing like our worries run through We can also maybe a make it say or ask Where is X Or not? I don't know\n",
      "SPEAKER_02: I'm sort of having impression that getting it to say the right thing and the right circumstances is much more difficult than Getting it to understand something given the circumstances and so on You know, I mean just as it's sort of harder to learn to Speak correctly in a foreign language rather than learning to understand it right?\n",
      "SPEAKER_02: I mean just the fact that we'll get the point is that getting it to understand one construction doesn't mean that it will always know exactly When it's correct to use that\n",
      "SPEAKER_01: It's it's Well, I've done generation and language for ductile research for four four and a half years and so it's you're right It's not the same as the understanding. It's in some ways easier in some ways harder. Yeah, but um I think it'd be a Fun to look at it or into that question. It's a pretty strange idea\n",
      "SPEAKER_03: That's the basic idea. I guess it'd be to give a lot of the system to have intentions basically Is that's basically what needs to be added to the system for it?\n",
      "SPEAKER_01: Yeah, I think even think even what it would be the the prior intention So let's say we have to see that I mean no, let's we have to we have some some top down processing given certain setting Okay, now we change nothing and just say ask something Right\n",
      "SPEAKER_03: What would it ask? It wouldn't know what to ask It Unless it was in a situation we'd have to set up a situation where you didn't know where something was and it wanted to go there Yeah, which means it we'd need to set up an intention inside of the system right Which is basically I don't know where something is and I need to go there\n",
      "SPEAKER_01: Do we really need to do that?\n",
      "SPEAKER_03: because No, I guess not\n",
      "SPEAKER_01: It's I know it's it's strange, but look at it Look at our baseness if we don't have Let's assume we don't have any input from the language Right so there's also nothing we could query the ontology, but we have a certain user setting If you just ask what is the likelihood of that person wanting to enter something it'll give you an answer Right sure they are And so whatever that is is the generic default intention That it would find out which is wanting to know where something is maybe I don't know what it's going to be but there's going to be something that well you're not going to you're going to get a variety of\n",
      "SPEAKER_02: Intentions out of that then I mean you're just talking about like given this user What's the what is it what is that user most likely to want to do?\n",
      "SPEAKER_01: Well, you can have it sort of some user and context stuff and ask what's the Posterior probabilities of all of our decision notes You could even say let's take all the priors that's observed nothing query all the posterior probabilities It's going to tell us something right\n",
      "SPEAKER_03: Well it will Assign values to all the notes. Yes\n",
      "SPEAKER_01: And with posterior probabilities for all the values of the decision notes Which if we have an algorithm that filters out whatever the the best or the most consistent Answer out of that will give us the Intention x nihilo And that is exactly what would happen if we ask it to produce an utterance it would be based on that extension x nihilo Which we don't know what it is but it's there So we wouldn't even have to to kickstart it by giving it a certain attention or Observing anything on the decision note And Whatever that maybe that would lead to what is\n",
      "SPEAKER_03: Undershastle or what is I guess what I'm afraid of is if we don't you know set up a situation we'll just get a bunch of garbage out like You know everything's exactly 30%\n",
      "SPEAKER_01: Yeah, so what we actually then need to do is write a little script that changes all the settings You know go goes through all the permutations which is we did it didn't we calculate that one?\n",
      "SPEAKER_03: That was that was absurdly low and the last meeting because I went and looked at it because I was thinking That could not be right and it would it was on the order of 20 output nodes and something like 20 30 input nodes So to test every output node I would at least See said we two to 30 for every output node Which is very very large oh\n",
      "SPEAKER_01: That's nothing for those neural guys. I mean they trained for millions and millions of epochs. Well, I'm talking about\n",
      "SPEAKER_03: I was gonna think of my water Talking about billions and billions and billions and A number two to 30 is like it Boscow said we calculated out and Boscow believes that it's larger than the number of particles in the universe\n",
      "SPEAKER_02: And I don't know if that's right or not It's big It's just that's it's a billion right two to the 30\n",
      "SPEAKER_03: Well, it's 30 is a billion, but if we have to do it two the 20 times Okay, then that's a very very large number. Oh, okay. Yeah, that's big because we have to query the node for every all right Uh, or query the net to the 20 times or not to excuse me 20 times. Okay. So it comes to 20 billion or something Yes, that's pretty big. That's big actually. Oh, we calculated a different number before. How do we do that?\n",
      "SPEAKER_02: Hmm. I remember there being some other one flittering around but anyway Yeah, yeah, it's anyway the point is given all of these different factors It's it's still going to be impossible to run through all of the possible situations or whatever, but I think this will get us a bit closer at least right? I mean\n",
      "SPEAKER_03: If it takes us a second to do it for each one and let's say it's 20 billion then that's 20 billion seconds, which is Ava do the math Long I've heard some hours and hours and hours but we can do randomized testing\n",
      "SPEAKER_02: Yeah\n",
      "SPEAKER_03: Which problem willistically will be good enough\n",
      "SPEAKER_01: Yeah, so it'd be it's an idea that one could for for example run run past um What's that guys for me No, you're usually here\n",
      "SPEAKER_02: You're in the group Jerry Jerry Felder. Yeah, that's Yeah, yeah, that would be the bald guy. Oh my advisor\n",
      "SPEAKER_01: And um, so this is just an idea that's floating around and we'll see what happens and What other news do I have Yeah, we fix some more things from the smart com system, but that's not really a general interest Oh questions. Yeah, I'll ask Eva about the e-base and she's working on that. How is the generation XML\n",
      "SPEAKER_03: Thing I'm going to work on that today and tomorrow. Okay. No need to do it today or tomorrow. You can do it next week or I'm gonna finish it today. I hopefully Okay I want to do one of the things where I stay here because if I go home I can't finish it. I've tried About five times so far where I work for a while and then I'm like I'm hungry So I go home and then I think I'm not going back Yeah, that or I think to myself I can work at home and then I try to work at home, but I fail miserably Like I ended up at Blake's last night I'm not conducive. No, I almost got into a brawl But I did not finish the smart com but I've been looking into it. I said it's not like it's like a blank slate I found everything that I need and I It's the furthermore I told Jerry that I was gonna finish it before I get back so That's approaching. He's coming back when next. Oh, I think we think we'll see him definitely on Tuesday for the nice or no Wait the meek's are on Thursday\n",
      "SPEAKER_02: Maybe maybe okay, but we'll see him next week. All right That's good\n",
      "SPEAKER_01: Yeah The paper\n",
      "SPEAKER_03: Hmm I was thinking about that I think I Will try to work on the smart com stuff and I will if I can finish it today I'll help you with that tomorrow if you're working I don't have a problem with us working on it though\n",
      "SPEAKER_01: So okay, so you would say it's funky cool\n",
      "SPEAKER_03: I mean, it wouldn't hurt to write up a paper because I mean yeah, I was talking with Nancy and I said you don't know Whether you have a paper to write up until you write it up. So Well, since Jerry's coming back we can run it by him too, so yeah\n",
      "SPEAKER_01: What's your input?\n",
      "SPEAKER_02: Well, um, I don't have much experience with conference papers for competing the computer science realm So when I looked at what you had which was apparently a complete submission or just sort of said I didn't really know what to do with it like this is the sort of the basic outline of the system or whatever Or here's an idea, right? That's what that paper was here's here's one possible thing you could do Short eight pages and I just don't know What you have in mind for expanding like I what I didn't do is go to the website of the conference and look at what they're looking for or whatever\n",
      "SPEAKER_01: Well, it seems to me that\n",
      "SPEAKER_03: um Wait, is this a computer science conference or is it a\n",
      "SPEAKER_01: um Well, it's more it's both right it's it's sort of cognitive neuro psycholinguistic But all for the sake of doing computer science So it's sort of cognitive psycho Neuro plausibly Motivated architecture so natural language processing So it seems pretty interdisciplinary and I mean the keynote speaker is Tomasello Right so The question is what could we actually Do and and keep a straight face while doing it and I really can't keep a straight face doing anything My idea is well you can say we have done a little bit and that's it and Sort of the right position paper we want to also do that which is not too Good might be more interesting to do something like Let's assume We're right we have a steric closet a delusion of adequacy and take our where is accentance and say we will just talk about this and how we cognitively norally So Psycholinguistically construction grammar really Motivated in vision Uh, understanding that So we can actually show how we parse it That should be able to we should be able to come up with sort of a A parse It's on just just put it on\n",
      "SPEAKER_03: Yeah, that Ben harass you. Yeah, good\n",
      "SPEAKER_00: Yes\n",
      "SPEAKER_01: Oh, you're will suffer in hell you know\n",
      "SPEAKER_02: There's a Diagram somewhere which tells you how to put that\n",
      "SPEAKER_03: That you have to put it on exactly like that so put that those things over your ears like that See the pathopuss the things are I shouldn't like that there you go\n",
      "SPEAKER_00: Okay, it hurts it hurts real bad\n",
      "SPEAKER_02: But that's what you get for coming late to the\n",
      "SPEAKER_00: Okay, this is your mic on yeah Talking about\n",
      "SPEAKER_01: Um, we're talking about this and it paper that we made just sort of Oh, which gentleman yeah and I just sort of Brought forth the idea that we take a sentence where is the part of tower and we we Pretend to parse it we pretend to understand it and we write about it\n",
      "SPEAKER_02: And on how all of these things Okay, then we pretend to submit into a major international conference\n",
      "SPEAKER_01: Oh It's the whatever architectures You know where there's this conference the seventh already international conference on Neuroly cognitively motivated architectures of natural language processing And keynote speakers are Tomasalo Oh, Mike why me make when he make when he I think so interesting like child language people. Yep Okay, so maybe you want to write something too\n",
      "SPEAKER_00: Why are they thinking of it? It says it normally like Like dialogue systems or you know\n",
      "SPEAKER_01: Even Neuro and\n",
      "SPEAKER_00: Uh learning and like\n",
      "SPEAKER_01: Comprehension production you can look at the website Okay, and the deadline is a 15th of June 10 year time why we've got over a week It would be nice to go right two papers actually. Yeah, one one from your perspective and one from or a pivot\n",
      "SPEAKER_00: I mean that's the kind of thing that maybe like um the general Can sort of like N T L is to like whatever the previous simulation based version maybe you're talking on the same kind of thing a general paper about The approach here would probably be good. Yeah, good to do some point anyway. Yeah\n",
      "SPEAKER_01: Well, I also think that if we sort of Write about what we have done in the past six months We we could Sort of craft a nice little paper that if it gets rejected which could happen Doesn't hurt because it's something we having it as a good good thing. It's a nice exercise. It's I usually enjoy writing papers. It's not I don't regard it as a painful thing And we should all do more for our publication lists and never hurts and Keith and or John O will go probably Will I in case of So the 22nd of September in South Brook and Germany\n",
      "SPEAKER_00: Okay, so is the what you're just talking about\n",
      "SPEAKER_02: What would one possibly put in center?\n",
      "SPEAKER_01: What to write about What is on what's our take home message? What what do we actually because I mean it I don't like papers where you just talk about what you plan to do I mean It's obvious that we can do any kind of evaluation and have no you know, we can't write an ACL type paper We say okay, we've done this and now we're whatever percentage better than everybody else, you know It's part too early for that But we can tell them what we think I mean it's never heard to try And Maybe even that's maybe the time to introduce the the new formalism that you guys have cooked up\n",
      "SPEAKER_03: In the process, don't they need to finish the formalism? It's not even\n",
      "SPEAKER_00: Okay, so it's a little thing\n",
      "SPEAKER_03: We said it was 4,000 lines is that it?\n",
      "SPEAKER_01: I don't know. Did you look at it?\n",
      "SPEAKER_02: It depends on the problem. Oh my gosh. Oh, I thought you were I thought we were talking about something which was\n",
      "SPEAKER_01: No, that's I mean, there's actually a problem. It's difficult. It's more difficult to write on four pages than eight\n",
      "SPEAKER_00: Yeah, and it's also difficult to even if you had a lot of substance. It's hard to demonstrate that in four pages\n",
      "SPEAKER_02: Yeah, that would be hard\n",
      "SPEAKER_01: Well, maybe it's just 4,000 lines. I don't they don't want any they don't have a tech style They just want us key pure ask you Lines whatever why for whatever reason I don't know not including figures and such Very unspecific\n",
      "SPEAKER_03: Well, just let's say that's closer to six pages actually 4,000 lines of asking okay 4,000 lines. I mean\n",
      "SPEAKER_02: Isn't it isn't it about 50 55 60 lines to a page?\n",
      "SPEAKER_01: I don't quote me on this this is numbers I have from looking how many characters are online? Okay, let's let's watch what we should should we discuss this over T and all of us look at the web I can't I'm wizarding today Okay, look at the web page look at the web page and let's talk about it maybe tomorrow afternoon For us to find it are like neural journal world and you will think you have a link. Okay. I got an email\n",
      "SPEAKER_03: By the way Keith is comfortable with us calling a cool Keith\n",
      "SPEAKER_02: He decided I'm chilling in the 510 Yeah Thank you and I'm also from the 212\n",
      "SPEAKER_01: Sorry, yeah, I'm like to see sleep next In two weeks or not and a week of business in Germany I mentioned that for you and otherwise you haven't missed much except for a really weird idea But you'll hear about that\n",
      "SPEAKER_00: I do that you and I are you about that you already told me?\n",
      "SPEAKER_01: No, no, no Yeah, that is something for the rest of the game. The thing with the goats and the helicopters Change the watch bed. It's time to walk the sheep Um Did you catch that illusion? No Presumably one of the water gate codes Anyways Um Don't make any plans for spring break next year That I'm shooting Tell me you're gonna do an interview in the your internal workshop in Sicily\n",
      "SPEAKER_00: That's what that's what he said\n",
      "SPEAKER_01: I've already got the funding\n",
      "SPEAKER_00: You'll get your flyers there Yeah, that's what it means. Okay, cool. You'll put us up too. I know I know about that part. I know about the almond trees Oh Too easy coconut High-neighborcy mango\n",
      "SPEAKER_01: Too easy too easy I'm mango school everywhere so do kiwi okay. I was trying to find something that he didn't grow in his farm But cook another pineapple that's that's tricky. Yeah\n",
      "None: Sorry So but we have to decide what like sort of the general I need is um I mean we're gonna have an example case Um, right the point is to like this where is case? Yeah, maybe you have it would be kind of the paper hat would have in my vision a nice flow\n",
      "SPEAKER_01: If we could say here is the Here's parsing if you want to do it right here is Understanding if you want to do it right and you know without going to the technical\n",
      "SPEAKER_00: And we're not doing like those things right. Yeah, right would that be clear in the paper or not?\n",
      "None: That would be clear we would I Made around a little paper that I have yeah, we can sort of see this is No, I don't think you got it. See this if you if you're not around you do and for taking the discussion\n",
      "SPEAKER_00: Okay, come on So parsing done right so we can leave it say this is what it's sort of\n",
      "SPEAKER_01: state-of-the-art today Right and say this is bad. Yeah, and then we can say well what we do is this Okay\n",
      "SPEAKER_00: Parsing done right interpretation done right example\n",
      "SPEAKER_01: Mm-hmm\n",
      "SPEAKER_00: Yeah, and I'm actually getting to the cognitive neural part\n",
      "SPEAKER_03: That's the only that's the question mark. Don't you need to reduce it if it's a Or reduce it if it's a finite of neuro\n",
      "SPEAKER_00: I mean the conference may be cognitive neural doesn't mean that every paper has to be both\n",
      "SPEAKER_01: Yeah, and you can you can just point to the to the literature you can say the construction base\n",
      "SPEAKER_00: You know so this paper wouldn't particularly deal with that side although it could reference the anti-allage sort of like The fact that the meant is you're Where designed to be compatible with Yeah, I guess four pages you could I mean you could definitely It's definitely possible to do it It's just be small like introducing the formalism might be not really possible in detail\n",
      "SPEAKER_02: But you can look in a yeah looking at that paper that that you had I mean, you know like you didn't really Explained in detail what was going on in the XML cases whatever just said really you know Here's the general idea some stuff gets put in there You know hopefully you can you can say something like a constituent tells you what the construction is made out of you know Without going into this intensity Yeah Give him the one paragraph whirlwind tour of what this is for\n",
      "SPEAKER_01: This would be sort of documenting what we think and documenting what we have in terms of the base net and stuff and since this never a bad idea to document things Yes, that's definitely a good idea There would be my We should sketch out the details maybe tomorrow afternoon if everyone is around You know you probably Wouldn't be part of it. Maybe you want think about it Um You may may ruin your career forever\n",
      "SPEAKER_03: Hey you might give blacklisted and\n",
      "SPEAKER_01: The Other thing Yeah, we actually have we made any progress on what we decided last week I'm sure you read the transcript of last week's reading right so Up to date We decided that we're gonna take a where is something question and pretend we have parsed it and see what we could possibly Hope to observe on the first one\n",
      "SPEAKER_03: I came in and I started asking you about how we were sort of going to sort out the decision nodes\n",
      "SPEAKER_00: Yes\n",
      "SPEAKER_03: I remember you talking to me just that what you said Where it was like we needed to or in my opinion we need to design a base another sub-base net You know, it was whether it was whether we would have a base net of the output and on the input or whether the construction was gonna be in the base net Oh, yeah, and outside of it and\n",
      "SPEAKER_00: Was that the question was that what well that was it was related to what we were talking about\n",
      "SPEAKER_01: Should I introduce to the pseudo square? Yeah, sure We have to put this in the paper This is this is my only constraint So the pseudo square I Saw the diagram in the other situation user Discourse right autonomy oh my god, that's amazing No way way\n",
      "SPEAKER_02: So\n",
      "SPEAKER_00: So once you start making full calls\n",
      "SPEAKER_02: Oh god, what you know like su studio that horrible\n",
      "SPEAKER_03: I've blocked every aspect of football as out of my mind. Sorry. I haven't\n",
      "SPEAKER_02: He names in here\n",
      "SPEAKER_01: Oh, but also he's talking about suicide and that's that's not a notion I want to have it both\n",
      "SPEAKER_00: Yes, really I didn't really listen to it. I was too young. It sounds too rocking for that anyway\n",
      "SPEAKER_02: So what what so I wanted our constraints time and time\n",
      "SPEAKER_01: Okay, so we have tons of little things here and we can't believe that that's never been thought of before\n",
      "SPEAKER_03: What are the dots I don't remember what those little bugs\n",
      "SPEAKER_01: Okay, you know these are our whatever believe that decision notes and they all contribute to these Oh Things down here That's you that's you we ask When the moment it's a base net and it has sort of 50 not yet specified interfaces Okay, I have taken care that we actually can build little interfaces To other modules that will tell us whether the user likes these things and the all these things and he whether\n",
      "SPEAKER_00: He's in a wheelchair or not supposed to be the international sign for interface. I think so yeah\n",
      "SPEAKER_03: I'd never seen it before either\n",
      "SPEAKER_02: Because things fit onto that And frankly, I've seen fashion\n",
      "SPEAKER_01: No, this is a hard-eat corporate agent Design, I don't know\n",
      "SPEAKER_02: There's maybe a different so wait what are these letters again the situation use or discourse and what about the utterance\n",
      "SPEAKER_00: That's the discussion of discourse. Yeah, this course is all things linguistic yeah\n",
      "SPEAKER_01: So this this includes the the current utterance plus all the previous utterances And for example Irina Gouriri which is going to be here And of July she's a new linguist working for email and what she would like to do for example is great for us. She would like to Take the end to on toilet so We have discussed in terms of the Eva Think of back at the Eva vector and John O coming up with the idea that if the person discussed the Discuss the admission fee in previously that might be a good indication that How do I get to the castle actually he wants to enter?\n",
      "SPEAKER_01: You know how do I get to X Discussing the admission fee in the previous utterance is a good indication So we don't want a hard code a set of leg seams or things that persons No to filter or search the discourse history So what would be kind of cool is That if we encounter a concept such a castle tower bank hotel we run it through the ontology and the ontology tells us it has Admission opening times it has admission fees it has this it has that and then we we we make a thosaurus Lexicon look up and then search dynamic the through the discourse history for Currencies of these things in a different window of utterances And that might you know give us additional input to believe a versus B or key versus a\n",
      "SPEAKER_00: Okay, so you're looking for a few keys that you know are cues to Sorry, a few specific cues to some attention. You can dynamic look up keys. Yeah, oh, so wait\n",
      "SPEAKER_02: So um grip since since the sort of technical stuff is going over my head The point is that you that When someone's talking about a castle you know that it's the sort of thing that people are likely to want to go into or Is it the fact that if there's an admission fee then one of the things we know about admission fees is that you pay them in order to go in and then the idea of entering is active in the discourse or something and then\n",
      "SPEAKER_01: Well, blah blah the idea is even more general the idea is to say We encounter a certain entity in a in a in an utterance. So let's look up everything we the ontology gives us About that entity what stuff it does what roads it has what Parts whatever it has functions and then we look In the discourse whether any of that or any surface structure corresponding to these roads function has ever occurred And then the discourse history can tell us yeah or no, okay, and then it's up for us to decide what to do with it Okay, so So we may think that if you say Where's the theater Um whether or not he has talked about tickets before then we he's probably want to go there to See you something okay, where's the opera and perperes and lots of people go to the opera to take pictures of it and to look at it lots of people go to attend the performance and The discourse can maybe tell us what's more likely If we know what to look for in previous statements And so we can hard code for opera look for tickets do look for this look for that We look for Mozart look for this But the smarter way is to go via the ontology and dynamically then look up\n",
      "SPEAKER_02: Okay, but you're still doing look up so that when the person so the point is that when the person says Where is it then you sort of say Let's go back and look at Other things and then decide rather than the other possibility, which is that all through discourse as they talk about different things you know like Prior to the where is it question they say, you know how much does it cost to get in you know to see a movie around here um Where's it close to theater the the point is that by mentioning admission fees that just sort of stays active now You know that becomes part of like those sort of current ongoing active conceptual structure and then Over in your base net or whatever when when the person says where is it you've already got you know since they were talking about admission And that evokes the idea of entering um then when they go and ask where is it then your enter note is already active Because that's what the person is thinking about. I mean, that's the sort of cognitive linguistic way and yeah\n",
      "SPEAKER_01: Ultimately, that's also what we want to get at I think that's that's the correct way. So of course we have to keep Memory of what was the last intention and how does it fit to this and what does it tell us in terms of the what we're examining I have further more I mean we can idealize that you know people don't change topics But they do but right even the for that there's a student of ours who's doing a dialogue act um recognition module so Maybe we're even in a position where we can take your approach which is of course much better Just to say how much harder is this program?\n",
      "SPEAKER_01: Mm-hmm and much harder to program. Yeah, all these pieces fit together and And but okay, nevertheless, so these are issues, but what we actually decided last week is to this your benefit is to pretend we have observed and parsed an utterance such as where is the powder tower or where is the zoo and specify what what we think the the output uh observe out input notes for our baseness for the sub sub D for the discourse bit should be so that and I will I will then come up with the ontology side uh bits and pieces so that we can say okay we we always just look at this utterance that's the only utterance we can do it's hard coded like three needs sort of hand parsed handcrafted but this is what we hope to be able to observe in general from utterances and from ontologies and then we can sort of fiddle with these things to see what it actually produces in terms of output so we need to find out what the various x construction will give us in terms of semantics and sem spec type things okay just where's x or any variance of that no um look at it this way yeah what did we decide we decided sort of the the prototypical where is x where you know we don't really know does he want to go there or just want to know where it is so the difference of where is the railway station versus where where where is green net\n",
      "SPEAKER_03: as i was just dancing sir we're not videotypical you're this so\n",
      "SPEAKER_02: so um we're supposed to the i mean we're talking about sort of anything that has the semantics of request for location right actually or i mean anyway the node in the uh the ultimate uh in the base net thing when you're done the the node that we're talking about um is one that says request for location true or something like that right um and and exactly how that gets activated you know like whether we want the sentence how do i get there to activate that node or not you know that's that's sort of the\n",
      "SPEAKER_01: issue that sort of the linguistics side has to deal with right well actually more the other way around we wanted something that represents uncertainty what in terms of going there or just wanting to know where it is for example some to direct information and so this is prototypically founded the where is something question surface structure what which can be you know should be maps to something that activates both i mean the idea is to i don't know right okay let's have it fit nicely with the paper i don't see and how we would be\n",
      "SPEAKER_03: able to distinguish between the two intentions just from the utterance the i mean before before\n",
      "SPEAKER_01: we don't before we cranked it through the base net and we we wouldn't that's exactly what we want\n",
      "SPEAKER_03: we wouldn't no we wouldn't okay but then so basically it's just a very construction we have a node in the net right and we turn on yeah that node what what does this exactly what is the uh well given that we know that the construction has these two things we can set up probabilities we can basically define all the tables for every further it should be so we have\n",
      "SPEAKER_01: um let's assume we we call something like a lock x node and a path x node and what we actually get if we just look at the discourse where is x should activate or should should be both whereas maybe where is x located we find from the data is always just ask for the person once and no where it is and how do i get to is always asked when the person just wants to know how to get there right so we want to sort of come up with what gets input and how in case of a various question so what what what what the outcome of of your parser look like and what other discourse information from the discourse history could we hope to get squeeze out of that at once so define the the input into the base that based on what the utterance where is x gives us so definitely have an entity node here which is activated via the autology so where is x produces something that stands for x whether it's castle bank restroom toilet whatever and then the autology will tell us\n",
      "SPEAKER_00: that it has a location or the logical cells where actually it is located no not at all where it\n",
      "SPEAKER_01: is located we have a user proximity node here somewhere which tells us how far the user how far away the user is respect to that entity so you're talking about for instance the construction\n",
      "SPEAKER_00: obviously involves this entity or refers to this entity and from the construction also you know that it is a location is or a thing thing that can be located right autology says this thing has a location slot sure in that so thing that is being that is the content of the question that's being queried by one interpretation of where is x and another one is path from current user current location to that location so so is the question I'm not sure what the is the question for this particular construction how we specify that that's the information it provides or or castle work both sides right yeah you don't need to you do that it's just sort of what\n",
      "SPEAKER_01: what would be observed in that case observed when you heard the speaker say where is x or when\n",
      "SPEAKER_00: that's been parsed so these little circles you have by the d is that that's exactly what we're looking\n",
      "SPEAKER_03: for I just I don't like having characterizing the constructions with location and path or characterizing them like that because you don't it seems like in the general case you wouldn't know you wouldn't had to characterize them I mean or for when there could be an interpretation that we don't have a node for in the I mean it seems like make no more sense to have a node for the construction and then let the chips fall where they may versus uh saying this construction either can mean location or path and in this case since it can mean either those things relate both of those\n",
      "SPEAKER_02: up same thoughts questions I'm thinking about it it would be the same so I think\n",
      "SPEAKER_01: in here we have our goal there right and we have our info on so in my my case this would sort of make this happy and this would make the goal there happy what you're saying is we have a worries question worries node that makes both happy right that's what you're proposing but just my mind just as fine so if we have a construction node worries x it's gonna both get the posterior probability that it's informed up informed is true up and that goal there is true up as well which would be exactly analogous to what I'm proposing is this makes makes something here true and this makes something also something here true and this makes this true up and this makes this\n",
      "SPEAKER_02: true up as well I kind of like it better without an extra level of indirection to you know with this points to this point to that and so on because yeah because we get we get tons of\n",
      "SPEAKER_01: constructions I think because you know people have many ways of asking yeah sure I changed my mind\n",
      "SPEAKER_00: actually so I agree with that I have a different kind of question might be related which is okay so implicitly everything in you were always referring to the speaker intent right like what they want you know the information that they want for it's always information that they want probably some kind right all right this doesn't massage you or no okay so let's see so I don't know if the I mean if just there's more here that's not shown that you it's already like part of the system whatever but whereas X like the fact that it is you know speech act whatever it is a question it's a question that queries on some particular thing X and X is that location there's like a lot of structure in representing that yeah so that seems different from just having the no location X yeah it goes into it right pretty fast being this that's so that's that what you're\n",
      "SPEAKER_01: exactly we have some we have specified to okay the next one would be here just for mood the next one would be what we can squeeze out of the I don't know maybe we want to observe the the length of the words used and or the prosody and make conclusions about the user's intelligence\n",
      "SPEAKER_00: I don't know so in some ways in the other sort of parallel set of more linguistic meetings we've been talking about possible semantics of some construction right where it was the simulation that's according to you know that that corresponds to it and as well that it's discourse whatever contact discourse information such as the boot and you know other stuff so are we looking for a sort of abbreviation of that that's tailored to this problem because that that has you know basically you know it's in progress does in development still but definitely has various\n",
      "SPEAKER_01: features slots attributes bindings between things that's exactly why I'm proposing it's too early to have to think of them of all of these discourse things that one could possibly observe so let's just assume for the subset of human beings I'm not allowed to ask anything but where is X okay this is the only utterance in the world what could we observe from that okay that exactly where's X not\n",
      "SPEAKER_00: the the choices of where is X or how do I get to just where is X just where is X okay and but\n",
      "SPEAKER_01: you know do it do it in such a way that we know that people can also say is the town hall in front of the bank so that we need something like a WH focus should be should be there that you know this\n",
      "SPEAKER_00: whatever we do or do not take other kinds of constructions into account well if you if you can\n",
      "SPEAKER_01: okay that's not do where possible right if if if it's not at all triggered by our thing then it's irrelevant and it doesn't hurt to leave it out for the moment but okay it seems like for instance\n",
      "SPEAKER_00: where's X the fact that it might mean tell me how to get to X like so would you want to say that those two are both like those are the two interpretations right the the ones that are location or path so you could say that this construction is a question asking about this location and then you can additionally infer if they're asking about the locations because they want to go to that place in which case the you're jumping a skeptic step and saying oh I know where it is but I also know how to get they wanted seem they seem to want to get their song and I tell them so there's like structure\n",
      "SPEAKER_02: right this it's not it's not that this is sort of like semantically ambiguous between these two it's really about this but why would you care about this well it's because you also want to know this\n",
      "SPEAKER_00: or something so it's like you infer the speaker attend and then for a plan a larger plan from that for which you have the additional information you're just being extra helpful\n",
      "SPEAKER_01: think with this is just a mental exercise if you think about focusing on this question how would you design that is it do you feel confident about saying this is part of the language already to to detect those plans and why would anyone care about the location if not you know and so forth or do you actually I mean this is perfectly legitimate and I would not have any problems with erasing this and say that's all we can activate based on the utterance out of context right and then the the miracle that we get out the attention go there happens based on what we know about that entity about the user about this really believes goes to the address blah blah absolutely fine but this is sort of thing I propose that we think about so that we actually end up with um um notes for the discourse and ontology so that we can put them into our base net never change them so we all there is as well as x and if I can play around with the observed things and we can run our better travel base and have it produce some output and for the first time in in in the world we look at our output and um let's see whether it's any good you know I mean\n",
      "SPEAKER_02: here's hoping right across your fingers yeah I mean for me this is just a bit better of curiosity\n",
      "SPEAKER_01: I wouldn't I would like to look at what this at-hark process of designing a belief net actually produce if if we ask it where is something and maybe it also enables you to think about certain things more specifically um come up with interesting questions to which you can find interesting answers and additionally you might fit in really nicely with the paper because if we run an example for the paper I suggest there it is yeah so this might be a nice opening paragraph for the paper is saying you know people look at kinds of ambiguities and um in the literature verse bank and whatever kinds of garden path phenomenon and we can say well that's all nonsense hey these things are never really ambiguous in discourse be don't ever occur really in discourse but normal statements that seem completely unabiguous such as where is the blah blah actually art terribly complex and completely ambiguous and so whatever everybody has has been doing so far and you know has been completely nonsensical and can all go into the waste paper but it's always a good way to begin yeah\n",
      "SPEAKER_03: and the only I am great all other useless nice overture but you know just not really\n",
      "SPEAKER_01: okay I mean exactly but that might be you know saying hey you know some stuff is is actually complex if you look at it in in in the vacuum and and ceases to be complex in reality and some stuff that's that's absolutely straightforward in the vacuum is actually terribly complex in reality would be nice sort of also a nice um bottom up linguistics um type message versus the old top down scroll I'm running out of time okay when do you need to start wizarding at 410 okay this is the other bit of news the subjects today no face or she can't be here and do the wizarding so I'm gonna do wizarding until it's gonna do the instructing also we're getting a person who just got fired from her job person from Oakland who is interested in maybe continuing the wizard bit once they leaves in August and um she's gonna look at it today which is good news in the sense that if we want to continue after the third after July we can we could and um and that's also maybe interesting four keys and whoever if you want to get some more stuff into the data collection I mean there's we can completely change the setup anytime we want okay look at the results we've gotten so far for the first whatever 50 some subjects 50 had 50 so far no we're approaching 20 now but until phase yeah leaving we surely will hit some higher numbers and so that's cool do more fun stuff yeah I'll\n",
      "SPEAKER_02: have to look more into that data is that around like because that's pretty much getting posted or\n",
      "SPEAKER_01: something right away when you get it or it has to be transcribed we have found someone here who's hand transcribed the first 12 okay first thousand subjects just so we can build a language model for the regularizer okay but um so those should be available soon okay the first 12\n",
      "SPEAKER_02: and I can I mean you know that I that I looked at the first the first one and got enough data to keep me going for you know the first July so yeah but you can listen to all of them from your\n",
      "SPEAKER_01: Solaris box if you want it's always fun\n",
      "'\n",
      "\n",
      "'>>> Text: SPEAKER_02: On graves I'm not singing it yet.\n",
      "None: Okay.\n",
      "None: Hi, team.\n",
      "SPEAKER_02: Hope you had a good lunch.\n",
      "SPEAKER_02: Okay, we're back for the conceptual design meeting.\n",
      "SPEAKER_02: Let's get started.\n",
      "SPEAKER_02: Okay, here's the agenda for today's meeting.\n",
      "SPEAKER_02: We're going to open it, and I'm going to keep the minutes as project manager.\n",
      "SPEAKER_02: We're going to have three presentations, one from each of you again.\n",
      "SPEAKER_02: Then we are going to come to decision on their mode control concepts, and then we're going to close it up.\n",
      "SPEAKER_02: We have 40 minutes again.\n",
      "SPEAKER_02: Okay, and just to reiterate, after this meeting, the team will reach a decision on the concepts of their mode control.\n",
      "SPEAKER_02: Okay, let's go ahead and start off with your presentations.\n",
      "SPEAKER_02: Who would like to go first?\n",
      "SPEAKER_01: Just trying to move mine right now.\n",
      "SPEAKER_02: Courtney, would you mind starting us off?\n",
      "None: Yeah.\n",
      "SPEAKER_02: Are you trying to do the training?\n",
      "SPEAKER_03: Yeah.\n",
      "SPEAKER_03: Okay, so, trend watching.\n",
      "SPEAKER_03: Since we do put the fashion electronics, it is kind of important how our product looks.\n",
      "SPEAKER_03: So, I guess we can go ahead and go to the next.\n",
      "SPEAKER_03: So, what they want right now, customers want fancy versus functional.\n",
      "SPEAKER_03: Basically, about 58% of what they like of the product that they want, describe me like the, in order of how much they want, 58% of the decision of what it should look like, fancy versus functional.\n",
      "SPEAKER_03: And then it has to also be technologically innovative and yet easy to use.\n",
      "SPEAKER_03: So, the customer basically is confused.\n",
      "SPEAKER_03: They don't know exactly what they want.\n",
      "SPEAKER_03: They want us to tell them.\n",
      "SPEAKER_01: They want everything.\n",
      "SPEAKER_03: Yes, exactly.\n",
      "SPEAKER_03: So, we can go next.\n",
      "SPEAKER_03: Okay, so, in Milan and Paris recently, the trends have been showing that clothing, shoes and furniture are basically just covered with fruits and vegetable patterns.\n",
      "SPEAKER_03: So, I don't know if we want to go in that.\n",
      "SPEAKER_03: And also, the spongy feels in contrast to last year.\n",
      "SPEAKER_03: I don't know, really.\n",
      "SPEAKER_03: I mean, I guess the spongy could relate to the buttons if we want to, rather than like a hard clicky button that you find on like some mobiles and stuff.\n",
      "SPEAKER_03: You'd want like a softer touch.\n",
      "SPEAKER_03: I mean, do you guys know what I mean?\n",
      "SPEAKER_03: Right, yeah.\n",
      "SPEAKER_03: But as for the fruits and vegetable patterns, I don't know if we really want to go with that, because it is just a trend.\n",
      "SPEAKER_03: And our product, we want to stay around for much longer than just a few months.\n",
      "SPEAKER_03: Right, because people don't buy a new remember every month.\n",
      "SPEAKER_03: Yeah, I mean, that could just be a spring thing right now.\n",
      "SPEAKER_01: I can address some of that issue, I think, with my presentation.\n",
      "SPEAKER_03: Okay, awesome.\n",
      "SPEAKER_03: So, design preferences, we need easy to read, like large buttons, clearly labeled.\n",
      "SPEAKER_03: So, I mean, because we talked about that being a problem.\n",
      "SPEAKER_03: And then also buttons illuminating upon touch.\n",
      "SPEAKER_03: You said that in your design with the bulb.\n",
      "SPEAKER_03: And that could also tie in with the color scheme.\n",
      "SPEAKER_03: We need the real reaction logo, the color scheme, obviously.\n",
      "SPEAKER_03: That's one of our key goals, we want to promote our product.\n",
      "SPEAKER_03: And I was thinking about different types of designs, and I came up with something actually right here.\n",
      "SPEAKER_03: So, what we could do is something like an old fashioned telephone, like this, where we put the buttons around, like we put a big on-off button or something else in the middle.\n",
      "SPEAKER_03: I mean, it could be the arrows or whatever for channel up and down, and then put the numbers around in like an old fashioned dial shape.\n",
      "SPEAKER_03: Because then it'll appeal to older generation and, like you said, retro.\n",
      "SPEAKER_03: So, it's cool.\n",
      "SPEAKER_03: So, it's classically retro.\n",
      "SPEAKER_03: So, I mean, that's just an idea.\n",
      "SPEAKER_02: I like it.\n",
      "SPEAKER_02: Ready for the next slide?\n",
      "SPEAKER_03: Yep.\n",
      "SPEAKER_03: And that's it.\n",
      "SPEAKER_02: Great.\n",
      "SPEAKER_02: Great presentation.\n",
      "SPEAKER_02: Ready?\n",
      "SPEAKER_02: Hang on.\n",
      "SPEAKER_00: Let's see if it's there.\n",
      "SPEAKER_00: Which one is it?\n",
      "SPEAKER_00: I don't know.\n",
      "SPEAKER_00: Interface concept?\n",
      "None: No?\n",
      "SPEAKER_02: Interface concept.\n",
      "SPEAKER_00: Either refresh it or, oh wait, maybe I didn't put it in there.\n",
      "SPEAKER_00: Hang on.\n",
      "SPEAKER_01: I don't know if mine will always read copy of something, brother.\n",
      "SPEAKER_01: Sorry?\n",
      "SPEAKER_01: I copied mine before I sent it over.\n",
      "SPEAKER_00: Oh, okay.\n",
      "SPEAKER_00: Sorry.\n",
      "SPEAKER_00: Hang on.\n",
      "SPEAKER_00: Don't know where to go.\n",
      "None: There we go.\n",
      "None: Okay.\n",
      "None: Okay.\n",
      "None: Okay.\n",
      "None: Okay.\n",
      "None: Okay.\n",
      "None: Okay.\n",
      "None: Okay.\n",
      "None: Okay.\n",
      "None: Okay.\n",
      "None: Okay.\n",
      "None: Okay.\n",
      "None: Okay.\n",
      "None: Okay.\n",
      "SPEAKER_02: Okay.\n",
      "SPEAKER_02: Okay.\n",
      "None: Okay.\n",
      "SPEAKER_00: Okay.\n",
      "SPEAKER_00: Okay.\n",
      "SPEAKER_00: Looking at the interface concept is going to be mostly examples of possibilities of where we can go with this.\n",
      "SPEAKER_00: If you want to start the next slide, sure.\n",
      "SPEAKER_00: I can't really see it, but there's two possible ways on the left.\n",
      "SPEAKER_00: If you see it on the sides of the remote, you have the sort of scroll down.\n",
      "SPEAKER_00: So you have that option right there.\n",
      "SPEAKER_00: And then also there's the idea of the base.\n",
      "SPEAKER_00: That's sort of like an idea there.\n",
      "SPEAKER_00: And then on the right, you have what's really big trend right now.\n",
      "SPEAKER_00: It's the iPod.\n",
      "SPEAKER_00: It's becoming really fast thing.\n",
      "SPEAKER_00: And so you have this sort of very, very simplistic menu section with the round buttons.\n",
      "SPEAKER_00: And it's sort of like you have the both kind of trendy and hip, but also very sleek and very simple, but technologically advanced.\n",
      "SPEAKER_00: So if you wanted to do that, and we could find a way of sort of like using that idea into remote control and sort of look into it, but anyway, next.\n",
      "SPEAKER_00: There's the idea of like being able to do it by feel as well as by sight.\n",
      "SPEAKER_00: You know, you're in the dark, you don't want to be looking at your remote control.\n",
      "SPEAKER_00: And the picture particularly is pointing out if you look at the top volume button, it's a V.\n",
      "SPEAKER_00: And so you're kind of feeling a V like volume up.\n",
      "SPEAKER_00: What it really is is a V and what you think it is is down because it's the down arrow.\n",
      "SPEAKER_00: And so it's like sort of quizzes and you'd probably turn that the other way up.\n",
      "SPEAKER_00: And you could either do it by raised type, which could be, you know, if he sort of old fashioned in a way.\n",
      "SPEAKER_00: Either that or just have it by shape, for example, you have a specific triangular shape that you know you're looking at the up and down arrow.\n",
      "SPEAKER_00: And then the round ones you sort of feel by, you know, the second one down, that sort of thing.\n",
      "SPEAKER_00: So it's sort of looking into how we wanted to do it by feel.\n",
      "SPEAKER_00: Okay.\n",
      "SPEAKER_00: So this is sort of an example of going for a certain demographic, particularly the gear towards children.\n",
      "SPEAKER_00: That's cute.\n",
      "SPEAKER_00: It's very cute.\n",
      "SPEAKER_00: We could probably change it to yellow, bright yellow for the company logo.\n",
      "SPEAKER_00: You have the shape since it's very simplistic and friendly looking.\n",
      "SPEAKER_00: And then the other thing that you'll be able to do is just to be able to program certain channels that only these children watch.\n",
      "SPEAKER_00: You know, the CBB or something like that.\n",
      "SPEAKER_00: Keep them away from other channels.\n",
      "SPEAKER_00: So that's like another error.\n",
      "SPEAKER_00: I mean, these are three examples sort of looking at it.\n",
      "SPEAKER_00: You have the wider section for the main controls there.\n",
      "SPEAKER_00: You can see how many buttons there are.\n",
      "SPEAKER_00: And then on the left you have an example of the round buttons and a simpler design.\n",
      "SPEAKER_00: On the bottom we probably wouldn't need that because it's more for like a DVD function which we're not going to be using.\n",
      "SPEAKER_00: So again, it's sort of like just giving you ideas.\n",
      "SPEAKER_00: And then down at the bottom you have the logos and that's where you can put the R-R.\n",
      "SPEAKER_00: Real reaction.\n",
      "SPEAKER_00: And then finally these are like the sort of same examples but also some more just possibilities that we can go with.\n",
      "SPEAKER_00: None of them are particularly keen on by the way.\n",
      "SPEAKER_00: But it's sort of like just taking aspects out of that and saying well out of this one we like the round section or we like the button size on this.\n",
      "SPEAKER_02: Or I like the black finish or the silver finish or something.\n",
      "SPEAKER_03: I have four of those from out.\n",
      "SPEAKER_02: Okay, ready?\n",
      "SPEAKER_02: Let's go.\n",
      "SPEAKER_02: Okay, great job.\n",
      "SPEAKER_01: Okay, my turn.\n",
      "SPEAKER_01: Okay, what's the title?\n",
      "SPEAKER_01: It'll be copy of component design.\n",
      "SPEAKER_01: Yeah, it looks like it.\n",
      "SPEAKER_01: Okay, so basic remote operation runs as follows.\n",
      "SPEAKER_01: Press button makes connection with the power source and the rest of the circuit.\n",
      "SPEAKER_01: Chip sends is the connection chip produces a Morse code infrared signal specific to that button.\n",
      "SPEAKER_01: So you press the button and it produces a signal that's encoded specifically for that button.\n",
      "SPEAKER_01: Transistors amplify that signal and it goes to the TV center which interprets the signal and responds accordingly changes channel, etc.\n",
      "SPEAKER_01: So that being said, next slide please.\n",
      "SPEAKER_01: Findings which were the required materials for the basic internal construction.\n",
      "SPEAKER_01: So all the really simplistic functions that we just discussed.\n",
      "SPEAKER_01: We need rubber for buttons, aluminum for battery contacts, integrated circuit which consists of a diode transistor resonator, resistors and a capacitor.\n",
      "SPEAKER_01: All those basic things that make a circuit function.\n",
      "SPEAKER_01: Fiberglass and thin copper wire to create the actual circuit board itself.\n",
      "SPEAKER_01: And LED which is a light emitting diode.\n",
      "SPEAKER_01: Contact disks for the buttons, plastic for the casing and a power source, whatever power source we've actually determined we want.\n",
      "SPEAKER_01: Next slide please.\n",
      "SPEAKER_01: Thank you.\n",
      "SPEAKER_01: Personal preferences.\n",
      "SPEAKER_01: To save money for the components, the remote should be mass produced and basic materials should be bought on mass.\n",
      "SPEAKER_01: If we find another company who can produce the required chips casing LED any additional materials we decide we require at a less expensive rate than we ourselves are producing, we should go for it.\n",
      "SPEAKER_01: Next slide please.\n",
      "SPEAKER_01: Just talking to the manufacturing division.\n",
      "SPEAKER_01: They suggested power options, solar cells, hand dynamo and kinetic power so you shake it and increases the power.\n",
      "SPEAKER_01: I'm not sure how the hand dynamo works, they have yet to get back to me on that.\n",
      "SPEAKER_01: Next slide please.\n",
      "SPEAKER_01: Suggested casing options.\n",
      "SPEAKER_01: Okay.\n",
      "SPEAKER_01: We can offer options for casing such as straight curve, double curved, you know, very specific to the customer.\n",
      "SPEAKER_01: Options for materials, plastic, rubber, titanium, wood.\n",
      "SPEAKER_01: I don't think anyone's going to go for a wood one because winter is.\n",
      "SPEAKER_01: Oh yeah.\n",
      "SPEAKER_01: No, it's winter's in.\n",
      "SPEAKER_01: Certain restrictions do apply here though. Latex you can't do solar power with a latex one.\n",
      "SPEAKER_01: So if they want soft squishy rubber, they can't have the solar power adoption.\n",
      "SPEAKER_01: Double curved.\n",
      "SPEAKER_01: You can't do titanium.\n",
      "SPEAKER_01: That would be two curvatures.\n",
      "SPEAKER_01: So it would actually, if the shape of your hand you curve here and you curve here.\n",
      "SPEAKER_01: So you could have two curves that match the shape of your hand to make it more comfortable to hold.\n",
      "SPEAKER_01: Now if you wanted that, you can't do titanium.\n",
      "SPEAKER_01: And so adjusted functions for the buttons, scrolling function could be very beneficial to us instead of actual buttons themselves.\n",
      "SPEAKER_01: I think I have one more slide.\n",
      "SPEAKER_01: No, I don't.\n",
      "SPEAKER_01: The manufacturing division also has said that they have several types of chips and they've just developed a sample sensor or sample speaker chip, which we could utilize.\n",
      "SPEAKER_01: Push button requires a simple chip and scroll requires more complicated chip.\n",
      "SPEAKER_01: So it depends on what we decide we want to do.\n",
      "SPEAKER_01: In addition to that, if we're offering all those different options to the customer for producing their remote, we're going to have to have multiples of each type like a double curved in rubber.\n",
      "SPEAKER_01: Each option should have a certain select number produced with all those options.\n",
      "SPEAKER_01: So we'll have to mix it up, make sure we produce enough of everyone.\n",
      "SPEAKER_01: But that could also drive up the price of the actual remote itself if they know that we only produced 5,000 double curved wooden remotes.\n",
      "SPEAKER_02: That's all I got.\n",
      "SPEAKER_02: Alright, well thank you for those informative presentations.\n",
      "SPEAKER_02: Let's go back to now we have to make some decisions.\n",
      "SPEAKER_00: Let me just add one more thing that I couldn't say for sure.\n",
      "SPEAKER_00: And that's just that new technology that I've developed on the voice rescue mission.\n",
      "SPEAKER_00: Oh, this is the thing we were talking about earlier.\n",
      "SPEAKER_00: Except it's sort of odd and not exactly sure why they're explaining it in the way they are.\n",
      "SPEAKER_00: There's a sample sensor and there's a sample speaker unit.\n",
      "SPEAKER_00: So you would say like good morning coffee maker and it would respond good morning Joe.\n",
      "SPEAKER_00: But I'm not sure exactly how it's going to work because do you program the we program the responses and the questions.\n",
      "SPEAKER_00: Does that mean that the user then has to ask the specific question and can't change it in order for it to be recognized or can it be altered in a certain way or just the actual user program it channel means this.\n",
      "SPEAKER_03: Yeah, like using the menu to be like enter your name into the screen like on the menu option so that way the so it's got like a limited memory and so you'd program it.\n",
      "SPEAKER_00: So it's sort of if you know that's kind of what you say.\n",
      "SPEAKER_03: I feel like voice recognition would be.\n",
      "SPEAKER_03: I don't know.\n",
      "SPEAKER_03: It would be too hard to really probably.\n",
      "SPEAKER_02: I mean we could do it.\n",
      "SPEAKER_02: But if it's within our price to get that kind of chip that would you know.\n",
      "SPEAKER_01: Well we are making the chip.\n",
      "SPEAKER_01: So I mean.\n",
      "SPEAKER_03: I guess we have to look at what our production cost is for the chip itself and it is a growing trend the higher technological like the I'm just like the more advanced it is.\n",
      "SPEAKER_01: Yeah better.\n",
      "SPEAKER_01: It'll sell.\n",
      "SPEAKER_01: I thought offering some of those options for different materials that it could be made of different you know.\n",
      "SPEAKER_01: I think we'd have to decide on the power options.\n",
      "SPEAKER_01: Maybe.\n",
      "SPEAKER_01: Yeah we could reduce.\n",
      "SPEAKER_02: Yeah.\n",
      "SPEAKER_02: I'll have the okay that kind of brings us to this let's let's think we can decide what kind of energy source we want to have first and foremost.\n",
      "SPEAKER_02: Do we want to go for batteries or a stand like the one that we saw illustrated earlier.\n",
      "SPEAKER_02: Oh the base yeah the base the charging base.\n",
      "SPEAKER_00: I don't know what it looks like before.\n",
      "SPEAKER_00: Is this something really really small.\n",
      "SPEAKER_00: Then it's sort of harder to imagine the base where that was quite a substantial size sort of standing up.\n",
      "SPEAKER_02: Yeah and we don't have multiple things that has to control just has to control the TV.\n",
      "SPEAKER_03: It's not going to be a huge universal about.\n",
      "SPEAKER_00: We need to decide well so we can figure out how big it's going to be like what exactly what buttons we want and exactly.\n",
      "SPEAKER_00: We want to figure this yes I won't because it still fits in your hands you still want it something that's comfortable and substantial but not necessarily full of buttons.\n",
      "SPEAKER_03: This one is really comfortable like I like the sides.\n",
      "SPEAKER_03: Whatever it'll lose it easier but if we have the the locator that we don't have to worry about that that's true.\n",
      "SPEAKER_03: So we can make it small if we have like a locating device.\n",
      "SPEAKER_01: We do a voice activated locator though we're going to be looking at a more substantial chip.\n",
      "SPEAKER_00: So that's the other thing it's like you know what are we going to have certain chips are going to require a bigger size period.\n",
      "SPEAKER_03: Two double A's for the size.\n",
      "SPEAKER_00: But like you know if we get more complicated then it's going to be bigger to just accommodate the chip size.\n",
      "SPEAKER_01: Honestly I think the customer would be kind of irritated by the fact that it has a base if we did do a nice small compact.\n",
      "SPEAKER_02: It's either going to be bigger with a base or smaller with just a battery like this guy.\n",
      "SPEAKER_02: Alright so what direction do you want to go and you want to vote?\n",
      "SPEAKER_03: I think if we had a locating device with a small one I think that seems way more advanced.\n",
      "SPEAKER_02: I'm kind of leaning in the direction of the base kind of bigger and the base.\n",
      "SPEAKER_03: That just seems clunky and yeah because I mean even looking at cell phones right now those trends the smaller the hotter it is.\n",
      "SPEAKER_01: Okay the only problem with that is you forget to take it out of your pocket and it goes in the wash.\n",
      "SPEAKER_01: Oh kidding.\n",
      "SPEAKER_01: You know what happens.\n",
      "SPEAKER_01: Yeah.\n",
      "SPEAKER_01: Three watches go that way too.\n",
      "SPEAKER_00: Oh watch.\n",
      "SPEAKER_03: Never watch the phone.\n",
      "SPEAKER_03: Oh no that would wow.\n",
      "SPEAKER_03: That would hurt.\n",
      "SPEAKER_02: Okay so what kind of material do we want to do?\n",
      "SPEAKER_01: Well we have lots of options.\n",
      "SPEAKER_01: I don't think wood is a viable option.\n",
      "SPEAKER_02: No.\n",
      "SPEAKER_02: What did you decide?\n",
      "SPEAKER_00: Go ahead.\n",
      "SPEAKER_00: I think that's high tanning if we're being restricted then.\n",
      "SPEAKER_00: I hope to lean away from that.\n",
      "SPEAKER_03: Yeah because if it's going to cause us more to produce a chip titanium would be more expensive.\n",
      "SPEAKER_03: Right.\n",
      "SPEAKER_03: However.\n",
      "SPEAKER_01: Oh would you recommend?\n",
      "SPEAKER_01: Oh we only want to sell it for 25 euro right?\n",
      "SPEAKER_01: Yeah.\n",
      "SPEAKER_01: Because I was thinking if we wanted to get the high end market that you could produce a few in titanium and make them a rarity.\n",
      "SPEAKER_03: So we could do that because all our research shows that people are definitely willing to spend more.\n",
      "SPEAKER_00: How are you restricted by this?\n",
      "SPEAKER_04: Well the original.\n",
      "SPEAKER_02: I think we should just focus on one design and one concept right now.\n",
      "SPEAKER_02: I'm not sure that we'll have the time and money to produce a whole array of remotes.\n",
      "SPEAKER_02: If this was a successful remote we might then produce a higher end version of it.\n",
      "SPEAKER_02: I think.\n",
      "SPEAKER_02: Good plan.\n",
      "SPEAKER_02: Good plan.\n",
      "SPEAKER_02: Okay so we want to go for plastic or what would you recommend for materials?\n",
      "SPEAKER_01: Honestly I'd recommend like since we're going with batteries instead of solar power.\n",
      "SPEAKER_01: I'd recommend maybe a soft latex because we could produce you know how cell phones have those overlays that you can change the color.\n",
      "SPEAKER_01: We could do one that fits in with the trends of the year.\n",
      "SPEAKER_01: So because this year is all fruit.\n",
      "SPEAKER_01: Got on the news.\n",
      "SPEAKER_01: Who knows.\n",
      "SPEAKER_01: We could do a cherry cover for this year and then if next year is stripes or solids.\n",
      "SPEAKER_01: You know.\n",
      "SPEAKER_00: Okay.\n",
      "SPEAKER_00: So you're talking about like when it leaves our sales room then it's all going to be cherry colored or is it going to be the kind of thing where people come back.\n",
      "SPEAKER_00: Or we could like take it back.\n",
      "SPEAKER_02: Cases maybe.\n",
      "SPEAKER_02: And by the extra case.\n",
      "SPEAKER_02: If they wanted.\n",
      "SPEAKER_02: I think it's good to sell a basic thing and then sell.\n",
      "SPEAKER_01: So we could do like a hard base plastic and then we could give.\n",
      "SPEAKER_01: Two latex covers.\n",
      "SPEAKER_01: Yes.\n",
      "SPEAKER_01: Okay.\n",
      "SPEAKER_01: To start.\n",
      "None: Okay.\n",
      "SPEAKER_03: Yeah because the soft latex definitely is squishy.\n",
      "SPEAKER_03: That's in.\n",
      "SPEAKER_03: Well I mean squishier than like.\n",
      "SPEAKER_03: Right.\n",
      "SPEAKER_03: Yeah.\n",
      "SPEAKER_03: Right.\n",
      "SPEAKER_02: It's just a hard plastic.\n",
      "SPEAKER_02: Okay.\n",
      "SPEAKER_02: And what kind of chip would we need for this guy.\n",
      "SPEAKER_01: How complicated are we going to go with the voice activated.\n",
      "SPEAKER_02: I don't think we should do voice.\n",
      "SPEAKER_02: I think we should just do the recognition for when it's lost.\n",
      "SPEAKER_02: You know.\n",
      "SPEAKER_02: Could we.\n",
      "SPEAKER_03: Yeah.\n",
      "SPEAKER_03: Because that what type of yeah for voice activation would it be like a certain term.\n",
      "SPEAKER_03: What would we say like.\n",
      "SPEAKER_03: Because people could just be talking and we don't want it going off all the time.\n",
      "SPEAKER_03: Right.\n",
      "SPEAKER_01: Well we could give it a specific code.\n",
      "SPEAKER_01: You know remote missing.\n",
      "SPEAKER_03: Ooh.\n",
      "SPEAKER_03: See I'm strangely trying to because I know that's.\n",
      "SPEAKER_03: It's definitely going to be big because it's.\n",
      "SPEAKER_03: I don't know.\n",
      "SPEAKER_00: It's just so high tech.\n",
      "SPEAKER_00: My little sister got for Christmas.\n",
      "SPEAKER_00: She got one of those key finders.\n",
      "SPEAKER_00: That's like a key ring.\n",
      "SPEAKER_00: And you have to whistle in a certain frequency for it to work.\n",
      "SPEAKER_00: Yes.\n",
      "SPEAKER_00: See that would not be a laugh.\n",
      "SPEAKER_00: And it would start going off and her person you couldn't turn it off.\n",
      "SPEAKER_00: Oh.\n",
      "SPEAKER_00: It's a little bit.\n",
      "SPEAKER_00: Okay.\n",
      "SPEAKER_01: So I think having a key phrase is much better.\n",
      "SPEAKER_02: Okay.\n",
      "SPEAKER_02: All right.\n",
      "SPEAKER_02: But it's not going to be voice activated in the fact that you would say channel up and it would work.\n",
      "SPEAKER_02: Right.\n",
      "SPEAKER_02: Yeah.\n",
      "SPEAKER_03: No, no, we don't know.\n",
      "SPEAKER_03: Okay.\n",
      "SPEAKER_03: But do you can your can the department make that would be like a mid class.\n",
      "SPEAKER_01: Oh, really then so we don't actually have to go for.\n",
      "SPEAKER_01: Well, if they've just about the sample sensor sample speaker.\n",
      "SPEAKER_01: It's a brand new chip.\n",
      "SPEAKER_01: Why not introduce it in this way?\n",
      "SPEAKER_02: Yeah.\n",
      "SPEAKER_02: Okay.\n",
      "SPEAKER_02: And what size batteries?\n",
      "SPEAKER_02: Double A triple A.\n",
      "SPEAKER_03: I think triple A.\n",
      "SPEAKER_03: It'll be lighter too.\n",
      "SPEAKER_00: More than a package.\n",
      "SPEAKER_00: More than a package.\n",
      "SPEAKER_00: More than a package.\n",
      "SPEAKER_01: I think well, we could do two.\n",
      "SPEAKER_01: We could do one small lithium.\n",
      "SPEAKER_01: Because you know, the lithium batteries are doing quite well in most other electronic products.\n",
      "SPEAKER_01: Right.\n",
      "SPEAKER_01: So they're more widely available now.\n",
      "SPEAKER_01: And they also have a longer battery life than most batteries.\n",
      "SPEAKER_02: They're more expensive than a two.\n",
      "SPEAKER_01: But if you only have to replace it every five years.\n",
      "SPEAKER_00: That's the good thoughts.\n",
      "SPEAKER_01: Well, how about initial you get one battery when you buy it.\n",
      "SPEAKER_01: Because I'm pretty sure we can get them.\n",
      "SPEAKER_03: We could get a cheap bottle.\n",
      "SPEAKER_02: Come back to it next meeting.\n",
      "SPEAKER_02: Yeah.\n",
      "None: All right.\n",
      "SPEAKER_02: Okay.\n",
      "SPEAKER_02: So we've covered that first category.\n",
      "SPEAKER_02: User interface concept.\n",
      "SPEAKER_02: Okay.\n",
      "SPEAKER_02: I kind of like your idea about the retro phone dial.\n",
      "SPEAKER_02: And that the central button could have maybe our logo on it.\n",
      "SPEAKER_02: It might be the four way scroll too.\n",
      "SPEAKER_02: Yeah.\n",
      "SPEAKER_02: It could be whatever.\n",
      "SPEAKER_03: As long as there's something big in the middle because like the old phones.\n",
      "SPEAKER_03: Yeah.\n",
      "SPEAKER_03: There's like that just like piece of metal or like a picture or something.\n",
      "SPEAKER_00: I think that is if it got too big though.\n",
      "SPEAKER_00: So if you have the circle and the button in the middle then is it going to get wider than your hands are?\n",
      "SPEAKER_00: Because and then would the button be too small if it was enough to fit on it?\n",
      "SPEAKER_00: Complete.\n",
      "SPEAKER_01: In the sample ones that you showed us there was one that had the scroll buttons on the side.\n",
      "SPEAKER_01: Yeah.\n",
      "SPEAKER_01: Which I think if we make it curved like a and like a hand shape.\n",
      "SPEAKER_01: Like if we put the the scroll button on the side.\n",
      "SPEAKER_01: Oh, I see.\n",
      "SPEAKER_01: That could be particularly useful.\n",
      "SPEAKER_03: I think so.\n",
      "SPEAKER_03: So scroll buttons on the side.\n",
      "SPEAKER_03: Yeah.\n",
      "SPEAKER_03: But it's on the top.\n",
      "None: Okay.\n",
      "SPEAKER_03: But we definitely if we have scroll thing on the side we definitely have to have them labeled.\n",
      "SPEAKER_03: Yeah.\n",
      "SPEAKER_03: Like on the side of it.\n",
      "SPEAKER_03: It's just up and down.\n",
      "SPEAKER_03: If it's just up and down.\n",
      "SPEAKER_00: Is that for volume or channel?\n",
      "SPEAKER_01: Which I don't know.\n",
      "SPEAKER_01: Well, you could do.\n",
      "SPEAKER_01: We have both sides.\n",
      "SPEAKER_02: Can we?\n",
      "SPEAKER_01: Yeah.\n",
      "SPEAKER_01: We should probably make it that you have to depress it to activate it then.\n",
      "SPEAKER_01: Yeah.\n",
      "SPEAKER_01: Because otherwise you're not just holding it and going like this.\n",
      "SPEAKER_00: You know.\n",
      "SPEAKER_00: Instead of a scroll you just have a button up on the side.\n",
      "SPEAKER_00: Which are on the side.\n",
      "SPEAKER_00: Okay.\n",
      "SPEAKER_04: Yeah.\n",
      "SPEAKER_04: Okay.\n",
      "SPEAKER_02: Any other ideas?\n",
      "SPEAKER_02: What color?\n",
      "SPEAKER_02: Oh, yeah.\n",
      "SPEAKER_02: Latex covers.\n",
      "SPEAKER_01: We have to make sure that the logo always sticks out when we put the latex covers on.\n",
      "SPEAKER_01: So we'll have to like have a little square or something.\n",
      "SPEAKER_01: So that the logo is available.\n",
      "SPEAKER_00: So having a yellow strip at the bottom with the R.R. like that.\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_02: So the bottom of it.\n",
      "SPEAKER_02: I think maybe we should do it on a button itself though because people are able to change the covers.\n",
      "SPEAKER_02: I don't know.\n",
      "SPEAKER_02: Maybe the on-off button something.\n",
      "SPEAKER_02: Some, the menu button.\n",
      "SPEAKER_02: I don't know.\n",
      "SPEAKER_02: But you know if we're going to put our company logo on there and somebody could just get another one.\n",
      "SPEAKER_02: Are they all going to have our company logo on them?\n",
      "SPEAKER_02: Every cover?\n",
      "SPEAKER_01: Yeah.\n",
      "SPEAKER_01: I don't think we should do that because that would just be icky.\n",
      "SPEAKER_01: Yeah.\n",
      "SPEAKER_01: So I think maybe putting it on a button is probably a good idea.\n",
      "SPEAKER_02: If we want it to be visible.\n",
      "SPEAKER_02: Are all of those, those ones that you showed where they were silver metallic looking?\n",
      "SPEAKER_02: Yeah.\n",
      "SPEAKER_02: But those are plastic, right?\n",
      "SPEAKER_02: They're not titanium.\n",
      "SPEAKER_02: I kind of like that look.\n",
      "SPEAKER_02: But or if it was really fun?\n",
      "SPEAKER_02: Yeah.\n",
      "SPEAKER_02: Or if we're going for the retro look, I think like a really shiny black would be cool.\n",
      "SPEAKER_02: Yeah.\n",
      "SPEAKER_02: Or a good gunmetal gray.\n",
      "SPEAKER_02: Because that would be great.\n",
      "SPEAKER_03: That would be great.\n",
      "SPEAKER_03: Cibund, silver and black.\n",
      "SPEAKER_02: Here you go.\n",
      "SPEAKER_02: Good metal gray.\n",
      "None: I'm just really wary of putting anything on a button.\n",
      "None: Why?\n",
      "None: It'll wear off.\n",
      "None: Yeah, buttons.\n",
      "SPEAKER_00: Well, then what's the button do?\n",
      "SPEAKER_00: And then you're like, oh, I'm just going to put it on a button.\n",
      "SPEAKER_00: Why?\n",
      "SPEAKER_00: It'll wear off.\n",
      "SPEAKER_00: Yeah, buttons.\n",
      "SPEAKER_00: Well, then what's the button do?\n",
      "SPEAKER_00: And how do you know what that button does?\n",
      "SPEAKER_00: Yes.\n",
      "SPEAKER_00: Just looking at your examples, you just don't ever see the logo on a button.\n",
      "SPEAKER_00: It's always on the actual casing.\n",
      "SPEAKER_04: Right.\n",
      "SPEAKER_01: There's nothing saying that we have to put the logo on the front.\n",
      "SPEAKER_01: We want to be seen.\n",
      "SPEAKER_01: It's visible.\n",
      "SPEAKER_03: It's visible.\n",
      "SPEAKER_02: It's visible, though, because if it was only on the back, really, the only time you're going to see it is when you drop it or when you're changing the battery.\n",
      "SPEAKER_00: The other option is, I don't know if you can see it, but it's like, if I can find it again.\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_00: It's like the second to last slide.\n",
      "SPEAKER_02: Okay.\n",
      "SPEAKER_02: And yours was called interface.\n",
      "SPEAKER_02: Yeah.\n",
      "SPEAKER_02: This one?\n",
      "SPEAKER_02: Yeah.\n",
      "SPEAKER_02: For some reason, I can't get it to just go to that slide directly.\n",
      "SPEAKER_00: Okay.\n",
      "SPEAKER_00: It's the very right one.\n",
      "SPEAKER_00: You see at the bottom, it's kind of difficult to see, but you have like a sort of division between the bottom, like where the logo is.\n",
      "SPEAKER_00: And if we have the replaceable section, it's like the top.\n",
      "SPEAKER_00: It doesn't necessarily replace the entire top.\n",
      "SPEAKER_00: So you have that one piece that stays in the rest, sort of clips in.\n",
      "SPEAKER_00: Okay.\n",
      "SPEAKER_00: Yes.\n",
      "SPEAKER_00: You envisioning it.\n",
      "SPEAKER_00: And so that stays to stay when you have the logo.\n",
      "SPEAKER_00: And then you have the slipback client clips in, and that's a bit of changes.\n",
      "SPEAKER_01: We're using a latex overlay.\n",
      "SPEAKER_01: So that actually would go over top of everything and have holes for the buttons.\n",
      "SPEAKER_01: So I was thinking maybe instead of doing that, what we could do is leave a space for where the logo should be.\n",
      "SPEAKER_02: Yeah.\n",
      "SPEAKER_02: Like a little cutout kind of.\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_00: Okay.\n",
      "SPEAKER_00: You know, for like a cell phone, it's like the screen.\n",
      "SPEAKER_00: Right.\n",
      "SPEAKER_00: It's always just left open.\n",
      "SPEAKER_00: And so what are we going to do it like right yellow?\n",
      "SPEAKER_00: Yeah.\n",
      "SPEAKER_03: Anybody see anything that they liked in the buttons that are blue based?\n",
      "SPEAKER_03: Well, a lot of those buttons are blue based.\n",
      "SPEAKER_03: Well, kind of.\n",
      "SPEAKER_03: And then if we do have them illuminate upon contact, they can illuminate yellow.\n",
      "SPEAKER_03: Yellow.\n",
      "SPEAKER_03: I like that idea.\n",
      "SPEAKER_03: Like the one all the way on the left, you can see it on your computer better.\n",
      "SPEAKER_03: Where the button is actually blue, but the number itself is clear or white or whatever.\n",
      "SPEAKER_03: So if you pressed it, it would illuminate yellow.\n",
      "SPEAKER_03: So we'd have blue and yellow for the touch.\n",
      "SPEAKER_03: Oh, that one.\n",
      "SPEAKER_02: I like the yellow illumination idea.\n",
      "SPEAKER_02: Very good.\n",
      "SPEAKER_02: Okay.\n",
      "SPEAKER_02: Any other ideas or thoughts?\n",
      "SPEAKER_02: Yeah.\n",
      "SPEAKER_02: I asked him to be fairly in agreement about what we want to do with his project.\n",
      "SPEAKER_02: So let me catch up.\n",
      "None: Okay.\n",
      "SPEAKER_00: Do we finalize what buttons we're including?\n",
      "SPEAKER_00: It's just everything that we've said before.\n",
      "SPEAKER_02: I think there will be time for that later.\n",
      "SPEAKER_02: I'm guessing.\n",
      "SPEAKER_02: Okay.\n",
      "SPEAKER_02: Next meeting is going to start in 30 minutes.\n",
      "SPEAKER_02: And here's what we're each of us going to do.\n",
      "SPEAKER_02: The ID is going to do the look and feel design, the UID, the user interface design.\n",
      "SPEAKER_02: I think you're going to get a lot of, I mean, the final say on what buttons get put.\n",
      "SPEAKER_02: We'll all talk about it, but I think that's pretty much what you're going to do, right?\n",
      "SPEAKER_02: Yeah.\n",
      "SPEAKER_02: Okay.\n",
      "SPEAKER_02: And you're going to do some product evaluation.\n",
      "SPEAKER_02: Okay. And right now, the ID and UID, you two are going to work together on a prototype using modeling clay.\n",
      "SPEAKER_01: Great.\n",
      "SPEAKER_01: Later.\n",
      "SPEAKER_02: Yep.\n",
      "SPEAKER_02: Okay.\n",
      "SPEAKER_02: And you should all be getting an email pretty soon.\n",
      "SPEAKER_02: All right.\n",
      "SPEAKER_02: Thank you for a very productive meeting.\n",
      "SPEAKER_02: Bye.\n",
      "'\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"O7nZQqWAngGr9NzE2ELZc1",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"markdown",
   "source":[
    "## Training Scripts"
   ],
   "attachments":{
    
   },
   "metadata":{
    "datalore":{
     "node_id":"t1gxUsHW6TJkbuR0pmaL0K",
     "type":"MD",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from datasets import concatenate_datasets\n",
    "from transformers import AutoTokenizer,AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorWithPadding\n",
    "checkpoint = \"philschmid\/bart-large-cnn-samsum\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ],
   "execution_count":5,
   "outputs":[
    {
     "data":{
      "application\/vnd.jupyter.widget-view+json":{
       "version_major":2,
       "version_minor":0,
       "model_id":"72a17111e618405e81727f632a0c84c8"
      }
     },
     "metadata":{
      "application\/vnd.jupyter.widget-view+json":{
       "datalore":{
        "widget_id":"0tEHTv9LS3vZJ5c406hr1E"
       }
      }
     },
     "output_type":"display_data"
    },
    {
     "data":{
      "application\/vnd.jupyter.widget-view+json":{
       "version_major":2,
       "version_minor":0,
       "model_id":"90295067b0a34bd48ddcf6a23350a10c"
      }
     },
     "metadata":{
      "application\/vnd.jupyter.widget-view+json":{
       "datalore":{
        "widget_id":"XwblyaL6AfayOfOiCqzwv8"
       }
      }
     },
     "output_type":"display_data"
    },
    {
     "data":{
      "application\/vnd.jupyter.widget-view+json":{
       "version_major":2,
       "version_minor":0,
       "model_id":"414c97b15a974a369893d1204f7f759b"
      }
     },
     "metadata":{
      "application\/vnd.jupyter.widget-view+json":{
       "datalore":{
        "widget_id":"JUPTQMo3zAfIw4kQFb4KBl"
       }
      }
     },
     "output_type":"display_data"
    },
    {
     "data":{
      "application\/vnd.jupyter.widget-view+json":{
       "version_major":2,
       "version_minor":0,
       "model_id":"d5d77517355744ae85a10e880f006a2d"
      }
     },
     "metadata":{
      "application\/vnd.jupyter.widget-view+json":{
       "datalore":{
        "widget_id":"eYMH8RGgTKz98MFl79IWr4"
       }
      }
     },
     "output_type":"display_data"
    },
    {
     "data":{
      "application\/vnd.jupyter.widget-view+json":{
       "version_major":2,
       "version_minor":0,
       "model_id":"ed3c1432d94a454e8457084354232476"
      }
     },
     "metadata":{
      "application\/vnd.jupyter.widget-view+json":{
       "datalore":{
        "widget_id":"psorl0V8ZaxZgYXB4BdJYA"
       }
      }
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"K3IWk5ft2JqKs5xw76Jj0z",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "\n",
    "# The maximum total input sequence length after tokenization.\n",
    "# Sequences longer than this will be truncated, sequences shorter will be padded.\n",
    "tokenized_inputs = concatenate_datasets([my_data_train_test[\"train\"], my_data_train_test[\"test\"]]).map(lambda x: tokenizer(x[\"dialogue\"], truncation=True), batched=True, remove_columns=[\"dialogue\", \"summary\"])\n",
    "max_source_length = max([len(x) for x in tokenized_inputs[\"input_ids\"]])\n",
    "print(f\"Max source length: {max_source_length}\")\n",
    "\n",
    "# The maximum total sequence length for target text after tokenization.\n",
    "# Sequences longer than this will be truncated, sequences shorter will be padded.\"\n",
    "tokenized_targets = concatenate_datasets([my_data_train_test[\"train\"], my_data_train_test[\"test\"]]).map(lambda x: tokenizer(x[\"summary\"], truncation=True), batched=True, remove_columns=[\"dialogue\", \"summary\"])\n",
    "max_target_length = max([len(x) for x in tokenized_targets[\"input_ids\"]])\n",
    "print(f\"Max target length: {max_target_length}\")\n",
    "\n"
   ],
   "execution_count":6,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Max source length: 1024\n",
      "Max target length: 201\n"
     ],
     "output_type":"stream"
    },
    {
     "data":{
      "application\/vnd.jupyter.widget-view+json":{
       "version_major":2,
       "version_minor":0,
       "model_id":"ae9bc3ce26b84a9388d930b7c3bcb630"
      }
     },
     "metadata":{
      "application\/vnd.jupyter.widget-view+json":{
       "datalore":{
        "widget_id":"8BSUwrrN3JtBjjXyZ4nd8c"
       }
      }
     },
     "output_type":"display_data"
    },
    {
     "data":{
      "application\/vnd.jupyter.widget-view+json":{
       "version_major":2,
       "version_minor":0,
       "model_id":"ccb44d126a85459cad5b39dc5f7fb0de"
      }
     },
     "metadata":{
      "application\/vnd.jupyter.widget-view+json":{
       "datalore":{
        "widget_id":"ZfGCdaB0aOKd8QtG0BjsLW"
       }
      }
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"6xp2fLukqGM2271apX5ZoY",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Use a pre-trained tokenizer to tokenize the dataset because model needs tensor input.\n",
    "\n",
    "def preprocess_function(data, padding=\"max_length\"):\n",
    "    model_inputs = tokenizer(data[\"dialogue\"], max_length=max_source_length, padding=padding, truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=data[\"summary\"], max_length=max_target_length, padding=padding, truncation=True)\n",
    "    \n",
    "    if padding == \"max_length\":\n",
    "        labels[\"input_ids\"] = [\n",
    "            [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "        ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n"
   ],
   "execution_count":7,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"un65HFw4GMzKF1QxKDl4kv",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "tokenized_dataset = my_data_train_test.map(preprocess_function, batched=True, remove_columns=[\"dialogue\", \"summary\", \"meeting_id\"])\n",
    "print(f\"Keys of tokenized dataset: {list(tokenized_dataset['train'].features)}\")"
   ],
   "execution_count":8,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Keys of tokenized dataset: ['input_ids', 'attention_mask', 'labels']\n"
     ],
     "output_type":"stream"
    },
    {
     "data":{
      "application\/vnd.jupyter.widget-view+json":{
       "version_major":2,
       "version_minor":0,
       "model_id":"dcb48036018843089f159f76fa06d605"
      }
     },
     "metadata":{
      "application\/vnd.jupyter.widget-view+json":{
       "datalore":{
        "widget_id":"fxrlPfTcTanee54ZVHv5aP"
       }
      }
     },
     "output_type":"display_data"
    },
    {
     "data":{
      "application\/vnd.jupyter.widget-view+json":{
       "version_major":2,
       "version_minor":0,
       "model_id":"a00b29e5ed934be886389d305c2486b6"
      }
     },
     "metadata":{
      "application\/vnd.jupyter.widget-view+json":{
       "datalore":{
        "widget_id":"H5GApz8F9qCRartSUbXVFa"
       }
      }
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"Ocn0kCRY5BsUMFSCMY0esQ",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import evaluate\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# Metric\n",
    "metric = evaluate.load(\"rouge\")\n",
    "\n",
    "# Helper function to postprocess text\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    preds = [\"\\n\".join(sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    result = {k: round(v * 100, 4) for k, v in result.items()}\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    return result"
   ],
   "execution_count":9,
   "outputs":[
    {
     "name":"stderr",
     "text":[
      "[nltk_data] Downloading package punkt to \/home\/datalore\/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\/punkt.zip.\n"
     ],
     "output_type":"stream"
    },
    {
     "data":{
      "application\/vnd.jupyter.widget-view+json":{
       "version_major":2,
       "version_minor":0,
       "model_id":"66f44cfd557f46c2a15f6e12449ef578"
      }
     },
     "metadata":{
      "application\/vnd.jupyter.widget-view+json":{
       "datalore":{
        "widget_id":"2BXH3dZUpDjjWPkxZA2p5x"
       }
      }
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"Fo0fmf6ziZQlcZqZL7L7a5",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from transformers import AutoConfig\n",
    "config = AutoConfig.from_pretrained(checkpoint)\n",
    "config.max_length = 400\n",
    "config.min_length = 10\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint, config = config)\n",
    "\n",
    "\n"
   ],
   "execution_count":10,
   "outputs":[
    {
     "data":{
      "application\/vnd.jupyter.widget-view+json":{
       "version_major":2,
       "version_minor":0,
       "model_id":"d79b487980fe4d14ae0dd5b7f5c00505"
      }
     },
     "metadata":{
      "application\/vnd.jupyter.widget-view+json":{
       "datalore":{
        "widget_id":"tAkJv74P9hmbyZmuaVOaeV"
       }
      }
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"EiQ0cIqPfhzdwpVNlDMVlO",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Verify max_length and min_length has been changed\n",
    "model.generation_config"
   ],
   "execution_count":12,
   "outputs":[
    {
     "data":{
      "text\/plain":[
       "GenerationConfig {\n",
       "  \"_from_model_config\": true,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"decoder_start_token_id\": 2,\n",
       "  \"early_stopping\": true,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"forced_bos_token_id\": 0,\n",
       "  \"forced_eos_token_id\": 2,\n",
       "  \"length_penalty\": 2.0,\n",
       "  \"max_length\": 400,\n",
       "  \"min_length\": 10,\n",
       "  \"no_repeat_ngram_size\": 3,\n",
       "  \"num_beams\": 4,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"transformers_version\": \"4.26.1\"\n",
       "}"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"WyUidZeFbVMO4pZK25Txhw",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "# we want to ignore tokenizer pad token in the loss\n",
    "label_pad_token_id = -100\n",
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=label_pad_token_id,\n",
    "    pad_to_multiple_of=8\n",
    ")"
   ],
   "execution_count":13,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"Np0ycwganVA5VxyGnmsTj7",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from huggingface_hub import HfFolder\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "repository_id = f\"{checkpoint.split('\/')[1]}-icsi-ami-v2\"\n",
    "# Define training args\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=repository_id,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    predict_with_generate=True,\n",
    "    fp16=False, # Overflows with fp16\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=10,\n",
    "    # logging & evaluation strategies\n",
    "    logging_dir=f\"{repository_id}\/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=500,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    # metric_for_best_model=\"overall_f1\",\n",
    "    # push to hub parameters\n",
    "    report_to=\"tensorboard\",\n",
    "    push_to_hub=False,\n",
    "    hub_strategy=\"every_save\",\n",
    "    hub_model_id=repository_id,\n",
    "    hub_token=HfFolder.get_token(),\n",
    ")\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"Done.\")"
   ],
   "execution_count":14,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "Done.\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"K3SAmxBs3LAagxPmMA48t1",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "import torch\n",
    "torch.cuda.empty_cache()"
   ],
   "execution_count":15,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"jGtCDQ4HfpRtvWWTbMiVJA",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "trainer.train()"
   ],
   "execution_count":16,
   "outputs":[
    {
     "name":"stderr",
     "text":[
      "\/opt\/python\/envs\/default\/lib\/python3.8\/site-packages\/transformers\/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 135\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1350\n",
      "  Number of trainable parameters = 406290432\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 34\n",
      "  Batch size = 1\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-135\n",
      "Configuration saved in bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-135\/config.json\n",
      "Configuration saved in bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-135\/generation_config.json\n",
      "Model weights saved in bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-135\/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 34\n",
      "  Batch size = 1\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-270\n",
      "Configuration saved in bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-270\/config.json\n",
      "Configuration saved in bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-270\/generation_config.json\n",
      "Model weights saved in bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-270\/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 34\n",
      "  Batch size = 1\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-405\n",
      "Configuration saved in bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-405\/config.json\n",
      "Configuration saved in bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-405\/generation_config.json\n",
      "Model weights saved in bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-405\/pytorch_model.bin\n",
      "Deleting older checkpoint [bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-270] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 34\n",
      "  Batch size = 1\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-540\n",
      "Configuration saved in bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-540\/config.json\n",
      "Configuration saved in bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-540\/generation_config.json\n",
      "Model weights saved in bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-540\/pytorch_model.bin\n",
      "Deleting older checkpoint [bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-405] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 34\n",
      "  Batch size = 1\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-675\n",
      "Configuration saved in bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-675\/config.json\n",
      "Configuration saved in bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-675\/generation_config.json\n",
      "Model weights saved in bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-675\/pytorch_model.bin\n",
      "Deleting older checkpoint [bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-540] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 34\n",
      "  Batch size = 1\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-810\n",
      "Configuration saved in bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-810\/config.json\n",
      "Configuration saved in bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-810\/generation_config.json\n",
      "Model weights saved in bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-810\/pytorch_model.bin\n",
      "Deleting older checkpoint [bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-675] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 34\n",
      "  Batch size = 1\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-945\n",
      "Configuration saved in bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-945\/config.json\n",
      "Configuration saved in bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-945\/generation_config.json\n",
      "Model weights saved in bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-945\/pytorch_model.bin\n",
      "Deleting older checkpoint [bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-810] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 34\n",
      "  Batch size = 1\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-1080\n",
      "Configuration saved in bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-1080\/config.json\n",
      "Configuration saved in bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-1080\/generation_config.json\n",
      "Model weights saved in bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-1080\/pytorch_model.bin\n",
      "Deleting older checkpoint [bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-945] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 34\n",
      "  Batch size = 1\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-1215\n",
      "Configuration saved in bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-1215\/config.json\n",
      "Configuration saved in bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-1215\/generation_config.json\n",
      "Model weights saved in bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-1215\/pytorch_model.bin\n",
      "Deleting older checkpoint [bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-1080] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 34\n",
      "  Batch size = 1\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-1350\n",
      "Configuration saved in bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-1350\/config.json\n",
      "Configuration saved in bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-1350\/generation_config.json\n",
      "Model weights saved in bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-1350\/pytorch_model.bin\n",
      "Deleting older checkpoint [bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-1215] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co\/models =)\n",
      "\n",
      "\n",
      "Loading best model from bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-135 (score: 3.230754852294922).\n"
     ],
     "output_type":"stream"
    },
    {
     "data":{
      "text\/html":[
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1350' max='1350' style='width:300px; height:20px; vertical-align: middle;'><\/progress>\n",
       "      [1350\/1350 37:38, Epoch 10\/10]\n",
       "    <\/div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch<\/th>\n",
       "      <th>Training Loss<\/th>\n",
       "      <th>Validation Loss<\/th>\n",
       "      <th>Rouge1<\/th>\n",
       "      <th>Rouge2<\/th>\n",
       "      <th>Rougel<\/th>\n",
       "      <th>Rougelsum<\/th>\n",
       "      <th>Gen Len<\/th>\n",
       "    <\/tr>\n",
       "  <\/thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1<\/td>\n",
       "      <td>No log<\/td>\n",
       "      <td>3.230755<\/td>\n",
       "      <td>38.427400<\/td>\n",
       "      <td>13.646100<\/td>\n",
       "      <td>22.366000<\/td>\n",
       "      <td>35.235300<\/td>\n",
       "      <td>185.794118<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <td>2<\/td>\n",
       "      <td>No log<\/td>\n",
       "      <td>3.302587<\/td>\n",
       "      <td>40.174800<\/td>\n",
       "      <td>11.794400<\/td>\n",
       "      <td>23.265500<\/td>\n",
       "      <td>36.471800<\/td>\n",
       "      <td>146.852941<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <td>3<\/td>\n",
       "      <td>No log<\/td>\n",
       "      <td>3.519942<\/td>\n",
       "      <td>39.820900<\/td>\n",
       "      <td>12.162100<\/td>\n",
       "      <td>22.777200<\/td>\n",
       "      <td>36.496700<\/td>\n",
       "      <td>141.764706<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <td>4<\/td>\n",
       "      <td>2.213100<\/td>\n",
       "      <td>4.050838<\/td>\n",
       "      <td>40.432500<\/td>\n",
       "      <td>11.654700<\/td>\n",
       "      <td>22.995800<\/td>\n",
       "      <td>36.878200<\/td>\n",
       "      <td>131.441176<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <td>5<\/td>\n",
       "      <td>2.213100<\/td>\n",
       "      <td>4.698793<\/td>\n",
       "      <td>38.409700<\/td>\n",
       "      <td>9.830900<\/td>\n",
       "      <td>20.389400<\/td>\n",
       "      <td>34.196700<\/td>\n",
       "      <td>145.970588<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <td>6<\/td>\n",
       "      <td>2.213100<\/td>\n",
       "      <td>4.959008<\/td>\n",
       "      <td>38.575800<\/td>\n",
       "      <td>9.633500<\/td>\n",
       "      <td>20.865000<\/td>\n",
       "      <td>35.032100<\/td>\n",
       "      <td>169.235294<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <td>7<\/td>\n",
       "      <td>2.213100<\/td>\n",
       "      <td>5.426377<\/td>\n",
       "      <td>38.281300<\/td>\n",
       "      <td>9.576400<\/td>\n",
       "      <td>21.140600<\/td>\n",
       "      <td>34.598900<\/td>\n",
       "      <td>148.029412<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <td>8<\/td>\n",
       "      <td>0.401000<\/td>\n",
       "      <td>5.488677<\/td>\n",
       "      <td>38.301400<\/td>\n",
       "      <td>9.688100<\/td>\n",
       "      <td>21.239800<\/td>\n",
       "      <td>34.158400<\/td>\n",
       "      <td>139.352941<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <td>9<\/td>\n",
       "      <td>0.401000<\/td>\n",
       "      <td>5.804439<\/td>\n",
       "      <td>39.960300<\/td>\n",
       "      <td>10.432900<\/td>\n",
       "      <td>22.689500<\/td>\n",
       "      <td>36.240600<\/td>\n",
       "      <td>145.235294<\/td>\n",
       "    <\/tr>\n",
       "    <tr>\n",
       "      <td>10<\/td>\n",
       "      <td>0.401000<\/td>\n",
       "      <td>5.898717<\/td>\n",
       "      <td>39.092800<\/td>\n",
       "      <td>10.840800<\/td>\n",
       "      <td>21.913800<\/td>\n",
       "      <td>35.506700<\/td>\n",
       "      <td>138.794118<\/td>\n",
       "    <\/tr>\n",
       "  <\/tbody>\n",
       "<\/table><p>"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    },
    {
     "data":{
      "text\/plain":[
       "TrainOutput(global_step=1350, training_loss=0.9856559583875868, metrics={'train_runtime': 2260.1119, 'train_samples_per_second': 0.597, 'train_steps_per_second': 0.597, 'total_flos': 2925591212851200.0, 'train_loss': 0.9856559583875868, 'epoch': 10.0})"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"nS17ORLByfVSWVNmF41ct3",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "trainer.evaluate()"
   ],
   "execution_count":24,
   "outputs":[
    {
     "name":"stderr",
     "text":[
      "***** Running Evaluation *****\n",
      "  Num examples = 51\n",
      "  Batch size = 1\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ],
     "output_type":"stream"
    },
    {
     "data":{
      "text\/html":[
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'><\/progress>\n",
       "      [51\/51 01:58]\n",
       "    <\/div>\n",
       "    "
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    },
    {
     "data":{
      "text\/plain":[
       "{'eval_loss': 3.318760633468628,\n",
       " 'eval_rouge1': 37.6295,\n",
       " 'eval_rouge2': 10.8682,\n",
       " 'eval_rougeL': 21.9427,\n",
       " 'eval_rougeLsum': 34.6403,\n",
       " 'eval_gen_len': 127.62745098039215,\n",
       " 'eval_runtime': 122.1386,\n",
       " 'eval_samples_per_second': 0.418,\n",
       " 'eval_steps_per_second': 0.418,\n",
       " 'epoch': 5.0}"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"IBqLPGhbyu3EPJDr2QkJyG",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "# Save our tokenizer and create model card\n",
    "tokenizer.save_pretrained(repository_id)\n",
    "trainer.create_model_card()"
   ],
   "execution_count":17,
   "outputs":[
    {
     "name":"stderr",
     "text":[
      "tokenizer config file saved in bart-large-cnn-samsum-icsi-ami-v2\/tokenizer_config.json\n",
      "Special tokens file saved in bart-large-cnn-samsum-icsi-ami-v2\/special_tokens_map.json\n",
      "Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Sequence-to-sequence Language Modeling', 'type': 'text2text-generation'}, 'metrics': [{'name': 'Rouge1', 'type': 'rouge', 'value': 39.0928}]}\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"l5ee0tea0ca5um8qnPxIyf",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "sample = \"\"\"\n",
    "None: Can you help me?\n",
    "SPEAKER_02: No.\n",
    "None: You okay?\n",
    "SPEAKER_00: You okay?\n",
    "SPEAKER_00: Okay?\n",
    "SPEAKER_00: Is that okay?\n",
    "None: Come on.\n",
    "SPEAKER_00: Okay?\n",
    "SPEAKER_00: Okay.\n",
    "SPEAKER_00: All right, so start of the first meeting.\n",
    "SPEAKER_00: All right, so agenda of the first meeting.\n",
    "SPEAKER_00: Are we...\n",
    "SPEAKER_00: We have 25 minutes for this meeting.\n",
    "SPEAKER_00: We...\n",
    "SPEAKER_00: Are to get acquainted.\n",
    "SPEAKER_00: So, does everyone want to say who they are?\n",
    "SPEAKER_01: And that's sensible.\n",
    "SPEAKER_02: I'm Robin. I'm a marketing manager.\n",
    "SPEAKER_00: I'm Lisa. I'm a music designer.\n",
    "SPEAKER_00: I'm Nick. I'm the industrial designer.\n",
    "SPEAKER_00: And I'm Amostar. I'm on the project leader.\n",
    "SPEAKER_00: Project plan.\n",
    "SPEAKER_00: So, does anyone have any thoughts?\n",
    "SPEAKER_00: As to the tool training that is required.\n",
    "SPEAKER_02: I'm nice. I'll show you what you mean by tool training.\n",
    "SPEAKER_00: Neither am I.\n",
    "SPEAKER_00: Oh, I see. So, we shouldn't really be...\n",
    "SPEAKER_00: All right. Okay.\n",
    "SPEAKER_00: So, we have the project team, which is to basically to come up with a new remote control device.\n",
    "SPEAKER_00: We have...\n",
    "SPEAKER_00: The starting base was the original.\n",
    "SPEAKER_00: Which has been an existence now for a period of time.\n",
    "SPEAKER_00: And our idea is to make the new remote control device more user-friendly than the previous one.\n",
    "SPEAKER_00: And to be trendy or to be with it, and therefore to get a bigger market share and bigger audience.\n",
    "SPEAKER_00: So, the method of doing this is split up.\n",
    "SPEAKER_00: As you can see into the functional design, the conceptual design, and the detailed design.\n",
    "SPEAKER_00: So, in each of these phases, we'll basically be handing over to yourselves the designers of this...\n",
    "SPEAKER_00: This device.\n",
    "SPEAKER_00: And having meetings so that we can, during the course of the day, come up with a better implement than we had before.\n",
    "SPEAKER_00: And therefore have a successful conclusion to the D.\n",
    "SPEAKER_00: And you'll be doing various designs throughout the day to meet this end.\n",
    "SPEAKER_00: So, we've got two chain.\n",
    "SPEAKER_00: Try out whiteboard.\n",
    "SPEAKER_00: So, we'll...\n",
    "SPEAKER_00: Right. So, basically everyone's to supposedly draw their favourite animal over on the whiteboard over there.\n",
    "SPEAKER_00: I guess this is...\n",
    "SPEAKER_00: Make sure the whiteboard works.\n",
    "SPEAKER_00: I don't know who wishes to go first.\n",
    "SPEAKER_00: You wish to go...\n",
    "SPEAKER_00: Have a first bash at whatever.\n",
    "SPEAKER_02: Um...\n",
    "SPEAKER_00: Uh...\n",
    "SPEAKER_00: Good. I've got pocket study.\n",
    "SPEAKER_00: But now you move out from the microphone, and the camera...\n",
    "SPEAKER_00: What about you? That's right now, do you think?\n",
    "SPEAKER_00: I would guess so.\n",
    "SPEAKER_03: You've asked the microphone.\n",
    "SPEAKER_00: Technical problems. I mean, you designers are meant to come up with it.\n",
    "SPEAKER_00: So...\n",
    "SPEAKER_00: Oh, no.\n",
    "SPEAKER_02: Okay.\n",
    "SPEAKER_02: I think that I would have to see that my favourite animal is the cat.\n",
    "SPEAKER_02: What's my look at there?\n",
    "SPEAKER_02: Um...\n",
    "SPEAKER_02: And this would be because the very independent, the very intelligent, the compote the dogs maybe.\n",
    "SPEAKER_02: And it can be very, very affectionate. Some people don't think so, but are not very affectionate cats.\n",
    "SPEAKER_02: Um...\n",
    "SPEAKER_02: And they come back to themselves.\n",
    "None: Right.\n",
    "SPEAKER_00: Next.\n",
    "SPEAKER_02: Shall I look like that? Oh, actually.\n",
    "SPEAKER_00: I don't see. There's any need to. There's plenty of space.\n",
    "SPEAKER_00: I mean...\n",
    "SPEAKER_01: Whatever. I'm a hominatry.\n",
    "SPEAKER_03: Exactly.\n",
    "SPEAKER_03: So I can get the casserole at this time.\n",
    "SPEAKER_00: We've had more time to prepare over this site, so we've all stuck our bits in pieces in the pockets.\n",
    "SPEAKER_03: I didn't think that.\n",
    "SPEAKER_03: Okay.\n",
    "SPEAKER_03: Three pencered.\n",
    "SPEAKER_03: I'll try the red pen.\n",
    "SPEAKER_03: Okay.\n",
    "SPEAKER_03: Um...\n",
    "SPEAKER_03: I'm gonna go for the bath.\n",
    "SPEAKER_03: Wait, something else is draw very well.\n",
    "SPEAKER_03: I'll have a bath.\n",
    "SPEAKER_00: You get marks for artistic impression.\n",
    "SPEAKER_03: Oh, I lost it there.\n",
    "SPEAKER_03: I have to look something like a...\n",
    "SPEAKER_00: Um... So you're just doing the face.\n",
    "SPEAKER_00: I'll go for a...\n",
    "SPEAKER_03: A small, small, bare button.\n",
    "SPEAKER_03: Um...\n",
    "SPEAKER_03: And I like my animal that looks nothing like a bath because, um...\n",
    "SPEAKER_03: Has no, maybe because there's so many cartoon characters who've made a bath.\n",
    "SPEAKER_01: Right.\n",
    "SPEAKER_01: Hello. Um...\n",
    "SPEAKER_01: I'm gonna go for the dog.\n",
    "SPEAKER_01: I'm gonna draw one badly as well.\n",
    "SPEAKER_01: Uh...\n",
    "SPEAKER_01: Looks like he's going to get ducks and does something.\n",
    "SPEAKER_02: That's very good.\n",
    "SPEAKER_02: Right.\n",
    "SPEAKER_01: There's my dog.\n",
    "SPEAKER_01: Um... I like dogs because they're very loyal and they're always happy.\n",
    "SPEAKER_01: So whenever you're feeling sort of a bit...\n",
    "SPEAKER_01: Down or tired, they're always coming up and they're always, um, quite excited.\n",
    "SPEAKER_01: So, um...\n",
    "SPEAKER_01: You can always have a lot of fun with the dog and they're also good for exercises for you so they get out and they never get tired.\n",
    "SPEAKER_01: And when they're tired, they're quite cute as well.\n",
    "SPEAKER_01: Okay.\n",
    "SPEAKER_01: That's why I like dogs.\n",
    "SPEAKER_00: Alright.\n",
    "SPEAKER_00: Well, I've not actually had too many pets over my time because, to be honest with you, uh...\n",
    "SPEAKER_00: Not too keen on them.\n",
    "SPEAKER_00: Anyway, not to worry.\n",
    "SPEAKER_00: So what my daughters have got at the moment is they've got a few fish.\n",
    "SPEAKER_00: And so hopefully, um, won't prove too difficult to draw.\n",
    "SPEAKER_00: Uh...\n",
    "None: Mm-hmm.\n",
    "None: Mm-hmm.\n",
    "SPEAKER_00: As you can see, my artistic work is useless as well.\n",
    "SPEAKER_00: Anyway, um...\n",
    "SPEAKER_00: One of the best things about fish is that they don't really take, uh, too much looking after because, uh, with most of the animals, if you're going away in holiday or whatever, you've got to spend money or get a friend or whatever to look after them for you.\n",
    "SPEAKER_00: Whereas if you've got fish, you just gotta put the food in a dripper feed, which feeds them over a couple of weeks at your way and, uh...\n",
    "SPEAKER_00: Change the water every couple of months and buying a few plants, so other than the fact they keep dying, uh, fish are not... are reasonable pets in that, uh, they're low maintenance.\n",
    "SPEAKER_00: Right.\n",
    "SPEAKER_00: Okay.\n",
    "SPEAKER_00: Or still, what's...\n",
    "SPEAKER_00: Right, okay.\n",
    "SPEAKER_00: So, work has been done on, uh...\n",
    "SPEAKER_00: This project whereby, um...\n",
    "SPEAKER_00: 25 euros is the expected, uh...\n",
    "SPEAKER_00: Sound price?\n",
    "SPEAKER_00: Information has come from our marketing manager here.\n",
    "SPEAKER_00: Mm-hmm.\n",
    "SPEAKER_00: So, we're looking to sell internationally, not just in Europe.\n",
    "SPEAKER_00: We're looking at, um...\n",
    "SPEAKER_00: Having a production costs limited to, uh, 12.5 euro per unit.\n",
    "SPEAKER_00: And therefore making a profit margin of, uh, well, not actually a profit margin, it's, uh...\n",
    "SPEAKER_00: Because obviously you're going to have overheads in your southern costs to, uh, take, uh, from, uh...\n",
    "SPEAKER_00: From that to give you your profit margin per unit.\n",
    "SPEAKER_00: And so depending on what the, uh, the overhead costs are, will determine, uh...\n",
    "SPEAKER_00: How many units were, uh, looking to sell, or projecting to sell at this point in time.\n",
    "SPEAKER_00: So, um...\n",
    "SPEAKER_00: Experience with remote control, first idea is...\n",
    "SPEAKER_00: You're remote. So, I guess we're looking at, um...\n",
    "SPEAKER_00: I'm going to be discussing at this point in time to help you, um...\n",
    "SPEAKER_00: Folks design our new model, as it were. So, uh...\n",
    "SPEAKER_00: Any, any thoughts?\n",
    "SPEAKER_03: Um...\n",
    "SPEAKER_03: I maybe found myself about controls a bit, but it's a little small.\n",
    "SPEAKER_03: But I had to pass. So we could make something with a...\n",
    "SPEAKER_03: This is passed, but...\n",
    "SPEAKER_03: As I was making a function.\n",
    "SPEAKER_00: Okay, so...\n",
    "SPEAKER_00: So basically we're looking for some, um...\n",
    "SPEAKER_00: We're looking for a device that is, um...\n",
    "SPEAKER_00: Robost.\n",
    "SPEAKER_00: And...\n",
    "SPEAKER_00: And therefore, uh...\n",
    "SPEAKER_00: I'm going to get damaged too easily.\n",
    "SPEAKER_00: Um... I'm looking for a device.\n",
    "SPEAKER_00: That is, uh...\n",
    "SPEAKER_00: What was the other thing you just said there?\n",
    "SPEAKER_03: Um... So, easy to use.\n",
    "SPEAKER_03: Easy to use.\n",
    "SPEAKER_03: That's what I was able to say.\n",
    "SPEAKER_03: Yeah.\n",
    "SPEAKER_00: Yes.\n",
    "SPEAKER_03: This is easy to use and see.\n",
    "SPEAKER_00: And see.\n",
    "SPEAKER_00: Okay.\n",
    "SPEAKER_00: Uh...\n",
    "SPEAKER_00: Could we just check?\n",
    "SPEAKER_02: Is this just a television?\n",
    "SPEAKER_02: Because a lot of them...\n",
    "SPEAKER_02: Systems are kind of TV video combined now. TV, TV, TV combined.\n",
    "SPEAKER_02: And one of the most annoying things is having like five and more to the house.\n",
    "SPEAKER_02: So if you've got a combined system, it could be a combined law.\n",
    "SPEAKER_02: Or is it just a television that's supposed to do?\n",
    "SPEAKER_00: Um...\n",
    "SPEAKER_00: They still get back to you on that, but it seems to me sensible because, as you rightly said, there's nothing more annoying than having three or four devices littered about the, uh...\n",
    "SPEAKER_00: About the room and, uh...\n",
    "SPEAKER_00: So, a device for...\n",
    "SPEAKER_00: For all remotes.\n",
    "SPEAKER_03: So, it's a little...\n",
    "SPEAKER_01: Okay. Yeah.\n",
    "SPEAKER_01: Um... One of the things we found in the market research is that people have to get confused by the number of buttons on them as well.\n",
    "SPEAKER_01: Because there's quite often lots and lots.\n",
    "SPEAKER_01: And, um...\n",
    "SPEAKER_01: Sometimes, uh...\n",
    "SPEAKER_01: They'd sort of remote controls to be their own purpose because you're sat in the chair and the remote is somewhere else in the room.\n",
    "SPEAKER_01: So, whereas in the past you don't have to get up to change the channel.\n",
    "SPEAKER_01: Now you have to get up to sort of pick up the remote.\n",
    "SPEAKER_01: So, I don't...\n",
    "SPEAKER_01: We need to sort of maybe think about how...\n",
    "SPEAKER_01: We could maybe, uh...\n",
    "SPEAKER_01: The remote control which moves around the room.\n",
    "SPEAKER_01: That's maybe something for the future when you talk to your television.\n",
    "SPEAKER_00: That is, in a sense, it's mutually exclusive.\n",
    "SPEAKER_00: You can't have both the one device and then have a few buttons on it too.\n",
    "SPEAKER_00: Because you want simplicity as well.\n",
    "SPEAKER_00: You want any idiot to be able to use it.\n",
    "SPEAKER_00: Whilst at the same time you want, as you rightly say, one remote for all.\n",
    "SPEAKER_00: And so, these are probably mutually exclusive options.\n",
    "SPEAKER_00: That, uh...\n",
    "SPEAKER_00: You could argue that experience of using devices and similar devices as people get more and more used to using remotes.\n",
    "SPEAKER_00: Therefore, they're more often with handling them.\n",
    "SPEAKER_00: Therefore, you can make them more complicated as time goes on.\n",
    "SPEAKER_03: They would have better instructions with the remote.\n",
    "SPEAKER_03: Or we just do the design of the remote control itself or the instructions that we can with it.\n",
    "SPEAKER_00: There's instructions.\n",
    "SPEAKER_01: Yeah.\n",
    "SPEAKER_01: I mean, we've done some research about sort of, you know, what the cutting edge sort of handheld devices are.\n",
    "SPEAKER_01: And a lot of them sort of use, you know, they're like mini laptops.\n",
    "SPEAKER_01: So it's possible that we could devise a system where you're basically sort of holding a miniature computer which is controlling all your sort of your television, your stereo.\n",
    "SPEAKER_01: And where, you know, if you buy a new thing, then it's sort of, you can link it to that as well.\n",
    "SPEAKER_00: Okay.\n",
    "SPEAKER_00: Well, we've got five minutes before the end of the meeting.\n",
    "SPEAKER_00: So, we have to start winding up.\n",
    "SPEAKER_00: Is there next meeting in 30 minutes?\n",
    "SPEAKER_00: Okay.\n",
    "SPEAKER_00: So, um, right.\n",
    "SPEAKER_00: So we've got ID, the command of mine.\n",
    "SPEAKER_01: You just click return.\n",
    "SPEAKER_01: Okay.\n",
    "SPEAKER_01: Get rid of the message.\n",
    "SPEAKER_03: Or not.\n",
    "SPEAKER_01: If you hit just hit return and it should get rid of the message.\n",
    "SPEAKER_00: Oh, there we go.\n",
    "SPEAKER_00: Yeah.\n",
    "SPEAKER_00: That's what I was looking for.\n",
    "SPEAKER_00: Right.\n",
    "SPEAKER_00: So we've got functional.\n",
    "SPEAKER_02: What happened to the.\n",
    "SPEAKER_02: Yeah.\n",
    "SPEAKER_00: Sorry about that.\n",
    "SPEAKER_00: Okay.\n",
    "SPEAKER_00: So, um, the working design for ID, the, the technical functions design, marketing, the user requirement specification specific instructions sent to you about your person, by your personal coach.\n",
    "SPEAKER_00: So we all clear what objectives we're looking to meet in the next 30 minutes.\n",
    "SPEAKER_00: And I guess I'll try and write up some minutes of this meeting to, uh, to give it to you for the next meeting.\n",
    "SPEAKER_02: I'm not necessarily clear on what we're designing.\n",
    "SPEAKER_02: Is it a multi functional one or do we decide that ourselves?\n",
    "SPEAKER_02: So the more we work on it.\n",
    "SPEAKER_03: I think you just said the start of the television about television.\n",
    "SPEAKER_00: That's true.\n",
    "SPEAKER_00: During the course of our day, we might make decisions based on information or meetings that would change.\n",
    "SPEAKER_00: Okay.\n",
    "SPEAKER_00: Where we're going.\n",
    "SPEAKER_00: But at this point in time, I think you're right.\n",
    "SPEAKER_00: So make it just a TV.\n",
    "SPEAKER_00: Okay.\n",
    "SPEAKER_00: So.\n",
    "SPEAKER_00: Depart.\n",
    "SPEAKER_00: We will stay here and, uh, and break off.\n",
    "SPEAKER_00: So we'll see you in half now.\n",
    "SPEAKER_00: Okay.\n",
    "SPEAKER_00: Okay.\n",
    "SPEAKER_00: Right.\n",
    "None: Okay.\n",
    "\"\"\""
   ],
   "execution_count":18,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"eo3LLio5c0z1H98MuBog5u",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from transformers import pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\".\/bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-135\", tokenizer = checkpoint, truncation=True)\n"
   ],
   "execution_count":20,
   "outputs":[
    {
     "name":"stderr",
     "text":[
      "loading configuration file .\/bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-135\/config.json\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \".\/bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-135\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"force_bos_token_to_be_generated\": true,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 10,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "loading configuration file .\/bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-135\/config.json\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \".\/bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-135\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"force_bos_token_to_be_generated\": true,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 10,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "loading weights file .\/bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-135\/pytorch_model.bin\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at .\/bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-135.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
      "loading configuration file .\/bart-large-cnn-samsum-icsi-ami-v2\/checkpoint-135\/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at \/home\/datalore\/.cache\/huggingface\/hub\/models--philschmid--bart-large-cnn-samsum\/snapshots\/e49b3d60d923f12db22bdd363356f1a4c68532ad\/config.json\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"philschmid\/bart-large-cnn-samsum\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"force_bos_token_to_be_generated\": true,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 56,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at \/home\/datalore\/.cache\/huggingface\/hub\/models--philschmid--bart-large-cnn-samsum\/snapshots\/e49b3d60d923f12db22bdd363356f1a4c68532ad\/vocab.json\n",
      "loading file merges.txt from cache at \/home\/datalore\/.cache\/huggingface\/hub\/models--philschmid--bart-large-cnn-samsum\/snapshots\/e49b3d60d923f12db22bdd363356f1a4c68532ad\/merges.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at \/home\/datalore\/.cache\/huggingface\/hub\/models--philschmid--bart-large-cnn-samsum\/snapshots\/e49b3d60d923f12db22bdd363356f1a4c68532ad\/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at \/home\/datalore\/.cache\/huggingface\/hub\/models--philschmid--bart-large-cnn-samsum\/snapshots\/e49b3d60d923f12db22bdd363356f1a4c68532ad\/tokenizer_config.json\n",
      "loading configuration file config.json from cache at \/home\/datalore\/.cache\/huggingface\/hub\/models--philschmid--bart-large-cnn-samsum\/snapshots\/e49b3d60d923f12db22bdd363356f1a4c68532ad\/config.json\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"philschmid\/bart-large-cnn-samsum\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"force_bos_token_to_be_generated\": true,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 56,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at \/home\/datalore\/.cache\/huggingface\/hub\/models--philschmid--bart-large-cnn-samsum\/snapshots\/e49b3d60d923f12db22bdd363356f1a4c68532ad\/config.json\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"philschmid\/bart-large-cnn-samsum\",\n",
      "  \"_num_labels\": 3,\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 4096,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 12,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"force_bos_token_to_be_generated\": true,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"min_length\": 56,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"prefix\": \" \",\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50264\n",
      "}\n",
      "\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"aVCaIE48tBrypvgjbTnFPC",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "res = summarizer(sample , max_length = 200)\n",
    "print(f\"{res[0]}\")"
   ],
   "execution_count":59,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "{'summary_text': 'This is the first meeting of a new remote control project. Project Manager introduced the team to each other and Project Manager asked them to draw their favourite animals. The team agreed that the remote control should be more user-friendly than the previous one. The meeting ended with a general discussion on the design of the remote, including the functional design, conceptual design, and detailed design.'}\n"
     ],
     "output_type":"stream"
    },
    {
     "name":"stderr",
     "text":[
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 142,\n",
      "  \"min_length\": 56,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"ZvwkFgQgFMIPmx6RdLQuxt",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "from evaluate import evaluator\n",
    "import evaluate\n",
    "metric = evaluate.load(\"rouge\")\n",
    "print(metric.inputs_description)\n"
   ],
   "execution_count":14,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "\n",
      "Calculates average rouge scores for a list of hypotheses and references\n",
      "Args:\n",
      "    predictions: list of predictions to score. Each prediction\n",
      "        should be a string with tokens separated by spaces.\n",
      "    references: list of reference for each prediction. Each\n",
      "        reference should be a string with tokens separated by spaces.\n",
      "    rouge_types: A list of rouge types to calculate.\n",
      "        Valid names:\n",
      "        `\"rouge{n}\"` (e.g. `\"rouge1\"`, `\"rouge2\"`) where: {n} is the n-gram based scoring,\n",
      "        `\"rougeL\"`: Longest common subsequence based scoring.\n",
      "        `\"rougeLsum\"`: rougeLsum splits text using `\"\n",
      "\"`.\n",
      "        See details in https:\/\/github.com\/huggingface\/datasets\/issues\/617\n",
      "    use_stemmer: Bool indicating whether Porter stemmer should be used to strip word suffixes.\n",
      "    use_aggregator: Return aggregates if this is set to True\n",
      "Returns:\n",
      "    rouge1: rouge_1 (f1),\n",
      "    rouge2: rouge_2 (f1),\n",
      "    rougeL: rouge_l (f1),\n",
      "    rougeLsum: rouge_lsum (f1)\n",
      "Examples:\n",
      "\n",
      "    >>> rouge = evaluate.load('rouge')\n",
      "    >>> predictions = [\"hello there\", \"general kenobi\"]\n",
      "    >>> references = [\"hello there\", \"general kenobi\"]\n",
      "    >>> results = rouge.compute(predictions=predictions, references=references)\n",
      "    >>> print(results)\n",
      "    {'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}\n",
      "\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"m73CVBJAMk71aZ8OQY61y6",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "trainer.evaluate()"
   ],
   "execution_count":56,
   "outputs":[
    {
     "name":"stderr",
     "text":[
      "***** Running Evaluation *****\n",
      "  Num examples = 34\n",
      "  Batch size = 1\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 2.0,\n",
      "  \"max_length\": 400,\n",
      "  \"min_length\": 10,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.26.1\"\n",
      "}\n",
      "\n"
     ],
     "output_type":"stream"
    },
    {
     "data":{
      "text\/html":[
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='34' style='width:300px; height:20px; vertical-align: middle;'><\/progress>\n",
       "      [34\/34 01:18]\n",
       "    <\/div>\n",
       "    "
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    },
    {
     "data":{
      "text\/plain":[
       "{'eval_loss': 3.1403207778930664,\n",
       " 'eval_rouge1': 38.7497,\n",
       " 'eval_rouge2': 10.8123,\n",
       " 'eval_rougeL': 22.6838,\n",
       " 'eval_rougeLsum': 34.7075,\n",
       " 'eval_gen_len': 138.11764705882354,\n",
       " 'eval_runtime': 81.8894,\n",
       " 'eval_samples_per_second': 0.415,\n",
       " 'eval_steps_per_second': 0.415,\n",
       " 'epoch': 5.0}"
      ]
     },
     "metadata":{
      
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"XEBQpVrfHx8p2hFvrwDU9R",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "task_evaluator = evaluator(\"summarization\")\n",
    "eval_results = task_evaluator.compute(model_or_pipeline=summarizer\n",
    "                                      , data = my_data_train_test[\"test\"], input_column=\"dialogue\", label_column=\"summary\")\n",
    "print(eval_results)"
   ],
   "execution_count":15,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "{'rouge1': 0.3904652959716078, 'rouge2': 0.14393620735702914, 'rougeL': 0.24746191692763833, 'rougeLsum': 0.2476617812520101, 'total_time_in_seconds': 526.7507517189997, 'samples_per_second': 0.06454665681832311, 'latency_in_seconds': 15.492669168205875}\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"61hQpQWJJMf9tuUJUzjwXp",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "old_summarizer = pipeline(\"summarization\", model=\"vmarklynn\/bart-large-cnn-samsum-acsi-ami\", tokenizer = checkpoint, truncation = True)\n",
    "eval_results_old = task_evaluator.compute(model_or_pipeline=old_summarizer\n",
    "                                      , data = my_data_train_test[\"test\"], input_column=\"dialogue\", label_column=\"summary\")\n",
    "print(eval_results_old)"
   ],
   "execution_count":16,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "{'rouge1': 0.3686045117283241, 'rouge2': 0.12595355808827308, 'rougeL': 0.23618191347875278, 'rougeLsum': 0.23597138924820907, 'total_time_in_seconds': 527.3878147569994, 'samples_per_second': 0.06446868708118697, 'latency_in_seconds': 15.511406316382338}\n"
     ],
     "output_type":"stream"
    },
    {
     "data":{
      "application\/vnd.jupyter.widget-view+json":{
       "version_major":2,
       "version_minor":0,
       "model_id":"3fa2af848a8a41cbb25d0051ca19d2a5"
      }
     },
     "metadata":{
      "application\/vnd.jupyter.widget-view+json":{
       "datalore":{
        "widget_id":"bGxtXPgygdF6dYjsJa8Iak"
       }
      }
     },
     "output_type":"display_data"
    },
    {
     "data":{
      "application\/vnd.jupyter.widget-view+json":{
       "version_major":2,
       "version_minor":0,
       "model_id":"cc224c41aed9450781ecf9f0ff7d7318"
      }
     },
     "metadata":{
      "application\/vnd.jupyter.widget-view+json":{
       "datalore":{
        "widget_id":"oGbSEtcbW0ADaYebJrOWJP"
       }
      }
     },
     "output_type":"display_data"
    },
    {
     "data":{
      "application\/vnd.jupyter.widget-view+json":{
       "version_major":2,
       "version_minor":0,
       "model_id":"2c944bd7ef8a43b5b0ee4128064433b2"
      }
     },
     "metadata":{
      "application\/vnd.jupyter.widget-view+json":{
       "datalore":{
        "widget_id":"ViZJjgHdBQtfkaTTsrrpkA"
       }
      }
     },
     "output_type":"display_data"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"53kdkoiglf0RS63ftEYDOM",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "train_eval_results = task_evaluator.compute(model_or_pipeline=summarizer\n",
    "                                      , data = my_data_train_test[\"train\"], input_column=\"dialogue\", label_column=\"summary\")\n",
    "print(train_eval_results)"
   ],
   "execution_count":17,
   "outputs":[
    {
     "name":"stdout",
     "text":[
      "{'rouge1': 0.395087405543628, 'rouge2': 0.1342562863153256, 'rougeL': 0.24645589644585283, 'rougeLsum': 0.2461069082339275, 'total_time_in_seconds': 1996.8952170309994, 'samples_per_second': 0.06760494934767741, 'latency_in_seconds': 14.791816422451847}\n"
     ],
     "output_type":"stream"
    }
   ],
   "metadata":{
    "datalore":{
     "node_id":"oMmhzedcwazJlxZL0QzhZ0",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  },
  {
   "cell_type":"code",
   "source":[
    "trainer.evaluate()"
   ],
   "execution_count":null,
   "outputs":[
    
   ],
   "metadata":{
    "datalore":{
     "node_id":"SA3MKyDMcFw6laxj6t8txK",
     "type":"CODE",
     "hide_input_from_viewers":true,
     "hide_output_from_viewers":true
    }
   }
  }
 ],
 "metadata":{
  "widgets":{
   "application\/vnd.jupyter.widget-state+json":{
    "version_major":2,
    "version_minor":0,
    "state":{
     "dfccad8e2c0644069df2d3138414be6b":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "15e8c2acc22b43c2bcf7dc89a8e4c505":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "d2e765c3dfdf4084b5633f6b06ae731c":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_dfccad8e2c0644069df2d3138414be6b",
       "style":"IPY_MODEL_15e8c2acc22b43c2bcf7dc89a8e4c505",
       "value":"Extracting data files: 100%"
      }
     },
     "f64bef196b1e401e9f937d7d72c8098a":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "eb7e3f1d47aa46bca810aa89e1f8a71e":{
      "model_name":"ProgressStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "a01d10188565423f8b619d2069a33a40":{
      "model_name":"FloatProgressModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "bar_style":"success",
       "layout":"IPY_MODEL_f64bef196b1e401e9f937d7d72c8098a",
       "max":1,
       "style":"IPY_MODEL_eb7e3f1d47aa46bca810aa89e1f8a71e",
       "value":1
      }
     },
     "f68762b3bfab447581d5924451262ef4":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "78f0108afbe74407935bb779ec007d36":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "d922c8d23aff431d96fbce8805ca9389":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_f68762b3bfab447581d5924451262ef4",
       "style":"IPY_MODEL_78f0108afbe74407935bb779ec007d36",
       "value":" 1\/1 [00:00&lt;00:00, 12.24it\/s]"
      }
     },
     "cfd324421cbf4f7092923e9bd2d4a52a":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "dccf2670f0034a77b8ffb2bf3623502a":{
      "model_name":"HBoxModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "children":[
        "IPY_MODEL_d2e765c3dfdf4084b5633f6b06ae731c",
        "IPY_MODEL_a01d10188565423f8b619d2069a33a40",
        "IPY_MODEL_d922c8d23aff431d96fbce8805ca9389"
       ],
       "layout":"IPY_MODEL_cfd324421cbf4f7092923e9bd2d4a52a"
      }
     },
     "7456d72550bd4d2483e920bacc5ad300":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "649cdf861180475a8d21facd245bddc5":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "56bee2fd56de4471843c62de697cf168":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_7456d72550bd4d2483e920bacc5ad300",
       "style":"IPY_MODEL_649cdf861180475a8d21facd245bddc5",
       "value":"Generating train split: "
      }
     },
     "bb3b20ce26944719a9a1b5ffd23cbd05":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       "width":"20px"
      }
     },
     "6a171ba1e16c4f30be6b8b6ef33d972b":{
      "model_name":"ProgressStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "11c76cec2e2a4b2eb839832c1fb64068":{
      "model_name":"FloatProgressModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "bar_style":"info",
       "layout":"IPY_MODEL_bb3b20ce26944719a9a1b5ffd23cbd05",
       "max":1,
       "style":"IPY_MODEL_6a171ba1e16c4f30be6b8b6ef33d972b",
       "value":1
      }
     },
     "816ebe1100bb422193112cc5efe30613":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "1066d562a452403eb939680f5db8780a":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "dbd95cd05074453486e327d6f3079ca7":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_816ebe1100bb422193112cc5efe30613",
       "style":"IPY_MODEL_1066d562a452403eb939680f5db8780a",
       "value":" 169\/0 [00:00&lt;00:00, 659.74 examples\/s]"
      }
     },
     "262d9b31627e4b7c8cae058dc8e4396c":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       "visibility":"hidden"
      }
     },
     "e582889030c0442bbe335b2886f033b0":{
      "model_name":"HBoxModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "children":[
        "IPY_MODEL_56bee2fd56de4471843c62de697cf168",
        "IPY_MODEL_11c76cec2e2a4b2eb839832c1fb64068",
        "IPY_MODEL_dbd95cd05074453486e327d6f3079ca7"
       ],
       "layout":"IPY_MODEL_262d9b31627e4b7c8cae058dc8e4396c"
      }
     },
     "e9768a8902eb4ff38469f6b109208e30":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "9abad18a842141bca4d12ac06113f425":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "e08989843e744a57a86e1189e02c2388":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_e9768a8902eb4ff38469f6b109208e30",
       "style":"IPY_MODEL_9abad18a842141bca4d12ac06113f425",
       "value":"100%"
      }
     },
     "6126f5eb70d747abb6365dcd7b694e37":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "6657c8f3513d4155a847504305bbb79c":{
      "model_name":"ProgressStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "c9c7d3a3177c4ab6a5a7c4b3ff19bd3b":{
      "model_name":"FloatProgressModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "bar_style":"success",
       "layout":"IPY_MODEL_6126f5eb70d747abb6365dcd7b694e37",
       "max":1,
       "style":"IPY_MODEL_6657c8f3513d4155a847504305bbb79c",
       "value":1
      }
     },
     "42ee62b8b9484e04917d3e016016839b":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "708f1d64153d44418b79e9e3aa3c7743":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "48baf60bbaba40efa28e43f9cee8a806":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_42ee62b8b9484e04917d3e016016839b",
       "style":"IPY_MODEL_708f1d64153d44418b79e9e3aa3c7743",
       "value":" 1\/1 [00:00&lt;00:00, 53.53it\/s]"
      }
     },
     "ce552f09b9864f0aadd3f5c9813f58b0":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "f98c7b6021544c17b998676b05d359a8":{
      "model_name":"HBoxModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "children":[
        "IPY_MODEL_e08989843e744a57a86e1189e02c2388",
        "IPY_MODEL_c9c7d3a3177c4ab6a5a7c4b3ff19bd3b",
        "IPY_MODEL_48baf60bbaba40efa28e43f9cee8a806"
       ],
       "layout":"IPY_MODEL_ce552f09b9864f0aadd3f5c9813f58b0"
      }
     },
     "a6a8eb3791ba40db8129a79684fe7bf6":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "74e23b4baa934a9fa5efbe5820ed6f75":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "1edad853a6054700b487ed1581bd49b4":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_a6a8eb3791ba40db8129a79684fe7bf6",
       "style":"IPY_MODEL_74e23b4baa934a9fa5efbe5820ed6f75",
       "value":"Downloading (…)okenizer_config.json: 100%"
      }
     },
     "a891c2d6ff404d6a9b77a6ad2ea93134":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "033368b7bd8848209a89088085b971df":{
      "model_name":"ProgressStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "1b8f3940a185416c980d5b393c27a4aa":{
      "model_name":"FloatProgressModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "bar_style":"success",
       "layout":"IPY_MODEL_a891c2d6ff404d6a9b77a6ad2ea93134",
       "max":300,
       "style":"IPY_MODEL_033368b7bd8848209a89088085b971df",
       "value":300
      }
     },
     "c80964b54f4a490080b77792c5152746":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "a83e5b929b954735afa370167fb24570":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "f1ec05e295dd43b28a1f28b0d8b2e774":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_c80964b54f4a490080b77792c5152746",
       "style":"IPY_MODEL_a83e5b929b954735afa370167fb24570",
       "value":" 300\/300 [00:00&lt;00:00, 16.6kB\/s]"
      }
     },
     "a016b9c606e74ecfa4254873ddaaee51":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "72a17111e618405e81727f632a0c84c8":{
      "model_name":"HBoxModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "children":[
        "IPY_MODEL_1edad853a6054700b487ed1581bd49b4",
        "IPY_MODEL_1b8f3940a185416c980d5b393c27a4aa",
        "IPY_MODEL_f1ec05e295dd43b28a1f28b0d8b2e774"
       ],
       "layout":"IPY_MODEL_a016b9c606e74ecfa4254873ddaaee51"
      }
     },
     "494fcdc608584de7a2b7f4ddcd1b394e":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "c41bad9c8a624b85af6fab4da1ecf900":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "93e3673701384809b879d31bde699279":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_494fcdc608584de7a2b7f4ddcd1b394e",
       "style":"IPY_MODEL_c41bad9c8a624b85af6fab4da1ecf900",
       "value":"Downloading (…)olve\/main\/vocab.json: 100%"
      }
     },
     "94dd08f4cbb846cf9b46d26227661531":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "046a55b7ad09447883a37d4845abfe39":{
      "model_name":"ProgressStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "b07b988caef140419e47f2058ae4d2d8":{
      "model_name":"FloatProgressModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "bar_style":"success",
       "layout":"IPY_MODEL_94dd08f4cbb846cf9b46d26227661531",
       "max":798293,
       "style":"IPY_MODEL_046a55b7ad09447883a37d4845abfe39",
       "value":798293
      }
     },
     "19afb2e15d084edfa2208f57dd98c1a5":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "11389af367d249c4bbd24aec25a016ec":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "eedef26a3abb47f1aab80ee89611bef0":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_19afb2e15d084edfa2208f57dd98c1a5",
       "style":"IPY_MODEL_11389af367d249c4bbd24aec25a016ec",
       "value":" 798k\/798k [00:00&lt;00:00, 2.42MB\/s]"
      }
     },
     "95de4e54ef034dccba2768bbd85fc322":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "414c97b15a974a369893d1204f7f759b":{
      "model_name":"HBoxModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "children":[
        "IPY_MODEL_93e3673701384809b879d31bde699279",
        "IPY_MODEL_b07b988caef140419e47f2058ae4d2d8",
        "IPY_MODEL_eedef26a3abb47f1aab80ee89611bef0"
       ],
       "layout":"IPY_MODEL_95de4e54ef034dccba2768bbd85fc322"
      }
     },
     "daea147f7c004f9ca93656a5aace241f":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "7a274d22ac0243f29ef2a5b090e06345":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "26c86524f9b44a37965157c1ef55d61f":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_daea147f7c004f9ca93656a5aace241f",
       "style":"IPY_MODEL_7a274d22ac0243f29ef2a5b090e06345",
       "value":"Downloading (…)olve\/main\/merges.txt: 100%"
      }
     },
     "f619250912c54c5aa3c6c0574b45422f":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "caa03000839e4c71a11f78f9259caf81":{
      "model_name":"ProgressStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "b9ebc0415e7a48ac80525d66f728967e":{
      "model_name":"FloatProgressModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "bar_style":"success",
       "layout":"IPY_MODEL_f619250912c54c5aa3c6c0574b45422f",
       "max":456356,
       "style":"IPY_MODEL_caa03000839e4c71a11f78f9259caf81",
       "value":456356
      }
     },
     "1509fd7c98374c50982d9f602eb80d60":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "ca3a3fb2f024472f8b50303614d8079d":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "04fea80fc69e4f449d9f418f9252f6c8":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_1509fd7c98374c50982d9f602eb80d60",
       "style":"IPY_MODEL_ca3a3fb2f024472f8b50303614d8079d",
       "value":" 456k\/456k [00:00&lt;00:00, 1.72MB\/s]"
      }
     },
     "28e1320f5bec41888d29a2f3e7512ccc":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "d5d77517355744ae85a10e880f006a2d":{
      "model_name":"HBoxModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "children":[
        "IPY_MODEL_26c86524f9b44a37965157c1ef55d61f",
        "IPY_MODEL_b9ebc0415e7a48ac80525d66f728967e",
        "IPY_MODEL_04fea80fc69e4f449d9f418f9252f6c8"
       ],
       "layout":"IPY_MODEL_28e1320f5bec41888d29a2f3e7512ccc"
      }
     },
     "e1d3bce7eab24f1287cac6836b361f21":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "26e9501de34b4dc4a437c0d5753eb035":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "acc02d249b13400b90d53d4c7568ed92":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_e1d3bce7eab24f1287cac6836b361f21",
       "style":"IPY_MODEL_26e9501de34b4dc4a437c0d5753eb035",
       "value":"Downloading (…)cial_tokens_map.json: 100%"
      }
     },
     "254aa279d35045c0b940c2d931eec5e2":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "24b79ad784f14bbe92ad9e63986ced7d":{
      "model_name":"ProgressStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "8c6161bdd837473dabf986e17dff2321":{
      "model_name":"FloatProgressModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "bar_style":"success",
       "layout":"IPY_MODEL_254aa279d35045c0b940c2d931eec5e2",
       "max":239,
       "style":"IPY_MODEL_24b79ad784f14bbe92ad9e63986ced7d",
       "value":239
      }
     },
     "20b400a0ce9a410c992a6c23c03a570e":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "5de71b18d7724660b01df52c2e6397ef":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "8ace13ff7469490ba708d82d172124bd":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_20b400a0ce9a410c992a6c23c03a570e",
       "style":"IPY_MODEL_5de71b18d7724660b01df52c2e6397ef",
       "value":" 239\/239 [00:00&lt;00:00, 18.8kB\/s]"
      }
     },
     "18a95783e60148959bb538776a851572":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "ed3c1432d94a454e8457084354232476":{
      "model_name":"HBoxModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "children":[
        "IPY_MODEL_acc02d249b13400b90d53d4c7568ed92",
        "IPY_MODEL_8c6161bdd837473dabf986e17dff2321",
        "IPY_MODEL_8ace13ff7469490ba708d82d172124bd"
       ],
       "layout":"IPY_MODEL_18a95783e60148959bb538776a851572"
      }
     },
     "4692e66253df41dcaf60bcc66bb7a632":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "b07e4eaa1f534e899cd4cd2eaa312169":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "14e932026f044119a0e768ea6cd687ab":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_4692e66253df41dcaf60bcc66bb7a632",
       "style":"IPY_MODEL_b07e4eaa1f534e899cd4cd2eaa312169",
       "value":"Map: 100%"
      }
     },
     "aea861b1cbd040b1a3acec01bf1a71d8":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "092b82ec34d44ac884e7a5d523998aef":{
      "model_name":"ProgressStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "b0cd73753c2b475da59a7f9c6ef7df21":{
      "model_name":"FloatProgressModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_aea861b1cbd040b1a3acec01bf1a71d8",
       "max":169,
       "style":"IPY_MODEL_092b82ec34d44ac884e7a5d523998aef",
       "value":169
      }
     },
     "9c17b5e8147e4830b780d95f4983cc96":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "ac504ab5e837445993fa38f5b876ec4f":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "87cdd9cb2c384ff8b3ac585bf25c81fe":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_9c17b5e8147e4830b780d95f4983cc96",
       "style":"IPY_MODEL_ac504ab5e837445993fa38f5b876ec4f",
       "value":" 169\/169 [00:01&lt;00:00, 90.62 examples\/s]"
      }
     },
     "1f9a0d3807df44de9488171451920bda":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       "visibility":"hidden"
      }
     },
     "ae9bc3ce26b84a9388d930b7c3bcb630":{
      "model_name":"HBoxModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "children":[
        "IPY_MODEL_14e932026f044119a0e768ea6cd687ab",
        "IPY_MODEL_b0cd73753c2b475da59a7f9c6ef7df21",
        "IPY_MODEL_87cdd9cb2c384ff8b3ac585bf25c81fe"
       ],
       "layout":"IPY_MODEL_1f9a0d3807df44de9488171451920bda"
      }
     },
     "2239566a727b4ead931960b4529d085b":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "71f83b7752544b6e8acd5639447e9890":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "6e65be8586554793b9c745466a10cd8b":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_2239566a727b4ead931960b4529d085b",
       "style":"IPY_MODEL_71f83b7752544b6e8acd5639447e9890",
       "value":"Map: 100%"
      }
     },
     "97133c3b7f2040f888a6ffe9d41da3de":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "1d1af324ca824018beb8c27d3a32a575":{
      "model_name":"ProgressStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "6c018578d3f04bc5bd6e86ece9c7a115":{
      "model_name":"FloatProgressModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_97133c3b7f2040f888a6ffe9d41da3de",
       "max":135,
       "style":"IPY_MODEL_1d1af324ca824018beb8c27d3a32a575",
       "value":135
      }
     },
     "833985cac9fa48fb9818ec8f3aef8d1e":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "c6062ef246c04d71beba75e60f66e8eb":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "99c425b1a66c435c8fa60958cb69dd04":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_833985cac9fa48fb9818ec8f3aef8d1e",
       "style":"IPY_MODEL_c6062ef246c04d71beba75e60f66e8eb",
       "value":" 135\/135 [00:01&lt;00:00, 83.96 examples\/s]"
      }
     },
     "c03362c76b0e4c30b09f4533b188252b":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       "visibility":"hidden"
      }
     },
     "dcb48036018843089f159f76fa06d605":{
      "model_name":"HBoxModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "children":[
        "IPY_MODEL_6e65be8586554793b9c745466a10cd8b",
        "IPY_MODEL_6c018578d3f04bc5bd6e86ece9c7a115",
        "IPY_MODEL_99c425b1a66c435c8fa60958cb69dd04"
       ],
       "layout":"IPY_MODEL_c03362c76b0e4c30b09f4533b188252b"
      }
     },
     "541b4949aa0147ec8dc234377edfbaa2":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "15a079364e0b4693bbbca3b859231b4c":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "8ecbdf9f90bd4501a4c5df16094ceaf4":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_541b4949aa0147ec8dc234377edfbaa2",
       "style":"IPY_MODEL_15a079364e0b4693bbbca3b859231b4c",
       "value":"Map: 100%"
      }
     },
     "afd8f02ec4aa4b659c2cfa5589e9a391":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "2dad96103a4f463a95d0c12e0a714737":{
      "model_name":"ProgressStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "eb88aff6fcbb49359c0552bf876f7383":{
      "model_name":"FloatProgressModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_afd8f02ec4aa4b659c2cfa5589e9a391",
       "max":34,
       "style":"IPY_MODEL_2dad96103a4f463a95d0c12e0a714737",
       "value":34
      }
     },
     "6cdcf858fb0f4c308f0ae112d8ea099f":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "f2b75e22426240df9dfe4ec99f09f5af":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "e77f74a23a554c2993bf0685234551cd":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_6cdcf858fb0f4c308f0ae112d8ea099f",
       "style":"IPY_MODEL_f2b75e22426240df9dfe4ec99f09f5af",
       "value":" 34\/34 [00:00&lt;00:00, 71.68 examples\/s]"
      }
     },
     "9bc8dcb9bbbb437ba35569d8e5e21572":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       "visibility":"hidden"
      }
     },
     "a00b29e5ed934be886389d305c2486b6":{
      "model_name":"HBoxModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "children":[
        "IPY_MODEL_8ecbdf9f90bd4501a4c5df16094ceaf4",
        "IPY_MODEL_eb88aff6fcbb49359c0552bf876f7383",
        "IPY_MODEL_e77f74a23a554c2993bf0685234551cd"
       ],
       "layout":"IPY_MODEL_9bc8dcb9bbbb437ba35569d8e5e21572"
      }
     },
     "3fe364adf18b47bcbb1bb3c6581bcd2c":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "3af8d2a99d524e05bd004dfa9bd9cbaf":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "83db78f6a57e49b086213085e21594bb":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_3fe364adf18b47bcbb1bb3c6581bcd2c",
       "style":"IPY_MODEL_3af8d2a99d524e05bd004dfa9bd9cbaf",
       "value":"Downloading builder script: 100%"
      }
     },
     "cdc34c988ff046daaababe6ab6750105":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "560bb03fc68047c6a659d4e07455a8f1":{
      "model_name":"ProgressStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "9b49c58c68e743a5b51eb124eeea6c93":{
      "model_name":"FloatProgressModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "bar_style":"success",
       "layout":"IPY_MODEL_cdc34c988ff046daaababe6ab6750105",
       "max":6270,
       "style":"IPY_MODEL_560bb03fc68047c6a659d4e07455a8f1",
       "value":6270
      }
     },
     "3ef62073c873455187b62ef8c2bf1a8a":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "9a1bc2b516fa49a4b4cb26b1692117f9":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "9419d920917140b6ab360b6a2e675ea2":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_3ef62073c873455187b62ef8c2bf1a8a",
       "style":"IPY_MODEL_9a1bc2b516fa49a4b4cb26b1692117f9",
       "value":" 6.27k\/6.27k [00:00&lt;00:00, 544kB\/s]"
      }
     },
     "d0e338bf72bb410891cb1a40dcc1663b":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "66f44cfd557f46c2a15f6e12449ef578":{
      "model_name":"HBoxModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "children":[
        "IPY_MODEL_83db78f6a57e49b086213085e21594bb",
        "IPY_MODEL_9b49c58c68e743a5b51eb124eeea6c93",
        "IPY_MODEL_9419d920917140b6ab360b6a2e675ea2"
       ],
       "layout":"IPY_MODEL_d0e338bf72bb410891cb1a40dcc1663b"
      }
     },
     "2915e377dbaa4a1482bf659c171ef391":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "5c2b5cacf6454c0d80f5217d41489421":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "0c437e02585a4499bf9fa43eebf6dcec":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_2915e377dbaa4a1482bf659c171ef391",
       "style":"IPY_MODEL_5c2b5cacf6454c0d80f5217d41489421",
       "value":"Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
      }
     },
     "0f4aece94d5949a2bda6b671348683e5":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "f10be46da90642a9a4f01090e43709c3":{
      "model_name":"ProgressStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "c75cc2a6437f4aa2a13c89cbfc0d6b59":{
      "model_name":"FloatProgressModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "bar_style":"success",
       "layout":"IPY_MODEL_0f4aece94d5949a2bda6b671348683e5",
       "max":1625565295,
       "style":"IPY_MODEL_f10be46da90642a9a4f01090e43709c3",
       "value":1625565295
      }
     },
     "87da9af87bdf47ea868ae767b05de9b7":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "d65d746f45d541629d76060b64f2ad34":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "60893d4d66c148b7a23b5ffa9a3a9cc8":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_87da9af87bdf47ea868ae767b05de9b7",
       "style":"IPY_MODEL_d65d746f45d541629d76060b64f2ad34",
       "value":" 1.63G\/1.63G [00:04&lt;00:00, 379MB\/s]"
      }
     },
     "122f1a60adb446eabf0d1d46f7b41590":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "d79b487980fe4d14ae0dd5b7f5c00505":{
      "model_name":"HBoxModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "children":[
        "IPY_MODEL_0c437e02585a4499bf9fa43eebf6dcec",
        "IPY_MODEL_c75cc2a6437f4aa2a13c89cbfc0d6b59",
        "IPY_MODEL_60893d4d66c148b7a23b5ffa9a3a9cc8"
       ],
       "layout":"IPY_MODEL_122f1a60adb446eabf0d1d46f7b41590"
      }
     },
     "2d8aeeff580a418baf99d68bafa28a76":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "72afc887c73840dbaef0b1b8e15a13ef":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "b72af09836ee428f9799f4bdd2723574":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_2d8aeeff580a418baf99d68bafa28a76",
       "style":"IPY_MODEL_72afc887c73840dbaef0b1b8e15a13ef",
       "value":"Downloading (…)lve\/main\/config.json: 100%"
      }
     },
     "21aed38a5c6746588b5a1433de7342fa":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "7b81072415eb4e829bd0a263bec4981d":{
      "model_name":"ProgressStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "004fd063b686414194fedfdae28f5620":{
      "model_name":"FloatProgressModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "bar_style":"success",
       "layout":"IPY_MODEL_21aed38a5c6746588b5a1433de7342fa",
       "max":1664,
       "style":"IPY_MODEL_7b81072415eb4e829bd0a263bec4981d",
       "value":1664
      }
     },
     "90ed107b5e7e426da7a015d5ab935088":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "4931e12c62a244ed80584df571b04ccf":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "2c0928b5ffea4df9b0bc216f42437787":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_90ed107b5e7e426da7a015d5ab935088",
       "style":"IPY_MODEL_4931e12c62a244ed80584df571b04ccf",
       "value":" 1.66k\/1.66k [00:00&lt;00:00, 125kB\/s]"
      }
     },
     "7fe90ca5e6b54392b4baddf1d7332e74":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "3fa2af848a8a41cbb25d0051ca19d2a5":{
      "model_name":"HBoxModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "children":[
        "IPY_MODEL_b72af09836ee428f9799f4bdd2723574",
        "IPY_MODEL_004fd063b686414194fedfdae28f5620",
        "IPY_MODEL_2c0928b5ffea4df9b0bc216f42437787"
       ],
       "layout":"IPY_MODEL_7fe90ca5e6b54392b4baddf1d7332e74"
      }
     },
     "f778cfd2744f4c769408f0f18df25257":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "19f1c25094f04adfa282bdcd94c75f46":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "f2d27a293bcf45f6882fde0dfa7520b5":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_f778cfd2744f4c769408f0f18df25257",
       "style":"IPY_MODEL_19f1c25094f04adfa282bdcd94c75f46",
       "value":"Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
      }
     },
     "df794e7a878540ec8c7d465ce8fd43d0":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "94ab7ed5457c414aa8e6ff3500cb1e07":{
      "model_name":"ProgressStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "cc52da9982614c3ab7c409854d7cb4f0":{
      "model_name":"FloatProgressModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "bar_style":"success",
       "layout":"IPY_MODEL_df794e7a878540ec8c7d465ce8fd43d0",
       "max":1625530125,
       "style":"IPY_MODEL_94ab7ed5457c414aa8e6ff3500cb1e07",
       "value":1625530125
      }
     },
     "5b45241057cb4d05ab3011543e74cd06":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "623ac408911c4eb78ed3e0db70bf6235":{
      "model_name":"DescriptionStyleModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "description_width":""
      }
     },
     "1ee2477ab18c4a029a0aea6a5e7c13b0":{
      "model_name":"HTMLModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "layout":"IPY_MODEL_5b45241057cb4d05ab3011543e74cd06",
       "style":"IPY_MODEL_623ac408911c4eb78ed3e0db70bf6235",
       "value":" 1.63G\/1.63G [00:35&lt;00:00, 50.4MB\/s]"
      }
     },
     "eac2bbba3530485ea5029cde4be730c9":{
      "model_name":"LayoutModel",
      "model_module":"@jupyter-widgets\/base",
      "model_module_version":"1.2.0",
      "state":{
       
      }
     },
     "cc224c41aed9450781ecf9f0ff7d7318":{
      "model_name":"HBoxModel",
      "model_module":"@jupyter-widgets\/controls",
      "model_module_version":"1.5.0",
      "state":{
       "children":[
        "IPY_MODEL_f2d27a293bcf45f6882fde0dfa7520b5",
        "IPY_MODEL_cc52da9982614c3ab7c409854d7cb4f0",
        "IPY_MODEL_1ee2477ab18c4a029a0aea6a5e7c13b0"
       ],
       "layout":"IPY_MODEL_eac2bbba3530485ea5029cde4be730c9"
      }
     }
    }
   }
  },
  "kernelspec":{
   "display_name":"Python",
   "language":"python",
   "name":"python"
  },
  "datalore":{
   "computation_mode":"JUPYTER",
   "package_manager":"pip",
   "base_environment":"default",
   "packages":[
    {
     "name":"evaluate",
     "version":"0.4.0",
     "source":"PIP"
    },
    {
     "name":"datasets",
     "version":"2.10.1",
     "source":"PIP"
    },
    {
     "name":"transformers",
     "version":"4.26.1",
     "source":"PIP"
    },
    {
     "name":"nltk",
     "version":"3.8.1",
     "source":"PIP"
    },
    {
     "name":"rouge-score",
     "version":"0.1.2",
     "source":"PIP"
    }
   ],
   "report_row_ids":[
    
   ],
   "version":2
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}