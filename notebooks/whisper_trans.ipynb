{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Speech to Text\n",
    "\n",
    "This is an example of speech to text modules and using whisper to do transcriptions.\n",
    "\n",
    "In this project we not only transcribe, but also summarize the transcriptions meeting summaries, indeintify speakers etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../services.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"../services.py\"\n",
    "from django.http import HttpResponse\n",
    "from mangorest.mango import webapi\n",
    "from pytube import YouTube\n",
    "from pyannote.audio import Pipeline\n",
    "from pyannote.core import Segment, Annotation, Timeline\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "import whisper, pytube, hashlib, os, datetime, json, torch, pyannote\n",
    "from transformers import pipeline\n",
    "\n",
    "# Taken from https://github.com/yinruiqing/pyannote-whisper\n",
    "class PyanWhisper:\n",
    "    PUNC_SENT_END = ['.', '?', '!']\n",
    "        \n",
    "    def diarize_text(transcribe_res, diarization_result):\n",
    "        timestamp_texts = PyanWhisper.get_text_with_timestamp(transcribe_res)\n",
    "        spk_text = PyanWhisper.add_speaker_info_to_text(timestamp_texts, diarization_result)\n",
    "        res_processed = PyanWhisper.merge_sentence(spk_text)\n",
    "        return res_processed\n",
    "\n",
    "    def get_text_with_timestamp(transcribe_res):\n",
    "        timestamp_texts = []\n",
    "        for item in transcribe_res['segments']:\n",
    "            start = item['start']\n",
    "            end = item['end']\n",
    "            text = item['text']\n",
    "            timestamp_texts.append((Segment(start, end), text))\n",
    "        return timestamp_texts\n",
    "    \n",
    "    def add_speaker_info_to_text(timestamp_texts, ann):\n",
    "        spk_text = []\n",
    "        for seg, text in timestamp_texts:\n",
    "            spk = ann.crop(seg).argmax()\n",
    "            spk_text.append((seg, spk, text))\n",
    "        return spk_text\n",
    "    \n",
    "    def merge_cache(text_cache):\n",
    "        sentence = ''.join([item[-1] for item in text_cache])\n",
    "        spk = text_cache[0][1]\n",
    "        start = text_cache[0][0].start\n",
    "        end = text_cache[-1][0].end\n",
    "        return Segment(start, end), spk, sentence\n",
    "    \n",
    "    def merge_sentence(spk_text):\n",
    "        merged_spk_text = []\n",
    "        pre_spk = None\n",
    "        text_cache = []\n",
    "        for seg, spk, text in spk_text:\n",
    "            if spk != pre_spk and pre_spk is not None and len(text_cache) > 0:\n",
    "                merged_spk_text.append(PyanWhisper.merge_cache(text_cache))\n",
    "                text_cache = [(seg, spk, text)]\n",
    "                pre_spk = spk\n",
    "            elif text[-1] in PyanWhisper.PUNC_SENT_END:\n",
    "                text_cache.append((seg, spk, text))\n",
    "                merged_spk_text.append(PyanWhisper.merge_cache(text_cache))\n",
    "                text_cache = []\n",
    "                pre_spk = spk\n",
    "            else:\n",
    "                text_cache.append((seg, spk, text))\n",
    "                pre_spk = spk\n",
    "        if len(text_cache) > 0:\n",
    "            merged_spk_text.append(PyanWhisper.merge_cache(text_cache))\n",
    "        return merged_spk_text\n",
    "\n",
    "    def write_to_txt(spk_sent, file):\n",
    "        with open(file, 'w') as fp:\n",
    "            for seg, spk, sentence in spk_sent:\n",
    "                line = f'{seg.start:.2f} {seg.end:.2f} {spk} {sentence}\\n'\n",
    "                fp.write(line)\n",
    "            \n",
    "device = \"cpu\"\n",
    "if (torch.cuda.is_available() ):\n",
    "    device = \"cuda\"\n",
    "\n",
    "\n",
    "model = whisper.load_model(\"base\", device=device)\n",
    "\n",
    "def getmodel():\n",
    "    global model;\n",
    "    \n",
    "    if model is None:\n",
    "        model = whisper.load_model(\"base\")\n",
    "        \n",
    "    return model\n",
    "\n",
    "    \n",
    "def transcribe_file(file =\"/Users/snarayan/Desktop/data/audio/index.mp4\", **kwargs):\n",
    "    result = getmodel().transcribe(file)\n",
    "    return result\n",
    "\n",
    "def splitIntoParas(tr, nLinesPerPara=4):\n",
    "    n= nLinesPerPara\n",
    "    l=tr.get('segments', [])\n",
    "    ret = \"\"\n",
    "    for i,j in enumerate(l[::n]):\n",
    "        a, b = i*n, i*n + n\n",
    "        o = \"\".join([j['text'] for j in l[a:b]])\n",
    "        ret += o.strip() + \"\\n\\n\";\n",
    "        #print(f'{a}-{b} {o} \\n')\n",
    "        \n",
    "    return ret\n",
    "\n",
    "test_url = \"https://www.youtube.com/watch?v=DuSDVj9a4WM&list=PLEpvS3HCVQ5_ZlyF1_i-WSwBzLoDLxoc9\"\n",
    "#--------------------------------------------------------------------------------------------------------    \n",
    "@webapi(\"/scribe/transcribe_youtube/\")\n",
    "def transcribe_youtube( url = test_url , force_download=False, force_transribe=False, **kwargs):    \n",
    "    h = hashlib.md5(url.encode())\n",
    "    file = \"/tmp/\" + str(h.hexdigest()) + \".mp4\"\n",
    "    \n",
    "    if (force_download or not os.path.exists(file)):  \n",
    "        file = YouTube(url).streams.filter(only_audio=True).first().download(filename=file)\n",
    "\n",
    "    print( f\"File: {file}\")\n",
    "    if (force_transribe or not os.path.exists(file +\".txt\")):  \n",
    "        print( f\"Calling transcription: {file}.txt\")\n",
    "        tr = getmodel().transcribe(file)\n",
    "        ret = splitIntoParas(tr)\n",
    "        with open(file +\".txt\", \"w\") as f:\n",
    "            f.write(ret)\n",
    "        with open(file +\".json\", \"w\") as f:\n",
    "            f.write(str(tr))\n",
    "            \n",
    "        transcription = ret\n",
    "    else:\n",
    "        with open(file +\".txt\", \"r\") as f:\n",
    "            transcription = f.read()\n",
    "        \n",
    "    return transcription;\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------    \n",
    "@webapi(\"/parrot/transcribe_wavinput/\")\n",
    "def transcribe_wavinput(url, **kwargs):\n",
    "    print(\"Hi: \" + url)\n",
    "    if url.method == 'POST':\n",
    "        file = request.FILES['file']\n",
    "        print(\"I'm in\")\n",
    "    # ret = \"\\n\\n My Name is: \" + n + \"\\n\"\n",
    "    # for g in kwargs:\n",
    "    #     if (g ==\"request\"):\n",
    "    #         continue;\n",
    "    #     ret += g + \" \" + kwargs.get(g) + \"\\n\"\n",
    "    # return ret\n",
    "    \n",
    "#--------------------------------------------------------------------------------------------------------    \n",
    "@webapi(\"/parrot/uploadfile\")\n",
    "def uploadfile(request,  **kwargs):\n",
    "    par = dict(request.GET)\n",
    "    par.update(request.POST)\n",
    "\n",
    "    DESTDIR =\"/tmp/parrot/\"    \n",
    "    if (not os.path.exists(DESTDIR)):\n",
    "        os.makedirs(DESTDIR)\n",
    "    \n",
    "    ret = \"File:\\n\"\n",
    "    for f in request.FILES.getlist('file'):\n",
    "        content = f.read()\n",
    "        filename = f\"{DESTDIR}{str(f)}\"\n",
    "        print(f\"\\nSaved file: {filename}\")\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(content)\n",
    "        ret += filename + \"\\n\"\n",
    "\n",
    "    print(\"Retuning \", ret)\n",
    "    return ret\n",
    "\n",
    "#--------------------------------------------------------------------------------------------------------    \n",
    "@webapi(\"/parrot/processfile\")\n",
    "def processfile(request, force_transribe=False, **kwargs):\n",
    "    print(\"\\nProcessing file: \", kwargs)\n",
    "\n",
    "    ret = uploadfile(request, **kwargs)\n",
    "    f = ret.split('\\n')[1]\n",
    "    \n",
    "    # Pyannote and Bart\n",
    "    diarizer = Pipeline.from_pretrained(\"pyannote/speaker-diarization@2.1\",\n",
    "                                    use_auth_token=\"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\")\n",
    "    summarizer = pipeline(\"summarization\", \"knkarthick/MEETING-SUMMARY-BART-LARGE-XSUM-SAMSUM-DIALOGSUM-AMI\", truncation=True)\n",
    "\n",
    "    print( f\"Calling transcription: {f}\\n\")\n",
    "    result = model.transcribe(f)\n",
    "    diarization = diarizer(f)\n",
    "    final_result = PyanWhisper.diarize_text(result, diarization)\n",
    "    \n",
    "    # Write to a new file\n",
    "    ret = \"\"\n",
    "    with open(f +\".txt\", \"w\") as new_f:\n",
    "        for seg, spk, sent in final_result:\n",
    "            line = f'{spk}:{sent}\\n'\n",
    "            new_f.write(line)                               \n",
    "            ret += line\n",
    "        transcription = ret\n",
    "    \n",
    "    # Generate Summary  \n",
    "    print(\"Summarizing...\")\n",
    "    summary = summarizer(transcription,min_length = 100,max_length=500)[0]['summary_text']\n",
    "\n",
    "    \n",
    "    print(\"\\n\\n\" + summary)\n",
    "    response = {'transcription': transcription, 'summary': summary}\n",
    "    return HttpResponse(json.dumps(response), content_type='application/json')    \n",
    "#-----------------------------------------------------------------------------------\n",
    "def process(sysargs):\n",
    "    print(\"Parsing and processing\")\n",
    "    \n",
    "    if (sysargs.url.strip()):\n",
    "        print( f\"Transcribing {sysargs.url}\")\n",
    "        transcribe_youtube(sysargs.url.strip())\n",
    "    \n",
    "#-----------------------------------------------------------------------------------\n",
    "sysargs=None\n",
    "def addargs():\n",
    "    global sysargs\n",
    "    p = argparse.ArgumentParser(f\"{os.path.basename(sys.argv[0])}:\")\n",
    "    p.add_argument('-u', '--url', type=str, default=\"\", help=\"Youtube URL\")\n",
    "    try:\n",
    "        sysargs, unknown=p.parse_known_args(sys.argv[1:])\n",
    "    except argparse.ArgumentError as exc:\n",
    "        print(exc.message )\n",
    "        \n",
    "    if (unknown):\n",
    "        print(\"Unknown options: \", unknown)\n",
    "        #p.print_help()\n",
    "    return sysargs    \n",
    "#-----------------------------------------------------------------------------------\n",
    "if __name__ == '__main__':\n",
    "    if (not colabexts.jcommon.inJupyter()):\n",
    "        t1 = datetime.datetime.now()\n",
    "        sysargs = addargs()\n",
    "        ret = process(sysargs)\n",
    "        t2 = datetime.datetime.now()\n",
    "        print(f\"#All Done in {str(t2-t1)} ***\")\n",
    "    else:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n My Name is: babui\\nan sada\\nj ewuiorwerwoe\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myName(\"babui\", an='sada', j=\"ewuiorwerwoe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1 = datetime.datetime.now() \n",
    "#tr = transcribe_youtube()\n",
    "dt2 = datetime.datetime.now() \n",
    "#--------------------------------------------------------------------------------------------------------    \n",
    "@webapi(\"/parrot/processfile\")\n",
    "def processfile(request, force_transribe=False, **kwargs):\n",
    "    print(\"\\nProcessing file: \", kwargs)\n",
    "\n",
    "    ret = uploadfile(request, **kwargs)\n",
    "    f = ret.split('\\n')[1]\n",
    "    \n",
    "    # Pyannote and Bart\n",
    "    diarizer = Pipeline.from_pretrained(\"pyannote/speaker-diarization@2.1\",\n",
    "                                    use_auth_token=\"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\")\n",
    "    # bart = BartForConditionalGeneration.from_pretrained(\"knkarthick/MEETING-SUMMARY-BART-LARGE-XSUM-SAMSUM-DIALOGSUM-AMI\"\")\n",
    "    # tokenizer = BartTokenizer.from_pretrained(\"\"knkarthick/MEETING-SUMMARY-BART-LARGE-XSUM-SAMSUM-DIALOGSUM-AMI\"\")\n",
    "    summarizer = pipeline(\"summarization\", \"knkarthick/MEETING-SUMMARY-BART-LARGE-XSUM-SAMSUM-DIALOGSUM-AMI\", truncation=True)\n",
    "\n",
    "\n",
    "    print( f\"Calling transcription: {f}\\n\")\n",
    "    result = model.transcribe(f)\n",
    "    diarization = diarizer(f)\n",
    "    final_result = PyanWhisper.diarize_text(result, diarization)\n",
    "    \n",
    "    # Write to a new file\n",
    "    ret = \"\"\n",
    "    with open(f +\".txt\", \"w\") as new_f:\n",
    "        for seg, spk, sent in final_result:\n",
    "            line = f'{spk}:{sent}\\n'\n",
    "            new_f.write(line)                               \n",
    "            ret += line\n",
    "        transcription = ret\n",
    "    \n",
    "    # Generate Summary  \n",
    "    print(\"Summarizing...\")\n",
    "    # input_ids = tokenizer.encode(transcription, return_tensors=\"pt\", truncation=True)\n",
    "    # with torch.no_grad():\n",
    "    #     outputs = bart.generate(input_ids)\n",
    "    # summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    summary = summarizer(transcription,min_length = 100,max_length=500)[0]['summary_text']\n",
    "\n",
    "    \n",
    "    print(\"\\n\\n\" + summary)\n",
    "    response = {'transcription': transcription, 'summary': summary}\n",
    "    return HttpResponse(json.dumps(response), content_type='application/json')    "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "whisperpyanndjango",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "46fee864bb45ac05443617bef70632a4a93ed12da25561ee732060b0c7acf590"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
