0:00:00	SPEAKER_00
 Okay, does anyone want to see Steve's feedback from the specification?

0:00:16	SPEAKER_06
 Is there much more in it than you said yesterday?

0:00:21	SPEAKER_00
 Not really, just what he was talking about, the duplication of effort.

0:00:26	SPEAKER_00
 Duplication of effort and stuff.

0:00:31	SPEAKER_00
 And shame that we should maybe think about having a prototype or a weak sex.

0:00:38	SPEAKER_00
 Which is necessary.

0:00:41	SPEAKER_00
 So, this is probably why all the times are...

0:00:46	SPEAKER_06
 Yeah, I'd say if for the prototype it's just like wherever possible, chunking the stuff that we have pre-annotated and stuff.

0:00:56	SPEAKER_06
 And for the stuff that we don't get pre-annotated right like a stupid baseline, then we should probably be able to...

0:01:02	SPEAKER_06
 Basically, that means we focus on the interface first, so that we take the ready-made parts and just see how we get them to get into the interface the way we want them.

0:01:10	SPEAKER_06
 And then we have a working prototype and then we can go back and replace pieces either by our own components or by more sophisticated components of our own.

0:01:18	SPEAKER_06
 So it's probably feasible.

0:01:20	SPEAKER_06
 I think I'm away this weekend.

0:01:24	SPEAKER_04
 So, we need...

0:01:26	SPEAKER_04
 We just want to have some data for the user face could even be random data.

0:01:33	SPEAKER_06
 Oh yeah, no. But also, the similarity thing, just my matrix itself for my stuff.

0:01:40	SPEAKER_06
 I think I can do that very quickly because I have the algorithm.

0:01:44	SPEAKER_06
 Yeah, I think today's meeting is really the one where we sort of settle down the data structure and as soon as we have that, probably like after today's meeting, we then actually need to...

0:01:54	SPEAKER_06
 Well, go back first of all and look at NIDEC smell to see how far that...

0:01:58	SPEAKER_06
 That which we want is compatible with NIDEC smell offers us.

0:02:02	SPEAKER_06
 And then just sort of everyone, make sure everyone understands the interface.

0:02:08	SPEAKER_06
 So, I think if today we decide on what data we want to have now and later maybe even today we go and look at NIDEC smell or some of us look at NIDEC smell in a bit more detail, just trying to make some sense of that code and see how does the representation work in their system.

0:02:25	SPEAKER_06
 And then sort of with that knowledge, we should be able to then say, okay, that type of NIDEC smell data, we want to load into it and this is how everyone can access it.

0:02:34	SPEAKER_06
 And then we should be able to go for it.

0:02:38	SPEAKER_00
 We'll do a job report for now.

0:02:42	SPEAKER_06
 But look at the documentation and like, seeing enough to make me think that if you want to use the NIDEC smell framework because they have a good event model that synchronizes sort of the data and in every display element.

0:02:55	SPEAKER_06
 So that takes a lot of work away from us.

0:02:57	SPEAKER_06
 Sort of that would be a reason for staying within their framework and using their general classes.

0:03:01	SPEAKER_06
 But beyond that I haven't looked at it at all.

0:03:05	SPEAKER_06
 Which is something we should really do.

0:03:07	SPEAKER_06
 Who actually like for this whole discussion, I mean who of us is doing stuff that is happening online and who of us is doing stuff that's happening offline.

0:03:16	SPEAKER_06
 Like my data is coming.

0:03:31	SPEAKER_04
 The basic word and thought is a fine as well.

0:03:34	SPEAKER_04
 The combined measure might not be if we want to wait for the user has typed into the search.

0:03:41	SPEAKER_05
 Okay.

0:03:47	SPEAKER_05
 There won't be any process in 10 to 10 to yes.

0:03:52	SPEAKER_06
 So basically apart from the display module, the display itself, we don't have an extremely high degree of interaction between sort of our modules that create the stuff and the interface.

0:04:05	SPEAKER_06
 The interface is mainly while it's running just working on data that's just loaded from a file I guess.

0:04:12	SPEAKER_00
 I don't know if the search function or something like that.

0:04:15	SPEAKER_00
 It depends how it's going to work.

0:04:18	SPEAKER_06
 Yeah, the search is sort of a strange beast anyway because for the search we're leaving the 9x smell framework.

0:04:28	SPEAKER_06
 But that's still sort of that's good that means that at least like we don't have the type of situation where somebody has to do like a billion calculations on data online.

0:04:38	SPEAKER_06
 That would make it a lot more like that would mean that our interface for the data would have to be a lot more careful about how it performs and everything.

0:04:45	SPEAKER_06
 And nobody is modifying that data at online time at all.

0:04:49	SPEAKER_06
 It seems nobody is making any changes to the actual data online.

0:04:55	SPEAKER_06
 So that's actually making it a lot easier. That basically means our browser really is a viewer mostly which isn't doing much with the data except for sort of selecting a piece of bit and then to save it.

0:05:11	SPEAKER_05
 Are we still going to go into the database?

0:05:13	SPEAKER_05
 Are we still going to dump it into the database?

0:05:15	SPEAKER_06
 Well some parts relevant for the search, yes.

0:05:18	SPEAKER_05
 I'd say so because if we are I recommend all read-off classes out of the database it'd be so much easier.

0:05:26	SPEAKER_05
 What if we're going to dump the part of the inter-data database anyway and most of our dump all the fields you want into the database, calculate everything from there.

0:05:36	SPEAKER_05
 Then we don't even have to worry that much about the underlying XML representation and just query it.

0:05:43	SPEAKER_06
 But nobody of us is doing much of searching from the data in the online stage.

0:05:48	SPEAKER_06
 And for altogether like the display itself I think we are easier if it's sitting on the XML than if it's sitting on the SQL stuff because if it's sitting on the XML we have the night XML framework with all its functionality for synchronizing through all the different levels whenever there's a change whenever something's moving forward and stuff and we can just look at their code like how their player moves forward and how that moving forward is represented in different windows and stuff.

0:06:15	SPEAKER_06
 So I think in the actual browser itself I don't want to sit on the SQL if we can sit on the XML, if we're sitting on the XML we have so much help.

0:06:24	SPEAKER_06
 And for like the calculations that we're doing apart from the search it seems everyone needs some special representations anyway.

0:06:40	SPEAKER_06
 Even our results, yeah in the night XML XML format so with the timestamps and stuff so that it's easy to tie together things.

0:06:54	SPEAKER_06
 So we have to think about is if we go with this multi-level idea like this idea that sort of if you start with the whole meeting series as one entity as one thing that you display as one whole sort of that then the individual chunks are the individual meetings and then you can click on a meeting and then sort of the meeting is the whole thing and the chunks are the individual segments that means sort of we have multiple levels of representation which we probably, if we do it this way like we have to discuss that if we do it this way then we should probably find some abstraction model so that the interface in the sense like deals with it is if it's the same so that the interface doesn't really have to worry whether it's a meeting in the whole meeting series or a segment within a meeting you know what I mean.

0:07:41	SPEAKER_06
 And that's probably stuff that we have to sort of like process twice then like for example that like the summary of a meeting within the whole meeting corpus or meeting series.

0:07:51	SPEAKER_06
 This meeting series is a good word that I don't really know how to call it you know what I mean like not the whole corpus but every meeting that has to do with one topic.

0:08:00	SPEAKER_06
 And so in the meeting series that a summary for a meeting within the meeting series is sort of compiled offline by a summary module and that is separate from a summary of a segment within a meeting.

0:08:13	SPEAKER_05
 So I don't think we can, we don't even need to do that because we got our information density calculated offline so all we do is treat the whole lot as one massive document I mean no it's not me so big we can't load in information density for the

0:08:29	SPEAKER_04
 meeting. I mean just summarize based on that. I thought we would just have like one big summary of only different importance levels displayed on it and depending on what our zoom level is we just display a part of it. So are we doing that at all levels are we. I mean we would have one very big thing offline and from that we would just select what we are displaying and just have different like fine greatnessness levels sort of.

0:09:02	SPEAKER_04
 Yes. So for example you would give a high value to those sequences you want to display in the meeting series summary.

0:09:12	SPEAKER_06
 So the only thing that would happen basically if I double click let's say from the whole meeting series on a single meeting is that the zoom level changes like the start and the end position changes and the zoom level changes.

0:09:26	SPEAKER_04
 That was what I saw.

0:09:28	SPEAKER_06
 I think we can do it online.

0:09:30	SPEAKER_06
 I thought we couldn't do that. I was under the impression that we couldn't do that because we couldn't load the data for all that.

0:09:36	SPEAKER_05
 But I don't know I mean that I don't think there's really much point in doing like that when it's just going to feed off in the end the information density measurement basically and that's all calculated offline.

0:09:49	SPEAKER_05
 So all you're really doing is sorting the list.

0:09:52	SPEAKER_05
 Is the computation hard part of it.

0:09:56	SPEAKER_05
 So I'm not sure if I got it. Well like the ideas we're calculating our information density offline first where the options in the whole core.

0:10:06	SPEAKER_05
 So you do is you say if you're looking at a series of meetings you say well our whole document comprises of all these who's stuck together and then all you have to do is sort them by information density like maybe wake up with the search terms.

0:10:22	SPEAKER_05
 So I think it's too slow to online to be honest.

0:10:28	SPEAKER_06
 I was just worried about the total memory complexity of it but I really did.

0:10:32	SPEAKER_06
 I mean I just sort of like took that from something that Jonathan once said about not loading everything but maybe I was just wrong about it.

0:10:39	SPEAKER_04
 But I think the difference might be that we would just want to have the words and that's not so much what he meant was not possibly loading everything was.

0:10:52	SPEAKER_04
 Yeah.

0:10:53	SPEAKER_04
 Load all the annotation stuff all the sound files.

0:10:57	SPEAKER_06
 So what we have is we would have a word like we would have words with some priority levels.

0:11:05	SPEAKER_06
 And that would basically be it already because even the selection would the summaries automatically feed from just how prioritize an individual word or how prioritize an individual utterances or other summaries sort of refined from that and made by a machine to make sentences and stuff.

0:11:21	SPEAKER_06
 Or are they just sort of taking out the words of the highest priority and then the words of the second highest priority.

0:11:26	SPEAKER_05
 No, the options.

0:11:28	SPEAKER_05
 The options is like mean.

0:11:36	SPEAKER_05
 The whole thing on the afterance level or we're doing it on the word level like the information that we're doing on the word level is if you want the audio to sync up you've got no way of getting in and extracting just that word.

0:11:42	SPEAKER_05
 I mean it's impossible.

0:11:44	SPEAKER_06
 I think we have started an end time for words that could be every single word.

0:11:47	SPEAKER_06
 Yeah but it might sound crazy in the player we should really maybe we can do that together at some point today that we checked out how the player works.

0:11:54	SPEAKER_06
 I don't think but there's maybe some marriage in altogether doing it on a matter and I'm getting quite lost.

0:12:00	SPEAKER_04
 Because what's our difference between the the importance measure and the skimming and do we do both or is it the same thing.

0:12:14	SPEAKER_05
 Well the skimming is going to use the importance.

0:12:19	SPEAKER_04
 But when you talk about summaries you talk about this about skimming and that.

0:12:25	SPEAKER_05
 Well mostly skimming.

0:12:27	SPEAKER_06
 But also about the displays in the in the text body in the in the latest draft that we had sort of became up with the idea that it isn't displaying after and part of it's also displaying a summarized version in you know like below the below the graph apart.

0:12:42	SPEAKER_06
 Yeah.

0:12:43	SPEAKER_06
 Maybe.

0:12:45	None
 Yeah.

0:12:46	SPEAKER_04
 Yeah.

0:12:49	SPEAKER_04
 Isn't that just.

0:12:51	SPEAKER_06
 Oh yeah it's just like there's like audio skimming and there's displayed skimming.

0:12:55	SPEAKER_04
 Yeah but it's just same data.

0:12:57	SPEAKER_06
 Yeah.

0:12:58	SPEAKER_06
 Yeah.

0:12:59	SPEAKER_06
 Maybe there's some merit of going all together for our trans level and not even bother to calculate.

0:13:04	SPEAKER_06
 I mean if you have to do it internally then you can do it but maybe like not even store the importance level for individual words and just sort of rank utterances as a whole.

0:13:13	SPEAKER_05
 The other thing about that is that we would say that we would say that we would be in sentences more or less.

0:13:18	SPEAKER_05
 Yeah.

0:13:19	SPEAKER_06
 So it might more sense than you would just extract it.

0:13:21	SPEAKER_06
 It might be better skimming and less memory required at the same time and I mean if you know how to do it for individual words then you can just in the worst case if you can't find anything else just sort of make the mean of the words over the utterance.

0:13:31	SPEAKER_04
 You know what I mean.

0:13:33	SPEAKER_04
 Not quite.

0:13:34	SPEAKER_04
 So what did you want to do?

0:13:35	SPEAKER_04
 You just wanted to assign.

0:13:37	SPEAKER_06
 What's the smallest chunk at the moment you're thinking of assigning importance measure to is it a word or is it a matter.

0:13:42	SPEAKER_04
 I thought about words.

0:13:44	SPEAKER_06
 So we're thinking of like maybe just storing it on a preference level.

0:13:50	SPEAKER_06
 Because it's less stuff to store probably for days in the audio playing and for in the display it's probably better if you have whole utterances than I don't know like what it's like if you just take single words out of utterances.

0:14:03	SPEAKER_06
 It probably doesn't make any sense at all whereas if you just show important utterances but the utterances a whole it makes more sense.

0:14:08	SPEAKER_06
 So it doesn't actually make a difference for your algorithm because it just means that if you work on a word level then we just mean it over the output.

0:14:16	SPEAKER_04
 Yeah I think we also thought about combining that matter with the matter as I get from hotspots and so on.

0:14:25	SPEAKER_04
 So that would also be on a short step.

0:14:29	SPEAKER_04
 So that's good anyway then.

0:14:30	SPEAKER_06
 Yeah.

0:14:31	SPEAKER_06
 Because that makes it a lot easier than to put it on an error.

0:14:33	SPEAKER_06
 But how about those words which don't carry any meaning at all?

0:15:01	SPEAKER_04
 Because if we ever reach over over whole utterances other words and there are quite unimportant words in there but quite important words as well.

0:15:13	SPEAKER_04
 I think we should just disregard them.

0:15:17	SPEAKER_05
 Maybe we should have like a cutter or something.

0:15:20	SPEAKER_05
 So it's a word that only gets about a certain threshold so anything that has less than 0.5 importance gets assigned to zero.

0:15:31	SPEAKER_06
 Or we do a pre-filtering of sort of the whole thing sort of like the other.

0:15:34	SPEAKER_06
 But the problem with that is it's easy to do in the text level but that would mean it would still play the error in your audio unless we sort of also store what pieces we cut out for the audio.

0:15:49	SPEAKER_06
 Yeah.

0:15:50	SPEAKER_06
 I think before we can like answer that specific question how we deal with that it's probably good for us to look at what the audio player is capable of doing.

0:15:58	SPEAKER_05
 I think we'll have to buffer.

0:16:00	SPEAKER_05
 Yeah.

0:16:01	SPEAKER_05
 I don't think it'll be very hard.

0:16:02	SPEAKER_05
 I think it'll be like an hour please work.

0:16:04	SPEAKER_05
 So what do you mean the buffering like you think the director is feeding another way for it essentially.

0:16:11	SPEAKER_05
 Yeah.

0:16:12	SPEAKER_06
 But not but not store it on the heart as can they load it in but load it indirectly from memory.

0:16:17	SPEAKER_05
 Yeah.

0:16:19	SPEAKER_05
 So just like there's down to like a media wave object or something like that.

0:16:23	SPEAKER_06
 But it's probably a stream if it exists each other it would probably some binary stream going in sometime.

0:16:28	SPEAKER_05
 I have no idea.

0:16:29	SPEAKER_05
 They must have like classes for dealing with fire is needed to have classes with concaten if I was even doing that.

0:16:37	SPEAKER_06
 Okay.

0:16:38	SPEAKER_06
 So I mean so that means that there's probably even if you go on a preference level there's still some merit on within utterances cutting out stuff which clearly isn't relevant at all.

0:16:46	SPEAKER_06
 Maybe also for the audio we'd have to do so.

0:16:48	SPEAKER_06
 Let's say we play the whole phrase but then in addition to that we have some information that says minus that part of something.

0:16:55	SPEAKER_06
 That's okay that we can do.

0:16:56	SPEAKER_05
 Oh I think I might try and build this basically a class that you just feed it a linked list of different waveforms that will just string them all together with what might be 10th and the second silence in between each one.

0:17:12	SPEAKER_06
 Yeah.

0:17:13	SPEAKER_06
 So maybe even I mean that sort of depends on how advanced we get.

0:17:17	SPEAKER_06
 If maybe if you realize that there's massive differences in gain or in something you can probably just make some simple normalization but that really depends on how much time you have and how much is necessary.

0:17:26	SPEAKER_06
 Yeah.

0:17:27	SPEAKER_06
 I don't know anything about audio and I have never seen the player so if you find that the player accepts some input from memory and if it's easy to do then I guess that's fairly doable.

0:17:36	SPEAKER_06
 So that means in the general structure we're actually quite lucky so we have we loaded to memory for the whole series of meetings.

0:17:43	SPEAKER_06
 Just the utterances and rankings for the utterances.

0:17:47	SPEAKER_06
 And some information probably that says well I guess that goes with the utterances who's speaking.

0:17:53	SPEAKER_05
 Oh yeah.

0:17:54	SPEAKER_06
 Because then we can also do the display about who's speaking.

0:17:56	SPEAKER_05
 We also really want the other search by who's speaking as well.

0:18:00	SPEAKER_02
 Yeah.

0:18:03	SPEAKER_06
 But I'm still confused because I thought like that's just what Jonathan said that we can't do like load massive document of that size.

0:18:12	SPEAKER_06
 But yeah.

0:18:13	SPEAKER_05
 Yeah.

0:18:14	SPEAKER_05
 Because all the calculations gone offline.

0:18:20	SPEAKER_06
 The other hand I mean it shouldn't be like 50 megabyte in RAM or something.

0:18:24	SPEAKER_06
 It shouldn't be massive.

0:18:26	SPEAKER_06
 Maybe 100 megabytes is quite busy.

0:18:36	SPEAKER_06
 Just thinking what's this sim.

0:18:38	SPEAKER_06
 So we do get an error message with the project if we load everything into the project with all the data they load.

0:18:46	SPEAKER_06
 So we know that doesn't work.

0:18:48	SPEAKER_06
 So our hope is essentially that we load less into it.

0:18:51	SPEAKER_06
 Yes.

0:18:52	SPEAKER_06
 So this is lazy loading things. I'm going to explain lazy loading.

0:18:56	SPEAKER_00
 It's on the map when it needs a particular type of file.

0:19:02	SPEAKER_06
 Like when it's being answered.

0:19:04	SPEAKER_06
 So that is that only by type of file.

0:19:06	SPEAKER_06
 Like if if the same thing is in different files would it then maybe like you know if if up trends are split over three or 10 or 100 different files.

0:19:17	SPEAKER_06
 Is that a chance movie that it doesn't try to load the model memory at the same time but just.

0:19:21	SPEAKER_00
 I think that's idea.

0:19:23	SPEAKER_06
 Why does it fail then in the first place and it shouldn't ever fail because then it should never.

0:19:27	SPEAKER_00
 If you would in a search over the whole corpus you'd talk to them all.

0:19:31	SPEAKER_06
 Yeah but it failed right when you load it right.

0:19:35	SPEAKER_06
 It's interesting.

0:19:39	SPEAKER_04
 It's just a different baseline.

0:19:43	SPEAKER_04
 So it's just a different way to load it.

0:19:51	SPEAKER_04
 For example it loads all the advances and so on but it doesn't load the discourse acts and.

0:19:57	SPEAKER_04
 So it's not the most.

0:20:01	SPEAKER_04
 Not the summaries.

0:20:04	SPEAKER_06
 Let's check that out.

0:20:06	SPEAKER_06
 I'll probably ask Jonathan about it.

0:20:09	SPEAKER_06
 So alternatively if we realize that we can't do the whole thing in one go we can probably just process some sort of meta data you know what I mean like sort of for the whole serious.

0:20:21	SPEAKER_06
 Chunks representing the individual.

0:20:25	SPEAKER_06
 Meetings are something.

0:20:27	SPEAKER_06
 Like something that represents the whole serious.

0:20:31	SPEAKER_06
 In a in a structure very similar to the structure in which we represent individual meetings.

0:20:37	SPEAKER_06
 But with data sort of always combined from the whole.

0:20:41	SPEAKER_06
 Serious so instead of having a single utterance that we display it probably be like.

0:20:45	SPEAKER_06
 That would be representing a whole.

0:20:49	SPEAKER_06
 Topic a segment in a meeting.

0:20:53	SPEAKER_06
 And so that using the same data.

0:20:55	SPEAKER_04
 You mean that you basically split up the big thing into different.

0:21:01	SPEAKER_04
 Some of these.

0:21:05	SPEAKER_04
 That you have a very.

0:21:09	SPEAKER_04
 Top level summary and.

0:21:13	SPEAKER_06
 Separate file.

0:21:15	SPEAKER_06
 I think in the sense of like creating a virtual a virtual meeting out of the whole meeting series sort of.

0:21:21	SPEAKER_05
 Easy just like.

0:21:23	SPEAKER_06
 Create a new.

0:21:25	SPEAKER_06
 Yeah sort of like offline create a virtual meeting which basically treats the meeting series is if it was a meeting and treats the individual meetings within the meeting series.

0:21:29	SPEAKER_06
 If they were segments and treats the individual segments within.

0:21:33	SPEAKER_06
 Meetings is if they were.

0:21:37	SPEAKER_06
 Up fences you know so we just sort of shifted one level up.

0:21:41	SPEAKER_06
 And that way we could probably use the same algorithm.

0:21:45	SPEAKER_06
 And just like make like one or two if that say okay if you are on.

0:21:49	SPEAKER_06
 Whole document a whole serious level and that was a double click then.

0:21:53	SPEAKER_06
 Don't just go into that segment but load a new file or something like it.

0:21:57	SPEAKER_06
 But in general use the same algorithm that would be an alternative if you can't actually load the whole thing and.

0:22:05	SPEAKER_06
 Because also like even if we.

0:22:07	SPEAKER_06
 Maybe this whole like maybe I'm worrying too much about the whole serious.

0:22:11	SPEAKER_06
 In one thing display because actually I mean probably users wouldn't.

0:22:15	SPEAKER_06
 You that one too.

0:22:17	SPEAKER_05
 It's really that much.

0:22:19	SPEAKER_05
 But what we can do is just roll the offline stuff and all we can do is just process.

0:22:27	SPEAKER_05
 Like the summarization say you wanted a hundred options in the summary.

0:22:31	SPEAKER_05
 Just look at the meeting take your top 100.

0:22:33	SPEAKER_05
 After it's neat other needs in it.

0:22:35	SPEAKER_05
 It's goes higher and the one's already in the.

0:22:39	SPEAKER_05
 Summary so far just replacing and then you only have to process one meeting at a time.

0:22:43	SPEAKER_06
 Yeah but I'm still worried like for example for the display.

0:22:47	SPEAKER_06
 If you actually if you wanted to play like for the whole serious.

0:22:51	SPEAKER_06
 The information density levels based on and the only granularity has individual.

0:22:57	SPEAKER_06
 That means you have to go through everything.

0:23:00	SPEAKER_06
 That friends in a series of 70 hours of meeting.

0:23:04	SPEAKER_05
 So maybe we should.

0:23:05	SPEAKER_05
 Store a main measure.

0:23:07	SPEAKER_05
 Yeah.

0:23:09	SPEAKER_05
 Yeah.

0:23:10	SPEAKER_06
 And if you make that structurally very similar to.

0:23:13	SPEAKER_06
 The like one level down like the way how we store in which latrances and stuff.

0:23:18	SPEAKER_06
 Maybe we can more or less use the same code and just.

0:23:20	SPEAKER_06
 Make a few ifs and stuff.

0:23:22	SPEAKER_06
 So but still so in general we having we having.

0:23:28	SPEAKER_06
 Atrances.

0:23:30	SPEAKER_06
 And they have a score.

0:23:33	SPEAKER_06
 And that's as much as we really need.

0:23:38	SPEAKER_06
 And they also have a time.

0:23:44	SPEAKER_06
 Of course.

0:23:46	SPEAKER_05
 And speaker information.

0:23:48	SPEAKER_05
 Yeah.

0:23:49	SPEAKER_05
 Top.

0:23:50	SPEAKER_06
 Yeah so an information which topic they are in.

0:23:53	SPEAKER_06
 And probably separate to that information about the different topics like that.

0:23:58	SPEAKER_06
 Yeah.

0:24:00	SPEAKER_06
 So.

0:24:02	SPEAKER_06
 So the skimming can work on that as the skimming just sort of sorts the utterances and puts as many in as it needs.

0:24:09	SPEAKER_05
 Oh yeah.

0:24:10	SPEAKER_05
 So.

0:24:11	SPEAKER_05
 Preserve the order when it's displayed.

0:24:14	SPEAKER_06
 Yeah.

0:24:15	SPEAKER_06
 Yeah it'll play them in some order in which they were set.

0:24:19	SPEAKER_06
 Otherwise it's going to be more entertaining.

0:24:23	SPEAKER_06
 But that that's enough data for the skimming.

0:24:26	SPEAKER_06
 Yeah.

0:24:27	SPEAKER_06
 And the searching for what the searching does is the searching leaves the whole framework.

0:24:31	SPEAKER_06
 Goes to the SQL database.

0:24:33	SPEAKER_06
 And gets like basically in the end gets just a time marker for whether it's like that utterance that you're concerned with.

0:24:40	SPEAKER_06
 And then we have to find I'm sure there's some way in the night XML to just say set position to that time mark.

0:24:46	SPEAKER_06
 And then it shifts the whole frame in the deluxe everything the element of the display and the display updates.

0:24:51	SPEAKER_00
 You don't want to go to the old tree display as well for multiple results.

0:24:55	SPEAKER_00
 Yeah.

0:24:56	SPEAKER_06
 Yeah.

0:24:57	SPEAKER_00
 Yeah.

0:24:58	SPEAKER_06
 Yeah but so so if if some.

0:25:00	SPEAKER_06
 So if in that tree display somebody clicks on something.

0:25:03	SPEAKER_00
 Each time the train is up.

0:25:05	SPEAKER_06
 Yeah and then you sort of feed the timestamp to the night XML central manager and that central manager alerts everything that's there like alerts the skim like the audio display alerts the text display alerts the visual display and says we have a new time frame and then they all sort of do the update routines with respect to the current level of soon so how much to display and starting position at where the.

0:25:27	SPEAKER_06
 Or maybe the mid position of it.

0:25:30	SPEAKER_06
 I don't know like if you start with the thing was found or if that thing was found is in the middle of the part that we displayed that I don't know what that we can decide about but it general sort of.

0:25:40	SPEAKER_06
 It's the same thing if like whether you play and it moves forward or whether you jump to a position through search it's essentially for all the window handling it's the same event.

0:25:49	SPEAKER_06
 Yeah, it's only that the event gets triggered by the search routine which would have pushed it into the text and says, please go there now.

0:25:58	SPEAKER_05
 So we should basically make our next document in memory.

0:26:04	SPEAKER_05
 That everyone's module changes that rather than the underlying data and then have that.

0:26:14	SPEAKER_05
 Why do we have to remember?

0:26:19	SPEAKER_05
 You can make it.

0:26:22	SPEAKER_06
 I mean like the information is coming from offline.

0:26:28	SPEAKER_06
 So we probably we don't even have to change the utterance document right because the whole way like the whole beauty of the night ex melis that it ties together lots of different files we can just create an additional ex-mail file which for every utterance like the utterance of ideas I presume some references.

0:26:43	SPEAKER_06
 So we just we tie just very short ex-mail file which is the only information it has it has whatever a number for for the wait for the information that we just tie that to the existing utterance and tie them to the existing speaker changes.

0:27:00	SPEAKER_04
 But there's no idea for that.

0:27:14	SPEAKER_04
 I think it's just one.

0:27:19	SPEAKER_06
 So we have to go over it like add some integer that we just increment from top to bottom sort of to every other as an ID.

0:27:36	SPEAKER_06
 Sometimes or try to understand how not to tell ideas work and maybe that's a special rule to follow when we use these ideas.

0:27:51	SPEAKER_06
 The girls said the utterance of themselves are not numbered at the moment.

0:27:55	SPEAKER_04
 I'm not quite sure I have only seen that the individual words have gotten an ID.

0:28:01	SPEAKER_06
 So I guess that would be solved with the split.

0:28:04	SPEAKER_04
 You always could have a look at the timestamps and then take the ones that belong together to form an attachment.

0:28:14	SPEAKER_04
 I think you just take these segments that are already.

0:28:20	SPEAKER_04
 Yeah, there's segments five and no these are my assignments.

0:28:27	SPEAKER_06
 I think that's just like to make a list of all the stuff where we can find somebody can do the paper.

0:28:40	SPEAKER_06
 So the stuff we have with utterances and speakers and wait for utterances.

0:28:51	SPEAKER_06
 For every utterance, the utterance has a speaker and the weight coming from outside which is tied to it.

0:28:59	SPEAKER_06
 And there is segments which are the segments are also a topic segment.

0:29:10	SPEAKER_06
 They are a super unit so the utterances are tied to topic segments.

0:29:22	SPEAKER_06
 And if the timestamps are on a word level then we somehow have to extract timestamps for utterances where they start.

0:29:29	SPEAKER_04
 There are timestamps for the segments.

0:29:34	SPEAKER_04
 What segments are for example when you look at the data what is displayed in one line?

0:29:42	SPEAKER_02
 Okay.

0:29:44	SPEAKER_06
 Is that the same about the utterances?

0:29:47	SPEAKER_06
 Is that the same as utterances that...

0:29:50	SPEAKER_05
 I think so.

0:29:51	SPEAKER_05
 It may not be exact at the time.

0:29:54	SPEAKER_04
 So I compared it with what I did for the post duration extraction.

0:30:01	SPEAKER_04
 And basically it's words that are uttered in a sequence without pauses but sometimes however there are short pauses in it and they are indicated by square brackets pause.

0:30:14	SPEAKER_06
 So that's one segment or is that two segments then?

0:30:21	SPEAKER_04
 Sometimes the annotators decided what was one segment and what wasn't.

0:30:27	SPEAKER_06
 Okay, but generally utterances is that which is called...

0:30:32	SPEAKER_06
 Sorry, segments is that which is called utterances now.

0:30:36	SPEAKER_06
 I think so.

0:30:37	SPEAKER_06
 It's sort of like one person's contribution at a time sort of meeting.

0:30:42	SPEAKER_06
 Okay.

0:30:43	SPEAKER_06
 So we have those and then we have some fields somewhere else which have topics.

0:30:51	SPEAKER_06
 Yeah, and the topic's basically just an ID probably with a start time or something and the utterances reference to those topics I guess.

0:30:59	SPEAKER_06
 The topics don't contain any redundant thing of like showing the whole topic again but they just sort of say a number and where they start and where they finish.

0:31:08	SPEAKER_06
 And the utterances then say which topic they belong to.

0:31:11	SPEAKER_04
 Yeah, but I think for some annotations an utterance can have several types.

0:31:20	SPEAKER_04
 Those are the dialogues.

0:31:24	SPEAKER_06
 Yeah, I know but I was thinking of the topic segmentation.

0:31:28	SPEAKER_06
 For that there would only be one, right? Because it's sort of like it's just a time window.

0:31:32	SPEAKER_06
 So if this lazy loading works then this should definitely fit into, I mean not memory then because it wouldn't all be memory at the same time.

0:31:43	SPEAKER_06
 So if you just have sort of that information like a long list of all the utterances slash segments and like shorter smaller lists which give weight to them.

0:31:55	SPEAKER_06
 And even though probably if there's a lot of overhead and having two different files you can probably merge the weights into it offline.

0:32:02	SPEAKER_06
 You know what I mean?

0:32:03	SPEAKER_06
 Like if there's a lot of bureaucracy involved with having two different trees and where the one ties to the other because the one is the weight for the other then it's probably quicker to just go wider or just ride it.

0:32:12	SPEAKER_05
 So you can just ride it in the XML file.

0:32:15	SPEAKER_05
 You can not handle just loading arbitrary, new, like the trib use and stuff.

0:32:22	SPEAKER_05
 I mean I always thought that it would be able to.

0:32:24	SPEAKER_06
 Yeah I thought there was the whole beauty that like you can just make a new XML file and sort of tie that to the other end.

0:32:29	SPEAKER_05
 So why do we need to have two XML trees and then we're on.

0:32:32	SPEAKER_06
 Oh yeah, so no I didn't mean tree, no, no I meant just like handling two different files internally.

0:32:38	SPEAKER_06
 So I was just thinking like if the overhead for having the same amount of data coming from two files instead of from one file is massive.

0:32:46	SPEAKER_06
 Then it would probably be for us easy to just like offline put the weight into the file that has the segments.

0:32:54	SPEAKER_06
 Yeah, that's left utterances already.

0:32:57	SPEAKER_06
 But that we can figure out.

0:33:00	SPEAKER_05
 The other thing is that would be easy to pass as well which means you wouldn't have to pass anything.

0:33:07	SPEAKER_06
 Yeah, yeah, no we'd be completely using like the whole infrastructure and basically just I mean the main difference really between our projects and that's really is that we load a different part of the data but otherwise we're doing it the same way that they are doing it.

0:33:25	SPEAKER_06
 So we just we're sort of running different types of queries on it.

0:33:28	SPEAKER_06
 In a sense I think we are running queries it's not just about what we load and what we don't look but we're running queries in the sense that we dynamically select by by weights don't we.

0:33:40	SPEAKER_06
 Now we have to check how fast that is like to say give us all the ones that whether that works with their query language whether that's too many results in whether we should.

0:33:50	SPEAKER_06
 No, because if it let's say I mean if their query language is strange and if it would return the 10 million results and it can't handle it, then we can just write our individual components in the way that they know what the threshold is so they still get all the data and just they internally say oh no this is less than three and I'm not going to play or something.

0:34:11	SPEAKER_05
 Yeah, I mean process it in chunks.

0:34:14	SPEAKER_05
 In just process it all in chunks.

0:34:17	SPEAKER_06
 Yeah, I'm just thinking for this whole thing of like a different level sort of cutting out different pieces whether we do that through a query where we say give us everything that's above this and this weight, or whether we keep the same infrastructure but every individual module like the player and the displays they like they still get sort of all the different differences all the different pieces but they say oh this piece of leaf out because it's below the current threshold level.

0:34:50	SPEAKER_05
 So, I think that's why I have cool information density as well as like an information density score for each meeting and each topic seven because otherwise we'll be recalculating the same thing over and over again.

0:35:04	SPEAKER_05
 And that will obviously make it much easier to display.

0:35:09	SPEAKER_06
 When do we need the one for the meeting?

0:35:12	SPEAKER_06
 Yeah, I guess for the so when we have to display where we display the whole series then if we have for the individual topic segment within the meeting, if we have ready calculator measures that we don't have to sort of extract that data from the individual Yeah, and that's also fairly it's just or long with our segments, isn't it? Yeah, for the segments are we extracting some type of title for them that we craft with some fancy algorithm manually, are we just taking the single most highly valued keyword

0:35:42	SPEAKER_05
 And then our friends for the segment heading, well we can start off by that, well I was going to start off off, I've got some halfway through and printing one that does just idea and then just change that to work on whatever

0:35:59	SPEAKER_06
 It's probably like in the end probably it wouldn't be the best thing if it's just the most highly ranked phrase a keyword because like for example for an introduction that would most definitely not be anything that has any title anywhere similar to introduction And then we can use the way for stuff like the hotspots and the key words for the sections and that. Also like for this part maybe if we go over with named entity in the end, if I mean one of the people doing deal has some named entity code to spare Like at least for the for sort of for finding topics titles for for segments just take a named entity which has a really high what's it called DFIDF whatever, because you'd probably be quite likely if they talk about a conference or a person that that would be named entity which is very highly frequently in that part. Yeah he said they're quite sparse so that basically was don't bother bathing too much of the general calculation but like especially if they're sparse probably individual named entities which describe what a segment is about would probably be quite good There's some name of some conference that could probably say that name of the conference quite often even though he's right that they make indirect references to it anyway.

0:37:16	SPEAKER_05
 He said you're counting implementing the idea what exactly are you it's not TFIDF it's just a rest of the agency because it's really easy to do basically. There's just like for a baseline.

0:37:37	SPEAKER_05
 So you're doing that on a on a per word level. Yeah. Okay. And then averaging the idea. Okay.

0:37:47	SPEAKER_05
 But it's not like related to the corpus at all it's just one of them in arbitrary text.

0:37:54	SPEAKER_06
 Okay. Okay. I was just wondering where you had to call this from at the moment.

0:37:59	SPEAKER_06
 So it seems the data structure isn't a big problem and that basically we don't have to have all these massive discussions of how we exactly interact with the data structure because most of our work isn't done with the data structure in memory in the browser but it's just an offline and everyone can represent it anyway they want as long as they sort of store it in the use of like the matter of presentation in the end.

0:38:25	SPEAKER_05
 It's like being useful to know how to store that thing.

0:38:32	SPEAKER_06
 Yeah that would mean understanding that I text the metal like metal sort of format in a lot more detail.

0:38:37	SPEAKER_06
 We should I think we should just have a long session in the computer room together and like now that we know a bit more what we want take a closer look at the topic segments.

0:38:53	SPEAKER_00
 And then yeah there's a few poem you think and it gives the timestamp and say each one was the actual like utterance segments and the less of them are called and they're all numbered.

0:39:10	SPEAKER_06
 That's what I just thought.

0:39:16	SPEAKER_00
 Yeah I haven't looked at this stuff much at all. So I guess I'm going to be segmenting it with the LCC and that's the same format I want to do back out and be equivalent.

0:39:32	SPEAKER_06
 Who's sort of doing the central coordination of the browser application or like integration? Yeah but also like all these elements like the loading and integration and handling the data loading and stuff.

0:39:51	SPEAKER_06
 I don't know what to think anyone's been able to do that. I'm sort of like I think I'll take over there to split just because I started with a bit and found it durable.

0:40:08	SPEAKER_06
 And I think everybody should sort of be the one person who understands most about what's essentially going on with the project like with a browser as a whole and where the data comes in.

0:40:26	SPEAKER_06
 So it's boring. It's also complicated. Yeah it could be difficult.

0:40:38	SPEAKER_06
 I can do it like several people together to probably just those people have to work together a lot and very closely and just make sure that they always understand what the other ones doing.

0:40:58	SPEAKER_00
 And then we'll maybe have to prioritize somebody to enter it here.

0:41:09	SPEAKER_06
 Yeah but I think actually like at the moment the integration comes first. I mean it's sort of at the moment the building the browser comes first and then only comes to creating new sophisticated data chunks because that's sort of the whole thing about having a prototype system which is more or less working on chunk data but at least we have the framework in which we can then test everything and look at everything because before we have that it's going to be very difficult for anyone to really see how much the work that they're doing is making sense because you just where I guess you can see something from the data that you have in your individual x-mails files that you create but it would be nice to have some basic system which just displays some stuff.

0:41:53	SPEAKER_06
 Or something like that. Or just adapt like there like just sort of go from their system and adapt it piece for piece and see how we could arrange like adapt the power system.

0:42:11	SPEAKER_06
 Does anyone want to like just sit with me and like play for three hours with an ad ex-mail at some point? I wouldn't like to be. I'd like to go to the gym I'm theoretically free but if there's any time.

0:42:30	SPEAKER_05
 Give nothing no for a time on Wednesday Wednesday I've got a 9-12.

0:42:40	SPEAKER_05
 9-12 from the nothing you have for you. I've got nothing in the afternoon. Anytime Wednesday afternoon I'd be playing.

0:42:47	SPEAKER_05
 So we're about just in Afton Tower. Yeah for us to whatever one is easy to discuss stuff I don't know. I'll be in. I'm not 5-12 on any way.

0:43:00	SPEAKER_05
 Okay what time do you want to do? Well I'll be there for 12. I've got some other stuff that needs to be done on that lab so if you're not there at 12 I can just work on that.

0:43:10	SPEAKER_06
 Okay so I'll just meet you in 18 India.

0:43:29	SPEAKER_06
 I guess at the moment nobody critically depends on like the night ex-mail stuff working right now. Like at the moment you can all do your stuff and I can do my other stuff.

0:43:40	SPEAKER_06
 And I can even do the display to a vast degree without technically having this flying framework working. So it's not that crucial.

0:43:48	SPEAKER_04
 I would need the raw text pretty soon because I have to find out how I have to put the segments into a bin.

0:43:59	SPEAKER_06
 Yeah actually I need the raw text as well. I was more thinking of the whole browser framework as a running program now.

0:44:05	SPEAKER_00
 Yeah I think we all need the raw text in different flavors don't we? Yeah that's what I thought you said but you did extract in the text.

0:44:17	SPEAKER_04
 I've only just got the notes I have to still have to order everything by the time. Yeah so you should be doing it in Python yeah. Yeah I think it's quite easy.

0:44:36	SPEAKER_00
 Because yeah I was having a look at it as well. And the speakers are on a separate file. You have to combine them all and then you order them.

0:44:47	SPEAKER_04
 That's what I thought. Yeah just combine them and order them. Right. So that's a quick time.

0:44:56	SPEAKER_04
 Well I was going to do so. What I found out was that there are quite a lot of things without time stamps and the beginning.

0:45:09	SPEAKER_04
 In the word file. Yeah that's just an idea. Yeah everything that's word has a timestamp.

0:45:19	SPEAKER_04
 But what are the other things that's some kind of number.

0:45:29	SPEAKER_00
 I'm not sure.

0:45:31	SPEAKER_04
 I think there are quite a lot of numbers in the beginning where there's no timestamps for the numbers.

0:45:40	SPEAKER_04
 I think they say quite a lot of numbers and before that there's this number.

0:45:45	SPEAKER_04
 Number within the XML context. Yeah there are numbers in the W tag but there are no timestamps.

0:45:53	SPEAKER_06
 Are they spoken numbers? Like do they look like they are utterances. Yeah there's the number task isn't there.

0:45:59	SPEAKER_06
 That's part of their thing.

0:46:01	SPEAKER_04
 That's at the end.

0:46:03	SPEAKER_04
 Yeah in the beginning as well sometimes I think. At least I'm so sorry.

0:46:08	SPEAKER_06
 We have to be cut that out anyway. Sorry you're going to screw up a lot of our data otherwise.

0:46:18	SPEAKER_04
 I'm not sure what it does to tell me. I think it wouldn't.

0:46:21	SPEAKER_04
 Of course I mean it would be because in every meeting.

0:46:26	SPEAKER_06
 It would probably make the. Yeah if you have segments for that probably.

0:46:30	SPEAKER_04
 And I think it even has its own annotation like digits or something.

0:46:36	SPEAKER_06
 I'm just thinking like it probably like the LSA would perform quite well and it would probably find another number task quite easily.

0:46:44	SPEAKER_06
 A constraint vocabulary with a high co-currents of the same nine words.

0:46:48	SPEAKER_04
 But what is it actually that numbers? It's just a system I think.

0:46:54	SPEAKER_04
 So but there are no timestamps.

0:46:57	SPEAKER_06
 I think it's also something that they said the numbers in order right?

0:47:01	SPEAKER_06
 They have to read numbers. Yeah I think it sounded like they wanted to check out how well they were doing with overlapping and stuff.

0:47:09	SPEAKER_06
 Because basically it's like they're reading them at different speeds but you know in which order they are said.

0:47:14	SPEAKER_06
 I didn't have a look at that.

0:47:16	SPEAKER_06
 I actually have some reasons for doing it.

0:47:19	SPEAKER_06
 I have some tips on saying like numbers at the end of the room.

0:47:24	SPEAKER_04
 And also there are different combinations of letters.

0:47:32	SPEAKER_04
 Is everything ordered at the timestamps global or are they local?

0:47:38	SPEAKER_04
 At any point.

0:47:39	SPEAKER_00
 I thought we'll make both of the pictures on YouTube.

0:47:43	SPEAKER_06
 Okay.

0:47:44	SPEAKER_06
 If you're doing IDFs or whatever you call your frequency that will mix up the name.

0:47:54	SPEAKER_06
 You need some dictionary for that at some point.

0:47:56	SPEAKER_06
 You need to have some representation of a word as not that specific occurrence of the word token but of a given word form.

0:48:05	SPEAKER_06
 Because you may count the word on the right.

0:48:07	SPEAKER_05
 Yes we should work together because I need a dictionary as well.

0:48:16	SPEAKER_05
 I was just going to use the hash that one and Java because I'm only going to do it on small documents.

0:48:23	SPEAKER_05
 It's just like until the information densities are from running.

0:48:28	SPEAKER_05
 Just saying to work with.

0:48:30	SPEAKER_06
 Didn't you say that?

0:48:31	SPEAKER_06
 I'm not sure.

0:48:38	SPEAKER_04
 Right.

0:48:45	SPEAKER_06
 Is there any one of you for the document frequency or total frequency?

0:48:50	SPEAKER_06
 You're going to have total frequency to work with that right?

0:48:54	SPEAKER_04
 Like over the whole corpus sort of word.

0:49:04	SPEAKER_05
 Why do you need to classify them to a different setting?

0:49:08	SPEAKER_04
 It's because when you use the type of classification system and I think it's not possible to have just one class that's supposed to be.

0:49:18	SPEAKER_05
 Can we just fill a second clock with junk that you don't care about?

0:49:23	SPEAKER_05
 Like copies of Shakespeare or something?

0:49:26	SPEAKER_04
 Yeah sure we could do that but I don't know if that makes sense.

0:49:29	SPEAKER_05
 Because if all we're looking for is the frequencies because it's only how that would be changed for a classification.

0:49:38	SPEAKER_04
 If we need just frequencies maybe we should just calculate them from using code or something.

0:49:48	SPEAKER_04
 Or maybe another tool.

0:49:57	SPEAKER_06
 Using which tool are you talking about?

0:49:59	SPEAKER_04
 Just using a power script.

0:50:01	SPEAKER_06
 Be careful with that.

0:50:03	SPEAKER_06
 My experience with the British National Corpus was that there's far more word types than you ever think.

0:50:08	SPEAKER_06
 Because anything that's sort of unusual generally is a new word type.

0:50:11	SPEAKER_06
 Like any typo or any strange thing where they put two words together.

0:50:15	SPEAKER_06
 And also any number is a word type of its own so you can easily end up with 100,000 words when you didn't expect them.

0:50:21	SPEAKER_06
 So generally dictionaries can grow bigger than you think they do.

0:50:26	SPEAKER_04
 I don't know how you want many terms you can handle.

0:50:30	SPEAKER_06
 Or you can probably also pre-filter like with regular expressions even just say if it consists of only digits then skip it.

0:50:37	SPEAKER_06
 Or even if it consists of any special character then skip because it's probably something with the dot in between which is usually not something you want to happen.

0:50:44	SPEAKER_05
 I can't remember who's got it.

0:50:48	SPEAKER_05
 It might be word met but one of these big corks has a list of stop words you can download and they're just basically this is really uninteresting boring words that we could filter out before we do that.

0:51:05	SPEAKER_05
 And I think that's one of the papers I read that's one of the things I did right at the beginning is they've got this big stop list and they just ignore all those.

0:51:15	SPEAKER_06
 But I did for my protocol just ignore the 100 most frequent words because they actually end up all being articles and everything.

0:51:27	SPEAKER_06
 So we need like several of us need a dictionary.

0:51:31	SPEAKER_05
 And I think that's a very useful way as well.

0:51:35	SPEAKER_05
 Am I the only one who needs it with frequencies or is that a useful way as well?

0:51:40	SPEAKER_06
 Frequencies.

0:51:41	SPEAKER_06
 Well I guess as soon as we have the raw tech we can probably just start with a Java hash map and just hash map over it and see how far we get.

0:51:49	SPEAKER_06
 I mean you can probably on a machine with a few hundred megabyte RAM you can go quite far.

0:51:53	SPEAKER_06
 You can run it on beefy so even if it goes wrong and if it doesn't really.

0:51:56	SPEAKER_05
 You want to look into getting some subset of the XC purpose on the guys machines.

0:52:01	SPEAKER_05
 So I hate working on the ices awful.

0:52:05	SPEAKER_05
 Like so it needs my home machine.

0:52:08	SPEAKER_06
 Oh yeah burning it on a like you should be able to burn the whole purpose.

0:52:11	SPEAKER_05
 Just dig.

0:52:12	SPEAKER_05
 Where has a CD.

0:52:13	SPEAKER_06
 Ah yeah I'll support about that two days ago.

0:52:16	SPEAKER_06
 In the informatics building there.

0:52:20	SPEAKER_06
 Sorry in applicant tower five.

0:52:22	SPEAKER_06
 The ones closest two machines closest to the support office so I presume.

0:52:27	SPEAKER_06
 I would I have the exact email I think you talk about sort of the ones that.

0:52:31	SPEAKER_05
 Right hand corner.

0:52:32	SPEAKER_06
 Yeah if you enter the big room in the right hand corner I think.

0:52:35	SPEAKER_06
 The thing is like you can only burn from the local file system so if it's from.

0:52:41	SPEAKER_06
 Well actually I think if it's mounted you can directly burn from there but the problem is I have my data on beefy and so I have to get it into the local temp directory and burn it from there but you can burn from there.

0:52:50	SPEAKER_05
 How big is it without.

0:52:53	SPEAKER_06
 Oh we looked at that map.

0:52:56	SPEAKER_05
 We looked at that map because I could just say it going over a C one night and just leave it going all night.

0:53:04	SPEAKER_06
 Yeah yeah we should be able to get it.

0:53:08	SPEAKER_06
 I don't think it was.

0:53:10	SPEAKER_06
 I don't think it was a gig about.

0:53:13	SPEAKER_05
 Yeah I mean the way.

0:53:21	SPEAKER_06
 And then like copy but you know what I figured out I'm quicker downloading over broadband.

0:53:26	SPEAKER_06
 And using this artist there's something strange about the way how they access the hardest how they mounted.

0:53:32	SPEAKER_06
 Which is unfortunate.

0:53:35	SPEAKER_05
 I'll see like a.

0:53:39	SPEAKER_05
 What operating system do you have.

0:53:44	SPEAKER_06
 What connection do you have at home.

0:53:47	SPEAKER_06
 Yeah so if any one of us gets it we can then just use it.

0:53:51	SPEAKER_06
 I can burn it to CD or put it on hard to spread everywhere.

0:53:56	SPEAKER_06
 Question is if you're not quicker if you because you should get massive compression out of that.

0:54:01	SPEAKER_06
 Like 50% or something with a good algorithm.

0:54:05	SPEAKER_06
 So if you compress it and just put it into a temperature as an off space.

0:54:10	SPEAKER_06
 The temps usually have a gig about three or really.

0:54:15	SPEAKER_06
 The temps yeah I don't like I mean there's no guarantee that anything stays there but overnight it'll stay.

0:54:20	SPEAKER_06
 And I think the temps usually have.

0:54:26	SPEAKER_06
 But that would have to be the temp directory of the machine you can SSH into directly off SSH.

0:54:36	SPEAKER_05
 Yeah I can do it from that session down I think compress it from a remote session in the same session.

0:54:43	SPEAKER_06
 Yeah they probably hate you for doing it.

0:54:49	SPEAKER_06
 They probably they'd like you more if you SSH into another computer.

0:54:57	SPEAKER_06
 Compress it there and then sort of copied into the gateway machine.

0:55:02	SPEAKER_06
 If you SSH in there if it's big warning about doing nothing at all in the gateway machine.

0:55:08	SPEAKER_05
 I was thinking of SSH and just into some machine.

0:55:12	SPEAKER_05
 Yeah and then just actually being.

0:55:16	SPEAKER_06
 I have I haven't figured out how to tunnel through the gateway into another machine.

0:55:22	SPEAKER_06
 It's not it's not easy definitely.

0:55:25	SPEAKER_06
 That's why I end up sort of copying stuff into the temp directory at the gate the machine.

0:55:29	SPEAKER_06
 Sorry if this is boring everybody else.

0:55:31	SPEAKER_06
 It's just details on how to get stuff home from.

0:55:34	SPEAKER_06
 We could probably just look at that together when we're meeting.

0:55:39	SPEAKER_04
 I just wanted so who's when doing the frequencies on the words because I think I will also I could also make use of it for the agreement.

0:55:56	SPEAKER_04
 I'm not going to do the same thing because I am in my eye and I talked about using the discourse acts first.

0:56:10	SPEAKER_04
 And then in the chunks of text I found looking for word patterns and so on.

0:56:17	SPEAKER_04
 So I would for example need the most frequent words.

0:56:25	SPEAKER_06
 So if you cut off all that I don't see as soon as somebody gives me the raw text of the whole thing.

0:56:34	SPEAKER_06
 I can probably just implement like a five line Java hash table frequency dictionary builder and see.

0:56:39	SPEAKER_04
 Yeah but I needed for my chance then I would.

0:56:44	SPEAKER_06
 Did you not say frequency of words no sorry.

0:56:47	SPEAKER_04
 I would like to look at the frequency of words in my in the regions of text I found out to be interesting.

0:56:59	SPEAKER_04
 So I wouldn't need it.

0:57:00	SPEAKER_04
 It would have to be recalculated.

0:57:03	SPEAKER_05
 You'd have to count yourself here.

0:57:05	SPEAKER_05
 But first how big is the chunks.

0:57:09	SPEAKER_05
 How big is the chunks.

0:57:12	SPEAKER_04
 I think it.

0:57:17	SPEAKER_04
 As big as the hotspot annotation.

0:57:22	SPEAKER_04
 So quite small.

0:57:23	SPEAKER_04
 That's quite small.

0:57:24	SPEAKER_05
 So you could just some addresses.

0:57:26	SPEAKER_05
 You could use just the same thing we used to build a big dictionary.

0:57:30	SPEAKER_05
 Just do that online.

0:57:32	SPEAKER_05
 So that would take time to build a little bit through that.

0:57:37	SPEAKER_05
 I mean just use the same tool.

0:57:40	SPEAKER_04
 Yes.

0:57:42	SPEAKER_04
 So I would probably just concatenate all my text chunks and then that same.

0:57:49	SPEAKER_06
 You don't want to have different counts for each chunk.

0:57:53	SPEAKER_06
 Just like for for something from all chunks.

0:57:56	SPEAKER_06
 Yes.

0:57:57	SPEAKER_06
 Oh yeah no that's yeah so once I write an art like if I write like an algorithm which does a hash table dictionary with frequency from a raw text then the raw text can be anything.

0:58:08	SPEAKER_06
 So how far are you getting raw text out of it do you think?

0:58:14	SPEAKER_04
 I can get all the raw text but it has to be on it still.

0:58:18	SPEAKER_06
 Okay well that's good because for the dictionary the order doesn't make it any more of it.

0:58:22	SPEAKER_06
 So yes so I'll get that from you and I'll write a hash table which goes over that and creates a dictionary file.

0:58:29	SPEAKER_06
 So for the dictionary is it okay if I do whatever word blank frequency or something.

0:58:33	SPEAKER_06
 Just put everybody for the start from that I mean I guess.

0:58:38	SPEAKER_05
 Well that's it.

0:58:39	SPEAKER_05
 I use in TF IDF for the information density.

0:58:44	SPEAKER_04
 It's in what is implemented in Ray's information game.

0:58:48	SPEAKER_04
 I'm not quite sure how they calculate that.

0:58:53	SPEAKER_05
 Because frequency would be useful I think.

0:58:57	SPEAKER_05
 Yeah I need frequency as well.

0:59:00	SPEAKER_05
 Depending on the context, the size and what we consider a document in the sense of calculating TF IDF is going to change.

0:59:11	SPEAKER_05
 Which might be thinking about.

0:59:13	SPEAKER_06
 I think we might have a lot in common what we talked about because I for my latent magic analysis need like counts of words within a document within a segment actually within a topic segment.

0:59:23	SPEAKER_04
 So that's what Ray was also I think you can just get probabilities for certain words for each document.

0:59:32	SPEAKER_06
 Can I convert these probabilities back into frequency?

0:59:37	SPEAKER_04
 I mean we have to look at that.

0:59:42	SPEAKER_06
 So that's what Ray was.

0:59:44	SPEAKER_06
 That's what LSA builds on.

0:59:45	SPEAKER_06
 I get built a document by frequency matrix.

0:59:48	SPEAKER_06
 I can probably get that even though but I already have my code to build it up.

0:59:53	SPEAKER_06
 I have my code already.

0:59:57	SPEAKER_06
 Yesterday you said you need the frequency counts actually for a document but you say not for the whole world.

1:00:04	SPEAKER_05
 You need the raw frequency as well.

1:00:09	SPEAKER_05
 You also need how many times things occur within each document.

1:00:17	SPEAKER_05
 And what we consider a document is going to depend on our context I think.

1:00:22	SPEAKER_05
 If we're looking at a whole lot of meetings we'll consider each meeting a document in terms of this algorithm and if we're viewing like say just small topic segment you might look at even each utterance.

1:00:37	SPEAKER_05
 Here's a small document.

1:00:39	SPEAKER_06
 It more and more appears to me that if we scrap the notion of the meeting as an individual thing and sort of see meetings as topic segments and have sort of like hierarchical topic segmentation instead then it's like you're walking here in framework.

1:01:02	SPEAKER_05
 So it's only something that's thought of how actually maybe it doesn't actually matter.

1:01:09	SPEAKER_05
 Maybe if you just do it once at the highest level it will be fine.

1:01:14	SPEAKER_05
 But I was just thinking it might be difficult to calculate the TFI yet offline for the different levels we might want.

1:01:21	SPEAKER_05
 So if we're going to allow this joint segment for example and how we're going to know what's going to be in context at any given time.

1:01:29	SPEAKER_05
 I suppose if you just did it globally treating a meeting with a document it'd probably still be work out fine because you don't even be comparing with everyone within the company.

1:01:40	SPEAKER_06
 Are we using this for the waiting in the end now this measure of your calculating?

1:01:50	SPEAKER_05
 I don't know I thought we didn't need that in the end.

1:02:00	SPEAKER_06
 Because if we're doing I think for the information density we should calculate it on the lowest level not on the highest level.

1:02:09	SPEAKER_05
 Sorry that's what I mean like yeah for each word or whatever that across the whole lot is what I mean by highest level across the whole process.

1:02:20	SPEAKER_06
 Yeah but don't you have to like go sort of like for in a document versus the whole thing that how it works.

1:02:27	SPEAKER_05
 Yeah I really thought it was the H meeting as a document.

1:02:30	SPEAKER_06
 I don't think that's a good idea because isn't it like that we expect it to change over with the different topic segments more that they're talking about something different in each topic segment.

1:02:46	SPEAKER_05
 And possibly.

1:02:51	SPEAKER_06
 Because that's what relative term frequency is about that like in some context they're talking more about a certain word than general. So that would more be the topic segments.

1:03:03	SPEAKER_04
 And that's what I thought as well that probably the topic segment level is the most informative.

1:03:13	SPEAKER_05
 Are they big enough to get anything.

1:03:24	SPEAKER_06
 So I'm just wondering if there's ways to abandon the whole concept of meetings and sort of.

1:03:30	SPEAKER_05
 Which is not really treating separate meetings is too much of a separate entity.

1:03:44	SPEAKER_06
 But on algorithmic level whether we actually whether there's some way to just represent meetings as a topic.

1:03:52	SPEAKER_05
 Yeah you just like whatever you want to look at just jam together into an external flow and that's your meeting even though bits it may have come from all over the place or whatever.

1:04:03	SPEAKER_05
 I don't see why that's really a big problem.

1:04:08	SPEAKER_06
 That's not really what I meant but I think I have to think more about what I meant.

1:04:13	SPEAKER_06
 I'm confused about everything.

1:04:17	SPEAKER_05
 So basically what you're saying to you take an arbitrary amount of data and process it with the same algorithm.

1:04:23	SPEAKER_05
 It doesn't matter conceptually what that data is.

1:04:26	SPEAKER_05
 It could be a meeting.

1:04:28	SPEAKER_05
 It could be two options.

1:04:29	SPEAKER_05
 It could be a meeting plus half a meeting somewhere else.

1:04:32	SPEAKER_06
 I'm not so concerned about them meeting plus something else.

1:04:35	SPEAKER_06
 I'm more talking about like yeah the keeping keeping the same algorithm in the same way of handling it and just saying.

1:04:42	SPEAKER_06
 Like just this topic here happens to be like a whole meeting and it has sort of sub topics such as that sort of topics are hierarchical concept.

1:04:53	SPEAKER_06
 Like the topic where there can be super topics and topics in the super topics are in the end what the meetings are in general.

1:05:01	SPEAKER_06
 At some level super topics are created like like topics.

1:05:05	SPEAKER_05
 I think it's very difficult.

1:05:06	SPEAKER_05
 I mean what you do is you just build an XML file and if you want it to get down to the entrances.

1:05:11	SPEAKER_05
 You go to the leads and then if you are in the next level up you go to the parents of those and like just go from like the leads in which towards the branch to build up things like you know when you pick on a segment it's going to have like words or whatever

1:05:31	SPEAKER_06
 are important.

1:05:39	SPEAKER_05
 As long as like the algorithm is designed with it in mind and then it's very good for them.

1:05:47	SPEAKER_06
 So just grab that again then.

1:05:49	SPEAKER_05
 Well like say you had like say for a meeting like you've got like say a hierarchy that looks quite big like this and like the utterances come off of here maybe. Then when whatever your algorithm is doing as long as when you're working with options you go for all the leads.

1:06:12	SPEAKER_05
 Then if you need something next up so like a topic segment you go to here.

1:06:18	SPEAKER_05
 But if you're looking at say this one that only went like this.

1:06:25	SPEAKER_05
 So you say you'd start with the leads and you go I want a topic segment so I go one layer up.

1:06:37	SPEAKER_05
 And then if you're working with just the topic segment in there because the only thing you have to worry about and like each time you want to hire level you just need to go up the tree.

1:06:42	SPEAKER_05
 As long as your algorithm respects that then we can just process any arbitrary X and O.

1:06:56	SPEAKER_06
 So that would be the series as a whole that would be sort of a meeting.

1:07:00	SPEAKER_05
 Me too.

1:07:01	SPEAKER_06
 I'm a bit brain damaged at the moment but I think I'll just sit together with you again and go through it again.

1:07:09	SPEAKER_05
 So I think as long as you build an algorithm that respects whatever structures in the file rather than imposing its own structure.

1:07:20	SPEAKER_06
 So is this structurally or is this not always identical?

1:07:27	SPEAKER_06
 Well no.

1:07:28	SPEAKER_06
 So that we can be treated with this algorithm more.

1:07:31	SPEAKER_05
 But I mean it could be as many nodes as you want. This one could be deeper maybe.

1:07:40	SPEAKER_05
 So then you start with all your utterances here.

1:07:42	SPEAKER_05
 And when you go up to get topic segments you go to here, here, here, here, here.

1:07:48	SPEAKER_05
 That might be a bit confusing.

1:07:49	SPEAKER_05
 I hope you have things on different levels.

1:07:53	SPEAKER_06
 I'm not sure how we can go from bottom up. I'll sort of take more that.

1:08:07	SPEAKER_06
 This is all too complicated worrying about that at that moment.

1:08:25	SPEAKER_06
 Anything that we're doing anything. Add their implementation in more detail that I understand what's going on so we'll see if we can get many browser displays two things seen together.

1:08:40	SPEAKER_06
 Yes, two things from their stuff to make sure that we understand it, understand it enough to modify.

1:08:47	SPEAKER_00
 You should be not have a good directory or something, you can put all our code in there.

1:08:52	SPEAKER_05
 Maybe use for that, maybe use for that, maybe use for that.

1:08:58	SPEAKER_06
 Yeah, how would you do that by just making like, read right for everyone?

1:09:05	SPEAKER_06
 Okay, who is most free space on there?

1:09:10	SPEAKER_05
 I don't know how it is.

1:09:12	SPEAKER_05
 I've probably got a read for now because everything on my website now can actually be deleted or stored at home as well.

1:09:23	SPEAKER_06
 Alternatively, we can probably just make another directory on the BPH scratch space.

1:09:29	SPEAKER_06
 That's where I'm having gigabytes and gigabytes of stuff at the moment.

1:09:32	SPEAKER_05
 Is that guaranteed to stay here?

1:09:34	SPEAKER_06
 No, no.

1:09:36	SPEAKER_00
 If not Steve, we can get space.

1:09:41	SPEAKER_05
 Maybe he should send a support form.

1:09:46	SPEAKER_06
 But I think if he sent to support he'd probably be a better partition.

1:09:53	SPEAKER_00
 Yeah, I'm sure he had to deal with it last year.

1:09:56	SPEAKER_05
 Because that would be really useful if we had a big directory, especially for transferring.

1:10:07	SPEAKER_05
 Having said that, we allowed to take a copy of the XC process.

1:10:10	SPEAKER_05
 So I need you to probably ask before we do it.

1:10:12	SPEAKER_06
 I think it said yes to that.

1:10:14	SPEAKER_06
 I think that when we were still in the seminar room, I asked that once or asked, is it possible to get it off?

1:10:19	SPEAKER_06
 And nobody said, like people were discussing about the technical practicalities, but nobody said anything about being allowed to not allow it.

1:10:27	SPEAKER_06
 I mean, we have access to it here and I guess it probably means that we can't give it to anybody else.

1:10:34	SPEAKER_06
 But if they give us access to it here, sitting on a dice machine, then they should be very...

1:10:40	SPEAKER_06
 Well, we shouldn't be able to leave it on our laptop.

1:10:42	SPEAKER_06
 I personally don't have too many friends who would be too keen on getting it anyway.

1:10:47	SPEAKER_06
 I have this really excited pirate copy.

1:10:50	SPEAKER_06
 Annotated meeting data.

1:10:52	SPEAKER_04
 So shall we stick together tomorrow then?

1:10:55	SPEAKER_04
 Yeah.

1:10:56	SPEAKER_04
 Okay.

1:10:57	SPEAKER_04
 So what is the text you're extracting?

1:11:02	SPEAKER_04
 Looking like them at the end?

1:11:05	SPEAKER_04
 It would be best.

1:11:07	SPEAKER_04
 At the moment it's because just...

1:11:09	SPEAKER_04
 I think it's actually very similar to what I did for my speaker.

1:11:15	SPEAKER_04
 I think I would perhaps have to change two lines of code to get you for each meeting, a file that says from this millisecond to this millisecond.

1:11:32	SPEAKER_04
 That was this sequence of words.

1:11:34	SPEAKER_04
 And so on.

1:11:35	SPEAKER_04
 So that's just changing two lines of code.

1:11:40	SPEAKER_04
 And it would be very good.

1:11:43	SPEAKER_04
 Okay.

1:11:45	SPEAKER_04
 Do you expect the words as well?

1:11:48	SPEAKER_04
 Yeah, so far I extracted the durations, but it's from the words file.

1:11:55	SPEAKER_04
 So I couldn't just...

1:11:58	SPEAKER_04
 I think the words instead of the durations, and it should...

1:12:14	SPEAKER_04
 I can try to do it in.

1:12:17	SPEAKER_04
 I can't have a little bit of it.

1:12:20	SPEAKER_04
 It makes sense for which one.

1:12:23	SPEAKER_04
 So we already expect from all the files.

1:12:34	SPEAKER_04
 Yeah, I just let it run over the first.

1:12:39	SPEAKER_04
 So if you also order...

1:12:41	SPEAKER_04
 Yes.

1:12:42	SPEAKER_02
 Wait, wait, wait.

1:12:43	SPEAKER_02
 Sorry.

1:12:44	SPEAKER_02
 Yeah, sure.

1:12:46	SPEAKER_04
 I was according to the starting terms and the other.

1:12:52	SPEAKER_06
 What I just realized we should really keep different series completely separate for virtually all purposes.

1:13:00	SPEAKER_06
 Just be careful about that.

1:13:03	SPEAKER_06
 What do you mean by that?

1:13:04	SPEAKER_06
 The exicopress isn't one meeting series, several meeting series with different people meeting for completely different things.

1:13:13	SPEAKER_04
 Yeah, I mean, I have one, but I give you one file for each meeting.

1:13:20	SPEAKER_04
 Yeah, not for each meeting series.

1:13:23	SPEAKER_04
 I can do that.

1:13:24	SPEAKER_06
 Let's just be careful that whatever sort of we merge together, the highest level of merging, it's not the whole exicopress, but the original series.

1:13:31	SPEAKER_05
 Yeah, it might be funny to see what is summarized the whole corpus.

1:13:35	SPEAKER_05
 I think we might actually...

1:13:39	SPEAKER_06
 I think it'd be very useful.

1:13:41	SPEAKER_06
 It's probably somewhere well or something like that.

1:13:45	SPEAKER_06
 I think we might just get away with for the whole project just like looking at only one series and just doing within one series.

1:13:52	SPEAKER_06
 I mean, you can do everything you want in one series.

1:13:54	SPEAKER_04
 Yeah, I mean, there's one series that has just one meeting.

1:13:57	SPEAKER_06
 Oh, yeah, that's actually...

1:14:01	SPEAKER_06
 Is the data always clearly split up a different series?

1:14:04	SPEAKER_06
 Is it like easy to just pick one?

1:14:06	SPEAKER_04
 The data is of the form you have the pre-identification letter.

1:14:11	SPEAKER_04
 So B-E-D or B-B-D or something, and that's always the same group.

1:14:16	SPEAKER_04
 And then after that, there's a number like 001 or 003.

1:14:21	SPEAKER_06
 So at every level, everyone has to be careful to really just take...

1:14:26	SPEAKER_06
 Even if at the highest level just takes stuff from one series, not merge stuff from different series together, because there would probably be just majorly messy.

1:14:33	SPEAKER_06
 So even if you make one single text file which has the whole corpus, sort of our corpus, there would still be from one series only.

1:14:44	SPEAKER_06
 But what you're producing at the moment is individual text files that sort of have the raw text for a whole meeting as a whole.

1:14:52	SPEAKER_04
 Yes, but I mean, as the start times, start for each meeting at zero, you could just probably just add the final second time to the next meeting.

1:15:09	SPEAKER_04
 And so I'm just going to draw it together.

1:15:12	SPEAKER_04
 And then we would have to change the information about who on which channel it was set to, by which person it was set, and that is actually starting another X and Y.

1:15:26	SPEAKER_06
 Okay.

1:15:28	SPEAKER_06
 So is anybody creating a real raw text thing at the moment, which is just the words?

1:15:35	SPEAKER_00
 That's what I'm going to need.

1:15:37	SPEAKER_04
 Yeah, but Ben just not print out the style of the end times.

1:15:45	SPEAKER_06
 But if they are... so it's not an end times just for the file, like is it just the first and the last line or is it for every single thing in...

1:15:52	SPEAKER_04
 So every single word.

1:15:54	SPEAKER_04
 Oh, for every single entrance.

1:15:56	SPEAKER_04
 Yeah, that depends on what you want.

1:15:57	SPEAKER_06
 So what do you mean by just not print out that?

1:15:59	SPEAKER_04
 I do this first, it's just string manipulation.

1:16:04	SPEAKER_06
 I mean, I would just... If you're into it, can you make a text that which just like makes just the words?

1:16:10	SPEAKER_06
 Sure.

1:16:11	SPEAKER_06
 Okay.

1:16:12	SPEAKER_06
 Do you want it straight flowing?

1:16:13	SPEAKER_06
 Because I would need something that marks the end of... is your segmented by traffic standards?

1:16:20	SPEAKER_06
 Is there any information you have to do topic to the automatic topic implementation?

1:16:23	SPEAKER_04
 No, I didn't do so.

1:16:24	SPEAKER_06
 Then I need something different later anyway.

1:16:27	SPEAKER_00
 Okay, but for now, if you...

1:16:28	SPEAKER_00
 That's what in the else you say, that marks the end of segment.

1:16:32	SPEAKER_06
 Okay, you're going to put that as now to put the segmentation.

1:16:35	SPEAKER_06
 Okay, so for now, can you create like sort of just a dump which is pure text, just pure text that I can get a dictionary and you can work on that for your topic segmentation?

1:16:44	SPEAKER_06
 Yeah.

1:16:45	SPEAKER_06
 And...

1:16:46	SPEAKER_04
 And you would want that all in one file for all the corpus?

1:16:52	SPEAKER_06
 For the series.

1:16:53	SPEAKER_06
 For the series.

1:16:54	SPEAKER_06
 But I can also deal with separate files.

1:16:56	SPEAKER_06
 I mean, I can just write the algorithm that it loads all files in every directory or something.

1:17:00	SPEAKER_06
 Yeah, I can directly put it in.

1:17:02	SPEAKER_06
 So if you can put it in one single megafile, that would be quite useful for me.

1:17:06	SPEAKER_04
 So only words for meeting series.

1:17:12	SPEAKER_06
 If you look for you, wouldn't it be easy if you had different files because any sort of no...

1:17:17	SPEAKER_00
 For me, it's better for buying.

1:17:20	SPEAKER_06
 So give me different files as long as...

1:17:22	SPEAKER_06
 If you could name them in a way that is easy to enumerate over them like whatever, one, two, three, four, five or something.

1:17:28	SPEAKER_06
 It's just anything that I can...

1:17:30	SPEAKER_04
 Yeah, they will just take over the names they have anyway.

1:17:36	SPEAKER_04
 Yeah.

1:17:37	SPEAKER_06
 Is it something that's easy to enumerate over?

1:17:40	SPEAKER_06
 Is it some ordered pattern?

1:17:42	SPEAKER_06
 Yeah.

1:17:43	SPEAKER_04
 One series has the same pre-starting letters.

1:17:47	SPEAKER_06
 Okay, cool.

1:17:48	SPEAKER_06
 Yeah.

1:17:49	SPEAKER_04
 So only words and words sometimes.

1:17:51	SPEAKER_04
 No, I don't need the time.

1:17:53	SPEAKER_04
 So just...

1:17:54	SPEAKER_04
 Need words but...

1:17:56	SPEAKER_04
 And the right order.

1:17:58	SPEAKER_02
 Yeah, you want to order.

1:17:59	SPEAKER_04
 Okay.

1:18:00	SPEAKER_04
 Okay.

1:18:01	SPEAKER_04
 We live.

1:18:02	SPEAKER_06
 Okay.

1:18:03	SPEAKER_06
 Orders.

1:18:04	SPEAKER_04
 I'm hard-based at times.

1:18:07	SPEAKER_04
 Yeah, and do want...

1:18:10	SPEAKER_04
 Yeah, sometimes they're contained in one another.

1:18:14	SPEAKER_04
 So...

1:18:15	SPEAKER_04
 Doesn't matter too much.

1:18:16	SPEAKER_04
 Just after.

1:18:17	SPEAKER_04
 Okay.

1:18:18	SPEAKER_04
 All of that.

1:18:21	SPEAKER_04
 All of that.

1:18:22	SPEAKER_04
 All of that.

1:18:23	None
 All of that.

1:18:24	SPEAKER_06
 When do you think you'll have, like, a primitive segmentation by some ready-made topic segmentation by some ready-made tool ready?

1:18:35	SPEAKER_00
 Then, no, but...

1:18:37	SPEAKER_00
 You really need to do it once you've got the barcode.

1:18:39	SPEAKER_00
 Okay.

1:18:40	SPEAKER_00
 Just run in the...

1:18:41	SPEAKER_06
 Okay, cool.

1:18:43	SPEAKER_06
 Because I'll need that then when it's done.

1:18:45	SPEAKER_00
 Yeah, hopefully that's neat.

1:18:47	SPEAKER_04
 Okay.

1:18:48	SPEAKER_04
 And I think for all the quotas, it's just from what I know from my attempts, it's nine megabytes.

1:18:54	SPEAKER_04
 Mm-hmm.

1:18:55	SPEAKER_04
 To have...

1:18:56	SPEAKER_04
 It should be similar to...

1:18:57	SPEAKER_04
 Yeah, yes.

1:18:58	SPEAKER_04
 Words.

1:18:59	SPEAKER_04
 Let's see.

1:19:00	SPEAKER_06
 Words, what's nine megabytes?

1:19:02	SPEAKER_04
 No, um, all the words together.

1:19:04	SPEAKER_04
 And for...

1:19:05	SPEAKER_04
 One of the meetings.

1:19:06	SPEAKER_06
 That sounds quite reasonable.

1:19:08	SPEAKER_06
 That's nine...

1:19:09	SPEAKER_06
 Nine characters over...

1:19:11	SPEAKER_04
 That's what I...

1:19:13	SPEAKER_04
 Because nine megabytes is what I got for when I said for every...

1:19:18	SPEAKER_04
...adurance.

1:19:19	SPEAKER_04
 This goes from there to there.

1:19:21	SPEAKER_06
 Okay.

1:19:22	SPEAKER_06
 That is for...

1:19:23	SPEAKER_06
 Are we picking one particular series at the moment or...?

1:19:26	SPEAKER_06
 Oh.

1:19:27	SPEAKER_06
 Yeah.

1:19:28	SPEAKER_04
 I'm doing it for all of it.

1:19:32	SPEAKER_04
 Doesn't matter.

1:19:33	SPEAKER_04
 Okay.

1:19:34	SPEAKER_02
 Yeah.

1:19:35	SPEAKER_06
 I guess you can probably process the data for all different series and then check which series is the best for the presentation.

1:19:43	SPEAKER_06
 It sounds a bit reasonable, nine megabytes to me.

1:19:46	SPEAKER_06
 If you think if it's roughly a million words...

1:19:49	SPEAKER_06
...and nine characters, the words sound really...

1:19:51	SPEAKER_04
 Yeah.

1:19:52	SPEAKER_04
 I hope this will be the same for the words.

1:19:54	SPEAKER_04
 It's just with that.

1:19:55	SPEAKER_04
 Yeah.

1:19:56	SPEAKER_02
 Yeah.

1:19:57	SPEAKER_06
 Yes, I'm going to build a dictionary then from that.

1:20:01	SPEAKER_06
 Like, just a list of the words and maybe a list of the words with the frequencies or a list of the words...

1:20:08	SPEAKER_06
...sorted alphabetically or numerically.

1:20:11	SPEAKER_06
 What does anyone want to sustain your wishes for dictionaries?

1:20:15	SPEAKER_05
 I could just use it with the frequency, I think, until the information density is finished.

1:20:23	SPEAKER_05
 That would be really useful.

1:20:25	SPEAKER_04
 Mm-hmm.

1:20:26	SPEAKER_06
 So I'll create a dictionary.

1:20:28	SPEAKER_04
 So, I'll probably send just one file of the first meeting to all those who need it so that you can have a look at what you want.

1:20:39	SPEAKER_06
 Yeah. And then the actual file we can probably copy from your home directory or something like it.

1:20:45	SPEAKER_04
 Yeah, I mean, if it's just for one meeting, it's really not today.

1:20:48	SPEAKER_06
 Yeah, but I'm saying for the whole thing in the end, like, a big thing.

1:20:51	SPEAKER_06
 You probably shouldn't do that, you know.

1:20:54	None
 Yeah.

1:20:55	SPEAKER_04
 How long would it take to make the frequency counts for the Java edge table?

1:21:03	SPEAKER_06
 From the time I get the file, I can do that in an afternoon, the next sort of the next morning.

1:21:09	SPEAKER_06
 Well, you mean how long processing time it takes?

1:21:11	SPEAKER_04
 No, how long you would have to program something?

1:21:14	SPEAKER_06
 It's in box-ended algorithm.

1:21:16	SPEAKER_06
 I've sort of written it for a deal, just a bit half an hour or something similar.

1:21:20	SPEAKER_06
 It's just you put them in a hash table and say, well, if it exists already in the hash table, then you increase the count by one end.

1:21:26	SPEAKER_06
 I probably implement some filter for filtering out numbers or something.

1:21:31	SPEAKER_04
 Because it's quite easy in Perl as well.

1:21:33	SPEAKER_04
 It's just a line of code for counting all the words.

1:21:37	SPEAKER_04
 Really? How do you do that?

1:21:39	SPEAKER_04
 Yeah, it's by hashes.

1:21:41	SPEAKER_06
 Okay, well, I don't know any Perl.

1:21:42	SPEAKER_06
 I mean, if anyone wants to do a Perl script for that, does it?

1:21:45	SPEAKER_06
 It's a nice thing.

1:21:49	SPEAKER_06
 I have no problem with that.

1:21:50	SPEAKER_06
 But I think I have the Java code virtually ready because for Dilla wrote something very similar, like for Dilla wrote something that counts there.

1:21:58	SPEAKER_06
 The different occurrences of all the text.

1:22:01	SPEAKER_05
 If you're doing it in Java, it could be serialized, the output as well as writing it to a file.

1:22:07	SPEAKER_05
 Sorry?

1:22:08	SPEAKER_05
 If you're doing it in Java, it could be serialized, the hash table as well as writing it to a file.

1:22:15	SPEAKER_06
 I've never serialized it.

1:22:17	SPEAKER_05
 Really easy.

1:22:18	SPEAKER_06
 Wouldn't that be absolutely massive?

1:22:21	SPEAKER_05
 I don't see why it would be any more massive than the file.

1:22:24	SPEAKER_06
 And then write the serialization to a file.

1:22:28	SPEAKER_06
 So you want a file which is the serialization of a hash table.

1:22:32	SPEAKER_05
 It's just a C pass in the file representation of it.

1:22:37	SPEAKER_05
 And now, because I'll be using it in Java anyway.

1:22:39	SPEAKER_05
 So I'll just be building data structure again.

1:22:42	SPEAKER_06
 I'll check if I understand how it works.

1:22:44	SPEAKER_06
 Otherwise, I can give you the code for loading a dictionary.

1:22:48	SPEAKER_06
 It's a line break separated file.

1:22:52	SPEAKER_05
 It seems like a bit silly to be passing it over and over again.

1:22:57	SPEAKER_02
 Yeah.

1:23:02	SPEAKER_06
 Yeah, I see if I understand how to serialize.

1:23:05	SPEAKER_06
 There's a serialized command so that gives me one mega-mother.

1:23:08	SPEAKER_05
 I think all the collections and things implement serializable already.

1:23:15	SPEAKER_06
 But do they automatically write to the file?

1:23:17	SPEAKER_06
 Anyway, I'll figure that out if we don't do that.

1:23:20	SPEAKER_06
 Yes, that's pretty much it.

1:23:25	SPEAKER_06
 So Dave and me look at how nightx mail works and we're out trying to either work some more

1:23:37	SPEAKER_05
 on the TF-IDS or the audio thing.

1:23:46	SPEAKER_06
 I'll build a dictionary as soon as I get the text. And yeah, so that when do we have to meet again then with this?

1:23:59	SPEAKER_00
 Do you know what's going on with all of this?

1:24:04	SPEAKER_06
 How are we going to do a demonstration next week?

1:24:07	SPEAKER_05
 We had to demonstrate something like that.

1:24:09	SPEAKER_05
 What do we have to demonstrate?

1:24:11	SPEAKER_06
 No, no, not demonstrate.

1:24:12	SPEAKER_06
 Didn't we agree that it would be useful to demonstrate or something like some primitive thing working next week?

1:24:20	SPEAKER_00
 Yeah, I suggested that we could have an initial prototype.

1:24:23	SPEAKER_06
 There's got to be very prototype.

1:24:26	SPEAKER_00
 I'm not surprised if we can get anything more than that.

1:24:32	SPEAKER_06
 Mmm.

1:24:37	SPEAKER_06
 Wow, let's go.

1:24:45	SPEAKER_06
 I feel like hanging mid-air and not really finding a point where you can get your teeth in it and start working properly.

1:24:53	SPEAKER_06
 It's also fuzzy though.

1:24:58	SPEAKER_05
 I think it's because we have to specify ourselves that it's not as focused as specification of most...

1:25:07	SPEAKER_06
 Yeah, but at the moment it's also an implementation level.

1:25:10	SPEAKER_06
 With the data structures, I'm just like over these vague ideas of some trees.

1:25:15	SPEAKER_05
 Once we start doing it, it will become more obvious.

1:25:19	SPEAKER_06
 Yeah, it's just our halfway through the project time.

1:25:23	SPEAKER_06
 That's what just freaks me out.

1:25:40	None
 I would give it a chance.

1:26:32	None
 you know, like, Evaluationridge C C C C you

