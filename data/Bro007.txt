0:00:00	SPEAKER_03
 Okay, so, today, looking at a number of things we're trying and, fortunately, for listeners to this, some of it's visual, but got tables in front of us. What is combo mean? So, combo

0:00:37	SPEAKER_04
 is a system where we have these features that go through the network and then these same three more features, but low pass filter with the low pass filter use in the MSG features.

0:00:53	SPEAKER_04
 So these low pass filter goes through another MLB and then the linear outputs of these two MLBs are combined just by adding the values and then there is this guilty and the output

0:01:10	SPEAKER_03
 is used as features. So, let me try to restate this and see if I have it right. There's the features, there's the OGI features and then those features go through a contextual, let's take this bottom arrow, one point by the bottom arrow. Those features go through a contextualized KLT. Then these features also get low pass filtered.

0:01:56	SPEAKER_04
 Yeah, so, yeah, I could grab through this and blackboard. Yeah, that's good. So, we have these features from OGI that goes through three paths, three, okay. The first is a KLT using several frames of the features. The second path is MLB, also using nine frames, several frame of features. The third path is this low pass filter, MLB. Adding the output is just like in the second proposal for the first evaluation. And then MLB and those

0:02:58	SPEAKER_03
 two together. Okay, so that's this bottom one. And then the one at the top and I presume these things that are in yellow are in yellow because overall they're the best. Yeah, that's the reason. Oh, that's focused on them. So, what's the block diagram for the one above it?

0:03:25	SPEAKER_04
 For the first yellow line, you mean? Yeah. So, it's basically the same except that we don't have this low pass filtering. So, we have only two streams. Well, there's no low pass processing. Use this additional feature stream. Do you, they mentioned, when I was

0:03:57	SPEAKER_03
 on the phone, what's the note? They mentioned some waiting scheme that was used to evaluate

0:04:04	SPEAKER_04
 all these numbers. Actually, the waiting seems to... Well, it's 40% 40, I think it's 60% for all the speech that comes with all these languages. The well-match is 40, medium 35, even. I miss much 25. And we don't have the TI digits. No. Okay. But yeah, generally what we observe with TI digits is that the result are very close, whatever the system. Okay.

0:04:42	SPEAKER_03
 And so, have you put all these numbers together into a single number representing that?

0:04:48	SPEAKER_03
 Not yet. Okay. So, that should be pretty easy to do. Yeah. And that would be good to make a compare the two and say what was better. Yeah. And how does this compare to the numbers?

0:05:01	SPEAKER_04
 Oh, so, OGI2 is just the top. Yeah. Top row. So, yeah. So, actually, OGI2 is the baseline with the OGI features. But this is not exactly the result that they have because they've still made some changes in the features. Okay. But actually, our results are better than their results. I don't know by how much because they did not send us their new results.

0:05:38	SPEAKER_03
 Okay. Okay. So, the one place where it looks like we're messing things up a bit is in

0:05:50	SPEAKER_04
 the highly mismatched Italian. Yeah. Yeah. There is something for any of you here because there are 36 and then sometimes we are around 42. Now, one of the ideas that you had mentioned

0:06:28	SPEAKER_03
 last time was having a second silence detection. Yeah. So, there are some results here.

0:06:37	SPEAKER_04
 So, the third and the fifth line of the table. So, felt is what that is. Yeah. So, it seems for the well-matched mismatched condition, it brings something. But, actually, apparently there is no room left for any silence detector at the server side because of the delay.

0:07:10	SPEAKER_03
 Oh, we can't do it. Okay. Yeah. Too bad. Good idea. But, anyway. Okay. Except, I don't know

0:07:22	SPEAKER_04
 because I think they are still working well. Two days ago, they were still working on this, trying to reduce the delay of the silence detector. So, but yeah, if we had time perhaps, we could try to find some kind of compromise between the delay that's on the end set and on the server side, but try to reduce the delay on the end set. But, well, for a moment, they have this large delay on the feature computation. Okay. So, all right. So, for now,

0:08:00	SPEAKER_03
 at least that's not there. You have some results with low pass filter, capstone. It doesn't have a huge effect, but it looks like it maybe can help in a couple places. Yeah. A little bit. And, yeah. And, let's see. Well, just that we have in there. I guess, at this point, this is, I guess I should probably look at these others a little bit. You yellow these out, but, oh, I see, yeah, that one you can't use because of the delay. That looks pretty good. Let's see. That one.

0:09:02	SPEAKER_03
 Well, even just the second row doesn't look that bad, right? That's just, that looks

0:09:22	SPEAKER_04
 like an interesting one, too. Actually, the second line is pretty much like the first line in yellow, except that we don't have this guilty on the first, on the left part of the diagram, just add the features. Yeah. Yeah. So, when we do this weighted measure,

0:09:57	SPEAKER_03
 we should compare the two because it might even do not better. And, it's a little slightly simpler. So, there's, so I would put that one also as a maybe. And, yeah. And, it's actually, it does, does significantly better on the highly mismatched Italian. So, and love a worse on the, it's on the MM case, but, well, yeah, it's worse on a few things.

0:10:37	SPEAKER_03
 So, see how that, see how that comes out on their measure. And, are we running this for TI digits or? Yeah. Now, is TI, is that part of the result that they get for the development, the results that they're supposed to get at the end of the month, the TI digits are there also? It's here. Okay. Okay. Let's see what else there is here. Oh, I see the one that I was looking down here at the row below the lower yellow one. That's, that's with the reduced KLT size. Yeah, reduced functionality. What happens there is it's around the same.

0:11:38	SPEAKER_03
 And so, you could reduce the dimension. What you're saying? Yeah, it's, it's, it's significant, but, but it's significantly worse. It's, it's, it's, it's, it's, it's, it's mostly worse. Yeah. I did this a little, I mean, not, not by a huge amount. I don't know.

0:12:03	SPEAKER_03
 What, what are the sizes of any of these sets? I'm sure you told me before, but I forgot.

0:12:10	SPEAKER_03
 So, you know, how many words are in one of these test sets? Yeah. Well, it depends, well,

0:12:23	SPEAKER_04
 the one much is generally larger than the other sets. And I think it's a row. Two thousand, two thousand, two thousand. What? I don't know. Sentences. Sentences. Some sets have 500

0:12:43	SPEAKER_03
 sentences. Yeah. So, so the sets, so the test sets are between 500 and 2,000 sentences, let's say, each sentence on the average has four or five digits or is it most of them

0:12:56	SPEAKER_02
 longer? Yeah. For Italian, even 70, but sometimes the sentences have only one digit and three times, like the number of credit cards, something like that. Right. So, between one and 16, see

0:13:17	SPEAKER_03
 the, I mean, the reason I'm asking is is we have all these small differences and I don't know how seriously to take them right. So, yeah. If you had, just, you know, to give an example, if you had, if you had a thousand words, then a tenth of a percent would just be one word, right. So, so, it means anything. So, yeah, be kind of, I can't, I can know what the sizes of these tests are. The size of the, yeah. Since these, well, also just to know the numbers, right. So, these, these are word error rates. So, this is on how many words.

0:14:02	SPEAKER_02
 Yeah. We have the result of the output of the H-tika. Yeah. The number of sentences, not

0:14:09	SPEAKER_03
 the numbers. Yeah, sure. Yeah. So, anyway, if you could just mail out what those numbers are and then that would be great. What else is there here? See, the second, the second from the bottom, it says S-I-L. This is some different type of silence or thing. What

0:14:29	SPEAKER_02
 was that? The output silence of the MLP. It's only one small experiment to know what happened. To fly also, to include also the silence of the MLP. We have the 56 phone and the silence to pick up the silence and to include also. This silence plus the K-L-T output.

0:14:55	SPEAKER_02
 Oh, so you're only using the silence? Yeah, because when we apply the K-L-T output.

0:15:00	SPEAKER_04
 No, I think there is this silence in addition to the K-L-T output. In addition to the K-L-T output.

0:15:05	SPEAKER_04
 Because we, we just keep, we don't keep all the dimensions after the K-L-T. And we're not sure if we try to add the silence also in addition to the 28 dimensions. Okay. What, what's OGI 45? It's OGI 2. It's the features from the first line. Yes. Right, but I mean, what is the last row mean? So, it's basically this, but without the K-L-T on the left. I

0:15:53	SPEAKER_03
 thought that was the one. I thought that was the second row. What's the difference between

0:16:01	SPEAKER_04
 the second line? You don't have these combos stuff, so you just... Oh, so this is like the

0:16:07	SPEAKER_02
 second line, but with the combo stuff. And with the output of the combo. Yeah. Okay, so,

0:16:15	SPEAKER_03
 all right, so it looks to me, I guess, the same given that we have to take the field ones out of the running because of this delay problem. It looks to me like the ones you said, I agree, there are the ones to look at, but it just would add the second row. Yeah. One. And then, if we can... Oh, yeah, also, when they're using this weighting scheme of 40, 35, 25, is that on the percentages or on the raw errors, I guess it's probably on the percentages, right?

0:17:04	SPEAKER_04
 I guess, yeah. Yeah, I kind of guess. All right, it's that query. Okay, maybe they'll argue about it.

0:17:11	SPEAKER_03
 Okay, so if we know how many words are in each, and then they've, they've promised to get something tomorrow, which will be there as far as they've gotten, right? And we'll operate with that.

0:17:28	SPEAKER_03
 How long did it... I guess if we're not doing all these things, if we're only doing...

0:17:33	SPEAKER_03
 I guess since this is development data, it's legitimate to do more than one, right?

0:17:48	SPEAKER_03
 I mean, or now, if in final test data, you don't want to do several and take the best. That's that's not proper, but if this is development data, we could still look at a couple. Yeah.

0:17:59	SPEAKER_04
 Yeah, we can, yeah, sure. But we have to decide, I mean, we have to fix the system.

0:18:05	SPEAKER_04
 Yes, on this data. Choose the best. Right. The question is when do we fix the system?

0:18:12	SPEAKER_03
 Do we fix the system tomorrow, or do we fix the system on Tuesday?

0:18:16	SPEAKER_03
 I think we fix on Tuesday, yeah. Okay, except that we do have to write it up.

0:18:19	SPEAKER_04
 Yeah, well, basically it's this way. Perhaps some kind of printing on some of the pets.

0:18:33	SPEAKER_03
 Right, so maybe what we do is we get the data from them, we start the training and so forth, but we start the write-up right away, because as you say, there's only minor differences between these.

0:18:46	SPEAKER_04
 I think we could start to, yeah. Yeah, there's something. Yeah.

0:18:51	SPEAKER_03
 And I would, yeah, I would kind of like to see it. Maybe I can add it a bit.

0:18:58	SPEAKER_03
 The money in the situation is my forte, which is English.

0:19:07	SPEAKER_03
 So, yeah, have you seen, do they have a format for how they want the system descriptions or anything? Not really. Okay.

0:19:20	SPEAKER_04
 There is the format of the table, which is quite impressive.

0:19:33	SPEAKER_03
 I see. Yes, for those who are listening to this and not looking at it, it's not really that impressive, it's just tiny.

0:19:40	SPEAKER_03
 It's all these little categories.

0:19:45	SPEAKER_03
 So they said B, said C, multi-conditioned clean.

0:19:52	SPEAKER_03
 No mitigation. Wow.

0:19:56	SPEAKER_03
 You know what, no, no mitigation means.

0:20:01	SPEAKER_04
 It should be...

0:20:05	SPEAKER_04
 Oh, that's probably the general error.

0:20:07	SPEAKER_03
 This is probably a channel error stuff.

0:20:10	SPEAKER_03
 Oh, this is... Right, it says right above your channel error resilience.

0:20:14	SPEAKER_03
 Yeah.

0:20:16	SPEAKER_03
 So recognition performance is just the top part, actually.

0:20:23	SPEAKER_03
 And they have the aspect between scene databases and non-scene, so basically, due development and evaluation.

0:20:30	SPEAKER_03
 And so, right, it's presumed there's all sorts of tuning that's gone on on the...

0:20:35	SPEAKER_03
 Let's see what they call scene databases.

0:20:38	SPEAKER_03
 And there won't be tuning for the unseen...

0:20:45	SPEAKER_03
 Multi-condition. Multi-condition.

0:20:52	SPEAKER_03
 So they have... Looks like they have...

0:21:01	SPEAKER_03
 So they're splitting up between the TI digits and everything else, I say.

0:21:05	SPEAKER_03
 So they everything else is the speech debt car. That's the...

0:21:09	SPEAKER_04
 Multi-conditioned. Yeah, so it's not divided between languages, you mean, or...

0:21:12	SPEAKER_03
 Well, it is. It is. But there's also these tables over here for the TI digits and these tables over here for the car, which is, which is, I guess, all the multi-lingual stuff.

0:21:22	SPEAKER_03
 And then there's...

0:21:25	SPEAKER_03
 They also split up between multi-conditioned and clean only.

0:21:29	SPEAKER_04
 Okay. Forty-indigets. Yeah. Actually, yeah. Forty-indigets, they want to train clean and unnoisy.

0:21:40	SPEAKER_04
 Yeah.

0:21:44	SPEAKER_03
 So we're doing that also, I guess.

0:21:47	SPEAKER_04
 Yeah. But...

0:21:50	SPEAKER_04
 We actually... Do we have the features? Yeah, for the clean-conditioned, but we did not test it yet.

0:21:57	SPEAKER_04
 The clean training stuff.

0:22:01	SPEAKER_04
 Okay.

0:22:04	SPEAKER_03
 Well, anyway, sounds like there'll be a lot to do just to work with our partners to fill out the tables for the next few days. I guess they have to send it out. See, the 31st is Wednesday.

0:22:21	SPEAKER_03
 And I think it has to be there by some hour European time on Wednesday. So I think basically...

0:22:28	SPEAKER_02
 It was a long time when they maybe, because... Excuse me?

0:22:32	SPEAKER_02
 That the difference in the time may be... It's so long different of the time. Maybe the 12th of the night of the Thursday one is not valid in Europe. We don't know exactly.

0:22:51	SPEAKER_03
 Yeah. So I mean, I think we have to actually get it on Tuesday, because I think...

0:22:58	SPEAKER_04
 Except if it's the 31st of midnight, we don't know.

0:23:02	SPEAKER_04
 Can't still do some work on Wednesday.

0:23:06	SPEAKER_03
 Yeah, well... Is it been... I thought it was actually something like 5pm on...

0:23:14	SPEAKER_03
 It was like, I thought it was 5pm or something. I didn't think it was midnight.

0:23:17	SPEAKER_03
 I thought they said they wanted it at 5pm.

0:23:19	SPEAKER_03
 Well, so 5pm their time is...

0:23:24	SPEAKER_02
 No, like 3pm. 3pm.

0:23:26	SPEAKER_02
 3pm. 3pm.

0:23:27	SPEAKER_03
 Alright, that's six in the morning here.

0:23:30	SPEAKER_02
 No. 3... 3... 8... 3pm?

0:23:33	SPEAKER_04
 No, we were wondering about the... the... the... the... the... the... the... we have to...

0:23:38	SPEAKER_02
 Oh yeah, yeah, yeah.

0:23:38	SPEAKER_04
 I don't know if it's 3pm.

0:23:40	SPEAKER_02
 3pm here is in Europe, with 9.

0:23:43	SPEAKER_02
 Yeah, it's 3pm here.

0:23:43	SPEAKER_03
 Yeah, it's 3pm here. But I didn't think it was midnight that it was...

0:23:45	None
 Oh.

0:23:45	SPEAKER_03
 I thought it was due it's some hour during the day, like 5pm or something.

0:23:50	SPEAKER_03
 In which case...

0:23:52	SPEAKER_03
 So I... well, we should look, but my assumption is that we basically have to be done Tuesday.

0:23:56	SPEAKER_03
 Yeah. So, then next Thursday we can sort of have a little aftermath.

0:24:03	SPEAKER_03
 But then we'll actually have the new day, which is the German and the Danish.

0:24:07	SPEAKER_03
 But that really will be much less work, because the system will be fixed.

0:24:12	SPEAKER_03
 Yeah.

0:24:13	SPEAKER_03
 So all we'll do is take whatever they have and...

0:24:18	SPEAKER_03
 and run it through the process.

0:24:20	SPEAKER_03
 We won't be changing the training on anything.

0:24:23	SPEAKER_03
 So there'll be no new training, there'll just be new HDK runs.

0:24:26	SPEAKER_03
 So that means in some sense we can kind of relax from this after Tuesday.

0:24:33	SPEAKER_03
 And maybe next meeting we can start talking a little bit about where we want to go from here in terms of the research.

0:24:46	SPEAKER_03
 You know, what things...

0:24:47	SPEAKER_03
 Did you think of when you were doing this process that just didn't really have time to adequately work on?

0:25:03	SPEAKER_04
 Yeah.

0:25:05	SPEAKER_01
 Oh, Stefan always had these great ideas.

0:25:07	SPEAKER_01
 Oh, but I would have time.

0:25:12	SPEAKER_04
 I'm not sure the other great ideas.

0:25:14	SPEAKER_04
 That's right.

0:25:16	SPEAKER_02
 But there are ideas.

0:25:17	SPEAKER_02
 It was a great idea.

0:25:19	SPEAKER_02
 To apply the sick guilty was a great idea.

0:25:23	SPEAKER_03
 Yeah, that was good.

0:25:25	SPEAKER_03
 And also it's still true that I think it's true that we at least got fairly consistent improve results by running the neural net transformation in parallel with the features rather than in sequence which was your suggestion and that seems to have been born out.

0:25:50	SPEAKER_03
 The fact that none of these are enormous is not too surprising.

0:25:56	SPEAKER_03
 Most improvements aren't enormous.

0:26:00	SPEAKER_03
 Some of them are.

0:26:01	SPEAKER_03
 But when you have something really, really wrong and you fix it, you can get really enormous improvements.

0:26:15	SPEAKER_03
 It's our best improvements over the years that we've gotten from finding bugs.

0:26:22	SPEAKER_03
 Okay, well, I think I see where we are and everybody knows what they're doing.

0:26:26	SPEAKER_03
 Is there anything else we should talk about?

0:26:34	SPEAKER_04
 I think it's okay.

0:26:38	SPEAKER_04
 So basically we will, I think we will try to focus on these three architectures.

0:26:48	SPEAKER_04
 And perhaps I was thinking also a fourth one with just a single guilty because we did not really test that removing these guiltys in particular single guilty at the end.

0:27:02	SPEAKER_03
 Yeah, I mean that would be pretty low maintenance to try it if you can fit it in.

0:27:09	SPEAKER_03
 Oh, I have, yeah, I do have one other piece of information which should tell people outside of this group too.

0:27:17	SPEAKER_03
 I don't know if we're going to need it.

0:27:18	SPEAKER_03
 But Jeff at the University of Washington has gotten a hold of some kind of server farm of 10 multi-processor IBM machines or 6,000s.

0:27:39	SPEAKER_03
 And so I think each one is four processors or something.

0:27:43	SPEAKER_03
 I don't know, 800 megahertz or something. There's four processors in a box and there's 10 boxes and there's some kind of type. So he's got a lot of processing power.

0:27:53	SPEAKER_03
 And we'd have to schedule it but if we have some big jobs and we want to run them, he's offering it.

0:28:01	SPEAKER_03
 So it's a, when he was here, he used not only every machine here but every machine on campus as far as I could tell. So it's got his payback. But again, I don't know if we'll end up with if we're going to be CPU limited and anything that we're doing in this group but if we are, that's an offer.

0:28:26	SPEAKER_03
 Okay, well, guys doing great stuff. So that's really neat.

0:28:38	SPEAKER_03
 I don't think we need to.

0:28:42	SPEAKER_03
 Oh, well, the other thing I guess that I will say is that the digits that we're going to record momentarily are starting to get into a pretty good size collection.

0:28:53	SPEAKER_03
 And in addition to the speech data stuff, we will have those to work with really pretty soon now.

0:29:02	SPEAKER_03
 So that's another source of data which is, understand what better control and that we can make measurements of the room that, you know, if we feel there's other measurements we don't have, we'd like to have. We can make them.

0:29:18	SPEAKER_03
 Dave and I were just talking about that a little while ago.

0:29:20	SPEAKER_03
 So that's another possibility for this kind of work.

0:29:30	SPEAKER_03
 Okay, if nobody else has anything else, maybe we should go around. Do our digits, do our digits, doodie. Okay, I'll start.

0:29:46	SPEAKER_03
 3231-3250. Let me say that again, transcript number 3231-3250.

0:29:57	SPEAKER_03
 780-03819-0598-1794-2345-74737-84416-9988-083-08556-1-2003.

0:30:28	SPEAKER_03
 4246-5234-403-670276.

0:30:40	SPEAKER_00
 I'm reading transcript 3251-3270.

0:30:45	SPEAKER_00
 898559-006-16150-243-278-4350-4756-479-567-606-70000-904.

0:31:13	SPEAKER_00
 Oh, sorry, 914-07-06-19-23-407-23-744-624-7479-605-8451.

0:31:35	SPEAKER_04
 Transcript 3291-3310-07-0898-187-2-301-55636-798-8866-868636-9-006-3867-186-866.

0:32:00	SPEAKER_04
 329-00332-99-2636-35348-76-495-6-78090-03060.

0:32:23	SPEAKER_01
 Transcript 3171-3190-5980-659817175394-89292836-9-011825-3604515158.

0:32:47	SPEAKER_01
 365-360-45156-700928-77-05430506589-126434.

0:33:13	SPEAKER_02
 Transcript 3191-321-061113-728992897-96100109-0100142336-47250-5455.

0:33:23	SPEAKER_02
 8992897 961000 0901014233647250 0.5446787078041907 0.43461753329347 0.4367257

0:34:32	None
 0.2347 quite very clean spring contours

