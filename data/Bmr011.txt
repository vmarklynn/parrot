0:00:00	SPEAKER_06
 Are we on?

0:00:02	SPEAKER_02
 We're on.

0:00:04	SPEAKER_02
 We're down.

0:00:06	SPEAKER_06
 Okay, so we can have a cent around the agenda.

0:00:14	SPEAKER_06
 Any agenda items that he has to talk about?

0:00:18	SPEAKER_07
 What's going on?

0:00:20	SPEAKER_07
 Has everyone met at dawn?

0:00:22	SPEAKER_07
 Yeah, doing.

0:00:24	SPEAKER_06
 Okay, agenda item one, introduce Don.

0:00:28	SPEAKER_03
 Well, I had a good question, but I know there was a discussion of it at a previous meeting that I missed, but just about the wish list item of getting good quality close packing mics on every speaker.

0:00:42	SPEAKER_06
 Okay, so let's do agenda building right now.

0:00:46	SPEAKER_06
 Okay, so let's talk about that a bit.

0:00:48	SPEAKER_06
 Close talking mics, better quality.

0:00:52	SPEAKER_04
 We can talk about that. You were going to start to say something.

0:00:58	SPEAKER_04
 Well, you already know about the meeting that's coming up, and I don't know if this is appropriate.

0:01:04	SPEAKER_06
 No, no, it's okay.

0:01:06	SPEAKER_06
 So we can talk.

0:01:08	SPEAKER_06
 So NIST folks are coming by next week, and so we'll talk about that.

0:01:12	SPEAKER_06
 Who's coming?

0:01:14	SPEAKER_06
 John Fiskis, and I think George Dunn and we'll be around as well.

0:01:18	SPEAKER_06
 Okay, so we can talk about that.

0:01:20	SPEAKER_06
 I guess just hear about how things are going with the transcriptions, right?

0:01:26	SPEAKER_06
 So, maybe, maybe this is going to discuss.

0:01:30	SPEAKER_06
 Anything else?

0:01:34	SPEAKER_06
 It's striking, but...

0:01:38	SPEAKER_03
 We've started running recognition on one conversation, but it isn't working yet.

0:01:46	SPEAKER_03
 But if anyone has... the main thing would be if anyone has knowledge about ways to post-process the waveforms that would give us better recognition, that would be helpful to know about.

0:02:00	SPEAKER_10
 Talk conversation.

0:02:04	SPEAKER_08
 Yeah, so what about, is there anything new with the speech? Non-speech?

0:02:10	SPEAKER_01
 No, I'm working on it, but it's not finished.

0:02:14	SPEAKER_06
 All right, that seems like a good collection of things, and we'll end up with other things.

0:02:20	SPEAKER_04
 I had thought under my topic that I would mention the four items that I put out for being on the agenda on that meeting, which includes the presugmentation of the developments and multi-trans.

0:02:34	SPEAKER_06
 Oh, under the NIST meeting.

0:02:36	SPEAKER_06
 All right, when I start off with this... I guess the order we wrote up seems fine.

0:02:44	SPEAKER_06
 So, better quality, close talking mics.

0:02:46	SPEAKER_06
 So, the one issue was that the lapel mic isn't as good as you would like, and so it'd be better if we had close talking mics for everybody, right?

0:02:58	SPEAKER_06
 Is that basically the point?

0:03:00	SPEAKER_03
 Yeah, and actually in addition to that, that the close talking mics are worn in such a way as to best capture the signal.

0:03:10	SPEAKER_03
 The reason here is just that for the people doing work, not on microphones, but on sort of like dialogue and so forth, or even on prosody, which Donna's going to be working on soon, it adds this extra variable for each speaker to deal with when the microphones aren't similar.

0:03:28	SPEAKER_03
 So, and I also talked to Mary this morning, and she also had a strong preference for doing that, and in fact she said that that's useful for them to know and starting to collect their data too.

0:03:38	SPEAKER_03
 Right, so one...

0:03:41	SPEAKER_06
 Well, one thing I was going to say was that we could get more of the head-mounted microphones, even beyond the number of radio channels we have, because I think whether it's radio or wire is probably second order in the main time.

0:03:57	SPEAKER_06
 So, the main thing is having the microphone close to the mic, not too close.

0:04:02	SPEAKER_07
 So, actually the way it was A's is correct.

0:04:08	SPEAKER_07
 So, it's not correct?

0:04:11	SPEAKER_07
 Yes, it's good.

0:04:13	SPEAKER_07
 So, it's in the corner of your mouth, so that the sound doesn't get on it, and then just sort of a thumb on the half away from your mic.

0:04:22	SPEAKER_03
 Right. But we have more than one type of, I mean, Princeton here.

0:04:27	SPEAKER_07
 This one isn't very adjustable, so this is good as I get it, instead of fixed.

0:04:31	SPEAKER_03
 But if we could actually standardize, you know, the microphones as much as possible, that would be really helpful.

0:04:38	SPEAKER_06
 Well, I mean, it doesn't hurt to have a few extra microphones around, so why don't we just go out and get an order of if this microphone seems okay to people?

0:04:47	SPEAKER_07
 I just get a half dozen of them. The only problem with that is right now, some of the gen ones aren't working.

0:04:54	SPEAKER_07
 The box is under the table.

0:04:57	SPEAKER_07
 And so, I've only been able to find three jacks that are working.

0:05:02	SPEAKER_08
 Can we get these?

0:05:04	SPEAKER_03
 No, but my point is...

0:05:05	SPEAKER_03
 I could just record these signals separately and timeline in what the start of the meeting.

0:05:10	SPEAKER_07
 Right.

0:05:11	SPEAKER_06
 Right now, we've got two microphones in the room that are not quote-unquote standard.

0:05:18	SPEAKER_06
 So why don't we replace those?

0:05:20	SPEAKER_06
 Okay, just two.

0:05:22	SPEAKER_06
 Well, however many we can plug in, if we can plug in three, let's plug in three.

0:05:26	SPEAKER_06
 Also, we've talked before about getting another radio.

0:05:30	SPEAKER_06
 And so then that would be three.

0:05:34	SPEAKER_06
 So we should go out to our full complement of whatever we can do, but have them all be the same mic.

0:05:40	SPEAKER_06
 I think the original reason that it was done the other way was because it was sort of an experimental thing.

0:05:46	SPEAKER_06
 And I don't think anybody knew whether people would rather have more variety or more uniformity.

0:05:54	SPEAKER_07
 Sounds like you're more into the lens.

0:05:58	SPEAKER_03
 Well, for short-term research, there's just so much effort that would have to be done upfront.

0:06:04	SPEAKER_08
 You're probably going to be great.

0:06:11	SPEAKER_08
 You're saying for dialogue purposes, so that means that the transcribers are having trouble with those mics, is that what you mean?

0:06:13	SPEAKER_03
 They would know more about the transcriber.

0:06:15	SPEAKER_04
 And that's true.

0:06:16	SPEAKER_04
 I mean, we could discuss this.

0:06:18	SPEAKER_04
 And a couple times.

0:06:19	SPEAKER_04
 So, yeah, the transcribers notice that in fact there's somewhere...

0:06:23	SPEAKER_04
 Well, I mean, it's the double thing.

0:06:26	SPEAKER_04
 It's the equipment and also how it's worn.

0:06:28	SPEAKER_04
 And they always...

0:06:29	SPEAKER_04
 They just write about how wonderful Adam's at his class.

0:06:33	SPEAKER_03
 So does the recognize there.

0:06:35	None
 No, really.

0:06:35	SPEAKER_03
 Yeah, that's a problem.

0:06:36	SPEAKER_03
 I'm a fah!

0:06:37	SPEAKER_03
 Yeah, it's not just that.

0:06:38	SPEAKER_03
 It's your talking to someone else's mic.

0:06:40	SPEAKER_04
 It's not so loud with no breathing.

0:06:42	None
 No, you know, it's like...

0:06:44	None
 It's...

0:06:45	None
 It's just...

0:06:46	SPEAKER_04
 The transcribers point at you and also the one he's just pointing...

0:06:49	SPEAKER_07
 The point of doing the close-talk mic is to get a good quality signal.

0:06:53	SPEAKER_07
 We're not doing any search-drunken close-talk mics.

0:06:55	SPEAKER_07
 So we might as well give it a good view.

0:06:57	SPEAKER_06
 Now, this is locked in the barn door after the horse was stolen.

0:07:01	SPEAKER_06
 We do have 30 hours of speech, which is on this way.

0:07:04	SPEAKER_06
 But, yeah, for future ones, we can get it a bit more uniform.

0:07:09	SPEAKER_06
 So I think we just do a field trip at some point.

0:07:12	SPEAKER_06
 Yeah, probably.

0:07:13	SPEAKER_06
 Yeah, to the store we talked about.

0:07:15	SPEAKER_04
 And there was some talk about maybe the headphones that are uncomfortable.

0:07:19	SPEAKER_07
 Yeah, so this is...

0:07:20	SPEAKER_07
 We'll do a field trip and see if all of the same mic that's more comfortable than these things, which I don't know.

0:07:28	SPEAKER_02
 Great.

0:07:30	SPEAKER_02
 Thank you very much.

0:07:31	SPEAKER_03
 It makes our table a lot easier.

0:07:32	SPEAKER_07
 Okay, we're researchers.

0:07:33	SPEAKER_07
 And we'll have big hits.

0:07:36	SPEAKER_07
 Yeah.

0:07:37	SPEAKER_06
 Okay, second item was the NIST visit.

0:07:41	SPEAKER_06
 It's going on there.

0:07:42	SPEAKER_06
 Okay, so...

0:07:43	SPEAKER_04
 John, this is coming on the second of February.

0:07:47	SPEAKER_04
 There's a lot of people here, not everyone.

0:07:51	SPEAKER_04
 And he expressed an interest in saying the room and in saying a demonstration on the modified multi-trans, which I'll mention in a second.

0:08:03	SPEAKER_04
 And also, it was interested in the pre-segmentation.

0:08:06	SPEAKER_04
 And then he's also interested in transcription conventions.

0:08:10	SPEAKER_04
 And so it seems to me in terms of like...

0:08:15	SPEAKER_04
 Okay, so the room is things like the audio, audio, audio, acoustic properties, the room and how the recordings are done and that kind of thing.

0:08:25	SPEAKER_04
 Okay, in terms of the multi-trans, well, that's being modified by Dave Gilbert to a hand-roll multi-channel recording.

0:08:33	SPEAKER_07
 I see this thing mentioned in my interview to this meeting.

0:08:36	SPEAKER_07
 I've got to do it.

0:08:37	SPEAKER_02
 Yeah, okay.

0:08:39	SPEAKER_02
 Sorry.

0:08:40	SPEAKER_02
 Yeah, well that's a game.

0:08:42	SPEAKER_02
 Yeah, it looks really great.

0:08:44	SPEAKER_04
 He has a prototype.

0:08:45	SPEAKER_04
 I didn't see it yesterday, but I didn't see it today.

0:08:50	SPEAKER_04
 And that's that will enable us to do nice, tight, time-marking of the beginning and ending of overlapping segments at present.

0:08:59	SPEAKER_04
 It's not possible with limitations of the original design and software.

0:09:05	SPEAKER_04
 And so in terms of like pre-segmentation, that continues to be a terrific asset to the transcribers.

0:09:12	SPEAKER_04
 Do you...

0:09:13	SPEAKER_04
 I know that you're also supplementing it for the do you want to mention something about that, too?

0:09:17	SPEAKER_01
 Yeah, what I'm doing right now is I'm trying to include some information about which channel there's some speech in, but that's not working at the moment.

0:09:32	SPEAKER_01
 I'm just trying to do this by comparing energies, normalizing energies and comparing energies of the different channels.

0:09:39	SPEAKER_01
 And so to give the transcribers some information in which channel there's the speech.

0:09:44	SPEAKER_01
 In addition to the thing we did now, which is just speech non-speech detection on the mixed file.

0:09:51	SPEAKER_01
 So I'm relying on the segmentation of the mixed file, but I'm trying to subdivide the speech portions into different portions if there is some activity in different channels.

0:10:04	SPEAKER_01
 Excellent.

0:10:05	SPEAKER_04
 So it'd be like providing also a speaker idea.

0:10:09	SPEAKER_06
 Something I guess I didn't put in the list, but on that same day later on, and maybe it's...no, actually, this week, they've go over it and I will be visiting with John Canny, who is a CS professor who's interested in array microphones.

0:10:32	SPEAKER_06
 Oh, he's doing array.

0:10:33	SPEAKER_06
 Thanks.

0:10:34	SPEAKER_06
 And so we want to see what commonality there is here.

0:10:39	SPEAKER_06
 Maybe they'd want to stick an array of microphones when we're doing things.

0:10:43	SPEAKER_06
 Or maybe it's not a specific array microphone they want, but they might want to just...you could imagine them taking the four signals from these table mics and trying to do something with them.

0:10:56	SPEAKER_06
 I also had a discussion.

0:10:58	SPEAKER_06
 So we'll be over there talking with him after the class I'm fighting, which you know what goes on with that.

0:11:08	SPEAKER_06
 I also had a completely unrelated thing I had a discussion today with Berger Kolmeier, who's a German scientist.

0:11:17	SPEAKER_06
 He's got a fair-sized group doing a range of things, sort of a lot of Tory related, largely for hearing aids and so on.

0:11:24	SPEAKER_06
 But does stuff with auditory models and he's very interested in directionality and location and head models and paper film things.

0:11:34	SPEAKER_06
 He and possibly a student, there's a student of his who gave a talk here last year, may come here in the fall for sort of a five month sabbatical.

0:11:47	SPEAKER_06
 So it might be around to get him to give some talks and so on.

0:11:51	SPEAKER_08
 So anyway, he might be interested.

0:11:54	SPEAKER_08
 There reminds me of a thought of an interesting project that somebody could try to do with the data from here.

0:11:59	SPEAKER_08
 Either using the mics on the table or using signal energies from the head worn mics.

0:12:04	SPEAKER_08
 And that is to try to construct a map of where people were sitting.

0:12:08	SPEAKER_07
 Oh, did he?

0:12:09	SPEAKER_07
 Oh, that's interesting.

0:12:11	SPEAKER_07
 So that's the cross-correlation stuff.

0:12:13	SPEAKER_08
 And so you could plot out who was sitting next to who?

0:12:16	SPEAKER_06
 I mean, he didn't do a very extreme thing, but it was a sort of given that the block of wood with the two mics on either side.

0:12:25	SPEAKER_06
 If I'm speaking, or if you're speaking or someone over there speaking, you're looking across correlation functions.

0:12:31	SPEAKER_06
 If someone was on the axis between the two is talking, then you get a big peak there.

0:12:36	SPEAKER_06
 And if someone's talking on one side or the other, it was the other way.

0:12:41	SPEAKER_06
 It even looks different if the two people are on the other side are talking, then if one in the middle, it actually looks different.

0:12:49	SPEAKER_08
 So I was just thinking, you know, as I sit here next to Tilo, when he's talking, my mic probably picks it up better than your guy's's mic.

0:12:57	SPEAKER_08
 So if you just looked at the energy on my mic, you could get an idea about who's closest to who.

0:13:05	SPEAKER_08
 Or who talks the last.

0:13:08	SPEAKER_06
 Yeah, well, you have to, the appropriate normalizations are tricky.

0:13:14	SPEAKER_03
 You just search for Adam's voice on each individual mic.

0:13:19	SPEAKER_06
 Yeah, we switched positions recently.

0:13:26	SPEAKER_06
 So those are just a little couple of news items.

0:13:29	SPEAKER_04
 And then one thing, so John Fiskus expressed an interest in microphone arrays is there.

0:13:38	SPEAKER_04
 And I also want to say his e can't stay all day, he needs to leave for from here to make a 245 white.

0:13:45	SPEAKER_04
 No, it's just morning from all night.

0:13:48	SPEAKER_04
 Right.

0:13:49	SPEAKER_04
 Makes a sketch on a little bit type.

0:13:50	SPEAKER_04
 But do you think that John Canny should be involved in this somehow or not?

0:13:55	SPEAKER_06
 Probably not, but I'll know better after I see him this Friday.

0:13:58	SPEAKER_06
 What kind of level he wants to get involved.

0:14:01	SPEAKER_06
 He might be excited to and it might be very appropriate for him to or he might have noticed once or ever.

0:14:07	SPEAKER_06
 I guess really don't know.

0:14:08	SPEAKER_07
 Is he involved in, I'm blanking on the name of the project.

0:14:12	SPEAKER_07
 NIST has done a big meeting room, instrumented meeting room with video and microphone arrays and very elaborate solvers.

0:14:19	SPEAKER_07
 Well, that's what they're starting up.

0:14:21	SPEAKER_07
 Okay.

0:14:22	SPEAKER_06
 Yeah, no, I mean, that's what all this is about.

0:14:24	SPEAKER_06
 They haven't done it yet.

0:14:26	SPEAKER_06
 Okay, they wanted to do.

0:14:28	SPEAKER_07
 The papers that look like they had already done some work.

0:14:31	SPEAKER_06
 Well, I think they've instrumented the room, but I don't think they haven't started recordings yet.

0:14:36	SPEAKER_06
 They don't have the transcription standard.

0:14:39	SPEAKER_06
 Are they going to do a video as well?

0:14:40	SPEAKER_06
 Yeah, I think.

0:14:42	SPEAKER_07
 I think so.

0:14:43	SPEAKER_07
 What I had read was a fairly large amount of software infrastructure recording, and also live room where you're interacting with the computer and with the video and lots of stuff.

0:14:57	SPEAKER_06
 Well, I'm not sure.

0:14:59	SPEAKER_06
 All I know is that they've been talking to me about a project that they're going to start out recording people meeting and meetings.

0:15:05	SPEAKER_06
 And it is related to ours.

0:15:07	SPEAKER_06
 They were interested in ours.

0:15:08	SPEAKER_06
 They wanted to get some uniformity with us about the transcriptions and so on.

0:15:13	SPEAKER_06
 And one notable difference, actually, I can't remember whether they were going to routinely click video or not.

0:15:19	SPEAKER_06
 But one difference from the audio side was that they are interested in using raymines.

0:15:26	SPEAKER_06
 So, you know, you just tell you the party line on that.

0:15:29	SPEAKER_06
 The reason I didn't go for that here was because the focus, both the buy interest and the madam's interest, was in impromptu situations.

0:15:39	SPEAKER_06
 And we're not recording a bunch of impromptu situations, but that's because it's different to get data for research than to actually imply it.

0:15:47	SPEAKER_06
 And so, for scientific reasons, we thought it was good to instrument this room as we wanted it.

0:15:51	SPEAKER_06
 But the thing we ultimately wanted to aim at was a situation where you were talking with one or more other people in an impromptu way, where you didn't actually know what the situation was going to be.

0:16:04	SPEAKER_06
 And therefore, it would not be highly unlikely that room would be outfitted with some very carefully designed array of microphones.

0:16:11	SPEAKER_06
 So, it was only for that reason.

0:16:13	SPEAKER_06
 You know, yet another piece of research seemed like you had enough to know portable array of mic.

0:16:19	SPEAKER_06
 No, so there's a whole range of things. There's a whole array of things that people do on this.

0:16:26	SPEAKER_06
 So, the big arrays, places like Rutgers and Brown and other places, they have big arrays with 100 mikes or something.

0:16:41	SPEAKER_06
 And so, there's a wall of mics.

0:16:43	SPEAKER_06
 You get really, really good beampointing that sort of thing.

0:16:47	SPEAKER_06
 And in fact, at one point, we had a proposal in with Rutgers where we were going to do some of the sort of per-channel signal processing, and they were going to do multi-channel stuff.

0:17:00	SPEAKER_08
 I've seen demonstrations of the microphone array. It's amazing.

0:17:04	SPEAKER_08
 Yeah, how they can cut out noise.

0:17:06	SPEAKER_06
 And then they have the little ones.

0:17:08	SPEAKER_06
 They don't have a block of wood.

0:17:10	SPEAKER_06
 Yeah, our block of wood is unique.

0:17:12	SPEAKER_06
 But no, there are these commercial things now. You can buy that have four mics or something.

0:17:23	SPEAKER_06
 So, yeah, there's a range of things that people do.

0:17:26	SPEAKER_06
 So, if we connect that with somebody who was interested in doing that sort of thing, that's a good thing to do.

0:17:31	SPEAKER_06
 I mean, whenever I've described the people who are interested on the acoustic side, that's invariably the question they ask.

0:17:37	SPEAKER_06
 Just like someone who's interested in the general dialogue thing, we always ask, are you recording video?

0:17:43	SPEAKER_06
 Right.

0:17:44	SPEAKER_06
 And you could see people always say, well, are you doing a ray of microphone?

0:17:48	SPEAKER_06
 So, it's a good thing to do.

0:17:50	SPEAKER_06
 But it doesn't solve the problem of how do you solve things when there's one mic or at best two mics in this imagined VBA that we have.

0:17:58	SPEAKER_06
 So, maybe we'll do some more of that.

0:18:01	SPEAKER_04
 I mean, I know that having a ray of imagined would be more expensive than a ray of mic and mic and mic and mic.

0:18:08	SPEAKER_04
 But couldn't you kind of approximate the natural situation by just shutting off channels when you're later on?

0:18:15	SPEAKER_04
 I mean, it seems like if the mic and mic falls down and affect each other, then couldn't you just record them within a ray and then just not use all the data?

0:18:23	SPEAKER_07
 It's just a lot of infrastructure for our particular purpose, recalculate the center.

0:18:28	SPEAKER_06
 Yeah, if 99% of what you're doing is shutting off most of the mics and going through that.

0:18:33	SPEAKER_06
 But if you get someone who has that as a primary interest then that drives the right answer.

0:18:37	SPEAKER_06
 That's right.

0:18:38	SPEAKER_07
 Someone came in and said, you really want to do it?

0:18:40	SPEAKER_07
 I mean, we don't care.

0:18:41	SPEAKER_08
 So, to save that data, you have to have one channel recording per mic in the array?

0:18:47	SPEAKER_06
 Well, at some level, at some level, but then, you know, there's...

0:18:51	SPEAKER_08
 What you save, I mean, if you're going to do research with that.

0:18:54	SPEAKER_06
 I don't know what they're going to do and I don't know how big their array is.

0:18:58	SPEAKER_06
 Obviously, if you were going to save all of those channels for later research, you'd use up a lot of space.

0:19:03	SPEAKER_07
 Well, their software infrastructure had a very elaborate design for plugin helpters and mixers and all sorts of processing so that they can do stuff in real time and not save that each channel.

0:19:14	SPEAKER_07
 Yeah, that was...

0:19:17	SPEAKER_06
 But I mean, for optimum flexibility later, you want to save each channel, but I think in practical situations, you would have some engine of some sort doing some processing to reduce this to the equivalent of a single microphone that was very directional.

0:19:33	SPEAKER_08
 Oh, okay.

0:19:35	SPEAKER_08
 Sort of saving the result of the beam plugin.

0:19:38	SPEAKER_03
 It seems to me that there's, you know, there are good political reasons for doing this, just getting the data because there's a number of sites like...

0:19:46	SPEAKER_03
 Right now, SRI is probably going to invest a lot of internal funding into recording meetings also, which is good, but they'll be recording with video and they'll be...

0:19:57	SPEAKER_03
 You know, it'd be nice if we can have at least make use of the data that we're recording as we go.

0:20:04	SPEAKER_03
 This is the first site that has really collected these really impromptu meetings and just have this other information available.

0:20:11	SPEAKER_03
 So if we can get the investment in just the infrastructure and then, I don't know, save it out or have whoever's interested, save that data out, transfer it there, it would be good to have the recording.

0:20:26	SPEAKER_07
 You mean to actually get a microphone or a radio?

0:20:29	SPEAKER_07
 Well, even if we're not...

0:20:32	SPEAKER_03
 I'm not sure about video that sort of a video has a little different nature since, right now we're all being recorded, but we're not being taped.

0:20:40	SPEAKER_03
 But definitely in the case of microphone array since if there's a community interested in this.

0:20:45	SPEAKER_07
 Well, I think we need to reset our hears interested in it.

0:20:49	SPEAKER_05
 It's a bunch of long.

0:20:50	SPEAKER_06
 See, the problem is it took at least six months for Dan to get together the hardware and the software and debug stuff and the microphones and the boxes and it was a really big deal.

0:21:03	SPEAKER_06
 And so I think we could get a microphone array in here pretty easily and have it mixed to one channel of some sort.

0:21:13	SPEAKER_06
 But I think for...

0:21:16	SPEAKER_06
 I mean, how we're going to decide...

0:21:20	SPEAKER_06
 For maximum flexibility later, you really don't want to end up with just one channel that's pointed in the direction of the person with the maximum energy or something like that.

0:21:29	SPEAKER_06
 I mean, you want actually to have multiple channels being recorded so that you can...

0:21:36	SPEAKER_06
 And to do that, we're going to end up greatly increase the this space that we use up.

0:21:41	SPEAKER_06
 We also only have boards that will take up to 16 channels and this meeting we've got eight people and six mics in there were already using 14.

0:21:50	SPEAKER_07
 And we actually only have 15.

0:21:53	SPEAKER_03
 15, 16. Well, if there's a way to say time to sort of solve each of these those...

0:22:00	SPEAKER_03
 So suppose you can get an array in because there's some person that Berkeley who's interested and has some equipment.

0:22:06	SPEAKER_03
 And suppose we can...

0:22:08	SPEAKER_03
 As we save it, we can transfer it off to some other place that holds this data.

0:22:14	SPEAKER_03
 Who's interested, even if it's the itself isn't.

0:22:18	SPEAKER_03
 And it seems like as long as we can time align the beginning, do we need to mix it with the rest? I don't know.

0:22:25	SPEAKER_06
 Yeah, so I think you need a separate set up and the assumption that you could time align the two.

0:22:30	SPEAKER_03
 I mean, it's just... it's worth considering as sort of once you make the upfront investment and can sort of save it out each time and not have to worry about the dis space factor than it might do with having the data.

0:22:42	SPEAKER_06
 It's not so much worried about this space. I mentioned that as a practical matter, but the real issue is that there's no way to do a recording extended to what we have now with low skew.

0:22:53	SPEAKER_06
 So you would have a completely separate set up, which would mean that the sampling times and so forth would be all over the place compared to this.

0:23:01	SPEAKER_06
 So it would depend on the level of processing you're doing later.

0:23:05	SPEAKER_06
 The kind of person who's doing array processing you actually care about funny little times.

0:23:12	SPEAKER_06
 So you actually would want to have a completely different set up than we have one that would go up to 32 channels or something.

0:23:17	SPEAKER_06
 So basically...

0:23:20	SPEAKER_06
 So I'm kind of skeptical.

0:23:22	SPEAKER_06
 But I don't think we can share the resource in that way.

0:23:27	SPEAKER_06
 What we could do is if there's someone else that's interested, they could have a separate set up which they wouldn't be trying to sync with ours, which might be useful for...

0:23:35	SPEAKER_06
 And then we can offer up the rule.

0:23:38	SPEAKER_06
 Yeah, we can offer the meetings and the physical space and... yeah, the transcripts.

0:23:42	SPEAKER_03
 Right, I mean, it'd be nice if we have more information on the same data.

0:23:47	SPEAKER_03
 Yeah.

0:23:48	SPEAKER_03
 But if it's impossible or if it's a lot of effort then you have to just balance it too.

0:23:52	SPEAKER_06
 Yeah, the thing will be... and talking to you, these other people to see what we can do.

0:23:59	SPEAKER_08
 Is there an interest in getting video recordings for these meetings?

0:24:03	SPEAKER_08
 Right, so we had some...

0:24:05	SPEAKER_07
 It's actually the same problem that you have an infrastructure problem.

0:24:10	SPEAKER_07
 You have a problem with people not wanting to be video-tabied with your problem.

0:24:13	SPEAKER_07
 And no one who's currently involved in the project is really hot to do it.

0:24:17	SPEAKER_08
 So there's not enough interest to overcome it.

0:24:20	SPEAKER_03
 Not entirely, but I know there is interest from other places that are interested in looking at meeting data and having the video.

0:24:27	SPEAKER_03
 So it's just...

0:24:28	SPEAKER_04
 Yeah, well, well, I have to mention the human subjects problems that increase with video.

0:24:35	SPEAKER_04
 Right.

0:24:36	SPEAKER_06
 Yeah, so people getting shy about it, there's this human subjects problem, there's the fact that then...

0:24:44	SPEAKER_06
 I heard comments about this.

0:24:46	SPEAKER_06
 Well, why don't you just put on a video camera?

0:24:48	SPEAKER_06
 You know, it's sort of like saying, well, we're primarily interested in some dialogue things.

0:24:54	SPEAKER_06
 But why don't we just throw a microphone out there?

0:24:57	SPEAKER_06
 I mean, the thing is, once you actually have serious interest in any of these things, then you actually have to put a lot of effort in.

0:25:03	SPEAKER_06
 And you really want to do it right.

0:25:06	SPEAKER_06
 So I think NIST or LBC or something like that, I think is much better shape to do all of that.

0:25:11	SPEAKER_06
 There will be other meeting recordings.

0:25:13	SPEAKER_06
 We won't be the only place to be meeting recordings.

0:25:15	SPEAKER_06
 We're doing what we're doing, and hopefully it will be useful.

0:25:19	SPEAKER_04
 It's pretty much done in the scientific form.

0:25:23	SPEAKER_07
 Probably not.

0:25:24	SPEAKER_07
 Did you sign up?

0:25:25	SPEAKER_07
 What did you do actually?

0:25:26	SPEAKER_07
 Did you read in the industry?

0:25:28	SPEAKER_09
 Yeah, I was...

0:25:29	SPEAKER_08
 You were here to meet you before.

0:25:30	SPEAKER_09
 I was here before once.

0:25:31	SPEAKER_09
 You were here to sign up for it.

0:25:32	SPEAKER_09
 Did you sign up for it?

0:25:33	SPEAKER_09
 I think so.

0:25:34	SPEAKER_09
 I'll get it done before we meet.

0:25:36	SPEAKER_04
 Thank you.

0:25:37	SPEAKER_04
 Yeah.

0:25:38	SPEAKER_04
 You don't have to leave me behind.

0:25:39	SPEAKER_04
 I just...

0:25:40	SPEAKER_05
 I can't really leave you behind.

0:25:42	SPEAKER_05
 You're being recorded, isn't it?

0:25:45	SPEAKER_02
 We don't perform electroshock during this meeting.

0:25:47	SPEAKER_02
 That's fine.

0:25:48	SPEAKER_02
 Usually.

0:25:49	SPEAKER_05
 Okay.

0:25:50	None
 Transcriptions.

0:25:51	SPEAKER_06
 Okay.

0:25:52	SPEAKER_04
 I thought about the many three aspects of this.

0:25:59	SPEAKER_04
 So first of all, I got eight transcribers.

0:26:03	SPEAKER_04
 Seven of them were linguists.

0:26:05	SPEAKER_04
 One of them was a graduate student in psychology.

0:26:08	SPEAKER_04
 I gave each of them their own data set.

0:26:12	SPEAKER_04
 Two of them have already finished the data sets.

0:26:14	SPEAKER_04
 And the meetings around, you know, it would say an hour.

0:26:17	SPEAKER_04
 Sometimes it's not just an hour and a half.

0:26:19	SPEAKER_04
 What I mean is one meeting.

0:26:21	SPEAKER_04
 Each person got their own meeting.

0:26:22	SPEAKER_04
 I don't want to have any conflicts of, you know, when to stop transcribing this one.

0:26:27	SPEAKER_04
 So I wanted to keep it clear whose data was.

0:26:30	SPEAKER_04
 And so...

0:26:31	SPEAKER_04
 And meetings, you know, I think that they go as long as two hours in some cases.

0:26:38	SPEAKER_04
 And that means, you know, if we've got two already finished and they're working on right now, all of them have additional data sets.

0:26:47	SPEAKER_04
 That means potentially as many as ten might be finished by the end of the month.

0:26:50	SPEAKER_04
 Also, the pre-signitation really helps a huge number.

0:26:53	SPEAKER_04
 And also, Dan Ellis's innovation of the multi-channel to hear really helped a lot, in terms of clearing up your earrings that evolve over labs.

0:27:03	SPEAKER_04
 But just out of curiosity, I asked one of them how long it was taking here.

0:27:07	SPEAKER_04
 One of these two is already finished her data set.

0:27:09	SPEAKER_04
 She said it takes about 60 minutes transcription for every five minutes of real time.

0:27:13	SPEAKER_04
 So it's about 12 to one, which is what we were making.

0:27:16	SPEAKER_04
 It's well in the finish.

0:27:17	SPEAKER_04
 Okay.

0:27:18	SPEAKER_04
 At least still, when they're finished, that means that they're finished with their pastor.

0:27:23	SPEAKER_04
 They still need to be edited and all, but it's word-level, the speed for change, the things that we were mentioned.

0:27:27	SPEAKER_04
 Okay. Now I wanted to mention the teleconference I had with John Fiskus.

0:27:32	SPEAKER_04
 I was sold for an hour and a half, and had not bought a lot of things in common.

0:27:37	SPEAKER_04
 He indicated to me that he's been spending a lot of time with, quite sure the connection, but spending a lot of time with the Atlas system.

0:27:49	SPEAKER_04
 And I guess that, I mean, I need to read up on that, and there's a website that has lots of papers.

0:27:54	SPEAKER_04
 But it looks to me like that's the name that has developed a system that birthed the leave room and developed for the annotated graphs approach.

0:28:03	SPEAKER_04
 So what he wants me to do, and what we will do, is to provide them with an RE transcribe meeting for him to be able to experiment with in this Atlas system.

0:28:14	SPEAKER_04
 And they do have some sort of self-draight, my impression, related to Alice, and that he wants to experiment with taking our data and putting in that form and see how that works out. I explained to him in tail the conventions that we're using here in this word-level transcript. And I explained the reasons that we were not coding more elaborately, and they focus on reliability.

0:28:40	SPEAKER_04
 He expressed a lot of interest in reliability. He's really up on these things.

0:28:45	SPEAKER_04
 He's very independently, yes, well, what about reliability?

0:28:49	SPEAKER_04
 He's interested in the consistency of the encoding and that sort of thing.

0:28:54	SPEAKER_03
 So can you explain what the Atlas and that move?

0:28:58	SPEAKER_04
 Well, at this point, I think, well, Adam's read more in more detail than I have on this.

0:29:04	SPEAKER_04
 I need to equate myself more with it, but there's a way of viewing, whenever you have coding categories, and you're dealing with taxonomy, then you can have branches that have alternative choices that you could use for each of them.

0:29:22	SPEAKER_04
 And it just sends up looking like a graph or a presentation.

0:29:24	SPEAKER_07
 Is Atlas the annotated transcription graph stuff?

0:29:29	SPEAKER_07
 I don't remember the acronym. The one I think you're referring to, they have this concept of an annotated transcription graph representation.

0:29:37	SPEAKER_07
 And that basically, when I based the format that I did, I based it on their work almost directly in combination with the TEI stuff. And so it's very, very similar.

0:29:47	SPEAKER_07
 And so it's a data representation and set of tools for manipulating transcription graphs of various types.

0:29:54	SPEAKER_08
 Is this the project that's sort of between NIST and a couple of other places?

0:30:01	SPEAKER_08
 I think you know the CIFA stuff.

0:30:03	SPEAKER_04
 Yeah, yeah.

0:30:04	SPEAKER_04
 There's a website that has lots of papers. I'll look through them and they've mainly had to do with this tree structure annotated tree.

0:30:11	SPEAKER_04
 And I have a thing.

0:30:13	SPEAKER_04
 So, in terms of the conventions that I've adopted, there's no conflict at all.

0:30:20	SPEAKER_04
 And he was very interested in, oh, how did you handle this one?

0:30:23	SPEAKER_04
 I said, well, you know, this way. And we had a really nice conversation.

0:30:27	SPEAKER_04
 Okay, now I also wanted to say a different direction is Brian Kingsbury.

0:30:32	SPEAKER_04
 So I correspond briefly with him.

0:30:35	SPEAKER_04
 He still has an account here. I told him he could SSH on use multitrans and have a look at the already done transcription.

0:30:43	SPEAKER_04
 And he did. And what he said was that what they'll be providing is will not be as fine-grained in terms of the time information.

0:30:52	SPEAKER_04
 And that's, you know, I need to get back to him and explore that a little bit more and see what they'll be giving us.

0:31:00	SPEAKER_08
 So, the specific piece of the folks that they're subcontracting out the transcription to are they like court reporters?

0:31:07	SPEAKER_04
 Apparently, well, I get the sense they're kind of like that. It's like a pool of somewhat secretarial.

0:31:13	SPEAKER_04
 I don't think that they're court reporters. I don't think they have a special keyboard and that type of training.

0:31:18	SPEAKER_04
 I get the sense they're more secretarial. And that what they're doing is giving them medical transcriptionist types people.

0:31:24	SPEAKER_08
 So, it's for their speech recognition products. So, they're hiring them. They're coming in. It's not a service they send the tapes out to.

0:31:32	SPEAKER_07
 Well, they do send it out, but my understanding is that that's all that's coming. It's transcription.

0:31:37	SPEAKER_07
 So, most of it is via voice people reading. I see. They're trying to real support them.

0:31:43	SPEAKER_04
 I see. After that, it's been monologues for us. And what they're doing is, Brian himself downloaded.

0:31:50	SPEAKER_04
 So, Adam, something to see, Brian himself downloaded. We wanted to have it so that they were familiar with terms.

0:31:57	SPEAKER_04
 What they wanted to do. He downloaded from CD on to audio tapes. Apparently, he did it one channel per audio tape.

0:32:04	SPEAKER_04
 So, each of these people is transcribing from one channel. And then what he's going to do is check it.

0:32:10	SPEAKER_04
 Before they go beyond the first one, check it.

0:32:14	SPEAKER_06
 So, each person gets one of these channels. So, if they hear something off in the distance, they don't...

0:32:21	SPEAKER_06
 They just go...

0:32:23	SPEAKER_07
 That's okay because you'll do all of them in the end of the mind.

0:32:27	SPEAKER_08
 But there could be problems, right? Like that.

0:32:29	SPEAKER_04
 I think it would be difficult to do it that way. I really...

0:32:32	SPEAKER_08
 Well, if you got that channel right there...

0:32:34	SPEAKER_07
 No, no, close talk.

0:32:36	SPEAKER_07
 Not the desktop. Are you?

0:32:38	SPEAKER_04
 Yes. I sure am. I really foolish to do otherwise.

0:32:41	SPEAKER_04
 I think it would be hard to come up with.

0:32:44	SPEAKER_03
 I think it's hard just playing the...

0:32:47	SPEAKER_03
 Just having played the individual files.

0:32:50	SPEAKER_03
 I mean, I know what your voice sounds like. I'm familiar with it.

0:32:54	SPEAKER_03
 It's pretty hard to follow, especially...

0:32:57	SPEAKER_03
 There are a lot of words that are so reduced phonetically that make sense when you know what the person was saying before.

0:33:03	SPEAKER_03
 Yeah, that's it.

0:33:04	SPEAKER_03
 Especially to define these where you are in...

0:33:06	SPEAKER_07
 We've had this discussion many times. The answers we don't actually know the answer because we haven't tried both ways.

0:33:12	SPEAKER_04
 Well, except I can say that my transcribers use the mix signal mostly.

0:33:16	SPEAKER_04
 Unless there's a huge disparity in terms of the volume of the mix, in which case, you know, they...

0:33:21	SPEAKER_04
 They wouldn't be able to catch anything except from the channel.

0:33:25	SPEAKER_07
 That might change in one of really fine time markings.

0:33:28	SPEAKER_07
 Well, okay.

0:33:30	SPEAKER_03
 But they're not giving really fine markings.

0:33:32	SPEAKER_03
 So, are they giving any time markings?

0:33:36	SPEAKER_03
 I'm not even asking.

0:33:37	SPEAKER_03
 And I stress my email to you and that needs to be with Compa.

0:33:39	SPEAKER_04
 But I didn't want to say that it's hard to follow one channel of a conversation even if you know the people.

0:33:45	SPEAKER_04
 And if you're dealing furthermore with a highly abstract network concepts you've never heard of.

0:33:50	SPEAKER_04
 One of these people was transcribing the network's group talk of the city.

0:33:54	SPEAKER_04
 I don't really know what a lot of these abbreviations are.

0:33:57	SPEAKER_04
 But I just put them in parentheses.

0:33:59	SPEAKER_04
 I just don't know if you're interested in that.

0:34:03	SPEAKER_07
 Just that of curiosity.

0:34:05	SPEAKER_07
 I mean, a lot of heavy accents.

0:34:07	SPEAKER_08
 Given all of the effort that is going on here in transcribing, why do we have IBM doing it?

0:34:11	SPEAKER_08
 Why not just do it all ourselves?

0:34:13	SPEAKER_06
 It's historical.

0:34:15	SPEAKER_06
 I mean, at some point ago we thought that, boy, we'd really have to ramp up to do that.

0:34:22	SPEAKER_06
 Like we just did.

0:34:23	SPEAKER_06
 And here's a collaborating institution that's volunteering to do it.

0:34:29	SPEAKER_06
 So that was a contribution they can make in terms of time, money.

0:34:35	SPEAKER_06
 I'm just wondering now.

0:34:36	SPEAKER_08
 I'm wondering now.

0:34:37	SPEAKER_03
 Yeah, my heart is asking the same question as sort of talking about more e-mail layers.

0:34:42	SPEAKER_03
 Yeah.

0:34:43	SPEAKER_05
 Yeah.

0:34:46	SPEAKER_06
 So, let's see.

0:34:54	SPEAKER_06
 I mean, I think they've proceeded long a bit.

0:34:56	SPEAKER_04
 Let's see what comes out of it and have some more discussions with them.

0:35:00	SPEAKER_04
 It's very, a real benefit having Ryan involved because his knowledge of what the

0:35:04	SPEAKER_07
 have a data need to be used and so what is useful to have. Yeah.

0:35:08	SPEAKER_03
 So Liz with the SRI recognize or can it make use of some time marks?

0:35:13	SPEAKER_03
 I think this is what Don has been, he's already been really helpful in chopping up these.

0:35:19	SPEAKER_03
 So first of all, before the SRI front end, we really need to chop things up into pieces that are not too huge.

0:35:29	SPEAKER_03
 But second of all, in general, because some of these channels, I'd say like, I don't know, at least half of them, probably on average, have a lot of cross talk.

0:35:43	SPEAKER_03
 It's good to get sort of short segments if you're going to do recognition, especially forced alignment.

0:35:52	SPEAKER_03
 So, Don has been taking a first stab actually using James first, the first meeting that James transcribed, which we did have some problems with and Tilo, I think told me why this was, but that people were switching microphones around in the very beginning.

0:36:07	SPEAKER_03
 So, yes, right.

0:36:08	SPEAKER_01
 And they were not switching them, but they were adjusting them.

0:36:11	SPEAKER_01
 So, after a minute or so, it's way better.

0:36:15	SPEAKER_03
 So, we have to sort of normalize the front end and so forth and have these small segments.

0:36:20	SPEAKER_03
 So, we've taken that and chopped it into pieces, based always on your cuts that you made on the mix signal.

0:36:29	SPEAKER_03
 And so, every speaker has the same cuts, and if they have speech in it, we run it through.

0:36:34	SPEAKER_03
 And if they don't have speech in it, we don't run it through and we face that knowledge on the transcription.

0:36:40	SPEAKER_03
 The problem is if we have no time marks, then for forced alignment, we actually don't know where, you know, in the signal, the transcriber heard that word.

0:36:50	SPEAKER_03
 And so, if it's a whole conversation and we get a long, you know, paragraph of talk, I don't know how they do this, we actually don't know which piece goes where.

0:37:04	SPEAKER_08
 Well, you need to, like, a forced alignment before you do the chopping, right?

0:37:08	SPEAKER_03
 No, we use the fact that, so when Jane transcribes in the way she has transcribers doing this, whether it's with a pre-segmentation or not, they have a chunk and then they transcribes the words in the chunk.

0:37:18	SPEAKER_03
 And maybe they choose the chunk or now they use a pre-segmentation and then correct it, necessary, but they're supposed to chunk and then a transcription, then a chunk and a transcription.

0:37:27	SPEAKER_03
 That's great, because the recognizer can...

0:37:30	SPEAKER_07
 It's all to be good sized for the right recognizer roles.

0:37:33	SPEAKER_03
 Right, and it helps that it's made based on sort of heuristics and human ear.

0:37:39	SPEAKER_03
 But there's going to be a real problem, even if we chop up based on speech silence, these, the transcripts from IBM, we don't actually know where the words were, which segments they belong to.

0:37:53	SPEAKER_08
 That's sort of what we're worried about. A forced alignment. That's what she's saying, is that they can't.

0:37:59	SPEAKER_03
 If you do a forced alignment on something really...

0:38:02	SPEAKER_03
 Well, even if you do it on something really long, you need to know...

0:38:05	SPEAKER_03
 You can always chop it up, but you need to have a reference of which words went with which chop.

0:38:11	SPEAKER_03
 So...

0:38:12	SPEAKER_06
 I think that they are...

0:38:19	SPEAKER_06
 Yeah, I'm sure they will, and so we have to have a dialogue with them.

0:38:25	SPEAKER_03
 It sounds like we just have concerns.

0:38:27	SPEAKER_03
 Maybe actually there is some, even if they're not fine-grained, maybe the transcribers, I don't know, maybe it's saved out in pieces or something, that would help.

0:38:37	SPEAKER_03
 But it's just an unknown right now.

0:38:39	SPEAKER_04
 I need to know a right to it. I just think it was that I got over 10.

0:38:43	SPEAKER_03
 But it is true that the segments... I haven't tried the segments that T-Lo gave you, but the segments that in your first meeting are great.

0:38:51	SPEAKER_03
 That's a good length.

0:38:53	SPEAKER_03
 Good size, good size.

0:38:54	SPEAKER_04
 I was thinking, would you find it to win line?

0:38:58	SPEAKER_04
 Give us a pre-signitation.

0:39:00	SPEAKER_04
 Maybe you have one already, at the meeting that the first transcrib meeting, the one that I transcried?

0:39:07	SPEAKER_01
 Sure, I have some, but that's the one where I'm training on.

0:39:13	SPEAKER_04
 Oh, I see.

0:39:14	SPEAKER_01
 A little bit of dog soup.

0:39:18	SPEAKER_03
 And actually, as you get transcribes for new meetings, we can try...

0:39:24	SPEAKER_03
 The more data we have to try the alignments on the better.

0:39:28	SPEAKER_03
 So it'd be good for... just to know as transcriptions are coming through the pipeline from the transcribers, we're playing around with parameters on the recognizer.

0:39:39	SPEAKER_03
 That would be helpful.

0:39:40	SPEAKER_03
 Especially as you get more voices.

0:39:42	SPEAKER_03
 The first meeting had, I think, just four people.

0:39:45	SPEAKER_04
 It wasn't nice, but it was suddenly on Tuesday.

0:39:48	SPEAKER_04
 And I was planning to do just a preliminary look over a two that are finished and then give it to you.

0:39:55	SPEAKER_04
 Okay.

0:39:58	SPEAKER_02
 That's great.

0:40:00	SPEAKER_06
 I guess the other thing, I can't remember if we discussed this in the meeting, but I know you and I talked about this a little bit.

0:40:06	SPEAKER_06
 There was an issue of...

0:40:08	SPEAKER_06
 Suppose we get in the... I guess it's in a vehicle position, although it is just saying where the weak link is in the chain.

0:40:16	SPEAKER_06
 Where we have all the data transcribed and we have these transcribers and we're still a bit slow on feeding.

0:40:28	SPEAKER_06
 At that point we've caught up and the weak link is recording meetings.

0:40:35	SPEAKER_06
 Okay.

0:40:37	SPEAKER_06
 Two questions come is, you know, how do we...

0:40:40	SPEAKER_06
 It's not really a problem one because we haven't reached that point, but how do we step out the recorded meetings?

0:40:45	SPEAKER_06
 And the other one is, is there some good use that we can make of the transcribers to do other things?

0:40:52	SPEAKER_06
 So I can't remember how much we talked about this in this meeting, but...

0:40:57	SPEAKER_04
 And there is one use that also we discussed, which was when Dave finishes the...

0:41:02	SPEAKER_04
 And maybe it's only been the modification to a multitrans which will allow fine grain encoding of overlaps, then it would be... These people would be very good to shift over to finer grain encoding of overlaps just when providing.

0:41:17	SPEAKER_04
 So right now you have two overlapping segments in the same time, and one would be improvement in the database, and in the answering interface, be possible to just do a click and drag thing and get the specific place of each of those at the time of the time.

0:41:31	SPEAKER_04
 So say, at the beginning of each segment.

0:41:34	SPEAKER_06
 Right, so I think we talked about three things. One was, it's had some discussion that has to have some very high level...

0:41:41	SPEAKER_06
...labelaps, types of overlaps and so forth, that someone could do.

0:41:45	SPEAKER_06
 Second was, some lower level of just doing these more precise timings.

0:41:50	SPEAKER_06
 And the third one is just completely wild airbrained idea that I have, which is that if we have time and people are able to do it, take some subset of the data and do some very fine grain analysis of the speech, for instance, marking in some overlapping, potentially overlapping fashion, the value of articulatory features.

0:42:14	SPEAKER_06
 You know, just sort of say, okay, it's voiced from here to here, there's nasal from here to here, and so forth.

0:42:21	SPEAKER_06
 And as opposed to doing phonetic analysis and assuming articulatory feature values for those things, obviously it's extremely time consuming. That would be really valuable.

0:42:39	SPEAKER_06
 But we could do it on some small subset.

0:42:42	SPEAKER_04
 Also, could you do anyone's consciousness that would be easier than a balance with it?

0:42:46	SPEAKER_04
 I don't think that being able to code that there's a fricative extended from here to here would be a lot easier than classifying precisely which a vowel that was.

0:42:57	SPEAKER_04
 I think a balanced bowser, I think harder.

0:43:00	SPEAKER_06
 Well, yeah, but I think also it's just the issue that when you look at the switchboard, for instance, very close up, where places where whether it's a consonant or a vowel, you still have trouble calling it a particular phone at that point.

0:43:16	SPEAKER_06
 Because there's this movement from here to here and it's...

0:43:21	SPEAKER_08
 You're saying sort of remove the high level of constraints and go bottom up.

0:43:24	SPEAKER_06
 Yeah, describe it now. I'm suggesting articulatory features.

0:43:27	SPEAKER_06
 Maybe there's even a better way to do it, but that's sort of a traditional way of describing these things.

0:43:35	SPEAKER_06
 And I mean, actually, this might be a neat technique to talk to.

0:43:39	SPEAKER_08
 Acoustic features versus psychological categories.

0:43:41	SPEAKER_06
 I mean, it's still some sort of categories, but something that allows for overlapping change of these things.

0:43:47	SPEAKER_06
 And then this would give some more groundwork for people who are building statistical models that allow for overlapping changes, different timing changes, as opposed to just click.

0:43:57	SPEAKER_06
 You're now in a state which, of course, allows to this speech.

0:44:00	SPEAKER_03
 So this is like gestural.

0:44:02	SPEAKER_06
 And actually, if we get into that, it might be good to haul John O'Hall into this, as his views on it.

0:44:10	SPEAKER_03
 But is the goal there to have this on meeting data so that you can do far-field stories of those gestures?

0:44:16	SPEAKER_03
 Or is it because you think there's a different kind of actual production in meetings that people use?

0:44:23	SPEAKER_06
 No, I think it's for that purpose.

0:44:25	SPEAKER_06
 I'm just viewing meetings as being a neat way to get people talking naturally.

0:44:32	SPEAKER_06
 And then it's natural in all senses, in the sense that you have microphones that are at a distance that one might have.

0:44:38	SPEAKER_06
 And you have the close mics, and you have people talking naturally.

0:44:42	SPEAKER_06
 And the overlap is just a digger of the fact that people are talking naturally.

0:44:45	SPEAKER_06
 So I think that given that it's that kind of corpus, if it's going to be a very useful corpus, if you say, OK, we've limited the use by some of our sensor choices.

0:44:57	SPEAKER_06
 We don't have a video, we don't, so forth.

0:45:00	SPEAKER_06
 But there is a lot of use that we could make of it by expanding the annotation choices.

0:45:06	SPEAKER_06
 And most of the things we've talked about have been fairly high level, and kind of a bomb up person.

0:45:12	SPEAKER_06
 I thought there'd be some of the others.

0:45:14	SPEAKER_04
 It's a really nice offer, those things that might range.

0:45:17	SPEAKER_06
 Hopefully someone would make use of it. I mean, people made a lot of use of Timit and did its markings.

0:45:24	SPEAKER_06
 And then the switchboard transcription thing, I think it's been very useful for a lot of people.

0:45:30	SPEAKER_03
 I guess I wanted to make a pitch for trying to collect more meetings.

0:45:39	SPEAKER_03
 Yeah.

0:45:40	SPEAKER_03
 Actually, I talked to Chuck Filmer, and I think they've what vehemently said no before, but this time he wasn't vehement, and he said, well, Liz, come to the meeting tomorrow and try to convince people.

0:45:51	SPEAKER_03
 So I'm going to try, go to their meeting tomorrow and see if we can try.

0:45:57	SPEAKER_03
 Because they have something like three or four different meetings.

0:46:00	SPEAKER_03
 And we have very interesting meetings from the point of view of a very different type of talk than we have here, and definitely than the front-end meeting, probably.

0:46:09	SPEAKER_08
 In terms of the topic.

0:46:10	SPEAKER_03
 Well, yes, and in terms of the fact that they're describing abstract things, and it just dialogue-wise, right?

0:46:18	SPEAKER_03
 So I'll try.

0:46:19	SPEAKER_03
 And then the other thing is, I don't know if this is at all useful, but I asked Lila if I can maybe go around and talk to the different departments in this building to see if there's any groups that, for free lunch, if we can still offer that.

0:46:31	SPEAKER_03
 You're not going to see nonexionic, academic, government, I don't know.

0:46:36	SPEAKER_07
 The problem is so much that it's done as confidential. It would be very hard for them.

0:46:40	SPEAKER_07
 Also, I think it takes its way to the point of that.

0:46:43	SPEAKER_04
 I mean, it seems like we had this idea before of having like linguistic students brought down for a few lectures.

0:46:48	SPEAKER_03
 Right, and we could also, we might try advertising again, because I think it would be good if we can get a few different sort of non-internal types of meetings, and just also more data.

0:46:59	SPEAKER_08
 Does John O'Hill have weekly phonetic reactions?

0:47:02	SPEAKER_03
 So I actually wrote to him and he answered, great, that sounds really interesting, but I never heard back, because we didn't actually advertise openly.

0:47:11	SPEAKER_03
 I told I'd asked him privately.

0:47:14	SPEAKER_03
 And it is a little bit of a trek for campus folks.

0:47:18	SPEAKER_07
 It would be nice if we got someone other than me who knew how to set it up to do the recording, so I didn't have to.

0:47:26	SPEAKER_03
 Exactly, and I was thinking.

0:47:28	SPEAKER_02
 He's supposed to be trained.

0:47:30	SPEAKER_03
 Plus, we could also get a student, and I'm willing to try to learn.

0:47:35	SPEAKER_03
 I mean, I would do my best.

0:47:37	SPEAKER_03
 The other thing is that there's a number of things at the transcription side that transcribers can do, like dialogue, tagging, this fluency tagging, things that are in the speech that are actually something we're working on for language modeling.

0:47:54	SPEAKER_03
 And Mari is also interested in Andreas as well.

0:47:57	SPEAKER_03
 If you want to process utterance, the first thing they say is, well, and that well is coded as some kind of interrupt tag, and things like that.

0:48:08	SPEAKER_04
 Of course, some of that can be done like so clearly.

0:48:10	SPEAKER_04
 And I also heard a lot of utility done to tagging.

0:48:13	SPEAKER_03
 Great, so a lot of this kind of, I think there is a second pass, and I don't really know what would exist in it, but there's definitely a second pass worth doing to maybe encode some kinds of, you know, is it a question or not?

0:48:25	SPEAKER_03
 That maybe these transcribers could do.

0:48:28	SPEAKER_04
 Maybe really good.

0:48:31	SPEAKER_04
 Well, while we're interested in just briefly to this question of more meeting data, two questions.

0:48:38	SPEAKER_04
 One of them is Jerry Falman's group.

0:48:41	SPEAKER_04
 They know that they recorded one meeting.

0:48:45	SPEAKER_06
 I think they're open to it.

0:48:46	SPEAKER_06
 I think all these things, I think there's, we should go beyond XE, but I mean there's a lot of stuff having an XE that we're not getting out of.

0:48:53	SPEAKER_03
 Okay, I thought that all these people had sort of said no twice already.

0:48:57	SPEAKER_06
 No, no, no, so there was the thing in Film Wars Group, but even there he hadn't what he'd said no to was for the main meeting, but they have several smaller meetings a week.

0:49:08	SPEAKER_06
 And the notion was raised before that that could happen, and just, you know,

0:49:13	SPEAKER_08
 and the other thing too is when they originally said no, they didn't know about this post-editing capability.

0:49:23	SPEAKER_06
 Yeah, so I mean there's possibilities there. I think Jerry's group, yes.

0:49:26	SPEAKER_06
 There's the network's group.

0:49:28	SPEAKER_06
 Do they still meet regularly?

0:49:30	SPEAKER_07
 Well, I don't know if they meet regularly or not.

0:49:32	SPEAKER_07
 They're no longer reporting.

0:49:34	SPEAKER_06
 But I mean, have they said they don't want to anymore?

0:49:38	SPEAKER_07
 What was his name?

0:49:40	SPEAKER_07
 Yeah, when with him gone, it sort of tripled off.

0:49:45	SPEAKER_05
 Okay, so they're down to three or four people, but the thing is three or four people is okay.

0:49:50	SPEAKER_04
 We might be only hearing this.

0:49:51	SPEAKER_07
 Well, he was sort of like contact, so I just need to find out who's running in the house.

0:49:55	SPEAKER_04
 Okay.

0:49:56	SPEAKER_04
 I see that Leva has a much meeting period.

0:49:58	SPEAKER_03
 Yeah, I mean, one thing that would be nice, and it sounds bizarre, but I'd really like to look at, to get some meetings where there's a little bit of heated discussion like arguments, or emotions, and things like that.

0:50:11	SPEAKER_03
 And so I think if there's any like Berkeley political groups, I mean that would be perfect.

0:50:15	SPEAKER_03
 So, yes, we might.

0:50:17	SPEAKER_07
 Who's really good at running in the street?

0:50:19	SPEAKER_05
 Well, and I saw that in the political party.

0:50:21	SPEAKER_05
 Yeah, with potential use from the defense department.

0:50:24	SPEAKER_03
 Well, maybe student groups or filmmakers or something, a little bit of color.

0:50:31	SPEAKER_04
 If we give them a chance to excite later, we might end up with like five minutes out of the club.

0:50:37	SPEAKER_03
 I don't mean that they're angry, but just something with some more variation in prasadic contours and so forth would be neat.

0:50:44	SPEAKER_03
 So, if anyone has ideas, I'm willing to do the legwork to go try to talk to people, but I don't really know which group there were.

0:50:49	SPEAKER_04
 What is this pursuing idea?

0:50:51	SPEAKER_06
 Yeah, there's a problem there in terms of the commercial value of the press.

0:50:59	SPEAKER_06
 It turned out to be a bit of a problem.

0:51:01	SPEAKER_04
 And I had one other aspect of this, which is John Biscuits expressed a major interest in having meetings which were all English speakers.

0:51:12	SPEAKER_04
 Now, he wasn't trying to shape us in terms of what we gathered, but that's what he wanted me to show him.

0:51:18	SPEAKER_04
 So, I'm giving him our initial meeting because he asked for all English.

0:51:22	SPEAKER_04
 And I think we don't have a lot of all English meetings right now.

0:51:25	SPEAKER_04
 Did he mean that non-British?

0:51:28	SPEAKER_04
 No, if he meant non-British, I think he said British was okay.

0:51:33	SPEAKER_08
 British is okay.

0:51:34	SPEAKER_06
 British is okay.

0:51:35	SPEAKER_06
 Well, I don't think if he didn't say that.

0:51:39	SPEAKER_04
 I bet he meant native speaking for a better.

0:51:42	SPEAKER_05
 I bet he did.

0:51:44	SPEAKER_05
 Oh, really?

0:51:45	SPEAKER_05
 That's why I wouldn't care.

0:51:46	SPEAKER_08
 Knowing the population.

0:51:47	SPEAKER_06
 I remember studying the BBN where they trained on, this was in Wall Street Journal days, or something they trained on American English, and then they tested on different native speakers from different areas.

0:51:59	SPEAKER_06
 And the worst match was people whose native tongue was Mandarin Chinese.

0:52:07	SPEAKER_06
 The second worst was British English.

0:52:10	SPEAKER_06
 That's fine.

0:52:11	SPEAKER_05
 So, it's...

0:52:13	SPEAKER_05
 German was much better.

0:52:15	SPEAKER_05
 It was Swiss.

0:52:17	SPEAKER_06
 So, I think if he's thinking in terms of recognition kind of technology, I think he would probably want to...

0:52:24	SPEAKER_06
 Are we on the issue?

0:52:25	SPEAKER_06
 Yeah, unless we're going to train with the whole country.

0:52:28	SPEAKER_04
 I think that the elements may be more that way, and they sort of feel like they have...

0:52:32	SPEAKER_06
 Maybe, so.

0:52:33	SPEAKER_07
 Yeah.

0:52:34	SPEAKER_07
 And maybe there were a few with us where Dan wasn't there in for us, as he worked on it.

0:52:40	SPEAKER_06
 It's pretty tough, this group.

0:52:43	SPEAKER_06
 So, what are the people who are involved in some artistic endeavor?

0:52:47	SPEAKER_06
 I mean, filmmaking.

0:52:48	SPEAKER_06
 Is that great?

0:52:49	SPEAKER_03
 I think that they would be...

0:52:50	SPEAKER_03
 Something where there is actually discussion, where there's no right or wrong answer, but...

0:52:54	SPEAKER_03
 But it's a matter of opinion, kind of thing.

0:52:57	SPEAKER_03
 Anyway.

0:52:58	SPEAKER_03
 Yeah, I do.

0:52:59	SPEAKER_08
 You're also going to get to have a political discussion.

0:53:01	SPEAKER_08
 Any department that calls itself science?

0:53:03	SPEAKER_08
 Yeah, I'm going to get a computer science.

0:53:05	None
 I'm going to say...

0:53:06	SPEAKER_03
 I'm actually serious because...

0:53:10	SPEAKER_03
 Yeah, yeah.

0:53:13	SPEAKER_03
 We have the setup here, and that has...

0:53:15	SPEAKER_03
 Chance to give us some very interesting fun data.

0:53:18	SPEAKER_03
 So, if anyone has ideas, you know any groups that are...

0:53:21	SPEAKER_03
 Well, I guess some of the students...

0:53:23	SPEAKER_03
 Student groups like clubs, things like that.

0:53:25	SPEAKER_06
 A little ad-up saying, come here and argue.

0:53:28	SPEAKER_03
 If you're really angry, someone use our conference room.

0:53:31	SPEAKER_07
 The business school might be good.

0:53:33	SPEAKER_07
 I actually spoke with some students up there, and they express willingness back when they thought they would be doing research on speech.

0:53:40	SPEAKER_07
 But when they lost interest in speech, they also stopped answering my email about other stuff.

0:53:46	SPEAKER_06
 Or people who are wrong.

0:53:48	SPEAKER_06
 What about tax cuts or something?

0:53:50	SPEAKER_06
 I heard that.

0:53:51	SPEAKER_06
 How tech they have a special room.

0:53:52	SPEAKER_10
 Someone said that it's a special room to get all your frustrations out.

0:53:54	SPEAKER_10
 You can go through a little throw up things and break things.

0:53:57	SPEAKER_10
 So, we don't know if that is not actually what we...

0:54:00	SPEAKER_03
 Yeah, to that extent.

0:54:02	SPEAKER_03
 Well, a far-fledged likes can pick up where the recruits are.

0:54:04	SPEAKER_05
 But we don't want them to throw the far-fledged mixes.

0:54:07	SPEAKER_07
 Please throw everything in that direction.

0:54:10	SPEAKER_07
 And itself.

0:54:12	SPEAKER_07
 I think I think it looked good.

0:54:14	SPEAKER_07
 There was a dorm room at Tech that someone had coded the walls and the ceiling and the floor with mattresses.

0:54:20	SPEAKER_07
 The entire room.

0:54:22	SPEAKER_06
 I had this my fourth thing here, processing of waveforms.

0:54:25	SPEAKER_06
 What did we mean by that?

0:54:26	SPEAKER_07
 Liz wanted to talk about menacing, improving accuracy.

0:54:30	SPEAKER_03
 Well, I think that was just sort of an IRA-ass deal.

0:54:34	SPEAKER_03
 Oh, where did that?

0:54:35	SPEAKER_03
 But it would be helpful if I can stay in the loop somehow with people who are doing any kind of post-processing, whether it's to separate speakers or to improve the signal, to noise ratio, or both, that we can sort of try out as we're running recognition.

0:54:52	SPEAKER_03
 So, is that...

0:54:53	SPEAKER_03
 Who else's work, I guess, Dan Ellis?

0:54:56	SPEAKER_03
 Yeah.

0:54:57	SPEAKER_06
 And Dave.

0:54:58	SPEAKER_06
 And Dave.

0:55:00	SPEAKER_06
 Again, he's interested in, in fact, we're looking, starting to look at some macro-canceration kind of things.

0:55:04	SPEAKER_06
 Okay.

0:55:05	SPEAKER_07
 Which is how much that is.

0:55:08	SPEAKER_07
 An issue with a close talking mic.

0:55:10	SPEAKER_06
 Well, isn't that what you want?

0:55:16	SPEAKER_03
 I don't know.

0:55:17	SPEAKER_06
 No, so what you want, when you're saying improving waveform, you want the close talking microphone to be better.

0:55:23	SPEAKER_06
 And the question is, to what extent is it getting hurt by any room acoustic source, it's just given that it's close, it's not a problem?

0:55:35	SPEAKER_03
 It doesn't seem like big room acoustic problem to my ear, but I'm not an expert.

0:55:39	SPEAKER_03
 It seems like a problem with crosstalk.

0:55:42	SPEAKER_07
 I bet there's plenty of room acoustic.

0:55:45	SPEAKER_03
 That may be true, but I don't know how good it can get either by those methods.

0:55:50	SPEAKER_03
 That's true.

0:55:51	SPEAKER_07
 I think it's just, yeah, what you said.

0:55:53	SPEAKER_03
 All I meant is just that as sort of, as this pipeline of research is going on, we're also experimenting with different ASR techniques, and so it'd be good to know about it.

0:56:05	SPEAKER_08
 So the problem is like, on the microphone of somebody who's not talking, they're picking up signals from other people, and that's...

0:56:12	SPEAKER_03
 Right, although if they're not talking, using the in-house transcriptions, we're sort of okay because no one transcribed any words there, and we throw it out.

0:56:22	SPEAKER_03
 But if they're talking at all, and they're not talking the whole time, so you get some speech, and then some more speech, so that whole thing is one chunk.

0:56:29	SPEAKER_03
 And the person in the middle who said only a little bit is picking up the speech around it, that's where it's a big problem.

0:56:36	SPEAKER_04
 You know, this does seem like it would relate to someone one of those ASR, who's working on this wall, and coding them.

0:56:42	SPEAKER_04
 And he also...

0:56:43	SPEAKER_03
 The energy, right?

0:56:44	SPEAKER_04
 Exactly.

0:56:45	SPEAKER_04
 I was trying to remember you had this interface where you showed us one time when you left off that you had different visual displays.

0:56:53	SPEAKER_00
 Yeah.

0:56:54	SPEAKER_00
 I only displayed different colors for the different situation, but for me, for my problems, it's enough, because it's possible in a simple view to compare with the equipment, the kind of assessment, what happened with the different parameters, only with different bands of colors for the few situations I consider for acoustic even, is enough to...

0:57:24	SPEAKER_00
 I see that you are considering now a very sophisticated set of graphics, as symbols to transcribe, no?

0:57:43	SPEAKER_00
 A lot.

0:57:44	SPEAKER_00
 Because before you are talking about the...

0:57:46	SPEAKER_00
 the possibility to include in the transcribed word program, a set of symbol, or a fixed symbol, to market the different situation during the transition.

0:57:57	SPEAKER_04
 So symbols for differences between lab and cell, and...

0:58:02	SPEAKER_04
 Yes.

0:58:03	SPEAKER_00
 The symbol you talk before, no?

0:58:07	SPEAKER_00
 To...

0:58:08	SPEAKER_04
 To mal...

0:58:09	SPEAKER_04
 The symbols so much.

0:58:10	SPEAKER_04
 The main change that I see in the interface is just that we'll be able to...

0:58:14	SPEAKER_04
 to more money in time and things.

0:58:17	SPEAKER_04
 But I...

0:58:18	SPEAKER_04
 There was another aspect of you, I was thinking about this topic, which is that it's not much to me, but it's not to me, so partly inels, is that you're doing involves taking segments, which are of a particular type, and putting them together.

0:58:33	SPEAKER_04
 And so if you have like a...

0:58:35	SPEAKER_04
 You know, a speech from one speaker, then you cut out the part that's not that speaker, and you combine segments from that same speaker to...

0:58:43	SPEAKER_04
 and run them through the recognize as that.

0:58:45	SPEAKER_03
 Well, we try to find as close of start and end time as we can to the speech from an individual speaker, because then we're more guaranteed that the recognizer will...

0:58:55	SPEAKER_03
 for the forced alignment, which is just to give us the time boundaries, because from those time boundaries then the plan is to compute prosotic features.

0:59:02	SPEAKER_03
 And the sort of more space you have that isn't the thing you're trying to align, the more errors we have.

0:59:10	SPEAKER_03
 So, you know, that it would help to have either a pre-processing of a signal that creates very good signal noise ratio, which I don't know how possible this is for the lapel, or to have closer time, you know, synced times, basically, around the speech that gets transcribed or both.

0:59:32	SPEAKER_03
 And it's just sort of an open world right now of exploring that.

0:59:36	SPEAKER_03
 So I just wanted to see, you know, on the transcribing end, from here, things look good.

0:59:41	SPEAKER_03
 The IBM one is more... is an open question right now, and then the issue of like global processing of some signal, and then, you know, before we chop it up, is yet another way we can improve things.

0:59:54	SPEAKER_08
 What about increasing the flexibility of the alignment?

0:59:57	SPEAKER_08
 Do you remember that thing that Michael Fink had did? That experiment? He did a wild bath?

1:00:01	SPEAKER_03
 Right. You can...

1:00:04	SPEAKER_03
 The problem is just that the acoustic, when the signal to noise ratio is too low, you'll get an alignment with the wrong duration path.

1:00:16	SPEAKER_03
 So that's the problem, is the... Yeah, it's not the fact that you have like...

1:00:20	SPEAKER_03
 I mean, what he did is allow you to have words that were in another segment, move over to the... at the edges of segmentation.

1:00:27	SPEAKER_03
 Or even words inserted that weren't there.

1:00:29	SPEAKER_03
 Right. Things here, the boundaries, where if you got your alignment wrong, because what they had done there is a line and then chop.

1:00:35	SPEAKER_03
 And this problem is a little bit more global.

1:00:38	SPEAKER_03
 It's that there are problems even inside the alignments, because of the fact that there's enough acoustic signal there to recognize or to eat as part of a word, and it tends to do that.

1:00:50	SPEAKER_03
 So...

1:00:53	SPEAKER_03
 But we'll probably have to do something like that in addition.

1:00:56	SPEAKER_03
 Anyway, so yeah, bottom line is just I wanted to make sure I can be aware of whoever's working on these signal processing techniques for detecting energies because that'll really help us.

1:01:11	SPEAKER_06
 Okay, T is started out there, I suggest we went through our digits.

1:01:22	SPEAKER_06
 So...

1:01:25	SPEAKER_06
 Transcript 3031-3050.

1:01:29	SPEAKER_06
 0368.

1:01:32	SPEAKER_06
 04960.

1:01:34	SPEAKER_06
 17050293462.

1:01:42	SPEAKER_06
 7204640.

1:01:44	SPEAKER_06
 8415281.

1:01:47	SPEAKER_06
 9.

1:01:49	SPEAKER_06
 0937762.

1:01:52	SPEAKER_06
 0.

1:01:53	SPEAKER_06
 109376028.

1:01:58	SPEAKER_06
 425495.

1:02:01	SPEAKER_06
 677890.

1:02:06	SPEAKER_07
 Transcript 30713090.

1:02:10	SPEAKER_07
 004217337.

1:02:15	SPEAKER_07
 4325.

1:02:17	SPEAKER_07
 5639826.

1:02:20	SPEAKER_07
 670740.

1:02:23	SPEAKER_07
 810.

1:02:25	SPEAKER_07
 051406.

1:02:28	SPEAKER_07
 623964.

1:02:32	SPEAKER_07
 507971.

1:02:35	SPEAKER_07
 7176171.

1:02:38	SPEAKER_07
 8503872.

1:02:41	SPEAKER_07
 9704299.

1:02:43	SPEAKER_07
 099093.

1:02:47	SPEAKER_08
 Transcript 3111-3130.

1:02:51	SPEAKER_08
 2878024.

1:02:54	SPEAKER_08
 304080.

1:02:58	SPEAKER_08
 6316884.

1:03:01	SPEAKER_08
 76685989.

1:03:05	SPEAKER_08
 010665.

1:03:10	SPEAKER_08
 33496408.

1:03:15	SPEAKER_08
 590.

1:03:17	SPEAKER_08
 689798.

1:03:20	SPEAKER_08
 804.

1:03:22	SPEAKER_08
 990.

1:03:24	SPEAKER_08
 03.

1:03:26	SPEAKER_08
 160281.

1:03:29	SPEAKER_01
 Transcript 3151-3170.

1:03:33	SPEAKER_01
 4499.

1:03:36	SPEAKER_01
 550606780.

1:03:40	SPEAKER_01
 0770394.

1:03:44	SPEAKER_01
 0470616824.

1:03:49	SPEAKER_01
 2939.

1:03:51	SPEAKER_01
 4507608494.

1:03:54	SPEAKER_01
 5107260.

1:03:57	SPEAKER_01
 84084567101.

1:04:01	SPEAKER_01
 0810101.

1:04:05	SPEAKER_01
 20184264019.

1:04:10	SPEAKER_09
 Transcript 3333113333.

1:04:15	SPEAKER_09
 0671307474.

1:04:20	SPEAKER_09
 0723864507284.

1:04:28	SPEAKER_09
 96045050081.

1:04:35	SPEAKER_09
 1 2 4 7 397.

1:04:40	SPEAKER_09
 5 4 8 2 6 6 4 5 7.

1:04:44	SPEAKER_09
 7 9 8 8 9 071231.

1:04:53	SPEAKER_03
 Transcript 28912910.

1:04:56	SPEAKER_03
 4185277240.

1:04:59	SPEAKER_03
 65347.

1:05:01	SPEAKER_03
 7 9 1 6 8 6 3.

1:05:04	SPEAKER_03
 9015.

1:05:07	SPEAKER_03
 012524.

1:05:10	SPEAKER_03
 3475840.

1:05:12	SPEAKER_03
 457.

1:05:14	SPEAKER_03
 56094.

1:05:16	SPEAKER_03
 7056932.

1:05:18	SPEAKER_03
 9509.

1:05:20	SPEAKER_03
 06031910523.

1:05:25	SPEAKER_00
 Transcript 2931.

1:05:28	SPEAKER_00
 That's 2950.

1:05:30	SPEAKER_00
 503.

1:05:32	SPEAKER_00
 6 81690008.

1:05:35	SPEAKER_00
 91987.

1:05:38	SPEAKER_00
 Old 605.

1:05:40	SPEAKER_00
 048.

1:05:42	SPEAKER_00
 028.

1:05:43	SPEAKER_00
 4123.

1:05:49	SPEAKER_00
 053185216.

1:05:53	SPEAKER_00
 5607400.

1:05:55	SPEAKER_00
 8 9 309 9 9 6 4 4.

1:06:00	SPEAKER_00
 0 0 3752110889.

1:06:05	SPEAKER_00
 3 14 5 0 7 4.

1:06:09	SPEAKER_00
 5 6 6 3.

1:06:12	SPEAKER_04
 Transcript 291-3010.

1:06:16	SPEAKER_04
 8 5 9 0 0 1 3 15 0 5 4 4 0 9 4 2.

1:06:26	SPEAKER_04
 5 6 7 4 6 8 3 6 7 7 8 4 8 9 0 1.

1:06:36	SPEAKER_04
 0 1 6 1 3 5 0 1 5 7 2 8 9.

1:06:41	SPEAKER_04
 8 8 9 3 4 5 0 8 7 4 7 1 1 8 4 0 305 1.

1:06:51	SPEAKER_00
 Did your feel go back?

