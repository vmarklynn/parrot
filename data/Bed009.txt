0:00:00	None
 Okay.

0:00:02	SPEAKER_03
 Testing channel 2.

0:00:04	SPEAKER_03
 Two.

0:00:06	SPEAKER_03
 Two.

0:00:08	SPEAKER_02
 Oh.

0:00:22	SPEAKER_04
 Hmm?

0:00:24	SPEAKER_04
 There.

0:00:32	SPEAKER_04
 Wow.

0:00:34	SPEAKER_04
 So, rough and terminate here.

0:00:36	SPEAKER_04
 Great.

0:00:38	SPEAKER_04
 Great.

0:00:40	SPEAKER_03
 Made it safety.

0:00:42	SPEAKER_03
 So, what we have been doing is they would like us all to read these digits.

0:00:46	SPEAKER_03
 But we don't already.

0:00:48	SPEAKER_03
 A couple people read it.

0:00:50	SPEAKER_03
 When it gives them all German accents.

0:00:52	SPEAKER_04
 Okay.

0:00:54	SPEAKER_04
 The way you do it is you just read the numbers not as each single.

0:01:00	SPEAKER_04
 So, just like I do it.

0:01:02	SPEAKER_04
 First you read the transcript number.

0:01:04	SPEAKER_04
 My transcript number is L95.

0:01:06	SPEAKER_04
 3230977352214082115160087096440 64404562850593 5261 358105 624 468 48551 4229 05756 07 32

0:01:42	SPEAKER_01
 Okay. What's my transcript number is L91 141628613157 0395 8 06622 0316143416171340652105 9821408492 126586666 866161311102066654159

0:02:52	SPEAKER_00
 Okay. My transcript number is L92 85034213760632 4970 6068 636 564 9306 641 8706 807 3 1770 7556 445660 4510 845 841 1037 1072 6774 1700

0:03:34	SPEAKER_02
 Okay. Let's be done with this. Okay. This is Mommy.

0:03:38	SPEAKER_02
 Come on in.

0:03:40	SPEAKER_02
 Okay. So, we're going to try to finish by five.

0:03:43	SPEAKER_03
 So, people who want to go here, Nancy Chang's talk downstairs.

0:03:49	SPEAKER_03
 And you guys are giving talks on tomorrow and Wednesday much.

0:03:53	SPEAKER_02
 That's great. Okay. So, you know what we're going to do?

0:03:57	SPEAKER_04
 I thought two things we'll introduce ourselves.

0:04:01	SPEAKER_04
 What we do. And we already talked with Andreas Tilo and David and some lines of code were already written today and almost tested.

0:04:13	SPEAKER_04
 And just going to say we have again the recognizer to pass the thing where we're working on and that should be no problem.

0:04:23	SPEAKER_04
 And then that can be sort of developed as needed when we enter the tourism domain.

0:04:31	SPEAKER_04
 We have talked this morning with Tillman about the generator.

0:04:37	SPEAKER_04
 And they are one of our diligent workers has to sort of volunteer to look over Tillman's shoulder while he is changing the grammar to English because we have we face two ways.

0:04:52	SPEAKER_04
 Either we do a simple concatenating grammar for the English generation which is sort of starting from scratch and doing it the easy way.

0:05:02	SPEAKER_04
 Always simply adopt the more in-depth style that is implemented in the German system.

0:05:10	SPEAKER_04
 And are then able not only to produce strings but also the syntactic parts, not parts in the syntactic tree that is underneath the syntactic structure.

0:05:21	SPEAKER_04
 Which is the way we decided we were going to go because it's easier in the beginning.

0:05:26	SPEAKER_04
 And that's required some knowledge of those grammars and some linguistic background.

0:05:33	SPEAKER_04
 But it shouldn't be a problem for anyone.

0:05:37	SPEAKER_02
 Okay, so that's the answer.

0:05:41	SPEAKER_02
 You're going to have some time to do that with these guys.

0:05:44	SPEAKER_04
 Sure.

0:05:45	SPEAKER_03
 Because you're the grammar major.

0:05:50	SPEAKER_03
 Okay.

0:05:51	SPEAKER_02
 I mean it makes sense doesn't it?

0:05:52	SPEAKER_03
 Yeah.

0:05:53	SPEAKER_03
 Okay, so I think that's probably the right way to do that.

0:05:59	SPEAKER_03
 And yeah, so I actually want to find out about it too but I may not have time to...

0:06:06	SPEAKER_04
 The ultimate goal is that before they leave we can run through the entire system input through output on at least one or two simple things.

0:06:17	SPEAKER_04
 And by virtue of doing that, then in this case, John will have acquired the knowledge of how to extend it at infinitum.

0:06:27	SPEAKER_04
 When needed, if needed, when wanted.

0:06:30	SPEAKER_04
 So for...

0:06:36	SPEAKER_02
 Okay, that sounds great.

0:06:38	SPEAKER_04
 And also, Ralph has hooked up with David and you're going to continue either all through tonight or tomorrow and whatever to get the password interface working.

0:06:53	SPEAKER_04
 They're sending out and ticking out lattices and doing this kind of stuff to see what works best.

0:06:59	SPEAKER_03
 So you guys enjoy your weekend?

0:07:02	SPEAKER_03
 Yes, yeah, I'm sorry.

0:07:04	SPEAKER_03
 You ever got to put the work?

0:07:09	SPEAKER_03
 Okay, so that's sort of one branch is to get us caught up on what's going on.

0:07:17	SPEAKER_03
 Also of course would be really nice to know what the plans are in addition to what's already in code.

0:07:24	None
 And we can...

0:07:25	SPEAKER_03
 I don't know what was or the time when we were set up to do that.

0:07:30	SPEAKER_03
 It probably will work better if we do it later in the week after we actually understand better what's going on.

0:07:37	SPEAKER_03
 So when do you guys leave?

0:07:39	SPEAKER_00
 We're here through Sunday.

0:07:41	SPEAKER_00
 Oh, okay, so...

0:07:42	SPEAKER_03
 So we'll find a time later in the week to get together and talk about your understanding of what smart comp plans are and how we can change it.

0:07:55	SPEAKER_04
 So we already said a day for that.

0:08:00	SPEAKER_04
 Might be a bit official while we're all here.

0:08:03	SPEAKER_02
 Okay.

0:08:05	None
 What does not work for me is Thursday afternoon.

0:08:17	SPEAKER_03
 I can do earlier than day on Thursday or most of the time on Friday.

0:08:32	SPEAKER_04
 Thursday morning sounds fine?

0:08:35	SPEAKER_04
 What are your constraints?

0:08:38	SPEAKER_04
 Thursday afternoon doesn't work for me, but...

0:08:42	SPEAKER_04
 It's either Thursday morning, no.

0:08:49	SPEAKER_02
 Thursday morning should be fine.

0:08:55	SPEAKER_02
 11?

0:08:58	None
 11 on Thursday.

0:09:00	SPEAKER_02
 I was just thinking I will 11 by 11.

0:09:05	SPEAKER_03
 This is a different to our morning people.

0:09:10	SPEAKER_00
 So he's there.

0:09:20	SPEAKER_00
 Third Sunday live.

0:09:23	SPEAKER_03
 And actually we could invite Andreas as well.

0:09:37	SPEAKER_03
 He will be in Washington.

0:09:39	SPEAKER_03
 That's true.

0:09:40	SPEAKER_03
 He's off the office trip already.

0:09:43	SPEAKER_04
 But David is here and he's actually...

0:09:50	SPEAKER_04
 Those everything about the smart comp plans.

0:09:53	SPEAKER_02
 Okay, we'll see if David can make it out.

0:10:01	SPEAKER_04
 Okay, so facing to what we've been doing here.

0:10:09	SPEAKER_04
 One thing we're also using this room to collect data.

0:10:14	SPEAKER_04
 Not this type of data, not meeting data, but sort of our version of a wizard experiment, not like the ones in Munich, but pretty close to it.

0:10:25	SPEAKER_04
 The major difference to the Munich ones is that we do it...

0:10:29	SPEAKER_04
 We add the telephone, even all the recording is done here.

0:10:33	SPEAKER_04
 And so it's sort of a computer call system that gives you tourist information to get places.

0:10:40	SPEAKER_04
 And it breaks halfway through the experiment and a human operator comes on.

0:10:44	SPEAKER_04
 And part of that is sort of try to find out whether people change their linguistic verbal behavior when first thinking they speak to a machine or then to a human.

0:10:55	SPEAKER_04
 And we're setting it up so that we can...

0:10:58	SPEAKER_04
 We hope to implant certain intentions in people, for example.

0:11:02	SPEAKER_04
 We have first looked at a simple sentence that...

0:11:08	SPEAKER_04
 How do I get to the powder tower?

0:11:11	SPEAKER_04
 Okay, so you have that castle of idle work and there is a tower and it's called powder tower.

0:11:16	SPEAKER_04
 And so what do you parse out of that sentence?

0:11:22	SPEAKER_04
 Probably something that we specified in M3L that is...

0:11:27	SPEAKER_04
 Action, go to whatever domain object, whatever, powder tower.

0:11:31	SPEAKER_04
 And maybe some model will tell us some GPS module in a mobile scenario where the person is at the moment.

0:11:38	SPEAKER_04
 And we've sort of gone through that once before in the DeepMap project.

0:11:41	SPEAKER_04
 And we noticed that first of all, what are...

0:11:44	SPEAKER_04
 I should have brought some slides.

0:11:47	SPEAKER_04
 But what are...

0:11:49	SPEAKER_04
 So here's the tower.

0:11:52	SPEAKER_04
 Think of this as a two-dimensional representation of the tower.

0:11:55	SPEAKER_04
 And our system that people here, to a point where they were facing a wall from the tower, there's no entrance here.

0:12:02	SPEAKER_04
 But it just happens to be the closest point of the road network to the geometric center.

0:12:07	SPEAKER_04
 And it just says how the algorithm works.

0:12:10	SPEAKER_04
 So we took out that part of the road network as a heck, and then it followed actually the way to the entrance, which was now the closest point of the road network to geometric center.

0:12:20	SPEAKER_04
 But what we actually observed in idle work is that most people, when they want to go, they actually don't want to enter.

0:12:26	SPEAKER_04
 Because it's not really interesting.

0:12:27	SPEAKER_04
 They want to go to a completely different point where they can look at it and take a picture.

0:12:32	SPEAKER_04
 So, let's say a simple parse from an utterance won't really give us, is what the person actually wants.

0:12:42	SPEAKER_04
 Does he want to go there to see it?

0:12:44	SPEAKER_04
 Does he want to go there now?

0:12:46	SPEAKER_04
 Later?

0:12:47	SPEAKER_04
 How does the person want to go there?

0:12:49	SPEAKER_04
 Is that person more likely to want to walk there, walk a scenic route, and so forth?

0:12:54	SPEAKER_04
 There are all kinds of decisions that we have identified in terms of getting to places and in terms of finding information about things.

0:13:02	SPEAKER_04
 And we are constructing, and then we've identified more or less the extra linguistic parameters.

0:13:08	SPEAKER_04
 It may play role, information related to the user and information related to the situation.

0:13:13	SPEAKER_04
 And we also want to look closely on the linguistic information, what we can get from the utterance.

0:13:21	SPEAKER_04
 That's part of why we implant these intentions in the data collection to see whether people actually are facing differently, whether they want to enter in order to buy something, or whether they just want to go there to look at it.

0:13:33	SPEAKER_04
 And so, the idea is to construct suitable interfaces and a belief net for a module that actually tries to guess what the underlying intention was.

0:13:48	SPEAKER_04
 And then, enrich or augment the M3L structures with what I thought, what more it sort of got out of that utterance.

0:13:57	SPEAKER_04
 So, if it can make a good suggestion, hey, that person doesn't want to enter.

0:14:02	SPEAKER_04
 That person just wants to take a picture, because he just bought a film, or that person wants to enter, because he discussed the admission fee before, or that person wants to enter, because he wants to buy something, and that you usually do inside of buildings and so forth.

0:14:15	SPEAKER_04
 These types of additional information are going to be embedded into the M3L structure, in a sort of subfield that we have reserved.

0:14:28	SPEAKER_04
 And if the action planner does something with that grade, if not, then that's also something that we can't really, at least we want to offer the extra information, we don't really, we're not too worried.

0:14:46	SPEAKER_04
 I mean, ultimately, if you have, if you can offer that information, somebody's going to do something with it sooner or later, that's sort of part of our belief.

0:14:54	SPEAKER_04
 For example, right now, I know the GIS from email is not able to calculate these viewpoints.

0:15:02	SPEAKER_04
 So, that's a functionality that doesn't exist yet, to do that dynamically.

0:15:06	SPEAKER_04
 But if we can offer that distinction, maybe somebody will go ahead and implement it.

0:15:12	SPEAKER_04
 Surely nobody is going to go ahead and implement it, if it's never going to be used.

0:15:17	SPEAKER_04
 What have I forgotten about?

0:15:20	SPEAKER_03
 Yeah, I'm happy to do it.

0:15:23	SPEAKER_03
 It's a good time to pause.

0:15:25	SPEAKER_03
 I see questions on people's faces.

0:15:29	SPEAKER_00
 What would the office want to be if you envision this as a module within SmartCom?

0:15:37	SPEAKER_04
 So far, I've sort of it sort of adding it on to the model and knowledge module.

0:15:43	SPEAKER_04
 So, this is one that already adds additional information to the, but it could sit anywhere in the attention recognition.

0:15:51	SPEAKER_04
 I mean, basically, this is what attention recognition literally sort of can.

0:15:56	SPEAKER_04
 That's why it should be.

0:16:00	SPEAKER_00
 Well, from my understanding of what the people at TIPS were originally trying to do, doesn't seem to quite fit into SmartCom currently.

0:16:09	SPEAKER_00
 So what they're really doing right now is only selecting among the alternatives, the hypothesis that they're given and enriched by the domain knowledge and the dismalarist modeler and so on.

0:16:21	SPEAKER_00
 So if this is additional information, that could be merged in with them.

0:16:25	SPEAKER_00
 And then it wouldn't be available to action planning and others.

0:16:32	SPEAKER_03
 Okay, that was one question.

0:16:39	SPEAKER_03
 Are there other things that, because we want to not pass over any questions or concerns that you have?

0:16:47	SPEAKER_00
 Whether they're two levels of giving an answer, I guess on both levels.

0:16:57	SPEAKER_00
 I don't have any further questions. The two levels of being, as far as I'm concerned, is standing here for the generation module and the other is my understanding of what SmartCom is supposed to be.

0:17:10	SPEAKER_03
 So, let me explain that a little bit from the point of view of the generation.

0:17:16	SPEAKER_03
 So the idea is that we've actually got this all laid out and we could show it to you.

0:17:21	SPEAKER_03
 I think Robert didn't bring it today, but there's a belief net, which is, there's a first cut of the belief net that doesn't, isn't fully instantiated in particular.

0:17:35	SPEAKER_03
 Some of the combination rules and ways of getting additional probabilities aren't there.

0:17:39	SPEAKER_03
 But we believe that we have laid out the fundamental decisions in this little space and the things that influence them.

0:17:47	SPEAKER_03
 So, one of the decisions is what we call this ABE.

0:17:51	SPEAKER_03
 You want to access view or enter.

0:17:58	SPEAKER_03
 So that's a discrete decision. There are only three possibilities.

0:18:02	SPEAKER_03
 And what we would like is for this knowledge modeling collection to add which of those it is and give it to the player.

0:18:15	SPEAKER_03
 But the current design suggests that if it seems to be an important decision and if the belief net is equivocal so that it doesn't say that one of these is much more probable than the other, then an option is to go back and ask for the information you want.

0:18:37	SPEAKER_03
 There are two ways one can imagine doing that. For the debugging, we'll probably just have a drop down menu and while you're debugging, you're just mucking.

0:18:46	SPEAKER_03
 But for a full system, then one might very well formulate a query, give it to the dialogue planner and say, are you planning to enter or whatever it might be. So that's under that model, then there would be a loop in which this thing would formulate a query, presumably give it to you that would get expressed and hopefully you get an answer back.

0:19:18	SPEAKER_03
 And that would of course, the answer would have a harsh two. You probably won't do this early on because the current focus is more decision making and stuff like that.

0:19:32	SPEAKER_03
 But while we're on the subject, I just wanted to give you a heads up.

0:19:38	SPEAKER_03
 It could be that some months from now, we said, okay, we're now ready to try to close that loop in terms of querying about some of those decisions.

0:19:50	SPEAKER_00
 So my suggestion then is that you look into the currently ongoing discussion about how the action plans are supposed to look like.

0:19:59	SPEAKER_00
 And they're currently agreeing or in the process of agreeing on an exemplification of something like a state transition network of how dialogues would proceed.

0:20:12	SPEAKER_00
 And these transition networks will be what the action plan of the next interprets in a sense.

0:20:19	SPEAKER_02
 You know this, honey?

0:20:21	SPEAKER_00
 And Mikhail is doing that right? Well, Markus is actually implementing that stuff and Markus and Michele together are leading the discussion there.

0:20:32	SPEAKER_03
 Okay. So we have to get it on that because partly those are like excements, the transition backgrounds.

0:20:42	SPEAKER_03
 And it may be that we should early on make sure that they have flexibility to be weak.

0:20:52	SPEAKER_04
 But they have understood this right? They govern more or less the dialogue behavior or the action.

0:21:00	SPEAKER_04
 It's not really what you do with the content of the dialogue, but it's.

0:21:07	SPEAKER_03
 I mean, there is this nice. So there's a. So the word action. Okay. Is what's ambiguous here. So one thing is there's an actual planner that tells the person first of me.

0:21:24	SPEAKER_03
 Where it tells the person how to go first go here first go there. Take a bus, whatever it is. So that's that form of planning and action and a round planner and GIS also to stuff.

0:21:39	SPEAKER_00
 But I think that isn't what you know. No, no, in smart home terminology that's called a function that's modeled by a function modeler.

0:21:48	SPEAKER_00
 And it's that that's completely encapsulated from the dialogue system. That's simply a functionality that you give data is in a query.

0:21:56	SPEAKER_00
 And then you get back from that functioning model, which might be a planner or a VCR or whatever. Some result. And that's then.

0:22:05	SPEAKER_03
 Okay. So that's what I thought. So action action here means that I have speech. Yeah. Dialogue.

0:22:12	SPEAKER_03
 Okay. I think that I think it's not going to. I think it's not going to be good enough. I don't know what I meant by that.

0:22:22	SPEAKER_03
 So I think the idea of having a transition diagram or the grammar of conversations is a good idea.

0:22:32	SPEAKER_03
 Okay. And I think we do have to get in on it. But I think that when so when you get to the tourist domain.

0:22:45	SPEAKER_03
 It's not just an information retrieval system. Right. So this is where I think people are going to have to think this to a bit more carefully.

0:22:53	SPEAKER_03
 So if it's only like in the film and TV thing, okay, you can do this. You just get information and give it to people.

0:23:02	SPEAKER_03
 But what happens when you actually get them moving and so forth and so on.

0:23:09	SPEAKER_03
 I think the notion of this is a self contained module. The functional module that interacts with where the tourist domain is.

0:23:23	SPEAKER_03
 Probably is too restrictive. I don't know how much people have thought ahead to the tourist domain.

0:23:32	SPEAKER_00
 Probably not another. Another more basic point there is that the current tasks and therefore the concepts of this.

0:23:41	SPEAKER_00
 What's called the action plan. It's really a dialogue manager is based on slots that have to be filled.

0:23:47	SPEAKER_00
 The kind of values in these slots would be fixed things like a time or a movie time setting like this.

0:23:54	SPEAKER_00
 Whereas in the tourist domain might be an entire route.

0:23:57	SPEAKER_00
 It's a very complex structure information in these slots. Not sure if complex slots of that type are really being taken into consideration.

0:24:09	SPEAKER_00
 So that's really something.

0:24:19	SPEAKER_00
 We need to be settled there. So this is really an ongoing discussion.

0:24:28	SPEAKER_04
 We have faced and implemented those problems once already.

0:24:33	SPEAKER_04
 Maybe we can even shovel some know-how from there to Markus and Micheal.

0:24:44	SPEAKER_04
 I'll talk to Micheal. How far is the M3L specification for the natural language input gone?

0:24:59	SPEAKER_04
 I haven't seen anything for the tourist path.

0:25:04	SPEAKER_01
 It's not defined yet.

0:25:07	SPEAKER_04
 You are probably also involved in that.

0:25:16	SPEAKER_01
 We'll meet next week.

0:25:22	SPEAKER_04
 Those are the two key issues. How does the input pipeline look like and what the action planner does with it?

0:25:39	SPEAKER_04
 I think of the internal working of the action planner and the function model as relevant.

0:25:54	SPEAKER_04
 That can be as detailed or as crude as you want it to be.

0:26:00	SPEAKER_04
 The internal workings of the action planner and the work with the state.

0:26:09	SPEAKER_04
 That shouldn't really matter too much.

0:26:12	SPEAKER_04
 It does have to keep track of your bare-on-part six of a route that consists of eight steps.

0:26:18	SPEAKER_03
 I think there are a lot of reasons why it matters.

0:26:30	SPEAKER_03
 The user says that the action planner told it if the parser and the language end doesn't know what the person has been told.

0:26:53	SPEAKER_03
 The person says that the planner says that the planner doesn't know that.

0:27:03	SPEAKER_03
 There are all sorts of dialogues that won't make any sense.

0:27:14	SPEAKER_00
 The point has been realized that it's not really defined yet.

0:27:24	SPEAKER_00
 There's going to be some kind of feedback from the action planner into all the analysis modules telling them what to expect, what the current state of the discourse is beyond what's currently being implemented.

0:27:38	SPEAKER_03
 This is not just the state of the discourse, this is actually the state of the plan.

0:27:49	SPEAKER_03
 It's great if people are already taking that into account.

0:27:55	SPEAKER_03
 The specifics are in this room.

0:28:10	SPEAKER_03
 The question is, can you put in this need a fair amount of feedback from planning it in these things which are much more continuous than the dialogue over movies and stuff?

0:28:25	SPEAKER_00
 The action planner needs to be able to have an expressive power that can deal with these structures.

0:28:40	SPEAKER_03
 The next question is, can you put in a fair amount of feedback from the action planner?

0:29:03	SPEAKER_03
 It ought to be called a dialogue manager.

0:29:13	SPEAKER_03
 What would happen if we said, we've talked about this and we've changed this.

0:29:22	SPEAKER_00
 Probably the most impossible.

0:29:26	SPEAKER_00
 Who you talk to, how we'll see.

0:29:36	SPEAKER_00
 I think this is just for historical reasons within the preparation phase of the project and not because somebody actually believes it ought to be action funded.

0:29:49	SPEAKER_03
 If that persists, then we're going to need another term for the thing that actually does the planning of the routes and whatever we're doing for the tourist.

0:30:01	SPEAKER_04
 That's external services.

0:30:06	SPEAKER_03
 That has all the wrong connotations.

0:30:09	SPEAKER_03
 It sounds like it's standalone, it does interact, it doesn't.

0:30:15	SPEAKER_03
 That's something I think you can't. It's fine for looking up when the show is on TV.

0:30:22	SPEAKER_03
 I think it's really wrong headed for something that has a lot of state it's going to interact in a complicated way with understanding the board.

0:30:35	SPEAKER_04
 I think just the spatial planner and the route planner, I showed you once the interaction between them among them in the deep map system.

0:30:45	SPEAKER_04
 A printout of the communication between those two fills up how many pages.

0:30:48	SPEAKER_04
 That's just part of how do I get to one place.

0:30:56	SPEAKER_04
 So this is definitely a good point to get into the discussion or to enter his discussion actually.

0:31:08	SPEAKER_04
 Is he new in the...

0:31:11	SPEAKER_00
 Yes.

0:31:13	SPEAKER_00
 He started, like, January.

0:31:16	SPEAKER_00
 He's going to be responsible for the interpretation of this action plan.

0:31:23	SPEAKER_04
 He's going to continue with the old thing.

0:31:30	SPEAKER_04
 Yes, I was just wondering the next question, we're going to stick to ProLoc or not.

0:31:40	SPEAKER_04
 But I do think the function modeling concept has a certain...

0:31:44	SPEAKER_04
 It makes sense in a certain light because the action planner should not be or the dialogue manager in that case should not...

0:31:52	SPEAKER_04
 We have to worry about whether it's interfacing with something that does route planning in this way or that way.

0:32:00	SPEAKER_03
 I agree. There is a logic to dialogue which is separable.

0:32:06	SPEAKER_04
 And it can sort of formulate what it wants in a rather abstract way.

0:32:15	SPEAKER_04
 Find me a good route for this. It doesn't really have to worry about how route planner AO or route planner B actually wants it.

0:32:23	SPEAKER_04
 So this seems like a good idea.

0:32:29	SPEAKER_03
 It's tricky because one could well imagine, I think it will turn out to be the case that this thing we're talking about, and the extended knowledge modeler will fill in some parameters about what the person wants.

0:32:45	SPEAKER_03
 One could well imagine that the next thing that's trying to fill out the detailed route planning, let's say, will also have questions that it would like to ask the user.

0:32:56	SPEAKER_03
 You could well imagine you get to a point where it's got a choice to make and it just doesn't know something.

0:33:04	SPEAKER_03
 So you would like it also be able to formulate a query and to run that back through the dialogue manager and to the output module and back around.

0:33:21	SPEAKER_03
 And a good design would allow that if you can't make it happen.

0:33:28	SPEAKER_00
 So that doesn't necessarily contradict an architecture where there really is a person that you will define the interface.

0:33:34	SPEAKER_03
 I totally agree. But what it needs, the point is, in that case the dialogue manager is sort of a vent driven.

0:33:41	SPEAKER_03
 So dialogue manager may think it's in a dialogue state of one sort.

0:33:46	SPEAKER_03
 And this one of these planning modules comes along and says, hey, right now we need to ask a question.

0:33:51	SPEAKER_03
 So that forces the dialogue manager to change state.

0:33:55	SPEAKER_00
 Okay, it can be true. Yeah, yeah, I think that's the concept of people.

0:34:05	SPEAKER_00
 And then the underlying idea, of course, is that there is something like kernel modules with kernel functionality that can pluck certain applications like tourist information or the whole scenario of controlling a VCR install.

0:34:20	SPEAKER_00
 And then extend it to arbitrary number of publications.

0:34:25	SPEAKER_00
 So that's an additional reason to have this well defined interface.

0:34:30	SPEAKER_00
 Keep these things like tourist information external.

0:34:36	SPEAKER_04
 Of course, there is another philosophical issue that I think you can debate.

0:34:47	SPEAKER_04
 But this makes sense to me that sooner or later a service is going to come and describe itself to you.

0:34:55	SPEAKER_04
 And that's sort of what Srini is working on in the Dumbled project where you find a GIS about that gives you information on Berkeley.

0:35:05	SPEAKER_04
 And it's going to be there and tell you what it can do and how it wants to do things.

0:35:10	SPEAKER_04
 And so you can actually interface to such a system without ever having met it before.

0:35:14	SPEAKER_04
 And the function modeler and the self description of the external service, handle it out.

0:35:21	SPEAKER_04
 And you can use the same language core understanding core to interface with planner a planner B planner C and so forth, which is, you know, a utopian completely utopian at the moment.

0:35:33	SPEAKER_04
 But slowly getting into the realm of the contingent.

0:35:44	SPEAKER_04
 But we are facing, of course, much more realistic problems and language input, for example, is of course crucial.

0:35:54	SPEAKER_04
 And also when you do the sort of deep understanding analysis that we envision, then of course, the, you know, what is the property of the stimulus, the last we get of that, the better.

0:36:09	SPEAKER_04
 And so we were thinking, for example, how much syntactic analysis actually happens already in the parser and whether one could interface to that potentially.

0:36:19	SPEAKER_01
 Currently, it's no syntactic analysis. But in the next release, and it's kind of, so we looked at the current pattern matching.

0:36:38	SPEAKER_03
 And as you say, it's just the surface pattern matching. So what are the plans roughly?

0:36:45	SPEAKER_01
 To integrate and syntactic analysis and some more features like segmentation. So then more than one utterance is there.

0:37:00	SPEAKER_03
 And this is all done, a pause between it, segmentation across. So the idea is to have a particular, particular parser in mind.

0:37:23	SPEAKER_03
 And if you thought through, is it an HBSG parser? Is it a, whatever? No, no, I think it's complicated for.

0:37:33	SPEAKER_01
 Okay. One person has to. Oh, you have to do it. Yeah. So things must be simple. I see. So.

0:37:42	SPEAKER_03
 But yeah, the syntactic analysis. People in finite state trans-susers. People at DFK, I have written a fair number of parsers. Other people over the years have written various parsers in DFK. None of them are suitable. I'm asking.

0:37:59	SPEAKER_01
 Yeah, the problem is that it has to be very fast because if you want to for more than one path and what's in the lattice from a speed track or not, so it's speed is crucial.

0:38:16	SPEAKER_01
 Not fast enough. It also has to be very robust cause of speed track recognition. I don't know. So there was a chunk parser in verbobile.

0:38:33	SPEAKER_03
 There was one of the branches. You know, I do, there were these various competing syntax modules. And I know one of them was a chunk parser. And I don't remember who did that.

0:38:51	SPEAKER_01
 I think that a tubing and I thought. I didn't know. Well, do you know something about it? Tubing was at least involved in putting the chunks together.

0:39:05	SPEAKER_00
 I can't quite recall whether they actually produced the chunks in the first place.

0:39:11	SPEAKER_03
 That's right. They had just done with a two-phase thing where the chunk parser itself was pretty stupid. And then there was a kind of trying to fit them together that used more context.

0:39:26	SPEAKER_00
 And especially you did some, was a learning based approach, which you learned from a big corpus of trees. And yes, the chunk parser was a financial machine that Mark Leidritch worked on and wasn't tubing them.

0:39:43	SPEAKER_00
 And somebody else was tubing that up, so it was done and tubing.

0:39:46	SPEAKER_01
 But is that the kind of thing you were thinking of? Yeah. It sounds like the star action. What? It's in this direction.

0:40:00	SPEAKER_04
 From Micheal Stubach, I've heard very good stuff about the chunk parser that is done by four-vice riches in embassy doing the parsing. So this sort of came as a surprise to me that embassy is featuring a nice parser.

0:40:21	SPEAKER_04
 But it's what I hear one could also look at that and see whether there is some synergy possible. And they're doing chunk parsing.

0:40:32	SPEAKER_04
 I can give you the names of the people who do it there. But then there's of course more ways of parsing things.

0:40:44	SPEAKER_03
 Of course, but given the constraints that you wanted to be small and fast and so forth, my guess is you're probably into some kind of chunk parsing.

0:40:56	SPEAKER_03
 And I'm not a big believer in this statistical cleaning up. That seems to be kind of a last resort if you can't do it any other way.

0:41:20	SPEAKER_03
 But I don't know. Maybe that's what you guys finally decided to do.

0:41:27	SPEAKER_03
 And if you looked just again for context, there's this one that they did at SRI some years ago, fastest pace.

0:41:36	SPEAKER_01
 Yeah, I've looked at that. But there's not much information available. But it's also finance Tetrance. It is. Yeah, it was pretty ambitious.

0:41:47	SPEAKER_01
 And of course it was English oriented. And fully finance Tetrance, I'm not so good for German.

0:41:57	SPEAKER_03
 Yeah, I guess that's the point is all the morphology and stuff. In English is all word order and it makes a lot more sense.

0:42:05	SPEAKER_01
 Yeah, okay. Good point. So in German, you've got most of this. So it's a choice between risk processing and set processing and template.

0:42:20	SPEAKER_01
 So what about like morphics? You've got stemmers or is that something? Yeah, but all in the in the lexicon.

0:42:35	SPEAKER_01
 But you have that. Yeah, information is a lot of that.

0:42:40	SPEAKER_03
 Okay, I see. So, but so you just connect to the lexicon. Yeah, at least for German, you have all of the stemming information.

0:42:52	SPEAKER_01
 Yeah, we can. We have knowledge passes from from Rappmökels. Yeah.

0:42:58	SPEAKER_03
 But it doesn't look like it you're using it. I didn't see it being used in the current template parser. I didn't see any.

0:43:17	SPEAKER_01
 Which we actually only look at the English. But it's used for stem forms.

0:43:28	SPEAKER_00
 I think there's some misunderstanding. Morphics is not used online. So the lexicon might be derived by morphics, but what's happening online is just retrieving from the lexicon, which we call the stemming information.

0:43:43	SPEAKER_00
 So it will be a full form lexicon. That's what you have. Yeah.

0:43:49	SPEAKER_04
 We threw out all the forms. We threw out all the forms because English.

0:43:54	SPEAKER_03
 Oh, okay. So, yeah, so I thought I so in German, then you actually do case matching and things like that in the in the pattern matcher or not.

0:44:02	SPEAKER_03
 Not yet. I didn't. Okay.

0:44:06	SPEAKER_03
 I didn't think I saw it. Yeah. Getting it from the lexicon is just fine.

0:44:15	SPEAKER_02
 Yeah.

0:44:21	SPEAKER_03
 Yeah. Here's the case where the English and the German might really be significantly different in terms of if you're trying to build some fast parser and so forth. You really might want to do it in a significantly different way.

0:44:42	SPEAKER_03
 So you guys have looked at this also in terms of, you know, if you're doing this for English as well as Germans, you think now that it would be this similar way?

0:45:00	SPEAKER_01
 Yeah. I think it's possible to do list processing. And maybe it's more adequate for English and German set processing.

0:45:20	SPEAKER_01
 Maybe some extensions have to be made for English version.

0:45:39	SPEAKER_04
 I'm sure there's going to be more discussion on that after your talk. We're just going to foreshadow.

0:45:54	SPEAKER_03
 Now actually, are you guys three of five? Do you have to go somewhere at five o'clock tonight? No. I think I was just talking.

0:46:10	SPEAKER_03
 I'm just going to practice talk. Great. So you're going to. Yeah. That's good. Because that will tell you a fair amount about the form of semantic construction grammar that we're using.

0:46:25	SPEAKER_03
 So I think that's probably as good an introduction as you get to the form of conceptual grammar that will be having mind.

0:46:40	SPEAKER_03
 So I won't talk particularly about how that relates to what Robert was saying at the beginning. Let me give you a very short version of this. So we talked about the fact that they're going to be a certain number of decisions that you want the knowledge modeler to make that we then fed to the function module.

0:47:09	SPEAKER_03
 So they're these decisions. And then one half of this we talked about a little bit is how if you had the right information, if you knew something about what was said and about something about was the agent, a tourist or a native or a business person or a younger role, whatever.

0:47:35	SPEAKER_03
 So we're also about the what we're calling the entity is that a castle is it a bank is it a town square is a statue, whatever. So all that kind of information could be combined into decision networks and decisions.

0:47:52	SPEAKER_03
 So the other half of the problem is how would you get that kind of information from the parsed input. So what you might try to do is just build more templates saying we're trying to build a template, you know, build a template somehow would capture the fact that you want to take a picture.

0:48:18	SPEAKER_03
 And we could you could do this and it's a small enough domain that probably.

0:48:24	SPEAKER_03
 But from our point of view, this is also a research project and there are a couple of people not here. The various reasons we're doing Dr. of the citations on this. And the idea that we're really after is a very deep semantics based on cognitive linguistics and the notion that there are a relatively small number of primitive conceptual schemas that characterize a lot of activity.

0:48:53	SPEAKER_03
 So a typical one in this formulation is a container.

0:48:59	SPEAKER_03
 And the notion is that all sorts of physical situations are characterized in terms of container point in and out of portals.

0:49:11	SPEAKER_03
 But also importantly for lay coffin these guys is also a metaphorical picture also characters this way you get in trouble.

0:49:22	SPEAKER_03
 So what we're really trying to do is to map from the discourse to the conceptual semantics level and from there to the appropriate decisions.

0:49:35	SPEAKER_03
 So another one of these primitive what are called image schemas is goal seeking.

0:49:43	SPEAKER_03
 There's an ocean of the source, path goal, trajectory possibly obstacles. The idea is this is another conceptual primitive.

0:49:52	SPEAKER_03
 And that all sorts of things particularly in the tourist domain can be represented in terms of source, path goal. So the idea would be could we build and analyze it, we'd take an utterance and say, aha, this utterance is talking about an attempt to reach a goal.

0:50:11	SPEAKER_03
 The goal is this, the person, the traveler is that, the sort we are now is this, they've mentioned possible obstacles, et cetera.

0:50:22	SPEAKER_03
 And this is an attempt to get very wide coverage. So if you can do this then the notion would be that across a very large range of domains you could use this deep conceptual basis as the interface.

0:50:39	SPEAKER_03
 And then the processing of that both on the input end recognizing that certain words in a language talk about containers or goals, et cetera.

0:50:53	SPEAKER_03
 And on the output end given this kind of information you can then make decisions about what actions to take provides they claim a very powerful general notion of deep semantics.

0:51:11	SPEAKER_03
 And we're really, Nancy is going to her talk is going to be not about using this in applications, but about modeling how children might learn this kind of deep semantic grammar.

0:51:32	SPEAKER_00
 And how do you envision the deep semantic to be worked with would it be highly ambiguous. And then there would be another module that takes that highly underspecified deep semantic construction and map it onto the current context to find out what the person really was talking about in that context.

0:51:52	SPEAKER_03
 Well, that's that's where the belief that comes in. So the idea is let's take this business not going to the powder tower. So part of what you'll get out of this will be the fact that if it works right.

0:52:06	SPEAKER_03
 Okay, that this is an agent that wants to go to this place and that's their goal. And there'll be additional situational information.

0:52:13	SPEAKER_03
 Okay, part of comes to the ontology the tower is this kind of part of it comes with the user. And the idea of the belief that is it combines the information from the dialogue which comes across in this general way.

0:52:28	SPEAKER_03
 You know, this is this is a goal seeking behavior along with specific information from the ontology about the kinds of objects involved about the situation about is raining. I don't know, whatever it is. And so that's the belief that we've laid out.

0:52:45	SPEAKER_03
 And so the coupling to the situation comes in this model from at the at the belief net company evidence from the dialogue with the ontology with the situation.

0:52:58	SPEAKER_03
 Nancy isn't going to talk about that just about the first steps. Right, the construction grammar.

0:53:11	SPEAKER_04
 And she's going to start in a minute.

0:53:16	None
 Yeah, I didn't want to give you a little.

0:53:43	None
 Okay.

