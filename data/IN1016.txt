0:00:30	SPEAKER_02
 Okay, we start waiting for people coming late.

0:00:44	SPEAKER_02
 I can say this because in this moment you cannot answer because you don't tell the microphone so I can say whatever and you cannot reply.

0:00:53	SPEAKER_03
 Okay, I don't reply coming.

0:00:55	SPEAKER_03
 Yeah, it's okay.

0:01:02	SPEAKER_03
 Well, okay, so ready.

0:01:11	SPEAKER_03
 We can maybe get a head start.

0:01:14	SPEAKER_00
 Have you been talking to Matthew about what you've been doing?

0:01:20	SPEAKER_00
 A little bit but I'm not sure he knows everything.

0:01:28	SPEAKER_00
 Well first we try to explain why this end-best list is scoring from the slides to enhance the speech recognition on the meetings data is not working.

0:01:45	SPEAKER_00
 So that's one thing and so what we did with Alessandro is performing some statistical tests to see whatever, if the words, the appearance of the words during the meeting is independent of the appearances of the different slides.

0:02:13	SPEAKER_00
 So in the case if it is dependent that would mean that certain words tend to appear during certain slides.

0:02:20	SPEAKER_00
 Yeah, which was the interest.

0:02:21	SPEAKER_00
 And then there will be a reason for believing that this will work.

0:02:31	SPEAKER_03
 And the result was no.

0:02:33	SPEAKER_03
 The result was no.

0:02:35	SPEAKER_03
 But the question is is that result no because it's no or is it also just because there's not really enough data to be sure about anything.

0:02:44	SPEAKER_02
 In my opinion it's not because of the nature of the language.

0:02:46	SPEAKER_02
 I mean intuitively of course you tend to use more of the words that are on the slide.

0:02:51	SPEAKER_02
 But the mass of the words that actually use are words that are common.

0:02:56	SPEAKER_02
 Just think that 50% of the words on average, whatever corpus you take are stop words.

0:03:02	SPEAKER_02
 Yeah, exactly.

0:03:03	SPEAKER_02
 So in terms of recognition 50% goes away.

0:03:06	SPEAKER_02
 But the rest remain in 50% are all words that appear one, two, three times.

0:03:12	SPEAKER_02
 So in any case even if actually they tend to be related or statistically related to a single slide.

0:03:20	SPEAKER_02
 In any case in terms of recognition, do not have a tone.

0:03:24	SPEAKER_02
 It's not going to.

0:03:25	SPEAKER_02
 Yeah, very little.

0:03:26	SPEAKER_02
 So that's the kind of thing, I mean that's the kind of measure in statistical independence is not on single words overall.

0:03:33	SPEAKER_02
 Which basically means in terms of recognition that doesn't have.

0:03:36	SPEAKER_03
 This is sort of a feeling that we had but hadn't shown.

0:03:41	SPEAKER_03
 I think from an application point of view it might be interesting to make sure that your vocabulary contains all the words on the slides.

0:03:49	SPEAKER_03
 But from a research perspective it's not interesting.

0:03:52	SPEAKER_02
 You know even if actually I remember you just made some measure saying okay let's look at how many words I don't have in the dictionary and are in the slides.

0:04:00	SPEAKER_02
 That be very few.

0:04:01	SPEAKER_02
 It was 2%.

0:04:02	SPEAKER_02
 Yeah, almost no.

0:04:03	SPEAKER_03
 This is how the dictionary is calculated, it's calculated such that if you don't have the word it doesn't affect to a right degree the word error right.

0:04:13	SPEAKER_02
 Exactly, so in some sense intuitively it sounds very good but in practical terms in terms of recognition here we have to be clear.

0:04:22	SPEAKER_02
 If you want to improve the recognition that improves very slightly.

0:04:27	SPEAKER_02
 It is different if you want to have other tasks where the only words that actually play are all are two words.

0:04:34	SPEAKER_02
 In that case you have the slight improvements yes at that point that can make the difference.

0:04:40	SPEAKER_02
 But does the recognition?

0:04:42	SPEAKER_03
 No, well this is yeah.

0:04:44	SPEAKER_02
 And some way the statistical independence I think it can be a good explanation to show why this happened.

0:04:51	SPEAKER_02
 Even if it is counterintuitive but that's what happens basically.

0:04:54	SPEAKER_01
 So I'm sure we were just quickly divided.

0:04:57	SPEAKER_00
 Yeah, sorry about that.

0:04:59	SPEAKER_00
 We were talking that we did some experiments to see if the word during meeting the words appear independently of the slides in the sense that if certain words tend to appear during certain slides.

0:05:12	SPEAKER_00
 Okay.

0:05:13	SPEAKER_00
 Or no.

0:05:14	SPEAKER_00
 And the answer is no.

0:05:15	SPEAKER_00
 Okay.

0:05:16	SPEAKER_00
 And so we did a statistical test for that and I will add also that we did that on the words after filtering them from the removing the stop words.

0:05:28	SPEAKER_00
 Of course.

0:05:29	SPEAKER_00
 Yeah.

0:05:30	SPEAKER_00
 So it's not going to make any difference.

0:05:31	SPEAKER_00
 So because yeah with the stop words okay there will be a reason for independence because there is such a huge mass of them.

0:05:41	SPEAKER_00
 But even after removing them it remains independent.

0:05:49	SPEAKER_00
 And actually so when I was doing the scoring experiments I was doing that on one meeting that I selected as being like the best looking one.

0:06:01	SPEAKER_00
 It had the most slides.

0:06:06	SPEAKER_00
 And now I did the same on the other meetings which were available where it's only three meetings because well there are four of them which are from the test set from the ami recognizer but only three of them have slides.

0:06:22	SPEAKER_00
 So it's total of three meetings and for the others the tendency because you know I was when I was doing the scoring I was taking into account one given slide also the neighboring slides and as I was increasing the number of slides which were affecting the utterance I was scoring the performance was improving slightly.

0:06:47	SPEAKER_00
 Very very little.

0:06:49	SPEAKER_01
 No no wait it's going very fast for me.

0:06:52	SPEAKER_01
 That is the thing actually it's very fast.

0:06:55	SPEAKER_01
 So first point the first thing you told me is that you took the slides and you had a big dictionary and you were seeing what words are the inside the slides right.

0:07:06	SPEAKER_01
 What the first statement I could not understand.

0:07:09	SPEAKER_00
 When you said the first thing we were talking about takes the experiment to see the if it's dependent or independent.

0:07:19	SPEAKER_01
 Could you please tell me a little bit more.

0:07:21	SPEAKER_00
 How we did?

0:07:22	SPEAKER_00
 Yeah.

0:07:23	SPEAKER_00
 So we used Pearson key square.

0:07:27	SPEAKER_01
 No no no don't go there.

0:07:31	SPEAKER_01
 No I want to understand what did you mean by the thing like saying that I took a dictionary and then a word from the slide and what you are looking for I cannot understand clearly

0:07:44	SPEAKER_00
 there. So you have to see if certain words have a tendency to appear during if they are more likely to appear during certain slides.

0:07:58	SPEAKER_01
 Okay but how do what's happened words like how do you expect that that and what.

0:08:03	SPEAKER_02
 Be careful it's not exactly this because for sure there are words that tend to be.

0:08:07	SPEAKER_02
 So the point is you want to verify whether you can improve the recognition rate by using as an information the words that are contained in the slide.

0:08:17	SPEAKER_02
 So basically the idea is that in the moment you are in the slide somewhere your language change accordingly to the slide.

0:08:23	SPEAKER_02
 Exactly.

0:08:24	SPEAKER_02
 So the fact of having that information somewhere can help you to improve the recognition.

0:08:28	SPEAKER_02
 Exactly.

0:08:29	SPEAKER_02
 But actually it's not what happens.

0:08:30	SPEAKER_02
 Yeah.

0:08:31	SPEAKER_02
 And this does not happen for many reasons.

0:08:32	SPEAKER_02
 First for example 50% of the words in any kind of text are stop words so everywhere.

0:08:40	SPEAKER_02
 And the reminding appear so little that in the case cannot really improve that much.

0:08:45	SPEAKER_02
 Most of the words we use actually whatever we talk about are common words.

0:08:51	SPEAKER_02
 So how to verify this I mean this is something that has been measured etc. but still is a bit qualitative.

0:08:56	SPEAKER_02
 To have a quantitative measure we simply did a measure of statistical independence between the words in general.

0:09:05	SPEAKER_02
 So not some words.

0:09:06	SPEAKER_02
 In other words you can see that if a word appears once basically it is 100% related to one slide.

0:09:14	SPEAKER_02
 But you have to if you want to consider in terms of recognition performance you have to make it overall.

0:09:20	SPEAKER_02
 What is important is not the word that appears once.

0:09:23	SPEAKER_01
 It appears in almost if it appears in all the slides it says 100% correlation for me.

0:09:30	SPEAKER_02
 If there is one word that appears once all over the meeting it appears in correspondence of one slide.

0:09:37	SPEAKER_02
 Of course it seems to be very related.

0:09:39	SPEAKER_02
 But very few words.

0:09:40	SPEAKER_02
 I like that.

0:09:41	SPEAKER_02
 They represent a very little part of the word mass.

0:09:45	SPEAKER_02
 So we simply use the very old test.

0:09:49	SPEAKER_02
 Statistical test that basically measure the hypothesis that some way the probability of having one word in correspondence of a certain slide is simply the product of the probability of the word.

0:10:02	SPEAKER_01
 Okay.

0:10:03	SPEAKER_02
 That's it.

0:10:06	SPEAKER_02
 Okay.

0:10:07	SPEAKER_01
 But in general the language I'm not certain words.

0:10:10	SPEAKER_01
 Certain words.

0:10:11	SPEAKER_02
 Because certain words for sure are strong dependencies.

0:10:14	SPEAKER_01
 But they are a few.

0:10:17	SPEAKER_01
 Okay.

0:10:18	SPEAKER_01
 Fine.

0:10:19	SPEAKER_01
 Now I'm okay.

0:10:20	SPEAKER_01
 I'm into the law.

0:10:21	SPEAKER_00
 And the answer to that was no.

0:10:25	SPEAKER_00
 And so when extending those experiments to the other meetings, when I was observing an improvement on the first meeting I was using.

0:10:38	SPEAKER_00
 So I was observing an improvement as I was increasing like the context.

0:10:45	SPEAKER_01
 But the improvement is on the ASR.

0:10:50	SPEAKER_00
 On the recognition.

0:10:52	SPEAKER_00
 So the improvement was also increasing as I was increasing the context.

0:10:56	SPEAKER_00
 Well on the other meetings it's really fluctuating and it looks more like, wow, what's the word for that?

0:11:16	SPEAKER_00
 Statistical fluctuations.

0:11:18	SPEAKER_00
 The fluctuation.

0:11:23	SPEAKER_03
 I mean it's probably very dependent on the speaker as well.

0:11:25	SPEAKER_03
 So people have a habit of just reading what they've got in their slides.

0:11:30	SPEAKER_03
 And some people.

0:11:31	SPEAKER_03
 In terms of quite purposefully talk about different things.

0:11:37	SPEAKER_03
 So that they've got multi-modality.

0:11:41	SPEAKER_03
 So I mean I guess that's not a surprising result then.

0:11:46	SPEAKER_02
 It is not in terms, I mean for me for example it was not in the sense that after working a little bit on language you realize that this kind of thing do not help.

0:11:55	SPEAKER_02
 Simply because most of the words have nothing to do specifically with the subject use.

0:12:00	SPEAKER_02
 Most of the words we use are strange.

0:12:02	SPEAKER_02
 But are simply necessary to build the sentence.

0:12:05	SPEAKER_02
 There are very few content words.

0:12:10	SPEAKER_02
 But it is true that intuitively as we are driven in our attention.

0:12:14	SPEAKER_02
 I mean in our understanding we are pretty much driven by attention that we tend to spot the words.

0:12:20	SPEAKER_03
 Yeah sure.

0:12:21	SPEAKER_03
 Which goes straight to the semantics.

0:12:23	SPEAKER_02
 Exactly.

0:12:24	SPEAKER_02
 And in some sense intuitively it seems that it can help.

0:12:27	SPEAKER_02
 I mean this is not the first attempt to do things like this and it never works.

0:12:32	SPEAKER_02
 Actually in terms of recognition.

0:12:34	SPEAKER_02
 For other tasks.

0:12:35	SPEAKER_02
 Maybe.

0:12:36	SPEAKER_02
 It can be helpful.

0:12:38	SPEAKER_01
 So you mean to say that like when one case you were saying that if you increase the context and all those things it helps in your ASI improvement but it doesn't.

0:12:54	SPEAKER_01
 It's more subjective I think this whole.

0:12:56	SPEAKER_03
 Well I mean it just comes down to the mere fact that word error rate is just take the words.

0:13:03	SPEAKER_03
 How many of them did you get right?

0:13:05	SPEAKER_03
 If plus or minus two or three or five or ten words doesn't really make any difference.

0:13:11	SPEAKER_03
 Even if those words at the end of the day would be quite important in any sort of search of the transcript.

0:13:18	SPEAKER_03
 But at the end of the day why wouldn't you just use the slides to search the transcript.

0:13:22	SPEAKER_03
 Yeah.

0:13:23	SPEAKER_03
 If you have the slides then.

0:13:26	SPEAKER_00
 Yeah.

0:13:27	SPEAKER_00
 So that's why if we look on the relationship that exists between the speech and the slides the task of improving the recognition.

0:13:44	SPEAKER_00
 The overall speech recognition using the slides seems to be not very good.

0:13:56	SPEAKER_03
 You can't expect much from it.

0:13:59	SPEAKER_03
 So have you been doing other things then?

0:14:02	SPEAKER_03
 Have you been thinking about what you would like to do in place of this or leading on

0:14:11	SPEAKER_00
 from this given what you've learnt? Well for now the most effort was on showing why it will not work especially those experiments and these statistical tests.

0:14:30	SPEAKER_00
 But we were thinking for example of a task like trying to see if a speaker is talking I mean if the speech is actually correlated with the slides which happened during the

0:14:53	SPEAKER_02
 not correlated but if the careful collet is a dangerous one. It seems to be the opposite of the slides.

0:15:06	SPEAKER_00
 Well if the.

0:15:08	SPEAKER_03
 Associated.

0:15:09	SPEAKER_00
 If the speaker is actually talking about what is in the slides or not.

0:15:16	SPEAKER_02
 Okay.

0:15:17	SPEAKER_02
 We're off lit.

0:15:18	SPEAKER_02
 Basically one thing it can be done and here on the contrary for example the few words that are or may say recognize more can really make the difference.

0:15:29	SPEAKER_02
 It is in the case if you want to see if I mean what you've seen in the meeting in the okay the representation then yeah still the slide is there but actually the people talk about other things or not really other things but the slide is no longer a support for the discussion.

0:15:46	SPEAKER_02
 There are moments that actually this is the support because the people describe etc.

0:15:51	SPEAKER_02
 And there are moments where it is not it's just a background thing and we are after estimating it very quickly but it was one third of the time at least in the meeting we have seen.

0:16:01	SPEAKER_02
 The slide were just there I mean but they were no longer used as a support it was a discussion with the between people.

0:16:07	SPEAKER_02
 So in that case the presence or the absence and especially the frequency which you observe the words that are on the slides can be an excellent clue indication a clear indication whether actually that's a support of the discussion meeting action.

0:16:27	SPEAKER_02
 It can be the easy it can be interpreted as a kind of focus of interest it can be simply interpreted in the sense of saying okay I mean you have this channel open there we have to take into account or not.

0:16:39	SPEAKER_02
 Or also in terms of action yeah when you see that the discussion is completely disconnected with respect to this.

0:16:47	SPEAKER_02
 Some way it means that it's happening something different before.

0:16:51	SPEAKER_02
 So I mean it's a kind of feature that in my opinion can be easily detected and that can be interesting to do relatively easy to do and in that case for example the few words that you get more can make the difference.

0:17:10	SPEAKER_02
 So it's a double way to show how so it depends on the task.

0:17:17	SPEAKER_01
 So maybe it can be something like in a meeting it can be like an unusual scenario for you in a presentation with the slide and the initial scenario that you're not using the slide at all.

0:17:34	SPEAKER_00
 Yeah or for example what happened for example in one of the meetings is that people were summarizing the results of the previous meeting also in the beginning.

0:17:44	SPEAKER_00
 So the meeting started with the summary of what happened the previous time and this was not related to what was on the slides.

0:17:54	SPEAKER_03
 Yeah okay so I mean you could begin with seeing the simple task of just determining whether or not the speech is related to the slide content which is sort of building upon what you know Dong and others have worked on in terms of you know is it discussion monologue from the original M4 data collection.

0:18:14	SPEAKER_03
 Are you also considering that you could actually look at the relationship between meetings for instance.

0:18:21	SPEAKER_03
 What do you mean?

0:18:23	SPEAKER_03
 Well okay well I mean if these similar sort of phrases or words were discussed in this meeting and were also discussed in the previous meeting then you sort of have a link between meetings for instance.

0:18:38	SPEAKER_02
 Yeah some way.

0:18:39	SPEAKER_02
 I don't know how this you have to check the statistics.

0:18:42	SPEAKER_03
 This is the worst thing.

0:18:44	SPEAKER_03
 I mean because obviously you've got to think towards what you know this one occupied for three years or whatever just unless I guess.

0:18:53	SPEAKER_03
 I have to look at all the features.

0:18:55	SPEAKER_02
 Yeah I know this we are just talking about a very short term if you want but things just to use the things I mean all the work that you just done basically which is a huge work.

0:19:04	SPEAKER_00
 It was recycling.

0:19:05	SPEAKER_02
 And the data we have then you know for the for a thesis of course it must be much better.

0:19:11	SPEAKER_02
 But I've got there's only two different kinds of works some of them you can do it on a single meeting so this kind of feature extraction because basically that's what it is saying yes now this channel is good now is background now is foreground etc.

0:19:27	SPEAKER_02
 Yeah okay.

0:19:28	SPEAKER_02
 Put it in that way this you do it on a single meeting.

0:19:31	SPEAKER_02
 And then there are corpus based on the C works.

0:19:38	SPEAKER_02
 So yeah that is one possibility for example finding the connection between different meetings.

0:19:44	SPEAKER_02
 And I don't know I mean at that point it becomes pretty much crucial the kind of data you have in the sense that for the way we've collected the data some way I don't know if it can be at the same time too easy in the sense that some way you have little groups of meetings extremely correlated.

0:20:02	SPEAKER_02
 Sure.

0:20:03	SPEAKER_02
 So I mean it makes it easier I mean I don't know how much significant can be at that level.

0:20:10	SPEAKER_03
 Yeah I mean it's and because we don't have all the data collected or annotated yet it's

0:20:15	SPEAKER_02
 very difficult you know. In a sense if you want this kind of first become interesting when the corpus is really big.

0:20:22	SPEAKER_02
 Yeah.

0:20:23	SPEAKER_02
 Yeah.

0:20:24	SPEAKER_02
 When you consider each meeting as a single item so it's interesting when you have tens hundreds thousands of meetings which is not the case.

0:20:33	SPEAKER_02
 But I mean you can do other work if you consider in terms of speaker terms or in terms of

0:20:37	SPEAKER_03
 the same kind of Yeah.

0:20:41	SPEAKER_03
 Yeah.

0:20:42	SPEAKER_03
 Yeah.

0:20:43	SPEAKER_03
 I think that's quite interesting I mean because it's an awful lot of speech activity.

0:20:47	SPEAKER_02
 Yeah.

0:20:48	SPEAKER_02
 So it's going to be one more feature that helps in.

0:20:52	SPEAKER_02
 But it is very short term I mean just you know it's just a few few few times we talked together and it was just very quick thing you can have like this.

0:21:04	SPEAKER_03
 Yeah so I mean as far as that you've got everything you need to do that I presume.

0:21:09	SPEAKER_03
 You don't need any extra stuff from us in the immediate.

0:21:12	SPEAKER_00
 Oh no.

0:21:13	SPEAKER_03
 I mean that's good.

0:21:14	SPEAKER_01
 No you have plenty of things to do.

0:21:18	SPEAKER_00
 But for the other thing you know the alternative measures or maybe we should finish with this first.

0:21:25	SPEAKER_03
 Yeah I wouldn't get too distracted I guess.

0:21:31	SPEAKER_03
 If you've got two tracks I'd like to.

0:21:33	SPEAKER_00
 Yeah this would be another subject I would like to discuss.

0:21:38	SPEAKER_00
 But yeah yeah it's no problem.

0:21:41	SPEAKER_00
 But basically just know if we finish discussing this.

0:21:47	SPEAKER_01
 Okay.

0:21:49	SPEAKER_01
 So well so ultimately now the next step what is the other one like kind of a.

0:21:57	SPEAKER_01
 So first you said that okay now you did this correlation studies and you showed that there's a very less correlation now in fact no correlation kind of thing.

0:22:10	SPEAKER_01
 And so what next and on top of it what you're going to build the question now.

0:22:20	SPEAKER_02
 But I think it has since in my opinion what are two things.

0:22:24	SPEAKER_02
 When this statistical test it can be we have made an experiment we get to result somewhat counterintuitive we give an explanation.

0:22:34	SPEAKER_02
 And that's something that's some way closer here.

0:22:39	SPEAKER_02
 So it gives you the kind of answer you get is that okay to go in that direction maybe it's not the best thing maybe to improve the recognition that way is not something you can expect so it gives you the possibility to decide to go in a different direction that can be more on this.

0:22:57	SPEAKER_01
 So I mean to the different direction that's what I mean to say what you like to take from there.

0:23:02	SPEAKER_00
 So it's not too easy to find yet.

0:23:04	SPEAKER_01
 It's not defined yet okay.

0:23:06	SPEAKER_00
 But something using this relationship between the slides and other even other take textual support and the speech.

0:23:20	SPEAKER_01
 But what kind of problem we need the definition of kind of problem right.

0:23:25	SPEAKER_03
 And the question is also are there other sort of more sensible ways of doing it for instance gaze tracking.

0:23:32	SPEAKER_03
 I mean if people are looking at the slides.

0:23:36	SPEAKER_02
 Well I think the advantage eventually with this kind of things is that are much easier.

0:23:46	SPEAKER_02
 Gaze tracking is still.

0:23:47	SPEAKER_02
 Yeah sure.

0:23:48	SPEAKER_03
 And it has specific to the environment and all that sort of thing.

0:23:51	SPEAKER_02
 The environment is a difficult thing and it requires cameras with pretty good quality etc.

0:23:56	SPEAKER_02
 But I think his question is more general and he says I mean based on this work do you figure out a direction if I get the direction.

0:24:06	SPEAKER_01
 That is the thing.

0:24:07	SPEAKER_01
 What is the next direction?

0:24:08	SPEAKER_01
 Is it not that?

0:24:09	SPEAKER_02
 I don't know in a direction for your thesis.

0:24:11	SPEAKER_01
 It's not happened that you're doing so many things and ultimately it doesn't go into a thesis.

0:24:17	SPEAKER_01
 Exactly.

0:24:18	SPEAKER_01
 That should not be the problem.

0:24:20	SPEAKER_01
 The thesis should be in one direction, one problem.

0:24:24	SPEAKER_01
 And it should go.

0:24:25	SPEAKER_01
 One direction or one direction or one direction.

0:24:27	SPEAKER_02
 What are the things completely not related to the future?

0:24:28	SPEAKER_01
 It doesn't make sense.

0:24:30	SPEAKER_01
 It may be good as a CV for you but then as a thesis you will have problems.

0:24:37	SPEAKER_01
 Defending it and all those things.

0:24:39	SPEAKER_01
 So what is that?

0:24:41	SPEAKER_01
 What would be the next possible direction you want to take?

0:24:48	SPEAKER_00
 Well this is the question I'm working on.

0:25:01	SPEAKER_03
 But I mean for instance it should be linked to the other stuff that you've been doing on call routing for instance.

0:25:09	SPEAKER_03
 And you know error measures.

0:25:12	SPEAKER_03
 Yeah, that's good.

0:25:13	SPEAKER_03
 Yes.

0:25:14	SPEAKER_03
 I mean I think it's possible to draw some sort of relationship between the two as we were saying.

0:25:21	SPEAKER_03
 I mean maybe if you don't measure things in terms of where they're right maybe this sort of information does actually mean something.

0:25:28	SPEAKER_03
 Given that 50% of the words are not actually interesting.

0:25:33	SPEAKER_03
 So I mean.

0:25:34	SPEAKER_00
 Yeah that could be interesting to try to merge those two things.

0:25:39	SPEAKER_00
 But still doesn't solve the problem.

0:25:42	SPEAKER_02
 What is that?

0:25:45	SPEAKER_02
 You are sure what you were going to do for your thesis.

0:25:51	SPEAKER_02
 As I always say I mean basically if you have to explain in four lines.

0:25:55	SPEAKER_02
 Yeah exactly.

0:25:56	SPEAKER_02
 What would be the topic of my thesis?

0:25:58	SPEAKER_02
 The subject of my thesis.

0:26:00	SPEAKER_02
 And it is something that is not just saying I'm going to do this and that.

0:26:06	SPEAKER_02
 I mean because you're not.

0:26:08	SPEAKER_02
 But yeah in a very broad sense I mean what you're going to investigate.

0:26:14	SPEAKER_01
 See that is going to tell something like the thing is that you can totally go into the text domain and be there you know.

0:26:24	SPEAKER_01
 It can be no problem but as long as it is okay.

0:26:29	SPEAKER_01
 But if you want to do with like something with the speech and all those things together then it's a different scenario.

0:26:38	SPEAKER_01
 You may not want to work on all the problems.

0:26:41	SPEAKER_01
 Someone may work on some other problem but then you make use of that to extend your work in something.

0:26:50	SPEAKER_01
 And as I also it depends like also I think if a boss is interested in working in both speech and text if I understand very well.

0:27:00	SPEAKER_01
 Yeah that part is also there.

0:27:03	SPEAKER_01
 Sure.

0:27:04	SPEAKER_00
 They are interested in that.

0:27:06	SPEAKER_01
 So it was like heavy like suggesting like you should like work on both sides you know the text and the speech aspect of it.

0:27:15	SPEAKER_02
 I don't know what Patrick's thing I suggested in the name is thinking about.

0:27:20	SPEAKER_02
 I mean he's exactly this there are all these scenarios that can be meeting that can be presentation where you have a relationship between speech between things that are saved and some textual documents.

0:27:36	SPEAKER_02
 Why not try to study this relationship to improve this relationship to use this relationship for whatever it is indexing or annotation or whatever metadata extraction.

0:27:48	SPEAKER_02
 And if you want for example this little work about seeing when the slight channel is background and foreground is not in the next and beginning of this kind of thing.

0:27:57	SPEAKER_02
 So a relationship between two channels that provide some kind of information.

0:28:02	SPEAKER_03
 I think it may be an interesting test scenario and we know that you're sort of basing something around speech and text.

0:28:13	SPEAKER_03
 I think there needs to be one sort of extra higher goal above that so that you can motivate

0:28:19	SPEAKER_02
 to do the research.

0:28:23	SPEAKER_01
 One thing interesting is what we came up in the discussion also you were telling that detecting such scenarios where there is no relation between the slide and the present talking.

0:28:35	SPEAKER_01
 That may be one good starting point for you actually.

0:28:38	SPEAKER_01
 And then at that point you do take something like that and then you show something like what he was saying that if there is if there is out of discussion the words are no way are going to help your recognition anyway.

0:28:55	SPEAKER_01
 Yes sir but if it is more on the slide information is not going to help you but if it is related to the what he is giving a presentation on the slide then you show your answer.

0:29:09	SPEAKER_01
 I mean if you detect this even then you can show that how where you can really help or not help because you say there is no correlation now but then here it comes at some point there might be a correlation there.

0:29:22	SPEAKER_02
 Don't be careful.

0:29:24	SPEAKER_02
 For the recognition in general there is no correlation in the sense that even if you are talking about what is on the slide most of the words you use most of the words you use are not really correlated to that.

0:29:37	SPEAKER_02
 They are simply words and consider also that we all speak English here and a part of native English speakers we have a very limited vocabulary in general.

0:29:46	SPEAKER_02
 So we tend to use all of the same words but to average you know linguistic research shows that to average the people use 500 words.

0:29:54	SPEAKER_02
 That is what we have a conversation.

0:29:55	SPEAKER_02
 Yeah for English it is especially lower.

0:29:57	SPEAKER_02
 We say everything with that and probably we not a native English speaker we use even less.

0:30:03	SPEAKER_02
 So that gives you an idea of why basically in terms of recognition it doesn't really help because you always use anyway the same words and the few occurrences of words that are there in terms of recognition make 1% so maybe it is not enough to justify an effort to improve the recognition.

0:30:23	SPEAKER_02
 Then you can change of task.

0:30:25	SPEAKER_02
 And use the task we were mentioning about the Bechannel or Fergram channel.

0:30:30	SPEAKER_02
 In that case the only words that really are important are those words that appear on both

0:30:36	SPEAKER_01
 slides.

0:30:37	SPEAKER_02
 Right and they are all. At that point I mean a little improvement of that it becomes a big improvement.

0:30:43	SPEAKER_02
 I mean maybe in terms of recognition it is 0.5% but in terms of that task it is maybe 20%.

0:30:51	SPEAKER_03
 Okay another thing you have to remember is these models have been tuned to include Ami data.

0:30:58	SPEAKER_03
 So I mean perhaps if you had slides and presentations to do with something that was off topic you didn't have you haven't seen any prior data then you might see a bigger contribution as well but I mean essentially you've actually sort of included the information from the slides in the language model.

0:31:14	SPEAKER_02
 That's another interesting point I mean we are using data that are fake in any case there are simulation, no real data.

0:31:22	SPEAKER_02
 And especially the slides I think I've seen the slides and they are pretty much artificial.

0:31:26	SPEAKER_03
 Okay okay they're pretty prepared.

0:31:29	SPEAKER_03
 Exactly.

0:31:30	SPEAKER_01
 Most of the time you have the title to do not the Ami data was that like that only.

0:31:35	SPEAKER_01
 Most of the time you know the header what are the three slides you are going to present everyone is presenting the same.

0:31:41	SPEAKER_02
 Yeah I mean everything is pretty much artificial that's what I mean.

0:31:44	SPEAKER_02
 So you mentioned for example this fact that sometimes speakers tend to read.

0:31:49	SPEAKER_02
 Especially through when you have pallet list and sometimes people really go through.

0:31:54	SPEAKER_02
 It didn't happen in the data simply because it was not the same thing they were prepared exactly.

0:32:00	SPEAKER_02
 Okay.

0:32:01	SPEAKER_02
 So for example it would be possible in a case because everything for structure is ready now we are going to collect the temptation there maybe we can see.

0:32:10	SPEAKER_01
 What about MLMI the one we collected last year.

0:32:13	SPEAKER_01
 The audio is very bad right.

0:32:16	SPEAKER_01
 I think it's really bad.

0:32:17	SPEAKER_01
 The dinner time is one single channel at least closed channel collection no.

0:32:21	SPEAKER_02
 You know that was collected a little bit like this without too much care it was it was personally a part of myel that decided to do it.

0:32:31	SPEAKER_02
 It was good.

0:32:32	SPEAKER_01
 It was good.

0:32:33	SPEAKER_02
 It was very good.

0:32:34	SPEAKER_02
 But basically it was made without any specific you know without thinking we want to recognize just to have them.

0:32:42	SPEAKER_02
 So especially the audio channel is absolutely.

0:32:45	SPEAKER_01
 So they are still using that desktop microphone or whatever.

0:32:49	SPEAKER_03
 Yeah they had like they you know they had to set up with the microphones.

0:32:54	SPEAKER_03
 So someone every there was one microphone shared between every two people.

0:32:59	SPEAKER_03
 But they had deals with people forgetting to turn the microphone on forgetting to turn it off.

0:33:04	SPEAKER_03
 It was it was meant I think they they chose that lecture theater possibly with the idea that it would be good for collecting data.

0:33:12	SPEAKER_03
 I mean I I'm sure they could have probably had university of Edinburgh hosted or whatever.

0:33:17	SPEAKER_03
 But I think the you know the HCOI part of it to be quite work out to how they planned.

0:33:25	SPEAKER_02
 Okay that's that's that's that is one of the reasons for example why would Shamark with point pretty much no slides as a mean of indexing.

0:33:33	SPEAKER_02
 Because at that point there is no interaction between humans and capture.

0:33:38	SPEAKER_02
 Because whenever you have microphones that you have to move it sits.

0:33:43	SPEAKER_02
 It's just completely.

0:33:46	SPEAKER_03
 It's I mean the same as us putting on the headphones and whatever I mean even that minor thing I mean any any audio captured during that period is is rubbish.

0:33:57	SPEAKER_03
 But yeah there's no sort of system that's really built to be able to say when you're.

0:34:02	SPEAKER_01
 So now the without me sometimes what is we should be getting a time recording for this camera.

0:34:09	SPEAKER_02
 We are building this slowly and it's it's important that and it's taking time for the material and so on.

0:34:16	SPEAKER_02
 But yeah that will be the thing.

0:34:17	SPEAKER_03
 Okay what will that incorporate will incorporate like an SMI and it will be one camera pointing

0:34:26	SPEAKER_02
 very general but just for display purposes essentially. One microphone and we are thinking to use a little microphone you know this this really thing and so that potentially helpful hopefully helpful to the recognition and the slides.

0:34:42	SPEAKER_02
 Okay through the projector.

0:34:44	SPEAKER_03
 Okay so no microphone arrays or anything like that.

0:34:49	SPEAKER_03
 I guess that's quite a that's a quite a big deal for setting up the recording.

0:34:52	SPEAKER_01
 Let's say that in any case.

0:34:54	SPEAKER_01
 It's quite a big problem to do that.

0:34:56	SPEAKER_02
 First of all we are trying to do something that can be easily the idea is really it's something that you take you bring somewhere else and it works.

0:35:04	SPEAKER_02
 So it must be as easy as possible.

0:35:07	SPEAKER_02
 But in any case I mean the device we are doing has input channels.

0:35:12	SPEAKER_02
 So some way you can add as many inputs as you want.

0:35:16	SPEAKER_02
 So we are dealing now with three but there are other input lines open.

0:35:22	SPEAKER_01
 Yeah but probably within the you know the post the thing is somewhere over project resupposed there.

0:35:32	SPEAKER_01
 The whiteboard or whatever the presentation is over there.

0:35:35	SPEAKER_01
 The speaker is more probably going to this way or that way.

0:35:37	SPEAKER_01
 So probably you may not need a very big microphone either probably one or two.

0:35:42	SPEAKER_03
 Yeah less pretend it's not going to happen in any foreseeable future.

0:35:48	SPEAKER_03
 I mean I'm just thinking from practical perspectives you'd have to the the AME recognition system that we have now is either for these microphones or for the microphone array.

0:36:00	SPEAKER_03
 There's no lapel system trying to instance.

0:36:02	SPEAKER_03
 I mean that in itself it would I mean you'd have some fun training some more speech recognition models.

0:36:08	SPEAKER_02
 The point we can use this and I was mentioning the the level microphone just like this but if you tell me this that's very interesting because at this point we can use this kind of things rather than why not suitably other data other test data and especially for this kind of problem I think it can be a much more useful kind of because there is real presentations I mean it's sure it's reality you know it's it's what you should be using for this type of task.

0:36:40	SPEAKER_02
 But it's more realistic and probably it can help.

0:36:45	SPEAKER_02
 I think going this direction of saying well let's see what happens between speech and slides.

0:36:51	SPEAKER_03
 And every time we we generate a new corpus and try to carry out new research we discover sort of areas that are too controlled.

0:36:59	SPEAKER_03
 I mean the AME ones are a lot better in terms of that than them four or whatever but still I mean especially when you get into higher level sort of interpretation it's.

0:37:15	SPEAKER_03
 I'm just curious do they like the Ixsee meetings do they have anything other than the audio do they have slides or anything.

0:37:20	SPEAKER_03
 I don't think they would.

0:37:21	SPEAKER_03
 Okay I'm just thinking whether or not there are any other sources I mean maybe chill.

0:37:25	SPEAKER_01
 Chill may be interesting for you but it may be interesting for your problem I think.

0:37:31	SPEAKER_03
 Because I think it's going to be more like the TAM type situation.

0:37:36	SPEAKER_01
 Yeah it's more like TAM but yeah that their collection is much like they have an audience and all those things people say it's a lecture meeting collection.

0:37:49	SPEAKER_01
 Are they going to release it through LDA or something.

0:37:54	SPEAKER_03
 I don't know but I mean given that it's coming from the same basis as AME I expect there has to be some sort of relatively liberal sort of participation policy.

0:38:05	SPEAKER_02
 Yeah yeah it's a European project anyway so it's probably available.

0:38:09	SPEAKER_01
 Chill may be interesting actually.

0:38:12	SPEAKER_03
 The one thing about that and this was something that came up in the last NIST evales was the fact that it's almost too uni modal.

0:38:19	SPEAKER_03
 You've just got one lecturer talking so once again you don't see the complex sort of levels of interaction.

0:38:26	SPEAKER_03
 I mean there's no way of getting around it.

0:38:29	SPEAKER_03
 I mean you just have to think of a task a challenge that is relevant to that type of recording which might you might use the same methods as what we've been talking about today but the actual sort of what you're trying to imagine might need to be slightly different I guess.

0:38:47	SPEAKER_03
 You know in terms of say measuring whether or not they're talking about the slides or the channel you might find 98% of your data is directly referring to your slides in a

0:38:56	SPEAKER_02
 time. But now we were measuring one third it's not.

0:38:59	SPEAKER_03
 That is in terms.

0:39:01	SPEAKER_02
 At least in...

0:39:02	SPEAKER_02
 No I'm talking now about the...

0:39:04	SPEAKER_03
 I mean if you move on to the use presentation of course and presentation you might want

0:39:11	SPEAKER_02
 to be doing something else basically. Of course.

0:39:14	SPEAKER_02
 No that is just something that in my opinion with the work has been already done is something we can get pretty quickly.

0:39:21	SPEAKER_02
 It's an interesting task.

0:39:22	SPEAKER_02
 It's more specific on meetings.

0:39:25	SPEAKER_02
 Certainly not for presentation.

0:39:29	SPEAKER_02
 It represents a nice task that can be measured that is clear and...

0:39:33	SPEAKER_03
 Yeah and at the end of the day you're probably going to be using learning about the same

0:39:39	SPEAKER_02
 techniques that you'll need for doing other things. In terms of action recognition can of course help.

0:39:46	SPEAKER_02
 But of course it's not going to be a kind of...

0:39:51	SPEAKER_02
 This is about this.

0:39:52	SPEAKER_02
 It doesn't make any sense.

0:39:54	SPEAKER_03
 It was to make a proposal basically.

0:39:57	SPEAKER_03
 I feel.

0:39:58	SPEAKER_02
 Yeah.

0:39:59	SPEAKER_02
 That's in a sense if you want.

0:40:00	SPEAKER_02
 I mean that's at least the way I see that I've made for my own thesis.

0:40:04	SPEAKER_02
 I mean you just find that the main which is large which can be very general so interaction between speech and slides.

0:40:13	SPEAKER_02
 Cool.

0:40:14	SPEAKER_02
 And then you see how all these things, these two little works or the statistical independence and detecting when it is are two little works that some way fits in that very general framework.

0:40:29	SPEAKER_02
 Okay.

0:40:30	SPEAKER_02
 Shown for this point of view.

0:40:32	SPEAKER_02
 The other things for example what I really would like to do which is kind of fun.

0:40:36	SPEAKER_02
 So when you have a ballot list can I click on one of the ballot and get the piece of speech where the guy was talking about that.

0:40:47	SPEAKER_02
 Sometimes people just read.

0:40:49	SPEAKER_02
 Sometimes people improve is more...

0:40:53	SPEAKER_02
 For example that's another thing that fits in that kind of framework.

0:41:00	SPEAKER_02
 And that's interesting in terms of...

0:41:02	SPEAKER_02
 First of all again is measurable in terms of browsing, in terms of retrieval, in terms of index in annotation, let's add a text to action.

0:41:12	SPEAKER_00
 That's to be a binary.

0:41:14	SPEAKER_00
 Do automatically speaker rating if they're good speakers or bad speakers depending if they just read.

0:41:20	SPEAKER_00
 Wow.

0:41:21	SPEAKER_00
 Look at this.

0:41:22	SPEAKER_02
 You know that something that's maybe joking now.

0:41:25	SPEAKER_02
 Something that can be done for example.

0:41:28	SPEAKER_03
 The police spot if they forget to talk about something and it won't let them continue on to the next slide.

0:41:33	SPEAKER_02
 And it's like those are all the points.

0:41:35	SPEAKER_02
 And so why there are parameters that can be measured that tell you that following certain criteria.

0:41:42	SPEAKER_02
 There is one very easy for example.

0:41:46	SPEAKER_02
 There are speakers that never look at the audience.

0:41:50	SPEAKER_02
 Those are bad speakers in general.

0:41:51	SPEAKER_02
 It's very wrong.

0:41:52	SPEAKER_02
 You have to look at the audience.

0:41:55	SPEAKER_02
 This is one.

0:41:56	SPEAKER_02
 There is for example, and this is something that eventually can be done.

0:42:00	SPEAKER_02
 If you have a certain number of words on your slides, you need a certain amount of time to read them.

0:42:06	SPEAKER_02
 The speakers that take a time which is too close to that, they are not good speakers because some way they're talking about...

0:42:15	SPEAKER_01
 I had a problem.

0:42:16	SPEAKER_01
 I had a problem.

0:42:17	SPEAKER_01
 I had like five years of health on my own.

0:42:20	SPEAKER_01
 They are not good.

0:42:21	SPEAKER_03
 Well, that was just through a sheer wide of content.

0:42:23	SPEAKER_02
 They are not giving you the time.

0:42:26	SPEAKER_02
 There is a certain number of things that can be some way detected and measured.

0:42:31	SPEAKER_02
 They tell you whether the speaker is actually respecting some form of...

0:42:35	SPEAKER_02
 It's a bit difficult and I will not go that much in that direction.

0:42:44	SPEAKER_02
 You're going to be possible, Samhli.

0:42:48	SPEAKER_01
 So what about the figure things?

0:42:50	SPEAKER_01
 What happens if there are figures coming on the slides?

0:42:52	SPEAKER_01
 What do you want to do with that?

0:42:54	SPEAKER_01
 Figure...

0:42:55	SPEAKER_03
 I think there are five.

0:42:57	SPEAKER_03
 There are tables, paper, yeah, visual things.

0:43:02	SPEAKER_02
 Well, for example, we submitted a project with Shamark to use that thing as metadata.

0:43:09	SPEAKER_02
 And basically, one thing, for example, we are trying to do, and again, this is something that can fit to be not...

0:43:15	SPEAKER_02
 After maybe that, but if you get the project, etc.

0:43:19	SPEAKER_02
 And it is something that Shamark and everyone want to do.

0:43:22	SPEAKER_02
 Based on the kind of graphic object you have, so tables, questions, figures, plots, etc.

0:43:30	SPEAKER_02
 The side one, for example, it is a result.

0:43:33	SPEAKER_02
 Try to get.

0:43:34	SPEAKER_02
 So that's again, in terms of structuring, browse and structuring, retrieval.

0:43:39	SPEAKER_02
 Okay, when it is a result, when it is an introduction.

0:43:46	SPEAKER_03
 Although I remember discussing this, because when the bill was working on his stuff, which was just based on the slides, he asked me, could I pre-segment the slides for him?

0:44:03	SPEAKER_03
 Because you wanted to have the topic segmentation.

0:44:06	SPEAKER_03
 And I said, well, just look at the headings.

0:44:09	SPEAKER_03
 Because anybody, generally, who writes slides.

0:44:12	SPEAKER_03
 It's not really true.

0:44:14	SPEAKER_02
 It's not true for me then.

0:44:17	SPEAKER_02
 Yeah, it's not really true.

0:44:18	SPEAKER_02
 That's one of the most funny things.

0:44:20	SPEAKER_02
 You can see when you work in this thing, each one of us has an idea.

0:44:24	SPEAKER_02
 And then it's not true at all.

0:44:26	SPEAKER_02
 Some people actually are stick very carefully.

0:44:30	SPEAKER_02
 If they put in the outline, let's say, title one, title two, then you find title one, title two.

0:44:37	SPEAKER_02
 But many other people, and I am one of those people, for example, are much more generous.

0:44:41	SPEAKER_02
 So my outline is something like introduction and experiment and results, conclusions.

0:44:47	SPEAKER_02
 You don't find the same title in the slides.

0:44:51	SPEAKER_02
 Okay.

0:44:52	SPEAKER_02
 It's really a different style of the time.

0:44:55	SPEAKER_02
 It's a stylistic thing.

0:44:56	SPEAKER_02
 It's not just the name.

0:44:57	SPEAKER_02
 People that don't put, for example, outline.

0:44:59	SPEAKER_02
 We were, for example, in the corpus of MLME.

0:45:04	SPEAKER_02
 So the one is on the demo.

0:45:05	SPEAKER_02
 50% of the presentation have no outline in the corpus of the term 2004 term presentation.

0:45:17	SPEAKER_02
 25% of the presentation have no outline at all.

0:45:22	SPEAKER_03
 Which whether or not that's a good or a bad thing.

0:45:25	SPEAKER_02
 It depends on the tone.

0:45:26	SPEAKER_02
 Yeah, well, it is.

0:45:27	SPEAKER_02
 And basically that's, again, the outline is typical, maybe in scientific presentation.

0:45:32	SPEAKER_02
 In that case, the majority has.

0:45:35	SPEAKER_02
 Other kind of presentation probably no.

0:45:37	SPEAKER_02
 It's a nebit we have, but...

0:45:42	SPEAKER_03
 Something we taught at university from a very young age.

0:45:46	SPEAKER_02
 There is nothing true.

0:45:49	SPEAKER_02
 Yeah, sure.

0:45:50	SPEAKER_02
 It's all subjective.

0:45:51	SPEAKER_02
 Nothing true.

0:45:52	SPEAKER_02
 It's everything.

0:45:53	SPEAKER_02
 It's changed pretty much.

0:45:54	SPEAKER_02
 So that was some...

0:45:55	SPEAKER_02
 Okay.

0:45:56	None
 Okay.

0:45:57	SPEAKER_04
 So what are you going to do?

0:45:58	SPEAKER_01
 Between the data when you collect and this.

0:46:03	SPEAKER_01
 What do you want to do now?

0:46:07	SPEAKER_01
 By the time you get the data, it's going to take another two months, if I am right, the whole capturing system and it's going to come.

0:46:15	SPEAKER_01
 So what is the next step?

0:46:18	SPEAKER_00
 Well, trying to really determine the subject, something for my proposal, I mean.

0:46:32	SPEAKER_01
 Yeah, you have to submit it in like two months also again.

0:46:35	SPEAKER_00
 Yeah, around February or March.

0:46:37	SPEAKER_00
 Yeah, I have to submit it.

0:46:39	SPEAKER_01
 So really...

0:46:40	SPEAKER_03
 It's funnier, right?

0:46:41	SPEAKER_00
 Yeah, yeah, it's frustrating.

0:46:42	SPEAKER_00
 And pause now.

0:46:43	SPEAKER_00
 So to find something for that, also will the thinking maybe turning this work into publication, the one about...

0:46:54	SPEAKER_00
 Not maybe.

0:46:55	SPEAKER_02
 For sure.

0:46:56	SPEAKER_00
 You did it bad.

0:47:00	SPEAKER_00
 And also, well, that depends a little on you, but try to finish with the...

0:47:09	SPEAKER_00
 All of them.

0:47:10	SPEAKER_00
 measures and the poll routing.

0:47:12	SPEAKER_00
 That's interesting.

0:47:13	SPEAKER_00
 Because I was talking with that about that to Ale.

0:47:15	SPEAKER_00
 Since I was...

0:47:17	SPEAKER_00
 I will recycle this poster for...

0:47:18	SPEAKER_00
 I am too, you know, about this.

0:47:21	SPEAKER_00
 And that could be cool to finish it.

0:47:24	SPEAKER_00
 Maybe fuse it with the E.M.s work and do a general paper he was suggesting.

0:47:29	SPEAKER_03
 After the hard drive crash, we took the time to actually rebuild the system and actually train...

0:47:36	SPEAKER_03
 Because originally we sort of had the idea of, I will use a recognizer that's been trained on a large amount of telephone speech data and that should give us a better result.

0:47:44	SPEAKER_03
 Just as a contrast, I trained one specifically on this data.

0:47:48	SPEAKER_03
 Results are almost identical.

0:47:51	SPEAKER_03
 Which says to me that something wrong with the data rather than...

0:47:55	SPEAKER_03
 And it's nothing serious.

0:47:57	SPEAKER_03
 It's simply that it hasn't been chunked or segmented in a way that's typical of speech resources.

0:48:07	SPEAKER_03
 In terms of you can have like a two second utterance credit cards and then 20 seconds of silence coming after.

0:48:15	SPEAKER_03
 Which when you first think about it, you just think, oh, silence, whatever, nothing will happen.

0:48:21	SPEAKER_03
 But a lot of the normalization techniques that we use...

0:48:24	SPEAKER_03
 Yeah, CMS, CVN.

0:48:27	SPEAKER_03
 So we needed these in Endpoint Detection system running before we can do that.

0:48:34	SPEAKER_03
 And we converging on having one now in tandem with this development of this web based recognizer.

0:48:43	SPEAKER_03
 But unfortunately all these things take time.

0:48:47	SPEAKER_03
 But I think we should see...

0:48:49	SPEAKER_03
 No, no, I think...

0:48:50	SPEAKER_03
 Yeah, it's decent sort of improvement.

0:48:53	SPEAKER_03
 Not just in terms of no longer having recognition errors whenever silence appears.

0:48:57	SPEAKER_03
 Because you get that immediate benefit that you don't have any insertion errors.

0:49:01	SPEAKER_03
 But also it should actually affect the recognition on the speech segment as well.

0:49:05	SPEAKER_02
 So essentially you say, what are the best risks?

0:49:07	SPEAKER_02
 This silence time which tend to be even more than...

0:49:11	SPEAKER_02
 It's better to have a kind of silence detection or something that really takes this and then recognize only that part.

0:49:18	SPEAKER_02
 This will improve the phoneme recognition, right?

0:49:22	SPEAKER_02
 That's what we expect.

0:49:23	SPEAKER_02
 Oh, I might...

0:49:24	SPEAKER_02
 Given the trouble we've had with this call for a second, make any promises.

0:49:28	SPEAKER_02
 At that point even the call router that Janja Yves made can improve its performance.

0:49:37	SPEAKER_01
 Yeah, that's the intention.

0:49:38	SPEAKER_01
 Exactly.

0:49:39	SPEAKER_02
 And it can be used after for the measure work.

0:49:43	SPEAKER_00
 So what you are saying is that you notice that when you tried other features and...

0:49:49	SPEAKER_03
 We're trying to system just on this data.

0:49:52	SPEAKER_03
 There were 6,000 utterances that weren't used for the core adding side of things.

0:49:58	SPEAKER_03
 I think there were 13,000 in Tycorpus, half of them roughly were thrown away.

0:50:04	SPEAKER_03
 So use that for acoustic training.

0:50:06	SPEAKER_03
 And the results from that were almost the same as what we got for CVS.

0:50:09	SPEAKER_00
 And initially it was a new answer.

0:50:12	SPEAKER_00
 No, no, no.

0:50:13	SPEAKER_03
 But one can imagine a commercial system that Stephen Cox used from nuance probably had all these things built in endpoint detection, etc.

0:50:23	SPEAKER_03
 So...

0:50:24	SPEAKER_01
 There should have had that actually.

0:50:27	SPEAKER_01
 So maybe we have to do this endpoint detection and probably a little bit of linear filtering.

0:50:32	SPEAKER_01
 And then I think it should be pretty much converging to the system.

0:50:36	SPEAKER_01
 But the reason with that, like what are systems we train on databases are they are chopped neatly.

0:50:42	SPEAKER_01
 That there is not too much talent beginning, no too much further than...

0:50:47	SPEAKER_01
 That's not so neatly further.

0:50:50	SPEAKER_01
 It's like custom made database.

0:50:54	SPEAKER_01
 But here it's not like that.

0:50:56	SPEAKER_01
 I see.

0:50:57	SPEAKER_03
 There's also just things like receiver, noise at the beginning and or at the end of...

0:51:04	SPEAKER_03
 And I mean these are things you can get rid of.

0:51:06	SPEAKER_01
 There are several things.

0:51:08	SPEAKER_01
 One thing is we can do this beginning and end detection.

0:51:11	SPEAKER_01
 As we said, or even we can try to use Franz Sellecom's approach actually.

0:51:19	SPEAKER_01
 And they have this front end which can do a spectral subtraction.

0:51:27	SPEAKER_01
 And plus it can give you a voice activity detection.

0:51:30	SPEAKER_01
 Okay, this is...

0:51:32	SPEAKER_01
 Part-frame basis.

0:51:34	SPEAKER_01
 It can give.

0:51:35	SPEAKER_01
 Okay.

0:51:36	SPEAKER_01
 So we can just run it quickly and see and probably you will have to run it.

0:51:41	SPEAKER_01
 It will give you the idea that is it okay, like...

0:51:44	SPEAKER_01
 Well, I don't mind running it.

0:51:45	SPEAKER_01
 I've got all the scripts.

0:51:46	SPEAKER_01
 No, no, no, not running.

0:51:47	SPEAKER_01
 I mean to say probably he should run it or like we can help him to run it actually.

0:51:53	SPEAKER_01
 Because at some point he has to get into...

0:51:56	SPEAKER_01
 I mean just...

0:51:57	SPEAKER_01
 I'm not sure I said the poor hate actually.

0:51:59	SPEAKER_01
 I mean to say that it's okay.

0:52:01	SPEAKER_01
 We have all the scripts but probably he should run it.

0:52:04	SPEAKER_01
 I mean to say...

0:52:05	SPEAKER_03
 I don't know.

0:52:06	SPEAKER_03
 Yeah.

0:52:07	SPEAKER_03
 Whatever I don't know.

0:52:08	SPEAKER_01
 I think...

0:52:09	SPEAKER_01
 I don't know what exactly.

0:52:11	SPEAKER_01
 All these experiments...

0:52:12	SPEAKER_01
 I don't know whether that's...

0:52:13	SPEAKER_00
 For the co-roaching itself or the recognition.

0:52:16	SPEAKER_01
 Because probably maybe we shall do...

0:52:21	SPEAKER_01
 To make it faster we should run...

0:52:23	SPEAKER_01
 If we run it, we have a server.

0:52:25	SPEAKER_01
 It's very fast.

0:52:26	SPEAKER_01
 We might as well.

0:52:27	SPEAKER_03
 Because I mean up until now you haven't been running any recognition.

0:52:31	SPEAKER_03
 And neither did John Eve on that data.

0:52:33	SPEAKER_00
 Yeah.

0:52:34	SPEAKER_00
 People join the scripts and the programs for performing the co-roaching.

0:52:41	SPEAKER_00
 I think starting from the new sequences.

0:52:45	SPEAKER_01
 But I mean to say that if we give him the scripts and ask him to run...

0:52:51	SPEAKER_03
 Oh sure.

0:52:52	SPEAKER_03
 I mean the scripts are so automated.

0:52:53	SPEAKER_03
 It's just a matter of submitting a job to the classroom.

0:52:56	SPEAKER_03
 No.

0:52:57	SPEAKER_00
 But it's...

0:52:58	SPEAKER_00
 Yeah.

0:52:59	SPEAKER_00
 I don't know how to do this last time.

0:53:00	SPEAKER_03
 I don't think the point of that.

0:53:01	SPEAKER_03
 I don't mind running it.

0:53:02	SPEAKER_03
 It would be like half an hour's work in a day to run the recognition scripts.

0:53:07	SPEAKER_03
 I mean I...

0:53:08	SPEAKER_03
 I know what you're saying.

0:53:11	SPEAKER_03
 Our team should familiarise himself with the ASR systems or whatever.

0:53:15	SPEAKER_03
 Fine.

0:53:16	SPEAKER_03
 But I don't...

0:53:17	SPEAKER_03
 I don't think this is a point that's worth sort of worrying about at this stage anyway.

0:53:23	SPEAKER_03
 I mean...

0:53:24	SPEAKER_00
 Yeah if he's just running a script.

0:53:25	SPEAKER_03
 Because I'm sort of assuming that we're going to have an endpoint detection system regardless of this...

0:53:31	SPEAKER_03
 Yeah.

0:53:32	SPEAKER_01
 Working on this nuance.

0:53:33	SPEAKER_01
 No.

0:53:34	SPEAKER_01
 So...

0:53:35	SPEAKER_01
 The endpoint system is different thing now.

0:53:36	SPEAKER_01
 That's...

0:53:37	SPEAKER_01
 We need it for Ami.

0:53:38	SPEAKER_01
 We need it for Ami.

0:53:39	SPEAKER_01
 We need it for...

0:53:40	SPEAKER_01
 I am the last thing.

0:53:41	SPEAKER_01
 I am the last thing.

0:53:42	SPEAKER_00
 Yeah.

0:53:43	SPEAKER_00
 I am the last thing.

0:53:44	SPEAKER_00
 But this is basically detecting speech and non-speech.

0:53:47	SPEAKER_00
 It's a lot more difficult than you would think.

0:53:49	SPEAKER_00
 No, no, no.

0:53:50	SPEAKER_00
 It's not a big no.

0:53:51	SPEAKER_00
 It's this problem here every time on the speech meeting.

0:53:53	SPEAKER_00
 How do we detect speech and...

0:53:55	SPEAKER_03
 Well it's speech and any other class of sound.

0:53:58	SPEAKER_03
 That's the problem.

0:53:59	SPEAKER_01
 Yeah.

0:54:00	SPEAKER_01
 Anything nonsense.

0:54:01	SPEAKER_01
 It's not just speech and silence.

0:54:04	SPEAKER_00
 It's speech and any other class.

0:54:06	SPEAKER_00
 It's not that.

0:54:07	SPEAKER_03
 It's just silence that would be easy.

0:54:12	SPEAKER_03
 And in controlled cases you can't just assume it's any energy below a certain threshold.

0:54:17	SPEAKER_03
 And this is what everybody sort of claimed the problem was solved with years ago.

0:54:21	SPEAKER_00
 But who really can do when somebody will really be able to do that, I mean detect...

0:54:27	SPEAKER_00
 Well I mean this is once again...

0:54:29	SPEAKER_00
 Yes from non-speech it will be a little revolutionary.

0:54:31	SPEAKER_03
 Yeah, sure.

0:54:32	SPEAKER_03
 But I mean this is once again a very constrained task again.

0:54:35	SPEAKER_03
 I mean it's... you're almost assured it's only going to be a single speaker on the microphone.

0:54:41	SPEAKER_03
 So I mean the only sort of noise you're going to have to deal with is...

0:54:46	SPEAKER_03
 It can be everything.

0:54:47	SPEAKER_03
 It can be something.

0:54:48	SPEAKER_03
 It's so impulsive I'm going to say.

0:54:49	SPEAKER_01
 Or that would be a good start.

0:54:51	SPEAKER_01
 Yeah.

0:54:52	SPEAKER_01
 Anyway, so we...

0:54:53	SPEAKER_01
 Okay, so we'll finish this quality stuff.

0:54:55	SPEAKER_01
 What do you say?

0:54:56	SPEAKER_01
 This is okay with you, right?

0:54:58	SPEAKER_01
 Because I think it has not been even submitted outside also.

0:55:03	SPEAKER_01
 What journey did you have?

0:55:05	SPEAKER_01
 No, no.

0:55:06	SPEAKER_01
 Basically, no done that.

0:55:07	SPEAKER_02
 Because it was not that...

0:55:09	SPEAKER_02
 At the level it could be.

0:55:11	SPEAKER_02
 Anyway, it was good I think with the better...

0:55:14	SPEAKER_02
 For me we're going to show right, definitely it could improve also the performance.

0:55:21	SPEAKER_03
 It was showing that.

0:55:23	SPEAKER_03
 You haven't heard from him I take it either.

0:55:25	SPEAKER_02
 No.

0:55:26	SPEAKER_02
 No, okay.

0:55:27	SPEAKER_03
 Well it would be nice to get the thesis I think.

0:55:30	SPEAKER_03
 There's a sort of just a research report sort of basis.

0:55:32	SPEAKER_02
 Yeah, yeah.

0:55:33	SPEAKER_02
 Yeah.

0:55:34	SPEAKER_02
 But we can some way find a guy and he should be at multi-tails so it should be relatively easy to...

0:55:41	SPEAKER_02
 At least there's this last news I had and then we can try to check him back.

0:55:47	SPEAKER_02
 I think it's less pressure.

0:55:50	SPEAKER_01
 So yeah, it's pretty much good time also.

0:55:52	SPEAKER_01
 And when do you intend to start writing the proposal?

0:55:59	SPEAKER_00
 Yeah, well this is basically a three-year main jobs proposal.

0:56:04	SPEAKER_01
 No, you should not wait till the end.

0:56:08	SPEAKER_01
 That's what I mean.

0:56:09	SPEAKER_03
 I should be looking towards the start of next year.

0:56:12	SPEAKER_03
 I assure you.

0:56:16	SPEAKER_00
 You should make it clear before on what I will write.

0:56:24	SPEAKER_00
 And even a first submission using this work will make things clearer for me writing them down.

0:56:34	SPEAKER_00
 Okay.

0:56:35	SPEAKER_02
 That will go very pragmatic.

0:56:37	SPEAKER_02
 There is a submission deadline for example 31 December for confidence on multimedia and

0:56:44	SPEAKER_01
 Expo where I think this tool works on... Yeah, it can go there.

0:56:50	SPEAKER_03
 And it's nice to get some feedback on...

0:56:52	SPEAKER_03
 I mean that feedback will probably come after your proposal.

0:56:55	SPEAKER_01
 I think it's good.

0:56:57	SPEAKER_01
 If it's a research report, you put it here, you can submit it for the conference.

0:57:02	SPEAKER_01
 It's quite good for the proposal itself.

0:57:05	SPEAKER_01
 Yeah, yeah, yeah.

0:57:06	SPEAKER_01
 Exactly.

0:57:07	SPEAKER_02
 Because as far as I understand this work on the Fonim anyway still takes some development time and the sense that...

0:57:13	SPEAKER_01
 I think we may have to...

0:57:15	SPEAKER_01
 It's kind of like... maybe take like two or three days to sit it out and say one...

0:57:23	SPEAKER_01
 Run was to one approach and then just do it as...

0:57:25	SPEAKER_01
 Yeah, so that any bugs or whatever.

0:57:27	SPEAKER_01
 Yeah, and probably that is the thing.

0:57:29	SPEAKER_01
 We have to sort of the bug kind of thing and see how reliable is this endpoint detection for us.

0:57:34	SPEAKER_03
 I'd prefer to go back to the CTS models I think as well.

0:57:37	SPEAKER_01
 Yeah, I think then we can go back to CTS.

0:57:39	SPEAKER_03
 I think they did work a little bit better.

0:57:42	SPEAKER_02
 Anyway, we use the trial results.

0:57:45	SPEAKER_02
 You have just to decide what you have to work first and finalize.

0:57:53	SPEAKER_02
 I think you can really...

0:57:54	SPEAKER_00
 Yeah, well I think first this submitted and this will help for a proposal and since we cannot start immediately with the measures, I think that's the best thing to do.

0:58:07	SPEAKER_01
 Okay.

0:58:08	SPEAKER_01
 So you wanted to talk something more than that.

0:58:12	SPEAKER_01
 Well, we have talked to you with that.

0:58:14	SPEAKER_01
 You wanted to talk something different also.

0:58:17	SPEAKER_00
 Well, no.

0:58:18	SPEAKER_00
 No.

0:58:19	SPEAKER_00
 For me it's a pretty...

0:58:20	SPEAKER_00
 Oh, maybe another meeting.

0:58:21	SPEAKER_00
 And it's another one I said.

0:58:22	SPEAKER_00
 And then I say another one.

0:58:23	SPEAKER_01
 No, so you're looking at the watch before?

0:58:24	SPEAKER_01
 No, I was just looking at this.

0:58:25	SPEAKER_01
 Okay, we are not out of time, you know.

0:58:26	SPEAKER_01
 I think we thought this like the night time.

0:58:27	SPEAKER_01
 Yeah, and I think that will be exactly one hour and...

0:58:28	SPEAKER_01
 So, you're looking at the watch before.

0:58:29	SPEAKER_01
 No, I was just looking at this.

0:58:30	SPEAKER_01
 Okay, we are not out of time.

0:58:31	SPEAKER_01
 You know.

0:58:32	SPEAKER_03
 The design we thought was like the night time.

0:58:33	SPEAKER_00
 Yeah, and I think that will be exactly one hour and...

0:58:34	SPEAKER_00
 So the tape is...

0:58:39	SPEAKER_00
 The tape is...

0:58:40	SPEAKER_00
 The tape is 60 minutes.

0:58:41	SPEAKER_01
 Yes, it happened with my friend.

0:58:43	SPEAKER_01
 Like he was taking pictures, pictures, pictures and it was going 37, 38, 40 even.

0:58:49	SPEAKER_01
 At the real level got over.

0:58:51	SPEAKER_01
 So I said, there's some problem with you.

0:58:54	SPEAKER_01
 The way you put the role inside.

0:58:57	SPEAKER_01
 There is some problem with it.

0:58:59	SPEAKER_01
 It has got struck somewhere.

0:59:00	SPEAKER_01
 It can never go to 40 or 40.

0:59:03	SPEAKER_01
 Not normally.

0:59:04	SPEAKER_01
 Yeah.

0:59:05	SPEAKER_03
 You got a 37, 38.

0:59:07	SPEAKER_01
 38 is 5, you know, 40, 41.

0:59:09	SPEAKER_01
 That's it.

0:59:10	SPEAKER_01
 He has already told us.

0:59:11	SPEAKER_01
 Yeah, okay.

0:59:12	SPEAKER_01
 Okay.

0:59:13	SPEAKER_01
 Fine.

0:59:14	SPEAKER_01
 So we are thinking pictures and pictures and I'm sure they are going to get maybe 5 pictures

0:59:21	None
 out of this. If you get 5, you feel lucky.

0:59:25	None
 Yeah.

0:59:26	None
 So, next week...

0:59:27	None
 So, we are going to get a picture.

0:59:30	None
 So, next week...

0:59:33	None
 So, we have to be...

0:59:35	None
 We have to be a photographer.

0:59:37	None
 We have to be a photographer.

0:59:38	None
 We have to be a photographer.

0:59:39	None
 We have to be a photographer.

0:59:40	None
 That's getting that much respect now.

0:59:42	None
 No, it's not.

0:59:43	None
 So, what's that good?

0:59:44	None
 I'm not?

0:59:45	None
 To do it.

0:59:46	None
 Oh, it's a business.

0:59:48	SPEAKER_00
 I think that's fine.

0:59:50	SPEAKER_00
 I think that's fine.

0:59:51	SPEAKER_03
 I mean, the point of the position is just to provide information to people.

0:59:56	None
 I'm going to be interested in the discussion.

1:00:01	None
 I think we have to be a photographer.

