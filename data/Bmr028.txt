0:00:00	SPEAKER_03
 And we're going.

0:00:05	SPEAKER_03
 So the only status item, well, first of all, we haven't decided whether we're meeting recorded data issues or recognition this week.

0:00:14	SPEAKER_03
 I think we were recognition.

0:00:17	SPEAKER_05
 What was on the list?

0:00:18	SPEAKER_05
 I mean, I sent you a couple things.

0:00:20	SPEAKER_03
 You only sent me one thing, which was demo status.

0:00:24	SPEAKER_03
 And asking which one we were on this week.

0:00:27	SPEAKER_03
 That was the second thing, right?

0:00:31	SPEAKER_03
 So should we simply assert that this week we are recognition and next week data issues?

0:00:35	SPEAKER_03
 I think that's correct.

0:00:36	SPEAKER_01
 I think so too.

0:00:37	SPEAKER_03
 And so I think what we should probably do is any quick, small stuff we can do every week.

0:00:43	SPEAKER_03
 So like Morgan asked about the demo status, we can go ahead and talk about that a little bit, and then alternate in more depth.

0:00:53	SPEAKER_05
 By the way, I won't be here next Thursday.

0:00:55	SPEAKER_05
 I'll be out of town.

0:00:57	SPEAKER_03
 But actually, I may not be here either.

0:01:01	SPEAKER_03
 So I've got to double check the dates.

0:01:03	SPEAKER_03
 But anyway, so demo status, first of all, I did a little thing for Liz with the transcriber tool that, first of all, it uses the forced alignments so that the words appear in their own segments, rather than in long chunks.

0:01:22	SPEAKER_03
 She said that that.

0:01:23	SPEAKER_03
 She thought that was a much better idea for the other stuff she's working on.

0:01:29	SPEAKER_03
 And that works fine, except it's even slower to load.

0:01:31	SPEAKER_03
 It's already pretty slow.

0:01:33	SPEAKER_09
 Is that because the transcripts go longer?

0:01:35	SPEAKER_03
 Yeah.

0:01:36	SPEAKER_03
 Yeah.

0:01:37	SPEAKER_03
 And the transcriber tool is just not very good at.

0:01:42	SPEAKER_09
 But that's, you didn't have to change the software for that, yet, right?

0:01:46	SPEAKER_09
 It's just formatting, they're writing kind of.

0:01:48	SPEAKER_03
 Yeah, it's just writing conversion tools from the format that the aligner actually did a SRT file for it.

0:01:57	SPEAKER_03
 And then just back into transcriber format.

0:02:00	SPEAKER_03
 Yeah, so my decision was for the first pass for this demo that Liz was talking about.

0:02:05	SPEAKER_03
 I decided that I would do only enough to get it working as opposed to any coding.

0:02:12	SPEAKER_03
 And so the other thing, she wanted to display the stylized F0s, I think they're cold.

0:02:17	SPEAKER_03
 Is that right?

0:02:17	SPEAKER_03
 Yeah, the linear fit.

0:02:19	SPEAKER_03
 So what I did is I just took the file with those and it converted it so that it looks like an audio file.

0:02:24	SPEAKER_03
 And so it shows that instead of the way file.

0:02:27	SPEAKER_03
 And so that's working.

0:02:28	SPEAKER_03
 And I think it actually looks pretty good.

0:02:30	SPEAKER_03
 I'd like someone who's more familiar with it to look at it, because when I was looking at it, we seem to have lots of stuff going on when no one's saying anything.

0:02:38	SPEAKER_06
 That's just background speech.

0:02:41	SPEAKER_04
 Yeah.

0:02:42	SPEAKER_04
 So you have to pad that out so that it looks like it's an eight-killer-heard sample thing.

0:02:48	SPEAKER_03
 You know, the audio file, you can specify any sampling rate.

0:02:52	SPEAKER_03
 And so I specified, instead of 16,000 or 8,000, I specified 100.

0:02:58	SPEAKER_03
 And the only problem with that is that there's a bug in transcriber that if the sample rate is too low, when it tries to compute the shape file, it fails and crashes.

0:03:10	SPEAKER_03
 But the solution to that is just set the option so it doesn't compute the shape file.

0:03:14	SPEAKER_03
 And it will work.

0:03:15	SPEAKER_03
 And the only problem with that is you can't zoom out on it.

0:03:19	SPEAKER_03
 You can zoom in, but not out.

0:03:20	SPEAKER_05
 That's a shape file.

0:03:22	SPEAKER_03
 The shape file is, if you think about a wave file, 16,000 samples per second is way too many to display on the screen.

0:03:29	SPEAKER_03
 So a transcriber does is it computes another thing to display based on the wave form.

0:03:34	SPEAKER_03
 And it displays it up.

0:03:36	SPEAKER_03
 And it allows you to show many different resolutions.

0:03:38	SPEAKER_03
 So there's a little user interface component that lets you select the resolution.

0:03:43	SPEAKER_03
 And if you don't compute the wave file, you can't zoom out.

0:03:48	SPEAKER_03
 You can't get a larger view of it, but you can zoom in.

0:03:53	SPEAKER_03
 And that's all right, because I had 100 samples.

0:03:55	SPEAKER_03
 That's already pretty far out.

0:03:58	SPEAKER_03
 And so I think it looks pretty good that all that lives.

0:04:01	SPEAKER_03
 Look at it and see what you get.

0:04:02	SPEAKER_02
 Sorry.

0:04:03	SPEAKER_02
 I got the wave file, but I couldn't get the words yet.

0:04:05	SPEAKER_02
 But the wave file part looks good.

0:04:08	SPEAKER_03
 OK.

0:04:10	SPEAKER_03
 We should, if you are having problems with the words, you should take your out why.

0:04:15	SPEAKER_02
 I'll have done.

0:04:16	SPEAKER_02
 I'm probably doing something wrong.

0:04:18	SPEAKER_02
 Sorry, the microphones moving around.

0:04:25	SPEAKER_03
 You put that part over your ear.

0:04:27	SPEAKER_02
 I can do that, but there's no orientation where there is.

0:04:36	SPEAKER_03
 I'll watch this with the mic.

0:04:38	SPEAKER_01
 Is it really easy to go in here here?

0:04:40	SPEAKER_01
 That bud doesn't have to go in here, right?

0:04:42	SPEAKER_03
 No, it doesn't have to, but I find that's the only way to wear it.

0:04:46	SPEAKER_03
 That the bud's in the ear and that the link is over it.

0:04:51	SPEAKER_03
 So anyway, I think that looks pretty good.

0:04:53	SPEAKER_03
 The only other thing we might want to do with that is be able to display more than one waveform.

0:04:58	SPEAKER_03
 And that actually shouldn't be too slow, because it's much lower resolution than a full waveform.

0:05:03	SPEAKER_03
 The problem with it is just it does require coding.

0:05:06	SPEAKER_03
 And so it would be much better to get Dave Galvard to do that than me, because he's familiar with the code, and is more likely to be able to get it to work quickly.

0:05:13	SPEAKER_06
 I mean, I think we can do like a quick hack just so we can play the audio file too.

0:05:17	SPEAKER_06
 Right.

0:05:18	SPEAKER_06
 With the display, like even if we, I think that even if we didn't display the waveform, it might be better to rather play the waveform than display.

0:05:27	SPEAKER_06
 I mean, like we were to choose, I don't know if I were to choose between one or the other.

0:05:30	SPEAKER_06
 I'd rather have it played than display.

0:05:33	SPEAKER_03
 Right.

0:05:35	SPEAKER_03
 But for the demo, maybe it doesn't matter.

0:05:37	SPEAKER_03
 I'm not sure whether you want to do the demo live anyway, or just screenshots of what we have.

0:05:41	SPEAKER_03
 The problem with doing it live is it takes so long to load that.

0:05:46	SPEAKER_09
 So this slide is not loading.

0:05:50	SPEAKER_09
 Is all due to the parsing of the XML?

0:05:54	SPEAKER_03
 I was talking to Dave Galvard about that.

0:05:55	SPEAKER_03
 And apparently, it's not actually the parsing of the XML raw that going from the XML to an internal tree structure is pretty fast.

0:06:03	SPEAKER_03
 But then it walks the tree to assemble its date internal data structures, and that's slow.

0:06:08	SPEAKER_04
 It seems like you should be able to spawn that off into a background process, because not everything is displayed in that tree at once.

0:06:15	SPEAKER_03
 No, but what it does is it actually assembles all the user interface components then, and then displays all the user interface.

0:06:22	SPEAKER_05
 I'm confused.

0:06:24	SPEAKER_05
 Is this downloading something that happens once?

0:06:27	SPEAKER_05
 Yes.

0:06:28	SPEAKER_05
 And then when you display different things, it's fine.

0:06:32	SPEAKER_05
 So in that case, a new transcript.

0:06:35	SPEAKER_05
 Well, no meeting, transcript, right?

0:06:37	SPEAKER_05
 But for audio files.

0:06:38	SPEAKER_03
 Well, actually, audio files are pretty fast, too.

0:06:40	SPEAKER_05
 For presentation.

0:06:43	SPEAKER_05
 You just have to have something running.

0:06:46	SPEAKER_03
 Right.

0:06:46	SPEAKER_03
 The only problem with that is if anything goes wrong, or if you want to switch from one thing to another.

0:06:50	SPEAKER_03
 Go wrong?

0:06:52	SPEAKER_02
 I think, yeah.

0:06:54	SPEAKER_02
 I guess for the demo, you can always play, just store the pieces that you're going to display and play those as separate files if we can't actually do it.

0:07:02	SPEAKER_02
 They do older files.

0:07:03	SPEAKER_02
 That's true.

0:07:03	SPEAKER_02
 We can just subset it.

0:07:04	SPEAKER_02
 Yeah.

0:07:05	SPEAKER_03
 That's a good idea.

0:07:05	SPEAKER_03
 That's actually probably the right thing to do.

0:07:07	SPEAKER_03
 Yeah, just take 10 minutes.

0:07:09	SPEAKER_05
 That's what I did for my truck.

0:07:11	SPEAKER_05
 Oh, you're downloading a whole meeting.

0:07:13	SPEAKER_05
 Yeah.

0:07:13	SPEAKER_05
 Oh, yeah.

0:07:15	SPEAKER_03
 Yeah, so that's actually the definitely the way to do it.

0:07:17	SPEAKER_03
 That's a good idea.

0:07:20	SPEAKER_05
 And then still do it ahead of time.

0:07:21	SPEAKER_05
 But then at least you're covered if there are any problems.

0:07:25	SPEAKER_03
 There's problem.

0:07:26	SPEAKER_03
 Yeah, I mean, even five minutes is probably enough.

0:07:29	SPEAKER_02
 Right.

0:07:30	SPEAKER_02
 So what happened?

0:07:31	SPEAKER_02
 Is it possible at all to display the words in their aligned location?

0:07:35	SPEAKER_02
 That's what I did.

0:07:36	SPEAKER_02
 OK.

0:07:36	SPEAKER_02
 So I'm sorry.

0:07:37	SPEAKER_02
 I missed.

0:07:38	SPEAKER_02
 OK.

0:07:38	SPEAKER_02
 Great.

0:07:39	SPEAKER_02
 But OK.

0:07:40	SPEAKER_02
 I couldn't get the words and the way from it at the same time for some reason.

0:07:43	SPEAKER_02
 And there must be some work on it with Don and see what I'm doing wrong.

0:07:48	SPEAKER_03
 Yeah, just ask.

0:07:49	SPEAKER_03
 Just come by my office.

0:07:49	SPEAKER_03
 I can show you as well.

0:07:50	SPEAKER_02
 Great.

0:07:51	SPEAKER_02
 Oh, thanks a lot.

0:07:52	SPEAKER_03
 It's really great.

0:07:53	SPEAKER_03
 And for the information retrieval, Don has been working on that.

0:07:57	SPEAKER_06
 So yeah, so it's coming along.

0:08:00	SPEAKER_06
 Just hacking, dance code, stepping through it.

0:08:03	SPEAKER_06
 But I think it's close.

0:08:07	SPEAKER_06
 Should be there pretty soon.

0:08:08	SPEAKER_06
 But at least with being able to search over a certain amount of meetings, just like really basic stuff, just asking for a word and looking through a bunch of different meetings.

0:08:21	SPEAKER_06
 And if we have time, we'll also add choosing which speakers you want to include and stuff.

0:08:26	SPEAKER_06
 But OK.

0:08:27	SPEAKER_05
 I'm going to start working on this week after.

0:08:29	SPEAKER_05
 So that's the point I'll need to look more carefully at what you guys have.

0:08:33	SPEAKER_06
 So is the end of the month still?

0:08:36	SPEAKER_05
 Right.

0:08:37	SPEAKER_05
 The Monday that we get to next is July 2nd, which is the first day I get back.

0:08:41	SPEAKER_00
 OK.

0:08:43	SPEAKER_03
 Yeah, so I think for the stuff Liz was talking about, we have something that'll work now.

0:08:47	SPEAKER_03
 And Liz can look at it and see if she wants anything else.

0:08:51	SPEAKER_03
 Maybe we can work on doing displaying multiple.

0:08:53	SPEAKER_03
 We're displaying one and playing back the other.

0:08:55	SPEAKER_02
 So do you think it's reasonable to display more than one before the demo?

0:09:00	SPEAKER_03
 I think I'd have to ask Dave.

0:09:02	SPEAKER_03
 I did it once before, and it was just so slow to scroll that I gave up.

0:09:07	SPEAKER_03
 But the advantages that these things are much lower sampling rate, so it might be all right.

0:09:12	SPEAKER_02
 OK.

0:09:13	SPEAKER_02
 Let me know.

0:09:14	SPEAKER_06
 Morgan, when's the demo?

0:09:16	SPEAKER_05
 Well, I'm giving a talk on July 16th, so Monday in four weeks.

0:09:27	SPEAKER_09
 So it was three weeks.

0:09:29	SPEAKER_09
 If Ross beat us the problem, this thing is written in tickle.

0:09:34	SPEAKER_09
 I mean, John AustroHouth started his own company based on tickle stuff, and maybe they have a native code compiled error or something.

0:09:43	SPEAKER_03
 I mean, we could check.

0:09:43	SPEAKER_03
 I don't think they do.

0:09:46	SPEAKER_03
 There was actually a Java backend that apparently is actually a little faster, a generate byte code.

0:09:52	SPEAKER_03
 But.

0:09:54	SPEAKER_05
 I was excited to hear that Java's faster than something.

0:09:57	SPEAKER_05
 Yeah.

0:09:58	SPEAKER_03
 Well, everything is faster than tickle TK.

0:10:00	SPEAKER_03
 It's a string substitution language, basically.

0:10:03	SPEAKER_03
 I should probably beat that out.

0:10:04	SPEAKER_03
 And John AustroHouth ever listens.

0:10:06	SPEAKER_01
 But tickle is wonderful.

0:10:08	SPEAKER_01
 It is wonderful.

0:10:09	SPEAKER_03
 It is for prototyping and user interface.

0:10:11	SPEAKER_03
 It's just really the language is awful.

0:10:13	SPEAKER_00
 Oh.

0:10:14	SPEAKER_00
 Beep.

0:10:15	SPEAKER_00
 Beep.

0:10:19	SPEAKER_03
 But let me tell you how I really feel.

0:10:22	SPEAKER_05
 I'll entitle to our opinion, too.

0:10:24	SPEAKER_01
 Yeah.

0:10:24	SPEAKER_05
 I like it.

0:10:25	SPEAKER_05
 Yeah.

0:10:28	SPEAKER_05
 Because the meeting is July 16, 18.

0:10:33	SPEAKER_05
 And I talk to the first day.

0:10:35	SPEAKER_05
 So I'm flying out there this Sunday before.

0:10:38	SPEAKER_05
 So I guess it would be desirable if a week ahead of that.

0:10:48	SPEAKER_05
 We basically thought we had it, which would allow a week.

0:10:53	SPEAKER_06
 For realizing we don't.

0:10:55	SPEAKER_03
 Yeah.

0:10:56	SPEAKER_03
 Then the other issue related to that is data release.

0:11:00	SPEAKER_03
 If we want to show this in public, it should be released.

0:11:03	SPEAKER_03
 So I haven't gotten any other replies from the original email asking for approval.

0:11:08	SPEAKER_03
 So I sent out another set this morning.

0:11:10	SPEAKER_03
 I saw that.

0:11:11	SPEAKER_03
 And now we'll see if we get any responses.

0:11:13	SPEAKER_02
 But it is.

0:11:14	SPEAKER_02
 I did want to say that.

0:11:16	SPEAKER_03
 Did you notice I put it in the filter?

0:11:19	SPEAKER_02
 No.

0:11:20	SPEAKER_02
 No.

0:11:21	SPEAKER_02
 No.

0:11:22	SPEAKER_02
 I just figured you.

0:11:23	SPEAKER_03
 There's a link there that now says, if you want to search by filter by regular expression, you can.

0:11:30	SPEAKER_02
 Perfect.

0:11:31	SPEAKER_02
 I didn't just for you.

0:11:32	SPEAKER_02
 Well, since you didn't answer the question, I had asked Adam whether it's possible to search only for your own name, your own utterances, so that you don't have to go through the whole meeting.

0:11:41	SPEAKER_02
 And I didn't hear back.

0:11:42	SPEAKER_02
 I thought, OK, it's probably too hard.

0:11:44	SPEAKER_02
 He's overloaded.

0:11:44	SPEAKER_02
 I won't say anything.

0:11:45	SPEAKER_02
 I'll just do it.

0:11:47	SPEAKER_02
 Great.

0:11:48	SPEAKER_02
 OK.

0:11:48	SPEAKER_03
 So anyway, it's actually an arbitrary regular expression.

0:11:52	SPEAKER_03
 If you search your name, you'll get all the things you said and any time anyone said your name.

0:11:57	SPEAKER_05
 That's great.

0:11:58	SPEAKER_05
 It's case in sensitive.

0:11:59	SPEAKER_05
 Correct.

0:11:59	SPEAKER_05
 Yeah.

0:12:00	SPEAKER_05
 That's great.

0:12:02	SPEAKER_04
 Did you actually look through your transcripts, or you just approved them all?

0:12:05	SPEAKER_04
 Well.

0:12:06	SPEAKER_04
 I just approved them.

0:12:07	SPEAKER_04
 I didn't look at it.

0:12:08	SPEAKER_02
 I started a spot check.

0:12:09	SPEAKER_02
 I was trying to remember.

0:12:11	SPEAKER_02
 I couldn't find the keywords for things that I thought I had said wrong.

0:12:16	SPEAKER_03
 It's hard to find.

0:12:18	SPEAKER_04
 That's a compliment to you.

0:12:20	SPEAKER_04
 He said, it's hard to find things you say wrong.

0:12:22	SPEAKER_02
 It's hard to find anything that you say.

0:12:25	SPEAKER_00
 Great.

0:12:26	SPEAKER_02
 Well, thank you for the filter.

0:12:27	SPEAKER_02
 It's really useful, because if you're only at part of a meeting or something.

0:12:31	SPEAKER_05
 So we have our first information retrieval example.

0:12:33	SPEAKER_05
 It's a great expression.

0:12:36	SPEAKER_02
 Yeah, that's actually, well, it's useful.

0:12:38	SPEAKER_03
 And it demonstrates why it doesn't work, because you really want to go more than one meeting.

0:12:42	SPEAKER_03
 And you need a better user interface for displaying the results.

0:12:45	SPEAKER_02
 But this helps a lot.

0:12:47	SPEAKER_05
 You want to say, we're, we're, we're, we'll find all the contentious things I said.

0:12:52	SPEAKER_04
 Find everything that should be bleeped.

0:12:54	SPEAKER_03
 That's right.

0:12:55	SPEAKER_03
 We do have that.

0:12:56	SPEAKER_03
 It nice marker is that, because we all know we're being recorded whenever anyone says anything like that, we then have a conversation about bleeping it out.

0:13:03	SPEAKER_02
 Yeah, you can search for beep or bleep.

0:13:04	SPEAKER_02
 Yeah.

0:13:05	SPEAKER_02
 Yeah.

0:13:06	SPEAKER_02
 And somebody else's turn.

0:13:12	SPEAKER_03
 Oh, and also we actually have a few people who have still not filled out speaker forms, specifically in the NSA ones.

0:13:18	SPEAKER_03
 And I noticed that when I tried to generate the transcripts for NSA, that there are a few with no speaker forms.

0:13:27	SPEAKER_03
 And so I have, I said out yet another this morning, which I think makes six totally males that I've sent to these people.

0:13:34	SPEAKER_03
 And so I think we need to escalate to some other method of trying to contact them.

0:13:44	SPEAKER_05
 Right.

0:13:44	SPEAKER_05
 It's a talk.

0:13:46	SPEAKER_05
 Has, has, has, has your social reply?

0:13:48	SPEAKER_05
 No.

0:13:49	SPEAKER_01
 It will work.

0:13:49	SPEAKER_01
 Maybe talk to him first in person.

0:13:51	SPEAKER_01
 That's what I would think.

0:13:52	SPEAKER_05
 He's not around to see any problems.

0:13:54	SPEAKER_01
 Always, right?

0:13:56	SPEAKER_05
 I saw him on Tuesday.

0:13:58	SPEAKER_05
 Yeah, he popped in.

0:13:59	SPEAKER_05
 He's basically like John.

0:14:00	SPEAKER_09
 A thinner time, I mean.

0:14:02	SPEAKER_03
 Well, if I could find phone numbers, that would certainly work.

0:14:04	SPEAKER_01
 What did you ask, why not?

0:14:06	SPEAKER_01
 Because I bet she has this information.

0:14:07	SPEAKER_03
 Yeah, that's a good idea.

0:14:08	SPEAKER_03
 Well, that's curfew.

0:14:08	SPEAKER_03
 She can catch up some of them down.

0:14:09	SPEAKER_05
 And tell her, tell your specific problem.

0:14:13	SPEAKER_01
 She picks.

0:14:14	SPEAKER_01
 And then there's still, Miguel is still an active member with a group.

0:14:18	SPEAKER_01
 And he's, what I mean is he's an active member.

0:14:19	SPEAKER_01
 And he's still here.

0:14:20	SPEAKER_03
 He's right there, yeah.

0:14:21	SPEAKER_03
 Very helpful.

0:14:22	SPEAKER_03
 Yeah, I didn't actually see who they all were.

0:14:25	SPEAKER_03
 A couple of them were like people at IBM who were here for one of the IBM meetings.

0:14:29	SPEAKER_03
 And a guy from SRI, who was at one of the SRI meetings.

0:14:32	SPEAKER_03
 And so those might be harder to track down.

0:14:35	SPEAKER_01
 Most of them though, really, we're visitors here.

0:14:37	SPEAKER_01
 And Lila should have all kinds of nice meetings, by the way.

0:14:39	SPEAKER_01
 Yeah.

0:14:41	SPEAKER_03
 They were people who didn't have accounts at XC.

0:14:43	SPEAKER_03
 So they're, they're harder to find.

0:14:44	SPEAKER_01
 Well, not the ones that, are you?

0:14:47	SPEAKER_01
 Are you sure?

0:14:48	SPEAKER_01
 I'm not sure about what.

0:14:49	SPEAKER_01
 Yeah, NSA 1 and NSA 3.

0:14:50	SPEAKER_01
 There were other people also.

0:14:51	SPEAKER_03
 There were other people also who didn't have to fill out speaker for us in addition to that.

0:14:55	SPEAKER_05
 In other meetings.

0:14:56	SPEAKER_01
 Yeah.

0:14:57	SPEAKER_05
 Oh, I see.

0:14:58	SPEAKER_05
 Well, SRI people is either blind.

0:15:00	SPEAKER_05
 And IBM people also just let us know.

0:15:04	SPEAKER_05
 Certainly have an email.

0:15:06	SPEAKER_01
 But I knew everybody in the NSA meetings.

0:15:08	SPEAKER_01
 So I'm sure that we have a fresh information on them.

0:15:13	SPEAKER_03
 Yeah, none of the emails bounced.

0:15:15	SPEAKER_03
 So I know they're going somewhere.

0:15:16	SPEAKER_00
 Good.

0:15:17	SPEAKER_03
 OK.

0:15:18	SPEAKER_03
 That's all I have.

0:15:21	SPEAKER_03
 You want to talk about recognition?

0:15:23	SPEAKER_03
 I have done anything.

0:15:24	None
 I want to talk about recognition.

0:15:25	SPEAKER_09
 I haven't done anything.

0:15:26	SPEAKER_09
 I want to talk about recognition.

0:15:27	SPEAKER_09
 I've done a couple of days.

0:15:28	SPEAKER_04
 So I haven't done anything.

0:15:29	SPEAKER_02
 We're sort of in a stage where we're, uh, Don's going through getting some of the next meetings that Jay has.

0:15:39	SPEAKER_02
 And, uh, you know, creating a second database.

0:15:43	SPEAKER_02
 So we haven't actually run anything yet.

0:15:46	SPEAKER_02
 We need to get a critical mass for that.

0:15:47	SPEAKER_09
 However, we just got an email from Tilo saying that we are ready to run.

0:15:52	SPEAKER_09
 I mean, we have segmentation.

0:15:53	SPEAKER_09
 Check the segmentation.

0:15:54	SPEAKER_02
 Yeah.

0:15:55	SPEAKER_09
 Yeah.

0:15:56	SPEAKER_09
 From his segment.

0:15:57	SPEAKER_09
 So great.

0:15:58	SPEAKER_09
 You had three different versions, different like the last thresholds between the segments.

0:16:03	SPEAKER_08
 Yeah, just, yeah, just move the output of the.

0:16:07	SPEAKER_08
 Right.

0:16:08	SPEAKER_09
 And you recommended using the one with two, two, two seconds.

0:16:11	SPEAKER_02
 What do you mean a different pass?

0:16:13	SPEAKER_08
 You can use the one with one second or whatever.

0:16:17	SPEAKER_08
 There's not much difference between the one second and the two second one.

0:16:21	SPEAKER_09
 I mean, the only advantage to using the longer threshold would be that you run less risk of missing some.

0:16:27	SPEAKER_09
 Act some speed.

0:16:28	SPEAKER_08
 And I think wouldn't it be better to have a little longer sequences for recognize?

0:16:34	SPEAKER_08
 Because the language model has sometimes it happens that it struts off within us.

0:16:39	SPEAKER_08
 Yeah, but we can be sure that is or we can be not not totally sure, but we can be somehow sure that there is nothing, not no speech between those.

0:16:49	SPEAKER_04
 Yeah.

0:16:50	SPEAKER_04
 So it is the two second thresholds.

0:16:51	SPEAKER_08
 I think that's the same as in the this move for the IBM thing.

0:16:56	SPEAKER_03
 It combines them if the pause is no more than six words.

0:17:00	SPEAKER_02
 So roughly on average, that's pretty good.

0:17:04	SPEAKER_02
 Right.

0:17:05	SPEAKER_03
 So the tradeoff as you get longer utterances, but you miss fewer utterances.

0:17:08	SPEAKER_08
 Yeah, but the trunks are really in general are short.

0:17:12	SPEAKER_08
 So I think it would be better to have more of them concernated together in order to have better language model language modeling.

0:17:20	SPEAKER_08
 I think two seconds.

0:17:22	SPEAKER_09
 I would maybe go with one second.

0:17:24	SPEAKER_09
 Well, take a look.

0:17:25	SPEAKER_09
 Do that.

0:17:26	SPEAKER_09
 Yeah.

0:17:27	SPEAKER_08
 Yeah, but there's really not much difference between the one second and so on.

0:17:31	SPEAKER_04
 I wouldn't think just the language model would continue across two seconds.

0:17:35	SPEAKER_09
 Well, yeah, you do.

0:17:38	SPEAKER_09
 You get false recognition.

0:17:39	SPEAKER_09
 So you've got to, yeah, you've got to hurt yourself occasionally by having missing the language model context, but you might hurt yourself more by having missed recognition due to background speech or.

0:17:53	SPEAKER_08
 I'm not too afraid about that as when there would be something, some background speed or something that would be a chunk in another.

0:18:02	SPEAKER_08
 Yeah, I think there's something in between.

0:18:05	SPEAKER_08
 I can't I do not come.

0:18:06	SPEAKER_08
 The longer it's better.

0:18:07	SPEAKER_08
 It's just when there is when there is sequentially and so I would I would use it.

0:18:11	SPEAKER_02
 There's a lot of these cases just like now where people say, and they're trying to talk and there's about a half second pause to a second in between and then another word.

0:18:21	SPEAKER_02
 And it's much better if we can keep those together, I think.

0:18:24	SPEAKER_03
 It's funny looking at some of the transcripts I was filtering by person and in one of the one of the early meetings, one particular person, almost the only thing they said the entire meeting was yeah, it was just a whole list of them.

0:18:38	SPEAKER_09
 I can't even know that was.

0:18:39	SPEAKER_09
 So we need to split the waveforms.

0:18:41	SPEAKER_09
 Or do you already have them split up?

0:18:43	SPEAKER_09
 No, you don't, right?

0:18:44	SPEAKER_09
 No.

0:18:45	SPEAKER_09
 So I guess Dawn would need your help to create a new set of split meetings.

0:18:51	SPEAKER_09
 Sure.

0:18:52	SPEAKER_02
 So you just fake the format that you take as input with the same times to a new set of same time.

0:18:57	SPEAKER_03
 Do we know about disk?

0:18:58	SPEAKER_03
 Yeah, there's that.

0:19:01	SPEAKER_03
 Abbott disk.

0:19:02	SPEAKER_05
 I know they're in.

0:19:03	SPEAKER_05
 Okay.

0:19:04	SPEAKER_05
 And but I don't know.

0:19:06	SPEAKER_04
 He was wasn't he asking a problem, right?

0:19:08	SPEAKER_05
 Yeah.

0:19:09	SPEAKER_05
 Well, there was an issue he wanted to take it down and then he did and then it didn't work.

0:19:14	SPEAKER_03
 I didn't hear any of the masking as you're going to need space to split them up.

0:19:18	SPEAKER_06
 And so I wanted to make sure I still have like probably six, seven eight gig on my desk.

0:19:27	SPEAKER_03
 I still have another couple days.

0:19:29	SPEAKER_02
 I have another six gig which Jeremy, if you're not using, is a couple weeks.

0:19:34	SPEAKER_05
 He probably needs us to prove another time to take things down, right?

0:19:38	SPEAKER_04
 Yeah, he didn't say anything to me about it.

0:19:41	SPEAKER_05
 I thought he said in that mail that he would need to take it down another time.

0:19:45	SPEAKER_05
 Yeah, he just didn't say when.

0:19:47	SPEAKER_05
 Well, no, I think he wanted us to tell him.

0:19:49	SPEAKER_02
 How about during the picnic?

0:19:51	SPEAKER_05
 Yeah, that's pretty good.

0:19:53	SPEAKER_03
 Yeah, I'm sure he thought it was.

0:19:55	SPEAKER_05
 I'm feeling about that.

0:19:57	SPEAKER_03
 Well, that's the point.

0:20:00	SPEAKER_03
 So it's Jane.

0:20:01	SPEAKER_03
 We have to coordinate that through.

0:20:03	SPEAKER_03
 What I was going to say is as soon as possible and I'm willing to not work for an hour to get it done.

0:20:09	SPEAKER_03
 But.

0:20:12	SPEAKER_05
 I think the people with disrupts the most are the transcribers.

0:20:19	SPEAKER_02
 Well, you know, all I need to do is mail, send them a mail like two days in advance so they can schedule their time.

0:20:26	SPEAKER_03
 I get what the last outage.

0:20:28	SPEAKER_01
 I wrote to them letting them know that this.

0:20:31	SPEAKER_01
 So early on, I can't make sure to almost decide when to do it.

0:20:35	SPEAKER_01
 I'm going to do it.

0:20:37	SPEAKER_05
 And just as long as we have a little warning.

0:20:45	SPEAKER_02
 So that means we can't save meeting data either, right?

0:20:49	SPEAKER_03
 Just not during that time when it's down, but that it should only be down for an hour.

0:20:53	SPEAKER_02
 So we can't have two meetings in a row or the first meetings during that hour.

0:20:57	SPEAKER_03
 Right.

0:20:58	SPEAKER_03
 Well, we can store them here.

0:21:00	SPEAKER_03
 We can store them here.

0:21:02	SPEAKER_03
 We just run the risk that if you have a crash, we lose the data.

0:21:05	SPEAKER_02
 There's no, I mean, the, oh, just, yeah, this is some popcorn or something.

0:21:09	SPEAKER_07
 Yep.

0:21:10	None
 Okay.

0:21:15	SPEAKER_05
 Yeah.

0:21:16	SPEAKER_05
 We store our data on popcorn.

0:21:18	SPEAKER_05
 That's really great.

0:21:19	SPEAKER_05
 It's just making we store our data on popcorn.

0:21:22	SPEAKER_05
 I'm making the students.

0:21:23	SPEAKER_05
 Can you?

0:21:24	SPEAKER_05
 So they do that.

0:21:25	SPEAKER_05
 Okay.

0:21:26	SPEAKER_05
 Megabytes and mega many megabytes too.

0:21:30	SPEAKER_05
 What?

0:21:31	SPEAKER_05
 What?

0:21:32	SPEAKER_03
 We have a kernel log popcorn too.

0:21:35	SPEAKER_05
 So what's on your queue for recognition experiments?

0:21:44	SPEAKER_05
 Let's talk about that for a second.

0:21:46	SPEAKER_05
 What was the question?

0:21:47	SPEAKER_05
 What was on his queue for recognition experiments?

0:21:50	SPEAKER_04
 I'm rebuilding the net that we're going to use for the tandem stuff.

0:21:54	SPEAKER_04
 And so what I'm doing is putting in the stream reader into the quick-knit libraries.

0:22:01	SPEAKER_04
 For the SRI feature files, which is the right way to do it.

0:22:05	SPEAKER_04
 I mean, when we did our first experiments and I was creating SRI feature files from the XC front end, I just had Perl scripts, you know, and hacked a bunch of stuff together just to get it going.

0:22:16	SPEAKER_04
 But the right way to do it is to integrate it in with the XC tools.

0:22:21	SPEAKER_04
 And so that's what I'm doing now.

0:22:23	SPEAKER_04
 And so once I get that done, then I'll generate the P files I need.

0:22:26	SPEAKER_04
 Because we already have the feature files in the SRI form.

0:22:30	SPEAKER_04
 And the SRI format, so what I need to do is make it so that the quick-knit stuff can read those.

0:22:36	SPEAKER_09
 Is that independent or related to also being able to write out the feature file in the SRI format?

0:22:44	SPEAKER_09
 There's an input stream in an output stream.

0:22:47	SPEAKER_09
 So then you could use, like, a fecalc and just specify as an output format.

0:22:56	SPEAKER_09
 Yeah, that's the point.

0:22:57	SPEAKER_09
 I'm just thinking about it.

0:23:00	SPEAKER_03
 If you- Right, quick-knit is a very nice stream-based library.

0:23:04	SPEAKER_03
 So without too much effort, once he has the classes written, we can incorporate it into all the standard tools.

0:23:13	SPEAKER_04
 So then it's tandem experiments.

0:23:15	SPEAKER_03
 And at some point, I'd like to get back to porting quick-knit to the multi-process or Linux box.

0:23:23	SPEAKER_03
 I have forward passes working, but I haven't done training yet.

0:23:28	SPEAKER_09
 So speaking of Linux, so there's some impetus at SRI to actually build support Linux as a platform.

0:23:40	SPEAKER_09
 So that means once we have everything running on Linux, we can also run all our jobs on your machines.

0:23:48	SPEAKER_02
 Yeah, exactly.

0:23:49	SPEAKER_04
 We don't have too many.

0:23:50	SPEAKER_04
 We just have that.

0:23:51	SPEAKER_04
 Just have a few.

0:23:53	SPEAKER_09
 I mean, if you can't use all the processors on whatever machine.

0:23:56	SPEAKER_03
 Well, that's a nice thing about it, since it's course parallelism, you don't have to do anything special.

0:24:01	SPEAKER_03
 I'd expect it.

0:24:02	SPEAKER_03
 So, I mean, that would be a fine use for before that machine.

0:24:05	SPEAKER_03
 So it's just five more processors.

0:24:09	SPEAKER_09
 Yeah.

0:24:11	SPEAKER_09
 So- And in the future, if Linux machines become way cheaper than Solaris machines, then that wouldn't be a reason not to use Linux anymore.

0:24:23	SPEAKER_07
 Yeah.

0:24:24	SPEAKER_05
 Yeah.

0:24:25	SPEAKER_05
 I think it would be neat at some point in this to do a recognition pass on one of the PCM mics for these same meetings that you're getting.

0:24:40	SPEAKER_05
 I mean, it's going to be terrible, but we just don't know how terrible.

0:24:45	SPEAKER_02
 It's also an interesting problem to come up with the reference.

0:24:50	SPEAKER_02
 So the reference file for the relative time that-

0:24:55	SPEAKER_00
 Oh, it's a good one.

0:24:56	SPEAKER_02
 So, well, it's an interesting question because I was thinking, well, you can force a line, the transcriber transcripts, and then, of course, you try to merge them in time. But how do you score?

0:25:08	SPEAKER_03
 I think the first pass is throw out words which are overlapped.

0:25:12	SPEAKER_03
 That would be a good first pass.

0:25:14	SPEAKER_03
 Just ignore everything that hasn't been done.

0:25:16	SPEAKER_05
 Yeah, because you have a set of scores about that.

0:25:18	SPEAKER_02
 Right.

0:25:19	SPEAKER_02
 Some of you then that wouldn't be so bad.

0:25:20	SPEAKER_02
 But there's a whole interesting discussion because, of course, the alignments are not perfect either.

0:25:24	SPEAKER_02
 Right.

0:25:25	SPEAKER_02
 So, in fact, we actually don't have a-

0:25:28	SPEAKER_05
 I mean, it's a little bit better than what we do with just these. Right.

0:25:32	SPEAKER_05
 And again, if you rule out the overlapped, you have some numbers for that, because that's yet another- I'm just concerned, of course, about that.

0:25:38	SPEAKER_02
 Oh, I see you mean one only one person is talking-

0:25:40	SPEAKER_00
 Yep. Yes.

0:25:42	SPEAKER_00
 Because you have scores for that.

0:25:43	SPEAKER_00
 We can try that.

0:25:44	SPEAKER_00
 Right.

0:25:45	SPEAKER_05
 Right, exactly.

0:25:46	SPEAKER_05
 Yeah, we should try.

0:25:47	SPEAKER_05
 That will be- I mean, one of the things that Dave was noticing we're talking this morning is that it seems like we don't know this in detail, but it seems like you're getting a lot from the channel adaptation, the speaker adaptation, and so forth.

0:26:00	SPEAKER_05
 So, you are already, and I recognize you're doing something that is likely to affect the far-fielk microphone performance.

0:26:11	SPEAKER_05
 So, it may not- I mean, it's going to be bad, but it may not be like, won't decode kind of bad.

0:26:18	SPEAKER_05
 It might only be that it- It may be 40%- Maybe, or something like that.

0:26:23	SPEAKER_02
 Do you assume you know the speaker when you do this?

0:26:26	SPEAKER_05
 I want us to assume the exact- whatever it was you assumed when you did the other-

0:26:31	SPEAKER_02
 The close mic. Well, there's only one person who it can be because they own that microphone.

0:26:37	SPEAKER_02
 I'm just wondering- That comes another far- I wonder when you're the gendered person.

0:26:40	SPEAKER_02
 That's for scoring.

0:26:41	SPEAKER_02
 That's for scoring.

0:26:42	SPEAKER_02
 You can do it or not do it as you choose.

0:26:43	SPEAKER_02
 Right.

0:26:44	SPEAKER_02
 You're saying for this- For the adaptation- Well, for everything first.

0:26:47	SPEAKER_02
 You know, you do a supervised adaptation.

0:26:50	SPEAKER_02
 Right.

0:26:51	SPEAKER_02
 All of these adaptations-

0:26:53	SPEAKER_09
 All of these assume you know-

0:26:56	SPEAKER_02
 Assume that the same person-

0:26:57	SPEAKER_09
 You would have to do the speaker segmentation first on the five field mic.

0:27:00	SPEAKER_03
 Well, but you can use the- When you're doing the scoring, since you're- You're going to be scoring against transcript, you can use-

0:27:06	SPEAKER_09
 When you want to cheat.

0:27:07	SPEAKER_03
 Well, you're doing that anyway. Well, I don't-

0:27:10	SPEAKER_01
 So, should she-

0:27:11	SPEAKER_03
 Try to cheat in the same way that you're doing with the close talk.

0:27:13	SPEAKER_01
 Actually, I don't like that- I don't like that too.

0:27:15	SPEAKER_05
 I- I have a suggestion.

0:27:17	SPEAKER_05
 Do the simplest thing first.

0:27:18	SPEAKER_05
 Yeah, right.

0:27:19	SPEAKER_05
 Because we're going to want to know that anyway.

0:27:21	SPEAKER_05
 So, the simplest thing is you cheat, saying- No, it's- no, it's even simpler thing than that is just that you don't know.

0:27:27	SPEAKER_09
 You mean you don't- You don't do all those numbers, right?

0:27:30	SPEAKER_09
 Yeah.

0:27:31	SPEAKER_02
 Oh, you- You can totally unwrap it.

0:27:33	SPEAKER_05
 Yeah, because you can get a number for that with the other as well, right?

0:27:36	SPEAKER_05
 You can turn those things off, right?

0:27:38	SPEAKER_09
 Yeah.

0:27:39	SPEAKER_09
 Actually, we don't have any models.

0:27:42	SPEAKER_02
 Oh, you can-

0:27:43	SPEAKER_09
 You can-

0:27:44	SPEAKER_02
 You can use a speaker- What about gender defects?

0:27:46	SPEAKER_09
 Actually, we would have to retrain models that are not- That have none of that stuff in it.

0:27:53	SPEAKER_09
 But actually, we could- We can just run it, assuming that it's all one speaker, basically.

0:28:01	SPEAKER_09
 Yeah.

0:28:02	SPEAKER_09
 And see what happens.

0:28:03	SPEAKER_05
 Yeah.

0:28:04	SPEAKER_05
 Yeah, and then put it in correctly and see how much that helps.

0:28:06	SPEAKER_05
 Yeah.

0:28:07	SPEAKER_05
 I mean, I was just thinking to do the one that's easiest first.

0:28:09	SPEAKER_05
 Because you want to know how much that's helping you in the right cases anyhow.

0:28:12	SPEAKER_05
 So, you have gender- Gender-depend models?

0:28:14	SPEAKER_08
 So, I- All the models gender-depend?

0:28:16	SPEAKER_08
 Yeah.

0:28:17	SPEAKER_02
 And then also-

0:28:18	None
 Yeah, so- So, you could do that- No, you could run both.

0:28:21	SPEAKER_09
 And pick whichever is better.

0:28:22	SPEAKER_09
 Here's what we would usually do on the least circumstances.

0:28:25	SPEAKER_09
 We would actually- We would run some sort of segmentation.

0:28:28	SPEAKER_09
 Tilosus is good at saying it probably.

0:28:31	SPEAKER_09
 And then we would do an answer- Provised clustering of the segments to- And put the similar ones into bins that would be sort of pseudo speakers.

0:28:43	SPEAKER_09
 And then we would do our standard processing on these pseudo speakers.

0:28:46	SPEAKER_09
 And that turns out to work very well on broadcast news, spy on those types of tasks where you don't have the speaker segmentation given to you.

0:28:55	SPEAKER_03
 Does the clustering do you give it sort of a target number of clusters or is it-

0:28:59	SPEAKER_09
 And that means- Either by target number or by some measure of the similarity that you've been using.

0:29:05	SPEAKER_03
 Yes, I'm just thinking one of the big differences with broadcast news in these meetings is we have many fewer participants.

0:29:11	SPEAKER_02
 The other thing is that you actually have direction here.

0:29:16	SPEAKER_02
 So unlike these corpora that are recorded with other microphones, like the right way to do this, I guess, you know, in the future would be- Speak on it, yeah.

0:29:25	SPEAKER_02
 In general, Tilo sitting there and this PCM is gonna- Well, there are different ways of taking that.

0:29:29	SPEAKER_03
 I mean, that would be true if you had a meeting situation with multiple mics.

0:29:33	SPEAKER_03
 But if you only had your PDA sitting in front of you.

0:29:36	SPEAKER_02
 Well, any case where the people are not all sitting at the same place and they're not moving around too much.

0:29:41	SPEAKER_03
 And you have more than one mic.

0:29:43	SPEAKER_05
 Yeah, if you don't have one more than one mic, you don't have a very good handle on location.

0:29:48	SPEAKER_02
 Well, you have distance and you have-

0:29:50	SPEAKER_05
 distance not enough.

0:29:53	SPEAKER_02
 I mean that James, the pickup of Adam on this mic is gonna be different than me in terms of energy and so forth over the whole meeting.

0:30:01	SPEAKER_03
 So just from clustering, you might be able to cluster a little bit.

0:30:03	SPEAKER_02
 You might get some clustering from the speaker and some of it from characteristics of the distance.

0:30:09	SPEAKER_05
 But say if you had a- Transcript, right.

0:30:12	SPEAKER_05
 Carried with micracing.

0:30:13	SPEAKER_05
 Sitting someplace, then sitting there, then it's- It's a response to him would be- Well, I think there are lots of- They're both picked up in the clustering.

0:30:20	SPEAKER_09
 You can send your normalizations like, you know, gain control before you do the clustering to rule out those types of things.

0:30:26	SPEAKER_02
 Or to just do the clustering knowing that you're capturing both.

0:30:30	SPEAKER_02
 It's just that the kind of clustering we've done before hasn't had that distance factor or-

0:30:36	None
 Yeah. or location factor in it in the same way.

0:30:38	SPEAKER_02
 And so we're not really modeling it directly if somebody does.

0:30:41	SPEAKER_02
 Yeah, that's an interesting- Maybe we had that because I think it would be a pretty big difference.

0:30:45	SPEAKER_02
 When you listen, you can sort of tell where people are, not which, you know, side.

0:30:50	SPEAKER_03
 Well, humans are really good at that transfer function through the head.

0:30:53	SPEAKER_03
 Right.

0:30:54	SPEAKER_02
 Things like that.

0:30:55	SPEAKER_03
 Even with one- You only have one ear.

0:30:57	SPEAKER_03
 You can still get good transfer.

0:30:58	SPEAKER_02
 So our clustering is not going to be intelligent that way.

0:31:01	SPEAKER_02
 It's just going to pick up whatever energy difference or whatever.

0:31:04	SPEAKER_05
 But anyway, I'd be neat to have that because we've been at this for a little while.

0:31:09	SPEAKER_05
 We don't have any results yet with conversational speech at a distance.

0:31:14	SPEAKER_05
 So we should at least get a first one.

0:31:17	SPEAKER_05
 Something, yeah.

0:31:18	SPEAKER_05
 And the other thing, this would kind of be a hail Mary.

0:31:21	SPEAKER_05
 But Dave does have this stuff that is helping on digits.

0:31:26	SPEAKER_05
 Yeah, so it would be cool to see if it helped.

0:31:28	SPEAKER_03
 You know, just throw that in.

0:31:29	SPEAKER_09
 Yeah.

0:31:30	SPEAKER_09
 Throw it to the whole training site.

0:31:31	SPEAKER_09
 Do you retreat?

0:31:32	SPEAKER_09
 Yeah.

0:31:33	SPEAKER_03
 That would be quick.

0:31:35	SPEAKER_03
 Since I think you did it in MATLAB.

0:31:38	SPEAKER_05
 Well, you can do it in something else.

0:31:41	SPEAKER_05
 But I mean, you know, it's-

0:31:43	SPEAKER_03
 Can you export C from MATLAB?

0:31:45	SPEAKER_05
 Actually, we're experimenting with FACE stuff now. And the first result he got was really great.

0:31:51	SPEAKER_05
 It actually didn't exactly eliminate the reverberation, but it completely got rid of the speech.

0:31:57	SPEAKER_05
 That would be a lot of fun.

0:32:00	SPEAKER_09
 Yeah, well, I was just taking the inputs and you're fine.

0:32:03	SPEAKER_05
 You think I didn't know that?

0:32:05	SPEAKER_05
 No, I got pretty excited because it completely got rid of the speech.

0:32:08	SPEAKER_05
 So I was thinking- So it's a speech detector, that's great.

0:32:11	SPEAKER_05
 That's interesting.

0:32:12	SPEAKER_05
 Could be useful for lots of things.

0:32:13	SPEAKER_01
 Take your rid of other stuff too, though.

0:32:14	SPEAKER_01
 You could get rid of other stuff besides the speech.

0:32:16	SPEAKER_03
 Well, yeah, sort of check that out.

0:32:17	SPEAKER_03
 Subtract that from the original signal and your set.

0:32:19	SPEAKER_01
 Wow, interesting.

0:32:20	SPEAKER_09
 Right then, you can estimate the- Noise estimate.

0:32:24	SPEAKER_09
 Signal to noise, that's great.

0:32:27	SPEAKER_05
 It reminds me of an AirVay and I were first playing with context dependent things for NETS.

0:32:33	SPEAKER_05
 And at one point, we took out the speech input, so we only had priors and our performance went up.

0:32:39	SPEAKER_03
 I guess that's why AirVay always talks about using the priors as one of the mixers in his always combats.

0:32:47	SPEAKER_03
 Well, of course it was a bug, but I mean it was-

0:32:50	SPEAKER_05
 That's still, but it was pretty. Wow, interesting.

0:32:52	SPEAKER_05
 It was pretty funny anyway.

0:32:54	SPEAKER_03
 So if you run your recognizer with all probabilities equal, what do you get at?

0:33:00	SPEAKER_03
 Probably garbage.

0:33:02	SPEAKER_03
 Whatever the learning model is.

0:33:03	SPEAKER_03
 The learning probably prints everything.

0:33:05	SPEAKER_03
 You got a switch, but we had to make it.

0:33:07	SPEAKER_05
 That's how it's generating.

0:33:10	SPEAKER_09
 Yes, so we have this new speaker adaptation.

0:33:13	SPEAKER_09
 It was a sort of feature normalization, like speaker adaptation, which I wrote about in the last set of support, which seems to be helping not percent of the half of the five.

0:33:27	SPEAKER_09
 So we haven't tried that yet on the meetings, but hopefully we'll help there too.

0:33:32	SPEAKER_09
 I want to ask-

0:33:33	SPEAKER_01
 So you know that the data, I've upgraded it considerably, so I've probably made- I probably corrected something like, well, it's really substantial amount of things that have caught changed added to it, including a lot of back channels.

0:33:46	SPEAKER_01
 So when you're running things, if you run it on the old- so if you run it on the new version, then the numbers will be- And you compare it to the- to runs on the old version, then you're going to end up with more of an improvement than would actually be the case.

0:34:01	SPEAKER_09
 We do all our experiments with the frozen version of the transcripts, as of- I don't know.

0:34:07	SPEAKER_09
 As of February?

0:34:08	SPEAKER_09
 I don't know when did we- So- Like the ACLT paper?

0:34:14	SPEAKER_01
 Sorry.

0:34:15	SPEAKER_09
 For these meetings?

0:34:16	SPEAKER_09
 We're talking about which version we're using for evaluating the recognition, which version of the transcripts?

0:34:22	SPEAKER_02
 Right.

0:34:23	SPEAKER_02
 There's somewhere in between January and late March or something like that.

0:34:27	SPEAKER_02
 Yeah, so long as you have the baseline, then you'll be able to tell.

0:34:31	SPEAKER_01
 Obviously, yeah.

0:34:32	SPEAKER_01
 So long as the same base are now being able to tell, but I'm just saying that if you would compare that with running that on the old version, it would be more of the same outcome.

0:34:40	SPEAKER_09
 It takes only a minute to restore all the old outputs with if you had new transcripts than which is- Right, because you haven't done any training.

0:34:51	SPEAKER_03
 Sorry?

0:34:52	SPEAKER_02
 Right, because we're not doing a training.

0:34:54	SPEAKER_02
 Yeah, we haven't modified the recognizer at all.

0:34:56	SPEAKER_02
 Right, so it's really- It would be easy to redo it.

0:34:58	SPEAKER_02
 At some point, we should update and restore everything with, you know, the practice and practice.

0:35:02	SPEAKER_02
 It'd be interesting just to see how much it changes.

0:35:04	SPEAKER_03
 It's a bit-

0:35:05	SPEAKER_02
 What are the changes we get as the changes? Sometimes the changes are cases where the recognizer would get it wrong anyway, because it was somewhere that we didn't have in the vocabulary.

0:35:15	SPEAKER_02
 But it does help to get the back tunnels back in and things like that.

0:35:19	SPEAKER_09
 So whenever the- Right now, the scoring is based on segments, which is not great because for instance, so the other way to do the scoring is using a list format called STM, so segment type- Yep, we know where.

0:35:36	SPEAKER_09
 So I have to convert the transcripts into this format, and then the scoring program actually looks at the times.

0:35:45	SPEAKER_09
 And, you know, you can have a different segmentation and you recognize the output and your references.

0:35:50	SPEAKER_09
 So that's what we need to-

0:35:54	SPEAKER_03
 Transcriber will export STM in case you care.

0:35:59	SPEAKER_09
 Well, but then there's other changes, so I mean, there's other- We strip away a lot of the markup and the transcripts, which, you know, isn't a trend on the template of the speech I can show up.

0:36:12	SPEAKER_02
 But that doesn't only change the scoring if a word has moved into a different segment.

0:36:17	SPEAKER_02
 I mean, I don't think that's- I hardly ever see that.

0:36:20	SPEAKER_02
 I think most of them are pretty good.

0:36:23	SPEAKER_09
 Well, I mean, if support- I assume you also changed some of that.

0:36:27	SPEAKER_09
 I did.

0:36:28	SPEAKER_09
 So if we want to use new transcripts with a different segmentation, then we can't use them in a current way we use score.

0:36:35	SPEAKER_09
 We have to-

0:36:37	SPEAKER_02
 Oh, you mean you need to rerun the recognition?

0:36:39	SPEAKER_09
 No, we have to-

0:36:41	SPEAKER_02
 I mean, if you rerun the recognition, then you just run it. I see, if you want to use the old- You can actually never, though, really infer what you would get with a different, you know.

0:36:50	SPEAKER_02
 It's probably more fair to rerun that.

0:36:53	SPEAKER_02
 In other words, it's not really a scoring script problem.

0:36:57	SPEAKER_09
 No, but if you just want to see what- Like, suppose you fix some type, or you're going to fix some typos, and you want to see what effect does it have on the word error.

0:37:08	SPEAKER_03
 Right, but-

0:37:09	SPEAKER_02
 Yeah.

0:37:10	SPEAKER_03
 If the segments change, that won't work.

0:37:11	SPEAKER_02
 It'll sort of work, but it's not exactly what you would maybe get from recognition.

0:37:15	SPEAKER_03
 Well, I mean, what happens if you break one segment into two? Suddenly, they don't match at all, and you can't line them up anymore.

0:37:21	SPEAKER_09
 Well, you can line them up in the top.

0:37:25	SPEAKER_09
 So the scoring program, if you give it an STM reference file, it will actually compare the words based on their timelapse.

0:37:34	SPEAKER_09
 So therefore, you can-

0:37:36	SPEAKER_03
 Does STM do per word or per utterance?

0:37:39	SPEAKER_09
 It's per utterance, but it allows- As long as you hypothesize the word in the right segment in a reference, it gives you credit for that.

0:37:47	SPEAKER_09
 So it does a word alignment, like you have to do for scoring.

0:37:51	SPEAKER_09
 And it does also- It constrains the words to lie within the segment.

0:37:55	SPEAKER_03
 Within the segment, yeah.

0:37:56	SPEAKER_09
 The reference, I see.

0:37:57	SPEAKER_09
 And for you to get credit for that, so-

0:38:00	SPEAKER_01
 That sounds great.

0:38:02	SPEAKER_09
 So it should be just a straightforward reforming issue of the right-

0:38:06	SPEAKER_01
 Yeah, I mean, I was thinking the other day that this- It's not just conversational speech, the fact that it has so much technological jargon in it.

0:38:15	SPEAKER_01
 It makes it considerably harder to- To transcribe and to double check and all those things.

0:38:23	SPEAKER_01
 So I think you're going to find a substantial gain in terms of the word accuracy.

0:38:28	SPEAKER_01
 As long as those words are in your vocabulary.

0:38:31	SPEAKER_01
 Well, it definitely helps with-

0:38:32	SPEAKER_02
 What percent? Forced alignment, too, because, you know, when we know the true words, and we're adding them to the vocabulary and training a language model, and so forth for future meetings, especially the front end meetings or meetings with a lot of jargon in them that- It's not represented in switchboard or call home, but it-

0:38:51	SPEAKER_01
 For all of our meetings. For all of our meetings have a lot of jargon in them.

0:38:54	SPEAKER_01
 But we know what those words are.

0:38:56	SPEAKER_01
 I mean, I don't know how you get them into the vocabulary, but it would seem- Now, I have to- I really need to raise a question about the term cheating.

0:39:04	SPEAKER_01
 Okay.

0:39:05	SPEAKER_01
 And the reason is, if I understand that cheating is a term which is used to apply for basically what- All of linguistics, corpus linguistics does and what- What my transcribers are doing and what I do, which is a methodology where by you actually physically mark things in the data.

0:39:21	SPEAKER_01
 Like the transcription, like the words-

0:39:23	SPEAKER_03
 All we need by that is that we're giving the recognizer more information than it would have if you were running it raw. Over a meeting that no person has ever listened to or transcribed.

0:39:33	SPEAKER_03
 Okay.

0:39:34	SPEAKER_01
 I mean, that- that part is okay, but I- But I do wonder sometimes if it might be possible to use a term that's a little bit less evaluative, like- The cheating is-

0:39:44	SPEAKER_05
 The cheating is pretty commonly used to me-

0:39:48	SPEAKER_02
 I guess it is. It's a long time and it's sort of- Because it's so strong or word, people don't take it that seriously.

0:39:56	SPEAKER_02
 Yeah.

0:39:57	SPEAKER_02
 And it's not negatively viewed, it just really means-

0:39:59	SPEAKER_05
 It's even more than that. I think it really gives a very strong perspective that you know that what you were doing is not an unbiased experiment.

0:40:10	SPEAKER_05
 If you don't say that, then people think, oh, they did that and they threw that, but that doesn't represent what would happen in the real world.

0:40:16	SPEAKER_05
 If you say, we did a cheating experiment, which is really the standard way you'd say it.

0:40:21	SPEAKER_05
 It says you deliberately put in a piece of the information that you would not have in the real world so that you can learn something.

0:40:27	SPEAKER_05
 This is part of your process.

0:40:29	SPEAKER_05
 So it's- I don't like-

0:40:31	SPEAKER_01
 Okay. I guess what I'm thinking is just in- When these are presented in an interdisciplinary context, it might be nice to add that explanation.

0:40:40	SPEAKER_01
 Otherwise, it sounds like a pejorative statement on an alternative methodology.

0:40:44	SPEAKER_01
 Because it sounds like it sort of devalues the other approach which is to put those distinctions in-

0:40:51	SPEAKER_05
 I mean, I've heard this at ICS, I hope you're years and years and years now. Yeah, it's pretty, pretty clear.

0:40:56	SPEAKER_09
 Well, through a broader audience you could call it a diagnostic experiment.

0:41:00	SPEAKER_02
 Actually, Jane is right like in conversation analysis, I've never heard people use this because they're not using an automatic system.

0:41:07	SPEAKER_02
 So it really- Right, well, you can do experiments, but the- It's cheating relative to what we call a system where we can completely control this black box.

0:41:19	SPEAKER_02
 And it's not a very smart system.

0:41:21	SPEAKER_02
 It only knows what we give it.

0:41:23	SPEAKER_02
 And if it knows more than we would really give it when it runs, we call it cheating.

0:41:27	SPEAKER_02
 But it's- yeah, it's only used in a community that does some type of computational modeling, I think.

0:41:34	SPEAKER_02
 It's really not used in any kind of community doing experiments on human perception or so.

0:41:41	SPEAKER_02
 Yeah, it's machine learning.

0:41:42	SPEAKER_05
 Certainly experiments.

0:41:44	SPEAKER_05
 I mean, when the neural net wave hit in the mid-80s and by the late-80s, we were reviewing thousands of papers that were coming out neural nets.

0:41:57	SPEAKER_05
 It was really hot and everybody thought it would do everything.

0:42:00	SPEAKER_05
 And a really common error that people were making was they were just reporting their classification results on the data that they were training on.

0:42:11	SPEAKER_05
 And so I think it was very important for people then who were doing something diagnostic to say, hey, I know I'm doing something that isn't kosher and to make it really clear that they knew it.

0:42:22	SPEAKER_05
 So that was, I think, why it became a popular experiment.

0:42:25	SPEAKER_01
 It just seems like, you know, if it were bootstrapping or if it were, I mean, there are other ways to maybe get the point of time.

0:42:30	SPEAKER_05
 But it is a bootstrapping.

0:42:31	SPEAKER_05
 It's really- It's using information you wouldn't normally have.

0:42:35	SPEAKER_05
 But it's cheating in a way that's- it's announcing to everybody, hey, I'm cheating by doing this.

0:42:40	SPEAKER_05
 It's saying so. It's all above the table.

0:42:42	SPEAKER_05
 I'm actually using this other thing.

0:42:44	SPEAKER_05
 Okay.

0:42:45	SPEAKER_05
 Bootstrapping would imply it was actually legitimate in some kind of way.

0:42:49	SPEAKER_05
 Well, I think-

0:42:50	SPEAKER_03
 But we're not de-legionizing the data, we're de-legionimizing the experiment. We're not saying that the data is cheating data.

0:42:57	SPEAKER_03
 We're saying we are cheating by using this data.

0:43:00	SPEAKER_03
 Okay.

0:43:01	SPEAKER_03
 Because normally you wouldn't have that data available.

0:43:03	SPEAKER_01
 Okay.

0:43:04	SPEAKER_01
 It does seem to me that it carries over some baggage with it that- that I can understand it in context as you described it.

0:43:11	SPEAKER_01
 But it seems to me that it does import some negative evaluation that would- Maybe not be good.

0:43:20	SPEAKER_01
 It has shock value and to the wrong audience, I think that that might be a negative shock.

0:43:25	SPEAKER_01
 Yeah.

0:43:26	SPEAKER_01
 To the wrong audience, I agree that-

0:43:28	SPEAKER_02
 Like a disclaimer. To the wrong audience, we should just explain what it means.

0:43:32	SPEAKER_01
 Yeah. We started with hand-marked data or with, you know, hand-transcribed data or- Shoot.

0:43:37	SPEAKER_01
 Yeah. Did you bring the microphone?

0:43:39	SPEAKER_01
 Just the clip.

0:43:40	SPEAKER_01
 Okay.

0:43:41	SPEAKER_01
 Okay.

0:43:42	SPEAKER_01
 Well, I feel better now.

0:43:43	SPEAKER_01
 Thank you very much.

0:43:44	SPEAKER_01
 The first time I had-

0:43:45	SPEAKER_02
 Thank you, I'm good. I thought, you know, the same thing and I guess you just after a while it becomes- It really is part of the jargon.

0:43:52	SPEAKER_02
 It's a bit of- It's also- A humblings when somebody says that if they get good results but we were cheating on this feature because we took it for granted even though we can't really assume that, then it's actually the opposite.

0:44:04	SPEAKER_01
 The trouble is that, you know, I understand it in that context, but it is almost resentful.

0:44:10	SPEAKER_01
 It's almost like, you know, resentful of the data, resentful of the- The hard work that's going into preparing the data.

0:44:16	SPEAKER_01
 No, no, I don't think you're saying the data is cheating.

0:44:19	SPEAKER_05
 I think you're saying- That's the same.

0:44:21	SPEAKER_05
 In my experiment, I cheated in this way.

0:44:23	SPEAKER_05
 I mean, another thing is what- This was talking about how in the switchboard test, in all the switchboard tests we've been doing, we've been making the same standard- Using the same standard way of getting the data to test on, which means that we weren't actually running it on data that had no speech.

0:44:43	SPEAKER_05
 And in a sense that was cheating.

0:44:45	SPEAKER_05
 Okay.

0:44:46	SPEAKER_05
 So it's a good wake-up call of people, well, we have this performance, but you have to keep in mind we're doing the whole real task in this way and this way and this way.

0:44:57	SPEAKER_05
 But I'll convince you that it's still important for you to listen to what I have say next because of this and this.

0:45:03	None
 Okay.

0:45:03	SPEAKER_05
 And so it's just a way of putting it all out on the table.

0:45:05	SPEAKER_03
 And it's used for a lot of different types of data.

0:45:08	SPEAKER_03
 So whether you have segmentation or not, is it male or female or not?

0:45:12	SPEAKER_03
 Do you know the signal to noise?

0:45:14	SPEAKER_03
 Like that's another one I see all the time where you assume it's known.

0:45:17	SPEAKER_03
 No, I just- And you say it's cheating because you don't actually compute it.

0:45:20	SPEAKER_05
 In the multi-band experiments, in the first one, we really wanted to find out what if you knew which band was really noisy?

0:45:26	SPEAKER_05
 Right.

0:45:27	SPEAKER_05
 I mean, suppose you just know that.

0:45:29	SPEAKER_05
 And then even if you know that, can that help you?

0:45:32	SPEAKER_05
 I mean, what strategy can you do to do well without that particular band in the spectrum?

0:45:37	SPEAKER_05
 And so that was important to know as a baseline.

0:45:40	SPEAKER_05
 And then once you knew that, then you go, well, now how do I know that that's noisy?

0:45:44	SPEAKER_05
 Okay.

0:45:45	SPEAKER_05
 But you know, I should also say that there's a lot of- It's not just we're cheating, but there's lots of other things that we talk about, which as soon as you go outside of a few narrow little group, it gets very, very confusing to people.

0:45:57	SPEAKER_01
 Oh, sure. Terminalogy is always context dependent. No question about it.

0:46:00	SPEAKER_01
 It's just that it seems like the point without the negative evaluation would be, however, you know, I understand your point.

0:46:07	SPEAKER_01
 That it has a long tradition in this field that he's not realized and is used.

0:46:10	SPEAKER_01
 This is interesting what Adam said about it being used also for a bunch of other-

0:46:14	SPEAKER_05
 Well, the example I was thinking of also was this thing that, that are they, and T.M.I. made about increasing the error rate?

0:46:20	SPEAKER_05
 And so we did a number of papers and talks and so forth about the virtues of increasing the- Oh.

0:46:27	SPEAKER_05
 Okay. I mean, and the whole point of it was not that it was good to increase the error rate, but it was good to be willing to risk increasing the error rate by trying risky things and trying, because there's this notion of a local minimum that if you just have some system that's very complex, then you turn some knobs to try to make it better and better, you'll never get out of this local minimum.

0:46:50	SPEAKER_05
 You have to be willing to jump to something that's quite different.

0:46:53	SPEAKER_05
 And the first time you jump to something quite different, or maybe the first ten times, or hundred times you do, it's going to be much, much worse because you've optimized the other system.

0:47:01	SPEAKER_05
 So the effect, immediate effect, is going to be to increase your error rate.

0:47:04	SPEAKER_05
 Interesting.

0:47:05	SPEAKER_05
 And so we had a couple of papers like towards increasing the error rate and speech and so on.

0:47:09	SPEAKER_05
 And we really did get feedback from a few people, some of whom were fairly senior, that well, you know, you're really concerned about you misleading people into the thinking they should be increasing the error.

0:47:24	SPEAKER_05
 And we saw that, but did you read the paper?

0:47:26	SPEAKER_05
 Did you read the paper?

0:47:27	SPEAKER_05
 Yeah, it was actually a little experiment.

0:47:30	SPEAKER_05
 We weren't, that's why we increased the error rate.

0:47:33	SPEAKER_02
 Actually, I think of cheating as a way to do some work where you can't address all of the computational tasks, like if we want to study speaker habits, but we can't do speaker detection.

0:47:47	SPEAKER_02
 But we want to assume, let's say we know this is Jane and we know this is Chuck, even though automatically to look at the habits, we would need to also first figure that out.

0:47:55	SPEAKER_02
 But we can sort of cheat on that factor because it's somebody else's research.

0:47:59	SPEAKER_02
 And then we just, so then we want to make a process concept for her.

0:48:03	SPEAKER_02
 What would this be like if we're perfect?

0:48:05	SPEAKER_02
 If someone else.

0:48:06	SPEAKER_02
 If this component were perfect.

0:48:07	SPEAKER_02
 Right. But we really can't work on that problem.

0:48:09	SPEAKER_02
 We don't have time when I'm interested or whatever.

0:48:12	SPEAKER_02
 It's too hard.

0:48:13	SPEAKER_00
 Usually.

0:48:14	SPEAKER_02
 But I assume it's given because you want to go forward with your research and assume that you have that information.

0:48:21	SPEAKER_02
 So I guess I don't ever think of it as negative, more like it's something we're not building.

0:48:26	SPEAKER_01
 The term itself is, you know.

0:48:28	SPEAKER_01
 But it's not matured towards the decision.

0:48:30	SPEAKER_01
 It's matured towards the decision.

0:48:31	SPEAKER_01
 It's matured towards a certain purpose.

0:48:32	SPEAKER_01
 I understand.

0:48:33	SPEAKER_03
 It's matured towards herself, right?

0:48:34	SPEAKER_03
 To say I am cheating in this experiment.

0:48:36	SPEAKER_03
 Yeah.

0:48:37	SPEAKER_03
 It's not saying that the data is bad.

0:48:38	SPEAKER_03
 It's saying that my experiment is bad.

0:48:40	SPEAKER_05
 Anyway, it's cloned, and it's interesting to hear that someone comes from a different direction.

0:48:46	SPEAKER_05
 It sounds the way it sounds to you.

0:48:48	SPEAKER_05
 But I'd never heard that before.

0:48:50	SPEAKER_05
 Yeah.

0:48:51	SPEAKER_01
 That's interesting.

0:48:52	SPEAKER_01
 Well, I wanted to raise the issue and I appreciate the discussion.

0:48:56	SPEAKER_01
 I wanted to ask one other question, which is a different matter, which is with respect to this thing that you've been working on for the recording monitoring script.

0:49:05	SPEAKER_01
 So the idea, you had the script that you're working on to be sure that the microphone will reser in the agenda.

0:49:11	SPEAKER_03
 I haven't got it back to that recently.

0:49:13	SPEAKER_03
 Okay.

0:49:14	SPEAKER_03
 I assume you're saying you want me to get back to it.

0:49:17	SPEAKER_01
 Well, I'm just wondering.

0:49:19	SPEAKER_01
 Because I am finding that in double checking, I run across one data set where the microphone was off early on, and then two other speakers, their microphones went off later, and this is how like seven speakers.

0:49:35	SPEAKER_01
 So out of seven speakers, four microphones basically, three microphones basically, which makes it hard for the data to be used for all possible purposes.

0:49:43	SPEAKER_01
 Do you think the battery ran out of there?

0:49:45	SPEAKER_01
 That's what I think.

0:49:46	SPEAKER_01
 I think the two that flaked late, I think it was a battery.

0:49:48	SPEAKER_01
 But if the script could alert the recording person to that, I mean, I don't know if there's a way to replace the battery.

0:49:54	SPEAKER_01
 If it happens in the middle of a meeting, maybe that's hopeless anyway.

0:49:56	SPEAKER_03
 Well, you can, but you'll lose a lot of data.

0:49:58	SPEAKER_03
 But I mean, that doesn't really help because often the recording person isn't in the room.

0:50:02	SPEAKER_03
 Oh, I see.

0:50:03	SPEAKER_03
 So what are you going to do?

0:50:05	SPEAKER_03
 I mean, well, if you're looking up at the board and I disable the screen saver, you will see that the mic is off, but that doesn't necessarily help.

0:50:11	SPEAKER_03
 Okay.

0:50:12	SPEAKER_01
 Then I guess that raises the question of whether we should screen the data before they get transcribed.

0:50:17	SPEAKER_01
 Because although I think that the data are still useful in terms of providing content, and that, I know that having three out of seven microphones out of commission during some part of the meeting restricts the usefulness of the data for other purposes.

0:50:34	SPEAKER_01
 I think that's a good way.

0:50:35	SPEAKER_02
 And maybe you don't want to have it.

0:50:36	SPEAKER_02
 I think that's a good idea.

0:50:37	SPEAKER_02
 Because for all kinds of studies, we don't really enjoy meetings where the signal's going off at times.

0:50:42	SPEAKER_02
 It just makes it hard to study any kind of parameters.

0:50:45	SPEAKER_02
 So if there's a way to check the signal quality before transcribing it, and you find any problem at all, it'd be much better to go to another meeting, I think.

0:50:53	SPEAKER_01
 I actually think that Tilos, and when you do the pre-segment or any run across travel, see he runs across some of these.

0:51:00	SPEAKER_01
 We have some part of that.

0:51:02	SPEAKER_08
 We have some part of that.

0:51:03	SPEAKER_08
 We mix them in whatever you find in the channels.

0:51:05	SPEAKER_03
 It's just hard to tell between that and just someone not talking.

0:51:08	SPEAKER_03
 Yeah.

0:51:09	SPEAKER_01
 And the other aspect of it is that when the microphone is not well adjusted, then even if it's not a little pelmike, you can get lapel mic type behaviors.

0:51:19	SPEAKER_01
 I'm expecting, for example, with this, that you're going to end up picking up high-speed signals and notes here.

0:51:25	SPEAKER_01
 Yeah, I mean, it's just a microphone is intentional.

0:51:28	SPEAKER_03
 Well, we should be getting new equipment in, so we don't have to use the earplugs anymore.

0:51:32	SPEAKER_02
 That's my ear.

0:51:33	SPEAKER_02
 I'm sure it's something wrong with my head.

0:51:34	SPEAKER_02
 But actually, is there a way to use whatever you're using for background noise to check post-talk that a microphone was constantly on?

0:51:43	SPEAKER_03
 I mean, you can do sort of a check, but it will be very hard to tell the difference between that and someone not talking.

0:51:50	SPEAKER_05
 So the microphone's dead, doesn't put out zeros?

0:51:53	SPEAKER_05
 No.

0:51:54	SPEAKER_05
 Really?

0:51:55	SPEAKER_02
 But then how are you detecting during a mic?

0:51:58	SPEAKER_02
 I use a threshold.

0:51:59	SPEAKER_03
 It's below a particular killer value.

0:52:01	SPEAKER_03
 It flashes yellow, so it's not perfect.

0:52:04	SPEAKER_02
 But is it better than nothing?

0:52:05	SPEAKER_02
 Yeah, probably.

0:52:06	SPEAKER_02
 Because it would really be easier.

0:52:07	SPEAKER_03
 I mean, this is the reason why I haven't gotten back to it, is because my first pass at it didn't really work because all the mics have different noise levels.

0:52:13	SPEAKER_03
 And so I have to do something a little more clever.

0:52:15	SPEAKER_06
 It's just the noise from the connections and the...

0:52:17	SPEAKER_06
 Yep.

0:52:18	SPEAKER_02
...everything.

0:52:19	SPEAKER_02
 So you could run that post-talk on an already recorded meeting in the sense that, you know, not everyone, as you just said, you won't be there.

0:52:25	SPEAKER_02
 And then if we find any problems, have transcribers listen, and I really think it's better not to transcribe a meeting that's going to have problems once you've spent all this effort.

0:52:33	SPEAKER_01
 The only argument for doing so would be with reference to the content.

0:52:37	SPEAKER_01
 Yes.

0:52:38	SPEAKER_01
 But maybe then it should be done in the old original way, instead of channelizing and having the...

0:52:44	SPEAKER_03
 Yeah, there's the standard deviation of the signal gives you a good clue.

0:52:48	SPEAKER_03
 I mean, if that is too low, then you can be pretty sure that it's empty.

0:52:52	SPEAKER_08
 Sometimes you capture that when you mix it together.

0:52:56	SPEAKER_08
 Right, exactly.

0:52:57	SPEAKER_01
 And actually, an alternative to even doing that level of transcription would be to have a transcriber listen and, you know, maybe just...

0:53:04	SPEAKER_01
 Oh, I don't know if a trans...

0:53:06	SPEAKER_01
 Someone who's associated with the meeting could have like a summary of points handled in the meeting.

0:53:11	SPEAKER_01
 You know, maybe if we could pay one person who knows that subject matter to do an outline of the meeting's content, instead of losing the...

0:53:18	SPEAKER_01
 Well, is there a...

0:53:19	SPEAKER_09
 If you could still transcribe the words based on the...

0:53:23	None
...f I guess the trout table in my mind is that it's not a very neat corpus.

0:53:33	SPEAKER_01
 If you say these data are available, but these are imperfect because of the bad guys' flake.

0:53:37	SPEAKER_01
 We'll just have to note this.

0:53:38	SPEAKER_02
 A much rather have, you know, meetings that have all the channel, even if we had to skip a meeting or something, just for all these other purposes.

0:53:45	SPEAKER_02
 We can't sway the meeting because otherwise we'll end up with very few meetings.

0:53:49	SPEAKER_05
 But we have to be able to get through the backlog of the good meetings.

0:54:17	SPEAKER_07
 We have to be able to get through the backlog of the good guys' flake.

0:54:45	SPEAKER_06
 We have to be able to get through the backlog of the good guys' flake.

