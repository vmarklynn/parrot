0:00:00	SPEAKER_08
 And we're on.

0:00:05	SPEAKER_06
 Okay.

0:00:07	SPEAKER_06
 When I close the door, I get it, uh, stuff in it all.

0:00:16	SPEAKER_08
 Hey Dave, you go ahead and turn on that stuff on.

0:00:23	SPEAKER_06
 So that's the virtual stuff.

0:00:30	SPEAKER_08
 You see for recording or?

0:00:31	SPEAKER_08
 Yeah, learning spots.

0:00:33	SPEAKER_08
 It's got like 16 channels.

0:00:37	SPEAKER_08
 The quality is quite good though.

0:00:40	SPEAKER_08
 Yeah, it's up to 30, pretty good.

0:00:46	SPEAKER_06
 So, uh, yeah, it's just, I must have.

0:00:49	SPEAKER_00
 Let's go ahead and start.

0:00:54	SPEAKER_00
 Okay.

0:00:55	SPEAKER_00
 So, yeah, this past week I've been mainly occupied with, um, getting some results from the SRI system trained on this short Hub 5 training set for the mean subtraction method.

0:01:09	SPEAKER_00
 I've done some tests last night, but, um, the results are suspicious. Um, it's, um, because they're the baseline results are worse than, um, Andreas, the results Andreas got previously.

0:01:22	SPEAKER_00
 And it could have something to do with, um, that's on digits.

0:01:26	SPEAKER_00
 That's on digits.

0:01:27	SPEAKER_00
 It could, it could have something to do with, um, down sampling. That's, that's worth looking into.

0:01:34	SPEAKER_00
 Um, and, um, a part of that, I guess, the main thing I have to talk about is, um, where I'm planning to go over the next week.

0:01:46	SPEAKER_00
 So, I've been working on integrating this mean subtraction approach into the smart com system.

0:01:51	SPEAKER_00
 And there's this question of, well, so, um, in my test before with HDK, I found it worked, it worked the best with about 12 seconds of data used to estimate the mean, but we'll often have less in the smart com system.

0:02:03	SPEAKER_00
 Um, so I think we'll use as much data as we have at a particular time, and we'll, we'll concatenate utterances together, um, to get as much data as we possibly can from the user.

0:02:16	SPEAKER_00
 But, um, there's a question of how to set up the models. So, um, we could train the models.

0:02:22	SPEAKER_00
 If we think 12 seconds is ideal, we could train the models using 12 seconds to calculate the mean to mean subtract the training data, or we could, um, use some other amount.

0:02:35	SPEAKER_00
 So, like I did an experiment where I, um, was using six seconds in test.

0:02:42	SPEAKER_00
 Um, but I tried 12 seconds in train, and I tried, um, the same in train. I tried six seconds in train, and six seconds in train was about 0.3% better.

0:02:58	SPEAKER_00
 Um, and, um, it's not clear to me yet, whether that's something significant. So, I want to do some tests and, um, actually make some plots of, um, for a particular amount of data in test, what happens if you vary the amount of data in train.

0:03:18	SPEAKER_06
 I don't know if you'd follow the stuff, but this is, uh, a, uh, long term, long term window, FFTs. Yeah, we'll be talking about it.

0:03:34	SPEAKER_00
 So, I was, I actually ran the experiments mostly. You know, I was, I was hoping to have the plots with me today. I just didn't get to it. But, um, yeah, I would be curious about people's feedback on this, because I'm, I think there are some, I think this is kind of like a bit of a tricky engineering problem, trying to figure out what's the optimal way to set this up.

0:03:56	SPEAKER_00
 So, um, I'll try to make the plots and then put some post script up on my, on my web page, and I'll mention my status report if you want to take a look.

0:04:05	SPEAKER_06
 You can clarify something for me. You're saying 0.3%. You take a 0.3% hit when the training and testing links aren't don't match or something. Is that what it is?

0:04:16	SPEAKER_00
 Well, I don't think it's just for any mismatch. Yeah. Take a hit. In some cases, it might be better to have a mismatch. Yeah. Like, I think I saw something like, like if you only have two seconds in test, or, um, maybe it was something like four seconds, you actually do a little better if you, um, train on six seconds. And if you train on four seconds.

0:04:40	SPEAKER_00
 Um, but the case that with the 0.3% hit was using six seconds in test, um, comparing train on 12 seconds versus train on six seconds, which was worse, the train on 12 seconds.

0:04:54	SPEAKER_06
 Okay, but 0.3% from what to what? That's 0.3%.

0:04:59	SPEAKER_00
 Um, the, the accuracies went from it was something vaguely like 95.6 accuracy, um, improved to 95.9. What I, what I, 4.4 to 4.1.

0:05:12	SPEAKER_06
 Okay. So, yeah. So about about an 8%, uh, 78% relative. Okay.

0:05:19	SPEAKER_06
 Um, yeah. Well, I think, you know, if you're going for an evaluation system, you'd care, but if you were doing a live system of people are actually using nobody would notice, I think the thing is to get something that's practical.

0:05:34	SPEAKER_00
 That's interesting. I see a point. I guess I was thinking of it as, um, an interesting research problem. Yeah.

0:05:43	SPEAKER_00
 I was thinking for the ASRU paper, we could have a section saying for smart com, we, we tried this approach in an interactive system, which I don't think has been done before.

0:05:55	SPEAKER_00
 And, and then there was two research questions from that. And one is that does it still work if you just use the past history.

0:06:02	SPEAKER_00
 And the other was this question of, um, that was just talking about now. So I guess that's why I thought it was interesting.

0:06:08	SPEAKER_06
 So, um, the time FFT, short time Keptstrom calculation, uh, mean, mean calculation work that people have in commercial systems, they do this all the time.

0:06:19	SPEAKER_06
 They, they calculated from previous utterances. Yes. But, but, uh, as you say, there hasn't been that much of this long, long time, uh, specter work.

0:06:29	SPEAKER_06
 Oh, oh, okay. So that's, that's, that's standard. Uh, pretty common. Yeah. Okay. Um, but, uh, yeah. So it is interesting.

0:06:37	SPEAKER_06
 I mean, there's two sides to these really small, uh, gradations and performance. Um, I mean on the one hand, in a practical system, if something is, uh, 4.4% error, 4.1% error, people won't really tell it to be able to tell the difference.

0:06:51	SPEAKER_06
 On the other hand, when you're doing, uh, research, you may, you might find that the way that you build up a change from a 95% accurate system to a 98% accurate system is through 10 or 12 little things that you do that each are 0.3%.

0:07:06	SPEAKER_06
 So, so they, they, it's, I don't mean to say that they're, they're irrelevant. Uh, they are relevant. But, um, for a demo, you won't see it. Right. Okay.

0:07:20	SPEAKER_00
 And, um, let's, let's see. Um, okay. And then there's another thing I want to start looking at. Um, with is the choice of the analysis window length. So I've just been using two seconds just because that's what Carlos did before.

0:07:39	SPEAKER_00
 Um, I wrote to him asking about how he chose the two seconds and it seemed like he chose it a bit informally. So, um, with it with the HDK setup, I should be able to do some experiments. Um, just varying that length, say between one and three seconds in a few different reverberation conditions.

0:07:59	SPEAKER_00
 Say this room and also a few of the artificial impulse responses we have for reverberation, just making some plots and seeing how they look. And, um, so with the sampling rate I was using one second or two seconds or four seconds is a power of two.

0:08:19	SPEAKER_06
 Um, number of samples and, um, I'll, I'll do for the ones in between. I guess I'll just zero pad. I guess one thing that might also be an issue. Um, it's part of what you're doing is you're getting a spectrum over a bunch of different kinds of speech sounds.

0:08:36	SPEAKER_06
 Um, and so it might matter how fast someone was talking. Oh, you know, if, if, if there's a lot of phones in one second, maybe you'll get a really good sampling of all these different things. And, uh, on the other hand, someone's talking slowly, maybe you need more.

0:08:53	SPEAKER_06
 So I don't know if you have some samples of faster or slower speech, but it might make a difference. I don't know.

0:09:01	SPEAKER_00
 Yeah, I don't, I don't think the TI digits data that I have, um, it would be appropriate. Yeah.

0:09:11	SPEAKER_00
 What would you, what about if I fed it through some kind of, um, speech processing algorithm that changed the speech rate?

0:09:19	SPEAKER_06
 Yeah, but then you'll have the degradation of, uh, whatever you do, uh, add it onto that. But maybe, yeah, maybe if you get something that sounds that does a pretty good job at that.

0:09:31	SPEAKER_00
 Yeah. Well, I just, if you think it's worth looking into, I mean, it is getting a little away from reverberation.

0:09:36	SPEAKER_06
 Um, yeah. It's just that you're making a choice. I was thinking more from the system aspect. If you're making a choice for smart com, that, that, that it might be that it's.

0:09:46	SPEAKER_06
 The optimal number could be different. Right. Yeah. Could be.

0:09:55	SPEAKER_00
 And then the third thing, um, I was, um, very explained LDA filtering to me yesterday. And so, um, Mike, Sharon is thesis, um, did a series of experiments, um, training LDA filters in different conditions.

0:10:14	SPEAKER_00
 And you were interested in having me repeat this for, for this mean subtraction approach. Is that right? Or for these long analysis windows, I guess is the right way to put it?

0:10:23	SPEAKER_06
 I guess the, the issue I was, the general issue I was bringing up was that if you're, have a moving, moving window, uh, a set of weights, times things that, uh, move along, shift along in time, that you have, in fact, a linear time and varying filter.

0:10:43	SPEAKER_06
 And you just happen to have picked a particular one by setting all the weights to be equal. And so the issue is what are some other filters that you could use in that sense of filter.

0:10:55	SPEAKER_06
 And, um, as I was saying, I think the simplest thing to do is not to train anything, but just to do some sort of, uh, hamming or handing, right, kind of window, kind of thing, just sort of the, the emphasize the journey.

0:11:07	SPEAKER_06
 So I think that would sort of be the first thing to do. But then, yeah, the LDA is, is interesting because it would sort of say, well, suppose you actually trained this up to do the best you could by some criterion.

0:11:19	SPEAKER_06
 What would the filter look like that? And, um, that sort of we're doing in this, uh, Aurora stuff. And, uh, it's still not clear to me in the long run whether the best thing to do would be to do that or to have some stylized version of the filter that looks like these things you've trained up because, um, you always have the problem that it's trained up for one condition isn't quite right for another. So, uh, that's, that's why that's why the rest of the filter is actually ended up lasting a long time.

0:11:48	SPEAKER_06
 People still using it quite a bit because you don't change it. So it doesn't get any worse.

0:11:53	SPEAKER_00
 Okay, so, um, actually, I was just thinking about what I was asking about earlier, which is about having less than, say, 12 seconds in the smart calm system to do the mean subtraction.

0:12:10	SPEAKER_00
 You said in systems where you kept still mean subtraction, they can catenate utterances. And do you know how they address this issue of testing versus training?

0:12:21	SPEAKER_03
 I think what they do is they do it always online. I mean that you just take what you have from the past that you calculate some mean of this and subtract some mean.

0:12:33	SPEAKER_03
 Okay. Um, then you can, you can increase your window. Why do I get, why do I get more samples?

0:12:43	SPEAKER_00
 Okay. Um, and so, so in that, in that case, what, what do they do when they're performing the capital mean subtraction on the training data?

0:12:54	SPEAKER_00
 So because you'd have hours and hours of training data. So do they cut it off and start over at intervals or.

0:13:02	SPEAKER_03
 So do you have, you mean you have files which are hours of hours alone or?

0:13:08	SPEAKER_03
 Well, no, I guess not. I mean, usually you have in the training set, you have similar conditions. I mean, file links are, I guess, the same order or the same size for test data.

0:13:22	SPEAKER_00
 Okay. But it's okay. So if someone's interacting with the system, Morgan, Morgan said that you would tend to chain utterances together.

0:13:31	SPEAKER_06
 Well, I think what I was, I thought what I was saying was that, um, at any given point, you are going to start off with what you had from before.

0:13:40	SPEAKER_06
 From, and so if you're splitting things up into utterances, so for instance, in a dialogue system, where are you going to be asking for some information?

0:13:48	SPEAKER_06
 There's some initials of something. And, you know, the first time out, you might have some general average, but you don't have very much information yet.

0:13:57	SPEAKER_06
 But after they've given one utterance, you've got something. You can compute your mean capture from that and then can use it for the next thing that they say, so that, you know, the performance should be better that second time.

0:14:09	SPEAKER_06
 And I think the heuristics of exactly how people handle that and how they handle their training. I'm sure very from place to place, but I think the ideally it seems to me anyway that you, you would want to do the same thing in training as you do in test.

0:14:24	SPEAKER_06
 But that's just a prejudice. And I think anybody, and this with some particular task, we experiment.

0:14:31	SPEAKER_00
 I guess the question I had was, um, amount of data was the amount of data that you give it to, um, update this estimate because say you, if you have say 5,000 utterances in your training set, um, and you keep the mean from the last utterance by the time it gets to the 5,000 utterances.

0:14:51	SPEAKER_06
 So those are all different people with different, I mean, in, so for instance, in the telephone task, these are different phone calls, so you don't want to chain it together from a different phone call.

0:15:01	SPEAKER_06
 Okay, so, so they would, so it's within speaker, within phone call, if the dialogue system, it's within whatever this characteristic you're trying to get rid of is expected to be consistent over.

0:15:12	SPEAKER_00
 Right, and, right, okay, so you, in so in training, you would start over at every new phone call or at every new speaker. Yeah, okay.

0:15:21	SPEAKER_06
 Now, you know, maybe do something from the others just because at the beginning of a call, you don't know anything.

0:15:26	SPEAKER_06
 So you might have some kind of general thing that's your best guess to start with.

0:15:30	SPEAKER_06
 So I, you know, a lot of these things are proprietary, so we're doing a little bit of guesswork here.

0:15:35	SPEAKER_06
 And what do, what do people do who really face these problems in the field? Well, they have companies, they don't tell other people exactly what they do.

0:15:42	SPEAKER_06
 But, but I mean, when you, the hints that you get from what they, when they talk about it, or that they do, they all do something like this.

0:15:48	SPEAKER_00
 Right, okay, I see. Because I, so this smart contest, first of all, it's this TV and movie information system.

0:15:55	SPEAKER_06
 Yeah, but you might have somebody who's using it. And later you might have somebody else using it.

0:16:00	SPEAKER_00
 Right. I see. I was about to say. So if you ask it, what, what movies are on TV tonight?

0:16:05	SPEAKER_00
 If I look at my wristwatch, when I say that, it's about two seconds.

0:16:08	SPEAKER_00
 Yeah. So when I currently have the mean subtraction, set up the analysis windows two seconds.

0:16:14	SPEAKER_00
 So what you just said about what do you start with raises a question of what do I start with then? I guess it, because...

0:16:20	SPEAKER_06
 Well, okay. So in that situation, though, maybe it's a little different there is, I think you're talking about there's only one...

0:16:28	SPEAKER_06
 It, it, it also depends. We're getting a little off track here.

0:16:31	SPEAKER_06
 Oh, right. But, but, but, there's been some discussion about whether the work we're doing in that project is going to be for the kiosk or for the mobile or for both.

0:16:41	SPEAKER_06
 And I think for this kind of discussion, it matters. If it's in the kiosk, then the physical situation is the same.

0:16:48	SPEAKER_06
 It's going to, you know, the exact interaction with the microphones is going to differ depending on the person and so forth, but at least the basic acoustics are going to be the same.

0:16:55	SPEAKER_06
 So if it's really in one kiosk, then I think that you could just chain together and, you know, as much as much speech as possible to, because what you're really trying to get at is the reverberation characteristic.

0:17:09	None
 Yeah.

0:17:09	SPEAKER_06
 But in, in the case of the mobile, presumably the acoustics is changing all over the place.

0:17:15	SPEAKER_06
 Right.

0:17:16	SPEAKER_06
 And in that case, you probably don't want to have it be endless, because you want to have some sort of, it's a question of how long do you think it's, you can get an approximation to a stationary something that it's not really stationary.

0:17:28	SPEAKER_06
 Right.

0:17:29	SPEAKER_00
 Right.

0:17:30	SPEAKER_00
 I, I guess I just started thinking of another question, which is for the very first frame, what, what do I do if I, if I take, if I use that frame to calculate the mean, then I'm just going to get nothing.

0:17:43	SPEAKER_00
 Right.

0:17:44	SPEAKER_00
 Right. So I should probably have some kind of default, mean for the first couple of frames.

0:17:50	SPEAKER_00
 Okay.

0:17:51	SPEAKER_06
 Or subtract nothing.

0:17:52	SPEAKER_00
 I mean, it's, or subtract nothing.

0:17:54	SPEAKER_00
 And that's, I guess that's something that's, people have figured out how to deal with in capstone mean subtraction as well.

0:18:00	SPEAKER_06
 Yeah, people do something.

0:18:01	SPEAKER_06
 They, they, they have some, in, in capstone mean subtraction for short term window analysis windows, as is usually done.

0:18:13	SPEAKER_06
 You're trying to get rid of some very general characteristic.

0:18:17	SPEAKER_06
 And so, if you have any other information about what a general kind of characteristic would be, then you can do it there.

0:18:24	SPEAKER_08
 You can also reflect the data.

0:18:26	SPEAKER_08
 So you take, you know, I'm not sure how many frames you need, but if you take that many from the front, flip it around.

0:18:34	SPEAKER_08
 Yeah, that's the negative values.

0:18:36	SPEAKER_06
 Yeah.

0:18:37	SPEAKER_06
 The other thing is that, and I remember BBN doing this is that if you have a multi pass system, if the first pass takes, it takes most of the computation.

0:18:50	SPEAKER_06
 The second and the third pass could be very, very quick, just looking at a relatively small, small space of hypotheses.

0:18:58	SPEAKER_06
 Then you can do your first pass without any subtraction at all.

0:19:02	SPEAKER_06
 And then your second pass eliminates those, most of those hypotheses by, by having improved, improved version of the analysis.

0:19:14	SPEAKER_00
 So, so that was all I had.

0:19:17	SPEAKER_00
 Yeah.

0:19:18	SPEAKER_05
 Okay, so for the past week or two, I've been just writing my formal thesis proposal. So I'm taking this qualifier exam, it's coming up in two weeks.

0:19:35	SPEAKER_05
 I finished writing a proposal and submit to the committee.

0:19:42	SPEAKER_05
 And should I explain more about what I'm proposing to do this?

0:19:49	SPEAKER_05
 Brief.

0:19:50	SPEAKER_05
 Okay. So briefly, I'm proposing to do a new approach to speech recognition, a combination of multi band ideas and ideas about the acoustic phonetic approach to speech recognition.

0:20:10	SPEAKER_05
 So I will be using these graphical models that implement the multi band approach to recognize a set of intermediate categories that might involve things like phonetic features or other feature things that are more closely related to the acoustic signal itself.

0:20:32	SPEAKER_05
 And the hope in all this is that by going multi band and by going into these intermediate classifications that we can get a system that's more robust to unseen noises and situations like that.

0:20:49	SPEAKER_05
 And so some of the research issues involved in this are what kind of intermediate categories do we need to classify? Another one is what other types of structures in these multi band graphical models should we consider in order to combine evidence from the sub-ant.

0:21:14	SPEAKER_05
 And the third one is how do we merge all the information from the individual multi band classifiers to come up with word recognition or from recognition.

0:21:29	SPEAKER_05
 So basically that's what I've been doing two weeks.

0:21:34	SPEAKER_05
 I got two weeks to brush up on presentation.

0:21:40	SPEAKER_06
 So I thought you were finishing your thesis in two weeks.

0:21:45	SPEAKER_08
 Oh that too.

0:21:47	SPEAKER_05
 Are you going to do any dry runs for your finger?

0:21:50	SPEAKER_05
 Yes.

0:21:51	SPEAKER_05
 I'm going to do some.

0:21:53	SPEAKER_05
 Would you be interested?

0:21:54	SPEAKER_05
 Sure.

0:21:55	SPEAKER_05
 I hope that.

0:21:57	SPEAKER_08
 Is that it?

0:21:58	SPEAKER_08
 That's it.

0:21:59	SPEAKER_08
 Okay.

0:22:00	SPEAKER_08
 Let's see.

0:22:01	SPEAKER_08
 So we've got 40 minutes left.

0:22:03	SPEAKER_08
 It seems like there's a lot of material.

0:22:05	SPEAKER_08
 Any suggestions about where we should go next?

0:22:09	None
 Yeah.

0:22:10	SPEAKER_02
 Actually, most of these in our last meeting with Ginter.

0:22:18	SPEAKER_02
 But I'll just.

0:22:19	SPEAKER_02
 So the last week I showed some results with only speech thread curve, which was like some 56% and I didn't.

0:22:27	SPEAKER_02
 I mean, I found out the results.

0:22:29	SPEAKER_02
 I mean, I wasn't getting that results on the TI digit.

0:22:32	SPEAKER_02
 So I was like looking into what is wrong with the TI digits.

0:22:35	SPEAKER_02
 Why I was not getting it and I found that the noise estimation is the reason for the TI digits to perform worse than the baseline.

0:22:43	SPEAKER_02
 So I actually, I mean, the first thing I did was I just scaled the noise estimate by a factor which is less than 1 to see if that.

0:22:50	SPEAKER_02
 Because I found that a lot of zeros in the spectrogram for the TI digits when I use this approach.

0:22:56	SPEAKER_02
 So the first thing I did was I just scaled the noise estimate and I found.

0:22:59	SPEAKER_02
 So the results that I have shown here are the complete results using the new, the new technique is nothing but the noise estimate scale by a factor of 0.5.

0:23:08	SPEAKER_02
 So it's just an id hoc.

0:23:10	SPEAKER_02
 I mean, some intermediate result because it's not optimized for anything.

0:23:13	SPEAKER_02
 So the results that trend, the only trend I could see from those results was like the current noise estimation or the noise composition scheme is working good for like the car noise type of thing.

0:23:26	SPEAKER_02
 Because I've the only very good result in the TI digits is the noise car noise condition for the test A which is like the best I could see that for any non stationary noise like Babel or subway or any street some restaurant noise.

0:23:44	SPEAKER_02
 It's like it's not performing very well.

0:23:48	SPEAKER_02
 So that's the first thing I could make out from this stuff.

0:23:56	SPEAKER_03
 I think what is important to see is that there is a big difference between the training modes.

0:24:01	SPEAKER_03
 If you have clean training, you get also a 50% improvement.

0:24:06	SPEAKER_03
 But if you have multi-condition training, you get only 20%.

0:24:10	SPEAKER_02
 And in that 20% is very inconsistent across different noise conditions. So I have like a 45% for car noise and then there's a minus 5% for the Babel and there is a 33% for the station.

0:24:24	SPEAKER_02
 And so it's not actually very consistent across.

0:24:28	SPEAKER_02
 So the only correlation between the speech.car and this performance is the stationarity of the noise that is there in these conditions and the speech.car.

0:24:37	SPEAKER_02
 So the overall result is like in the last page which is like 47% which is still very imbalanced because I have like 56% on speech.car and 35% on the TI digits.

0:24:49	SPEAKER_02
 And the 56% is like comparable to what the French telecom gets but 35% is way off.

0:24:59	SPEAKER_06
 So I can fuse but looking at the second page and it says 50% looking in the lower right hand corner, 50% relative performance.

0:25:12	SPEAKER_03
 For the clean training.

0:25:14	SPEAKER_06
 Is that if you look at 50% improvement?

0:25:19	SPEAKER_02
 That's for the clean training and the noise you're testing for the i digits.

0:25:23	SPEAKER_06
 So it's improvement over the baseline melcapstrom. But the baseline melcapstrom under those training doesn't do as well.

0:25:33	SPEAKER_06
 I'm trying to understand why it's 80% that's an accuracy number I guess right?

0:25:38	SPEAKER_06
 So that's not as good as the one up above.

0:25:41	SPEAKER_06
 But the 50 is better than the one up above so I'm confused.

0:25:45	SPEAKER_02
 Actually the noise composition whatever we are putting in it works very well for the high mismatched condition.

0:25:51	SPEAKER_02
 When it's consistent in the speech.car and in the clean training also it gives but this 50% is that the high mismatched performance.

0:26:01	SPEAKER_02
 It's equivalent to the high mismatched performance.

0:26:03	SPEAKER_08
 So since the high mismatched performance is much worse to begin with, it's easier to get it.

0:26:08	SPEAKER_02
 So by putting this noise.

0:26:11	SPEAKER_04
 Yeah if we look at the figures on the right we see that the reference.

0:26:16	SPEAKER_02
 The reference drops like a way of life.

0:26:18	SPEAKER_04
 Oh my gosh.

0:26:24	SPEAKER_06
 This is T.I. digits?

0:26:27	SPEAKER_02
 Yeah.

0:26:29	SPEAKER_02
 Yeah it's not written anywhere.

0:26:31	SPEAKER_02
 It's the first spreadsheet is T.I. digits.

0:26:33	SPEAKER_06
 How does clean training do for the car?

0:26:39	SPEAKER_02
 The car still that's still consistent.

0:26:42	SPEAKER_02
 I mean I get the best performance in the case of car which is the third column in the A condition.

0:26:47	SPEAKER_06
 No I mean this is added noise.

0:26:49	SPEAKER_06
 I mean this is T.I. digits.

0:26:50	SPEAKER_06
 I'm sorry I'm in the multi-language.

0:26:54	SPEAKER_02
 That's the next spreadsheet.

0:26:58	SPEAKER_02
 So that is the performance for Italian, Finnish and Spanish.

0:27:04	SPEAKER_06
 Training condition.

0:27:06	SPEAKER_06
 Oh right so clean it corresponds to the high mismatched.

0:27:10	SPEAKER_06
 And increase.

0:27:13	SPEAKER_02
 That's increase improvement.

0:27:17	SPEAKER_02
 That percentage increases the percentage improvement of the baseline.

0:27:20	SPEAKER_06
 Which means decrease in order right?

0:27:23	SPEAKER_06
 Yep.

0:27:24	SPEAKER_06
 Okay so percentage increase means decrease.

0:27:27	SPEAKER_03
 Okay.

0:27:30	SPEAKER_03
 There was a very long discussion about this on the answer of meeting.

0:27:36	SPEAKER_03
 How to calculate it.

0:27:39	SPEAKER_03
 I guess you are using finally this key which is that in the spreadsheet.

0:27:42	SPEAKER_02
 I'm not changing anything in there.

0:27:45	SPEAKER_02
 So yeah so all the HM numbers are very good.

0:27:53	SPEAKER_02
 And the percentage they are better than what the French League of Cats.

0:27:58	SPEAKER_02
 But the only number that's still I mean which Stefan also guarding is resolved was that medium mismatch of the Finnish which is a very strange situation where we use the we change the proto for initializing the HM.

0:28:13	SPEAKER_02
 I mean this is basically because it gets stuck in some local minimum in the training.

0:28:17	SPEAKER_02
 That's 75.79 in the Finnish mismatch which is that the 11.96 what do you see?

0:28:26	SPEAKER_06
 We have to jiggle it somehow.

0:28:28	SPEAKER_02
 Yeah so we start with the difference proto and it becomes 88 which is like some 50% improvement.

0:28:35	SPEAKER_02
 We'll start with a different one.

0:28:36	SPEAKER_02
 Different prototype which is like a different initialization for the transition probabilities.

0:28:43	SPEAKER_02
 The right now the initialization is to stay more in the current state which is 0.4.6 right?

0:28:48	SPEAKER_02
 Yeah.

0:28:49	SPEAKER_02
 And if you change it to 0.5.5 which is equal the voltage for transition and self-loop when it becomes 88%.

0:28:55	SPEAKER_08
 So that involves mucking with the back end?

0:28:57	SPEAKER_08
 Yeah we can't do it.

0:28:59	SPEAKER_07
 Yeah.

0:29:02	SPEAKER_03
 It is well known this medium-match condition of the Finnish data is very strange effects.

0:29:09	SPEAKER_02
 It has a very few words also it's very very small said actually.

0:29:15	SPEAKER_03
 There is a lot of utterances with music and the background.

0:29:22	SPEAKER_02
 It has a musicals.

0:29:24	SPEAKER_02
 I mean very audible music like you can.

0:29:29	SPEAKER_06
 So maybe for that one you need a much smarter V80.

0:29:36	SPEAKER_02
 So that's about the results.

0:29:45	SPEAKER_02
 The summary is like okay so the other thing I tried was which I explained in the last meeting is using the channel 0 for both dropping and estimating the noise.

0:30:00	SPEAKER_02
 And that's like just to get a feel of how good it is.

0:30:03	SPEAKER_02
 And it gets the 56% improvement in the speech that car becomes like 67% like 10% better.

0:30:09	SPEAKER_02
 But that's not a cheating experiment.

0:30:14	SPEAKER_03
 But the 47.9% which you have now sets already a remarkable improvement in comparison to the first proposal.

0:30:23	SPEAKER_02
 Yeah so we had 44% in the first proposal.

0:30:29	SPEAKER_02
 So the major improvement that we got was in all the high mismatch cases because all those numbers were in 60s and 70s because we never had in our compensations.

0:30:39	SPEAKER_02
 So that's where the biggest improvement came up not much in the well match and the medium match and the iDG it's also right now.

0:30:46	SPEAKER_02
 So this is still a 3 or 4% improvement over the first proposal.

0:30:51	SPEAKER_06
 Yeah so that's good.

0:30:54	SPEAKER_06
 So we can improve the noise estimation.

0:30:57	SPEAKER_03
 Yeah I started thinking about that.

0:30:59	SPEAKER_03
 I mean I discovered the same problem when I started working on this Aurora task almost two years ago that you have the problem with this multi.

0:31:09	SPEAKER_03
 At the beginning we had only this multi-conditioned training of the t iDG and I found the same problem just taking what we were used to use.

0:31:18	SPEAKER_03
 I mean some type of spectral subtraction you get even worse results in the basis.

0:31:24	SPEAKER_03
 Yeah I tried to find an explanation for it.

0:31:30	SPEAKER_02
 Yes Stefan also has the same experience of using the spectral subtraction right.

0:31:36	SPEAKER_02
 So here I mean I found that if I change the noise estimate I could get an improvement.

0:31:42	SPEAKER_02
 So something which I can actually pursue is the noise estimate.

0:31:49	SPEAKER_03
 Yeah I think what you do is when you have this multi-conditioned training mode then you can train models for the speech, for the words as well as for the pauses where you really have all information about the noise available.

0:32:08	SPEAKER_03
 It was surprising at the beginning it was also surprising to me that you get really the best results when doing it this way.

0:32:14	SPEAKER_03
 I mean in comparison to any type of training on clean data and any type of processing but it was so it seems to be the best what we can do in this moment with this multi-conditioned training.

0:32:28	SPEAKER_03
 And when we now start introducing some noise reduction technique we introduce also some how artificial distortions.

0:32:38	SPEAKER_03
 And this artificial distortions I have the feeling that they are the reason why we have the problems in this multi-conditioned training.

0:32:45	SPEAKER_03
 I mean the HMM suit chains they are based on gossians and modeling gossians.

0:32:52	SPEAKER_03
 And can I move a little bit with this?

0:33:00	SPEAKER_03
 And if we introduce now this spectral subtraction or wiener filtering stuff.

0:33:05	SPEAKER_03
 So usually what you have is maybe I'm showing now an adulope, maybe first time.

0:33:14	SPEAKER_03
 So usually in clean condition you have something which looks like this and if it is noisy it is somewhere here.

0:33:24	SPEAKER_03
 And then you try to subtract it or wiener filter or whatever.

0:33:28	SPEAKER_03
 And what you get is you have always these problems that you have these zeros in there.

0:33:34	SPEAKER_03
 And you have to do something if you get these negative values.

0:33:36	SPEAKER_03
 I mean this is your noise estimate and you somehow subtract it or do whatever.

0:33:41	SPEAKER_03
 And then you have, and then I think what you do is you introduce some artificial distribution in this model.

0:33:51	SPEAKER_03
 I mean you train it also this way but somehow there is no longer a gossian distribution.

0:33:58	SPEAKER_03
 It is somehow a strange distribution which we introduce with this artificial distortions.

0:34:03	SPEAKER_03
 And I was thinking that that might be the reason why you get these problems especially in the multi-conditioned training.

0:34:10	SPEAKER_02
 The models are not complex enough to absorb that additional variability that you are introducing.

0:34:21	SPEAKER_04
 I also have the feeling that the reason why it doesn't work is that the models are not complex enough.

0:34:31	SPEAKER_04
 Because I actually always had a good experience with spectral subtraction, just a straight spectral subtraction algorithm when I was using neural networks, big neural networks which maybe are more able to model strange distributions.

0:34:48	SPEAKER_04
 But yeah, then I tried exactly the same spectral subtraction algorithm on these Aurora tasks and it simply doesn't work. It's even the Earths.

0:35:01	SPEAKER_06
 We probably should at some point here try the tandem, the system two kind of stuff with this with the spectral subtraction for that reason.

0:35:09	SPEAKER_06
 Because again it should do a transformation to the main war maybe. It looks more gossian.

0:35:15	SPEAKER_03
 Yeah, I was just yesterday when I was thinking about it.

0:35:22	SPEAKER_03
 What we could try to do about it, I mean if you get at this situation that you get this negative failure, you simply set it to zero or to a constant or whatever.

0:35:34	SPEAKER_03
 If we would use some random generator which has a certain distribution, not a certain special distribution, we have to think about it.

0:35:47	SPEAKER_03
 And so we introduce again some natural behavior in this trajectory.

0:35:54	SPEAKER_02
 Very different from speech.

0:35:56	SPEAKER_03
 I mean it shouldn't confuse them. Yeah, similar to what you see really in the real noisy situation or in the clean situation but somehow a natural distribution.

0:36:12	SPEAKER_06
 This nots again sort of the idea of the additive thing as we head in the J stuff. Basically if you have random data in the time domain, then we look at this spectrum, it's going to be pretty flat.

0:36:35	SPEAKER_06
 So just add something everywhere rather than just in those places. It's just a constant.

0:36:44	SPEAKER_03
 I think it's just especially in this segment I mean you introduce some very artificial behavior.

0:36:51	SPEAKER_06
 Yeah, we see if you add something everywhere it has almost no effect up on top. And it has significant effect down there.

0:37:04	SPEAKER_02
 That's true. Those regions are the cost for this big radiation. Those negative values and whatever you get.

0:37:13	SPEAKER_03
 We could think how what we could try. It was just an idea.

0:37:21	SPEAKER_06
 I think it was noisy. People should just speak up.

0:37:31	SPEAKER_04
 Look at the French Silicon proposal. They use some kind of noise addition. They have a random number generator right.

0:37:39	SPEAKER_04
 They add noise on the trajectory of the low energy.

0:37:45	SPEAKER_04
 Cicero low energy.

0:37:50	SPEAKER_04
 But I don't know much effect.

0:37:54	SPEAKER_04
 So it is similar to what I think because they have to log energy.

0:38:01	SPEAKER_04
 Yeah. And then just generate random number. They have some kind of mean and variance.

0:38:06	SPEAKER_04
 And they add this number to the log energy simply.

0:38:12	SPEAKER_02
 So the log energy after the cleaning up. So they add a random noise to it.

0:38:18	SPEAKER_06
 To the just the energy or to the to the male filter only to the log energy.

0:38:24	SPEAKER_06
 So because I mean I think this is most interesting for the male filters.

0:38:29	SPEAKER_06
 Right. Or FFTs one of the other.

0:38:35	SPEAKER_03
 But they do not apply filtering of the low energy or what?

0:38:41	SPEAKER_03
 Like like like spectral subtraction.

0:38:44	SPEAKER_02
 No, their filter is in the time domain.

0:38:47	SPEAKER_02
 Yeah. So they filter the time signal and then what are they calculate from this low energy?

0:38:53	SPEAKER_02
 Yeah. And after that it is almost the same as the baseline system.

0:38:58	SPEAKER_02
 And then the final log energy that they get that that they add some random noise.

0:39:03	SPEAKER_06
 Yeah, but again it's just log energy as opposed to.

0:39:06	SPEAKER_02
 Yeah. So it's not the right. Yeah. It's not the male filter bank output.

0:39:10	SPEAKER_02
 This is a log energy computed from the time domain signal or from the male filter banks.

0:39:17	SPEAKER_04
 So maybe it's just a way to decrease the importance of this particular parameter in the world feature vector.

0:39:24	SPEAKER_04
 If you add noise to one of the parameters you want to flat-ribute.

0:39:28	SPEAKER_02
 The variance here reduced.

0:39:32	SPEAKER_06
 So it could reduce the dependence on the amplitude.

0:39:37	SPEAKER_03
 So maybe.

0:39:44	SPEAKER_02
 So. So the other thing is just looking at a little bit on the delay issue where the delay of the system is like 180 millisecond.

0:39:56	SPEAKER_02
 So I just just tried another system.

0:40:00	SPEAKER_02
 I mean another filter which I've like shown at the end, which is very similar to the existing filter.

0:40:07	SPEAKER_02
 Only thing that the phase is like a totally non-linear phase because it's a it's not a symmetric filter anymore.

0:40:12	SPEAKER_02
 This is for the all the A. Yeah. So this like so this makes the delay like zero for the LDA because it's completely causal.

0:40:21	SPEAKER_02
 So I got actually just the results for the Italian for that and that's like so the 51.09 has become 48.06 which is like 3% relative degradation.

0:40:33	SPEAKER_02
 So I have like the 51.09.

0:40:36	SPEAKER_02
 So I know how it fares for the other conditions. So it's like a 3% relative degradation.

0:40:44	SPEAKER_03
 But is there a problem of the 180 millisecond?

0:40:51	SPEAKER_03
 Well, I mean I talked about it with Ufine.

0:40:55	SPEAKER_06
 So basically our position is that we shouldn't be unduly constraining the latency at this point because we're all still experimenting with trying to make the performance better in the presence of noise.

0:41:10	SPEAKER_06
 There is a minority in that group who is arguing who are arguing for having a further constraining of the latency.

0:41:21	SPEAKER_06
 So we're just continuing to keep aware of what the tradeoffs are and you know what do we gain from having longer or shorter latencies.

0:41:30	SPEAKER_06
 But since we always seem to at least get something out of longer latencies not being so constrained we're tending to go with that if we're not told we can't do it.

0:41:40	SPEAKER_08
 Where was the smallest latency of all the systems last time?

0:41:45	SPEAKER_06
 Well, the French Telecom was was was very short latency and they had very good result of 35.

0:41:51	SPEAKER_06
 So it's possible to get very short latency but again we're the the approaches that we're using are ones that.

0:42:02	SPEAKER_06
 I was just curious about where we are.

0:42:05	SPEAKER_03
 But I think this 30 milliseconds it did not include the CDLT calculation.

0:42:11	SPEAKER_02
 This is included now.

0:42:14	SPEAKER_02
 If they include the Delta it will be additional 40 milliseconds.

0:42:21	SPEAKER_02
 Yeah, they're using a nine point window which is like a four on either side which is like.

0:42:28	SPEAKER_02
 They didn't include that.

0:42:34	SPEAKER_04
 Where does the compression compression and decoding delay comes from?

0:42:38	SPEAKER_02
 That's the way the the frames are packed like you have to wait for one more frame to pack because it's the CRC is computed for two frames all years.

0:42:47	SPEAKER_06
 Well, they would need that 40 milliseconds also.

0:42:51	SPEAKER_02
 No, they actually change the compression scheme altogether.

0:42:53	SPEAKER_02
 So they have their own compression and decoding scheme and they know what they have but they have coded zero delay for that because they know they changed it.

0:43:02	SPEAKER_02
 The compression they have their own CRC their own error correction mechanism so they don't have to wait more one more frame to know whether the current frame is in error.

0:43:12	SPEAKER_02
 So they change the whole thing so that there's no delay for that compression and part also.

0:43:20	SPEAKER_02
 Even you have reported actually zero delay for the compression.

0:43:23	SPEAKER_02
 I don't know maybe you also have some different.

0:43:27	SPEAKER_03
 I think I used this scheme as it was before.

0:43:33	SPEAKER_08
 Okay, we've got 20 minutes.

0:43:38	SPEAKER_04
 Did you want to go next?

0:43:41	SPEAKER_04
 I can go next, you have.

0:43:52	SPEAKER_04
 Oh, it's a moment.

0:43:54	SPEAKER_04
 Yeah, you have to take my man.

0:43:57	SPEAKER_06
 I think I'm confused.

0:44:01	SPEAKER_04
 All right, so you have one sheet.

0:44:04	SPEAKER_04
 This one is you don't need it.

0:44:07	SPEAKER_04
 So you have to take the wall.

0:44:09	SPEAKER_04
 The five there should be five sheets.

0:44:11	SPEAKER_06
 Okay, I have four now because I left one with Dave because I thought I was dropping one off and passing the other's on.

0:44:16	SPEAKER_06
 So no, we're not.

0:44:18	None
 Thanks.

0:44:27	SPEAKER_04
 Maybe there's not enough.

0:44:33	SPEAKER_04
 Yeah, this.

0:44:36	SPEAKER_04
 So yeah, there are two figures showing actually the performance of the current VAD.

0:44:48	SPEAKER_04
 So it's a new run network based on VLP parameters, which estimate seconds probabilities.

0:44:54	SPEAKER_04
 And then I just put a median filtering on this to smooth the probabilities.

0:45:04	SPEAKER_04
 I didn't use the scheme that's currently in the proposal because I don't want to.

0:45:10	SPEAKER_04
 In the proposal, well, in the system, we want to add like speech frame before every word and a little bit of a couple of frames after also.

0:45:23	SPEAKER_04
 But to estimate the performance of the VAD, we don't want to do that because it would artificially increase the.

0:45:30	SPEAKER_04
 The false alarm rate of speech detection.

0:45:35	SPEAKER_04
 So there is normally a figure for a finish and one for Italian.

0:45:42	SPEAKER_04
 And maybe someone has two for Italian because I'm missing one figure there.

0:45:47	SPEAKER_04
 No.

0:45:51	SPEAKER_04
 Yeah, so one surprising thing that we can notice first is that apparently the speech miss rate is higher than the false alarm rate.

0:46:06	SPEAKER_03
 So what is the little curve?

0:46:09	SPEAKER_04
 Yeah, there are two curves.

0:46:11	SPEAKER_04
 One curves for the close talking microphone, which is the lower curve.

0:46:16	SPEAKER_04
 One is for the distant microphone, which has more noise.

0:46:21	SPEAKER_04
 It's logical that the performance works.

0:46:24	SPEAKER_04
 So as I was saying, the miss rate is quite important, which means that we tend to label speech as silence.

0:46:36	SPEAKER_04
 I didn't analyze further yet, but I think it's maybe due to the fricative sounds, which maybe in noisy condition, maybe labeled silence.

0:46:49	SPEAKER_04
 And it may also be due to the alignment because, well, the reference alignment, because right now I just used an alignment obtained from a system train on channel zero.

0:47:02	SPEAKER_04
 I checked it a little bit, but there might be alignment errors.

0:47:09	SPEAKER_04
 Like the fact that the model tend to align their first state on silence and their last state on silence also.

0:47:20	SPEAKER_04
 So the reference alignment would label as speech some silence frame before speech and after speech.

0:47:27	SPEAKER_04
 This is something that we already noticed before.

0:47:34	SPEAKER_04
 So this code also explained the miss rate, maybe.

0:47:38	SPEAKER_03
 And this curve has the average over low database law?

0:47:42	SPEAKER_04
 Yeah, right.

0:47:48	SPEAKER_04
 And the different points of the curve are for five thresholds on the probability from point three to point seven.

0:48:04	SPEAKER_04
 So the threshold is the first threshold on the probability that puts the values to zero or one.

0:48:15	SPEAKER_04
 And then the median filtering.

0:48:18	SPEAKER_02
 So the median filtering is fixed.

0:48:21	SPEAKER_04
 You just change the threshold.

0:48:24	SPEAKER_04
 So going from channel zero to channel one, almost double the error rate.

0:48:38	SPEAKER_04
 Well, so it's a reference performance that we can know if you want to work on the VAD.

0:48:45	SPEAKER_04
 We can work on this basis.

0:48:50	SPEAKER_05
 Okay.

0:48:51	SPEAKER_05
 Is this VAD MLP?

0:48:53	SPEAKER_05
 Yeah.

0:48:55	SPEAKER_04
 How big?

0:48:56	SPEAKER_04
 It's a very big one.

0:48:57	SPEAKER_04
 I don't remember.

0:48:58	SPEAKER_02
 350 inputs, 1000 hidden inputs and 12 outputs.

0:49:10	SPEAKER_06
 Middle sized one.

0:49:12	SPEAKER_07
 Yeah.

0:49:13	SPEAKER_04
 I don't know if you have questions about that or suggestions.

0:49:27	SPEAKER_04
 It seems the performance seems worse on finish.

0:49:30	SPEAKER_04
 Well, it's not trained on finish.

0:49:33	SPEAKER_06
 What's the train?

0:49:34	SPEAKER_02
 I mean, the MLP is not trained on finish.

0:49:36	SPEAKER_02
 Right.

0:49:37	SPEAKER_02
 What's the train?

0:49:38	SPEAKER_02
 Oh, sorry.

0:49:39	SPEAKER_02
 It's Italian.

0:49:40	SPEAKER_02
 Yeah, it is.

0:49:41	SPEAKER_02
 Oh, it's train.

0:49:42	SPEAKER_02
 Yeah.

0:49:43	SPEAKER_07
 Okay.

0:49:45	SPEAKER_04
 And also there are funny noises on finish more than on Italian.

0:49:50	SPEAKER_04
 I mean, like music.

0:49:51	SPEAKER_04
 Yeah, that's true.

0:49:55	SPEAKER_04
 So, yeah, we were looking at this.

0:49:57	SPEAKER_04
 But for most of the noises, noises are...

0:50:02	SPEAKER_04
 I don't know if we want to talk about that.

0:50:05	SPEAKER_04
 But the car noises are below like 500 Earth.

0:50:08	SPEAKER_04
 And we were looking at the music utterances.

0:50:11	SPEAKER_04
 And in this case, the noise is smaller about 2000 Earths.

0:50:15	SPEAKER_04
 Well, music energy is very low, apparently, from 0 to 2000 Earths.

0:50:23	SPEAKER_04
 So maybe just looking at this frequency range from 500 to 2000 would improve somewhat the VD.

0:50:35	SPEAKER_07
 Yeah.

0:50:37	SPEAKER_02
 So the world...

0:50:39	SPEAKER_02
 Some parameters we wanted to use or something.

0:50:46	SPEAKER_03
 So is the training based on this label files which you take as reference?

0:50:57	SPEAKER_03
 Well, it trains the neural net.

0:50:59	SPEAKER_04
 No, it's not.

0:51:01	SPEAKER_04
 It was trained on some alignment obtained.

0:51:08	SPEAKER_04
 For the Italian data, I think we trained a neural network with embedded training.

0:51:16	SPEAKER_04
 So, re-estimation of the alignment using the neural net work, yes.

0:51:19	SPEAKER_04
 Right?

0:51:20	SPEAKER_02
 Yeah, we actually trained on the Italian training part when we had another system.

0:51:27	SPEAKER_04
 So it was a phonetic classification system for the Italian or data.

0:51:32	SPEAKER_04
 For the other data that it was trained on, it was different. Like for the IDGETs, you used a word, a previous system that you added.

0:51:40	SPEAKER_04
 Yeah, yeah, that's true.

0:51:42	SPEAKER_04
 So the alignments from the different database that are used for training came from different system.

0:51:47	SPEAKER_04
 So system, then we put them together and you put them together and train the real.

0:51:53	SPEAKER_04
 Yeah.

0:51:55	None
 Yeah.

0:51:59	SPEAKER_04
 But did you use channel...

0:52:02	SPEAKER_04
 Did you align channel one or so?

0:52:04	SPEAKER_02
 I just took the entire Italian training part.

0:52:07	SPEAKER_02
 So it was both channel zero plus channel one.

0:52:10	SPEAKER_04
 So the alignments might be wrong on channel one.

0:52:13	SPEAKER_04
 You know what?

0:52:14	SPEAKER_04
 It's possible.

0:52:15	SPEAKER_04
 So we might...

0:52:16	SPEAKER_04
 Yeah.

0:52:17	SPEAKER_04
 We can do a real alignments.

0:52:18	SPEAKER_04
 So these ones to retrain these alignments, which should be better because they come from close to working.

0:52:23	SPEAKER_04
 Yeah, that was my idea.

0:52:25	SPEAKER_03
 I mean, if it's not the same labeling, which is taking the spaces.

0:52:28	SPEAKER_03
 Yeah, possible.

0:52:29	SPEAKER_03
 Yeah.

0:52:30	SPEAKER_02
 I mean, so the system, so the VAD was trained on maybe different set of labels for channel zero and channel one.

0:52:36	SPEAKER_02
 Because the alignments were different for...

0:52:40	SPEAKER_02
 Certainly different because they were independently trained.

0:52:42	SPEAKER_02
 We didn't copy the channel zero alignments to channel one.

0:52:45	SPEAKER_07
 Yeah.

0:52:46	SPEAKER_02
 But for the new alignments, what you generated, you just copy the channel zero to channel one, right?

0:52:53	None
 Yeah.

0:52:54	SPEAKER_04
 And actually, when we look at the VAD for some utterance, it's almost perfect.

0:53:04	SPEAKER_04
 I mean, just drop one frame, the first frame of speech.

0:53:09	SPEAKER_04
 So there are some utterances where it's almost 100% VAD performance.

0:53:16	SPEAKER_04
 But...

0:53:17	SPEAKER_04
 Yeah.

0:53:24	SPEAKER_04
 So the next thing is...

0:53:28	SPEAKER_04
 I have the spreadsheet for three different systems.

0:53:31	SPEAKER_04
 But for this, you only have to look right now on the speech data curve performance because I didn't test...

0:53:40	SPEAKER_04
 So I didn't test the spectrosuppraction on the IDGT yet.

0:53:44	SPEAKER_04
 So you have three sheets.

0:53:46	SPEAKER_04
 One is the proposal one system.

0:53:50	SPEAKER_04
 Actually, it's not exactly a proposal one.

0:53:52	SPEAKER_04
 It's the system that Sony will just describe.

0:53:57	SPEAKER_04
 But with Wiener filtering from...

0:54:02	SPEAKER_04
 Franz Telekom included.

0:54:07	SPEAKER_04
 So this gives like 57.7% error rate reduction on the speech data curve data.

0:54:20	SPEAKER_04
 And then I have two sheets where it's for a system where...

0:54:25	SPEAKER_04
 So it's again the same system, but in this case, we have spectrosuppraction with a maximum overestimation factor of 2.5.

0:54:34	SPEAKER_04
 There is smoothing of the gain trajectory with some kind of low pass filter, which has 40 milliseconds latency.

0:54:45	SPEAKER_04
 And then after subtraction, I add a constant to the energies.

0:54:52	SPEAKER_04
 And I have two cases where the first cases were the constant is 25 dB below the mean speech energy and the other is 30 dB below.

0:55:05	SPEAKER_04
 For this two system, we have like 55.5% improvement and 58.1.

0:55:16	SPEAKER_04
 So again, it's around 56.57.

0:55:24	SPEAKER_06
 As I know, the TI digit number is exactly the same for this last two.

0:55:28	SPEAKER_04
 Yeah, because I didn't...

0:55:30	SPEAKER_04
 For the Franz Telekom spectrosuppraction, including in our system, the TI digit number are the right one, but not for the other system.

0:55:39	SPEAKER_04
 Because I didn't test it yet, this system, including with spectrosuppraction on the TI digit data.

0:55:46	SPEAKER_04
 I just tested it on speech.com.

0:55:48	SPEAKER_04
 Ah, so that means the only thing...

0:55:50	SPEAKER_04
 You have two.

0:55:51	SPEAKER_06
 You just should look at that 58.09%.

0:55:55	SPEAKER_06
 Okay, good.

0:56:18	SPEAKER_02
 So by reducing the noise, the addition threshold to like minus 30 dB is like...

0:56:25	SPEAKER_02
 You are like reducing the flow of the...

0:56:28	SPEAKER_02
 No, it's a region.

0:56:29	SPEAKER_04
 It's a flow of slower.

0:56:35	SPEAKER_06
 I'm sorry, so when you say minus 25 or minus 30 dB with respect to what?

0:56:40	SPEAKER_04
 To the average speech energy, which is estimated on...

0:56:46	SPEAKER_06
 Okay, so basically you're creating a signal-to-noise ratio of 25 or 30 dB.

0:56:51	SPEAKER_03
 But I think what you do is...

0:56:53	SPEAKER_03
 When you have this...

0:56:55	SPEAKER_03
 After you subtract it, I mean, then you get something with this...

0:57:00	SPEAKER_03
 When you set the values to zero, and then you simply add an additive constant again.

0:57:06	SPEAKER_03
 So you shifted somehow, this whole curve is shifted again.

0:57:10	SPEAKER_06
 But did you do that before the thresholding to zero?

0:57:14	SPEAKER_04
 It's after the thresholding.

0:57:16	SPEAKER_04
 Oh, so you really want to do it before, right?

0:57:19	SPEAKER_04
 Maybe you might do it before.

0:57:20	SPEAKER_06
 Yeah, because then you would have lots of that phenomenon.

0:57:23	SPEAKER_06
 Yeah.

0:57:24	SPEAKER_06
 I think.

0:57:25	SPEAKER_04
 But still, when you do this and you take the log after that, it reduces the variance.

0:57:31	SPEAKER_04
 Right.

0:57:32	SPEAKER_06
 Yeah, that will reduce the variance that will help.

0:57:35	SPEAKER_06
 But maybe if you did it before, you get lots of these funny looking things.

0:57:38	SPEAKER_06
 He's trying.

0:57:40	SPEAKER_02
 But before, it's like adding this...

0:57:45	SPEAKER_06
 Right at the point where you're doing the subtraction.

0:57:47	SPEAKER_06
 Okay.

0:57:48	SPEAKER_06
 Essentially, you're adding a constant into everything.

0:57:53	SPEAKER_03
 But the way you step on it, it is exactly the way I've implemented it, the fold.

0:57:58	SPEAKER_06
 Oh, you better do it different than that.

0:58:01	SPEAKER_06
 Just use a set it for a particular signal-to-noise ratio.

0:58:09	SPEAKER_06
 Set you what?

0:58:11	None
 Yeah.

0:58:12	SPEAKER_03
 I made a similar investigation lecture for that year.

0:58:17	SPEAKER_03
 Just adding this constant and looking...

0:58:20	SPEAKER_03
 How do you paint it?

0:58:21	SPEAKER_03
 Is it on the value of the constant?

0:58:23	SPEAKER_03
 Yeah.

0:58:24	SPEAKER_03
 So, those students are more to give on average the best result.

0:58:27	SPEAKER_03
 Yeah.

0:58:28	SPEAKER_03
 So, a range of a signal-to-noise ratio.

0:58:30	SPEAKER_07
 Oh, it's clear.

0:58:33	SPEAKER_04
 I should have given other results.

0:58:35	SPEAKER_04
 So, it's clear.

0:58:36	SPEAKER_04
 When you don't unknow, it's much worse, like around 5% worse, I guess.

0:58:43	SPEAKER_04
 And if you add too much noise, it gets worse.

0:58:47	SPEAKER_04
 So, and it seems that right now, this is a constant that does not depend on anything that you can learn from the utterance.

0:58:57	SPEAKER_04
 It's just a constant noise addition.

0:59:02	SPEAKER_04
 And I think...

0:59:06	SPEAKER_06
 I'm confused.

0:59:07	SPEAKER_06
 I thought you were saying it doesn't depend on the utterance, but I thought you were adding an amount that was 25 dB down from the signal-to-noise ratio.

0:59:14	SPEAKER_04
 Yeah. So, the way I did that, I just measured the average speech energy of the old Italian data.

0:59:19	SPEAKER_04
 Oh!

0:59:20	SPEAKER_04
 Then I use this as mean speech energy.

0:59:25	SPEAKER_06
 Oh, it's just a constant amount.

0:59:27	SPEAKER_04
 And overall...

0:59:28	SPEAKER_04
 I observe that for Italian and Spanish, when you go to 30 and 25 dB, it's good.

0:59:38	SPEAKER_04
 It stays in this range.

0:59:40	SPEAKER_04
 Well, the performance of this algorithm is quite good.

0:59:45	SPEAKER_04
 But for Finnish, you have a degradation already when you go from 35 to 30 and then from 30 to 25.

0:59:55	SPEAKER_04
 And I have the feeling that maybe it's because just Finnish has a mean energy that's lower than the other databases.

1:00:03	SPEAKER_04
 And due to this, the threshold should be...

1:00:06	SPEAKER_04
 Yeah.

1:00:07	SPEAKER_04
 The noise addition should be lower.

1:00:09	SPEAKER_06
 But in the real thing, you're not going to be able to measure what people are doing over half an hour or an hour or anything, right?

1:00:15	SPEAKER_06
 So, you have to come up with this number from something else.

1:00:19	SPEAKER_03
 But you're not doing it now, like, which dependent or?

1:00:23	SPEAKER_04
 It's not. It's just something that's fixed.

1:00:29	SPEAKER_06
 What he is doing language dependent is measuring what that number references that he comes down to 25.

1:00:35	SPEAKER_04
 No, because I did it.

1:00:37	SPEAKER_04
 I started working on Italian.

1:00:39	SPEAKER_04
 I obtained this average energy.

1:00:41	SPEAKER_04
 Yeah.

1:00:42	SPEAKER_04
 Then I used this one.

1:00:43	SPEAKER_02
 For all languages.

1:00:44	SPEAKER_02
 Yeah.

1:00:45	SPEAKER_06
 Okay.

1:00:46	SPEAKER_06
 So it's sort of arbitrary.

1:00:47	SPEAKER_04
 I mean, so if you think, yeah.

1:00:49	SPEAKER_04
 Yeah. So the next thing is to use this as maybe initialization and then use something online.

1:00:55	SPEAKER_04
 It's an important thing.

1:00:56	SPEAKER_04
 I expect improvement at least on Finnish because the way...

1:01:01	SPEAKER_04
 Well, for Italian and Spanish, this value works good, but not necessarily for Finnish.

1:01:12	SPEAKER_04
 But unfortunately, there is, like, this 40 millisecond latency.

1:01:21	SPEAKER_04
 Yeah. So I will try to so much reduce this.

1:01:27	SPEAKER_04
 I already know that if I completely remove this latency, so it...

1:01:34	SPEAKER_04
 There is 3% hit on Italian.

1:01:42	SPEAKER_02
 This latency...

1:01:43	SPEAKER_02
 Sorry.

1:01:44	SPEAKER_03
 Yeah.

1:01:45	SPEAKER_03
 Yes, moving was over this, sort of, say, the factor of the Wiener.

1:01:51	SPEAKER_03
 What was it?

1:01:53	SPEAKER_03
 This moving, it was over the subtraction factor, sort of, say.

1:01:59	SPEAKER_04
 It's the smoothing over the gain of the subtraction aggregate.

1:02:08	SPEAKER_03
 And you are looking into the future, into the past.

1:02:11	SPEAKER_04
 Right.

1:02:12	SPEAKER_04
 So you do smoot this.

1:02:16	SPEAKER_03
 Did you try simply to smooth...

1:02:24	SPEAKER_03
 To smooth through is the envelope?

1:02:31	SPEAKER_04
 No, I did not.

1:02:36	SPEAKER_03
 Because it means you should have a similar effect if you...

1:02:39	SPEAKER_03
 I mean, you have now several stages of moving, so to say you start up.

1:02:43	SPEAKER_03
 As far as I remember, you smooth somehow.

1:02:45	SPEAKER_03
 The envelope, you smooth somehow the noise estimate and later on, you smooth also this subtraction factor.

1:02:53	SPEAKER_04
 No, it's...

1:02:55	SPEAKER_04
 It's just a gain that smooth actually.

1:02:58	SPEAKER_04
 Actually, I do all the smoothing.

1:03:00	SPEAKER_04
 Oh, it was...

1:03:01	SPEAKER_04
 Yeah.

1:03:02	SPEAKER_04
 Yeah.

1:03:03	SPEAKER_04
 No, in this case, it's just a gain.

1:03:06	SPEAKER_04
 But the way it's done is that...

1:03:09	SPEAKER_04
 For low gain, there is this non-linear smoothing actually.

1:03:14	SPEAKER_04
 For low gains, I use the smoothed version.

1:03:21	SPEAKER_04
 But for high gain, I don't smooth.

1:03:28	SPEAKER_03
 It just...

1:03:30	SPEAKER_03
 The experience shows if you do the...

1:03:35	SPEAKER_03
 The best is to do the smooths moving as early as possible.

1:03:39	SPEAKER_03
 So when you start up, I mean, you start up with the...

1:03:43	SPEAKER_03
 Somehow with the noisy envelope.

1:03:46	SPEAKER_03
 But the best is to smooth this somehow.

1:03:52	SPEAKER_04
 Yeah, I could try this.

1:03:54	SPEAKER_02
 So before estimating the SNR itself smoothed envelope.

1:04:03	SPEAKER_04
 But yeah.

1:04:06	SPEAKER_04
 Then we need to find a way to smooth less also when there is high energy.

1:04:12	SPEAKER_04
 Because I noticed that it helps a little bit to smooth more during low energy portions.

1:04:20	SPEAKER_04
 Yes.

1:04:21	SPEAKER_04
 Less during speech because if you smooth...

1:04:24	SPEAKER_04
 Then you kind of distort the speech.

1:04:28	SPEAKER_04
 Right.

1:04:32	SPEAKER_03
 Yeah, I think when...

1:04:35	SPEAKER_03
 You could do it in this way that you say if you...

1:04:38	SPEAKER_03
 You have somehow a noise estimate.

1:04:41	SPEAKER_03
 If you say with my envelope, I'm close to this noise estimate.

1:04:45	SPEAKER_03
 Then you have a bad signal to a noise ratio and then you would like to have a stronger smoothing.

1:04:52	SPEAKER_03
 So you could...

1:04:54	SPEAKER_03
 Yeah, you could base it on your estimation of the signal to noise ratio on your actual.

1:05:05	SPEAKER_02
 Or some...

1:05:12	SPEAKER_04
 Yeah, but I don't trust the current value.

1:05:16	SPEAKER_02
 Yeah, not right now.

1:05:20	SPEAKER_07
 The value later will much better.

1:05:28	SPEAKER_04
 I think that's it.

1:05:34	SPEAKER_03
 To summarize the performance of the speech that car results as similar to the euros.

1:05:41	SPEAKER_02
 Yeah, so the 5080 is like the bad...

1:05:43	SPEAKER_02
 You have 56,000 euros.

1:05:44	SPEAKER_02
 Yeah, that's true.

1:05:46	SPEAKER_03
 And depending on this, the additive constant is slightly better.

1:05:50	SPEAKER_04
 It's better, of course.

1:05:53	SPEAKER_04
 And yeah, the condition where it's better than your approach, it's just because maybe it's better on well matched and that the weight on well matched is...

1:06:06	SPEAKER_02
 Yeah, you got a...

1:06:08	SPEAKER_04
 If you don't weigh differently, the different condition, you can see that your...

1:06:14	SPEAKER_04
 Well, the two-stage winner filtering is maybe better or...

1:06:19	SPEAKER_04
 It's better for I miss match, right?

1:06:22	SPEAKER_02
 Yeah, it's better for I miss match.

1:06:25	SPEAKER_02
 So the overall... Yeah, it was for the well matched condition.

1:06:31	SPEAKER_08
 So we need to combine these two.

1:06:34	SPEAKER_02
 That's the best thing is like the French telecom system is optimized for the well matched condition.

1:06:40	SPEAKER_02
 So they know that the weighting is good for the well matched.

1:06:43	SPEAKER_02
 So everywhere the well matched performance is very good for French telecom.

1:06:49	SPEAKER_02
 We also have to do something similar.

1:06:53	SPEAKER_06
 Our tradition here has always been to focus on this match.

1:06:59	SPEAKER_03
 Is this more interesting?

1:07:01	SPEAKER_03
 My body was a tool.

1:07:03	SPEAKER_03
 For a started working on this world.

1:07:07	SPEAKER_08
 Yeah.

1:07:09	SPEAKER_08
 Okay, Carmen, do you...

1:07:11	SPEAKER_01
 I only say that this is the summary of all the BTS' experiment.

1:07:18	SPEAKER_01
 And say that the result in the last...

1:07:23	SPEAKER_01
 For Italian, the last experiment for Italian are bad.

1:07:26	SPEAKER_01
 I make a mistake when I write.

1:07:28	SPEAKER_01
 Obviously, I copy one of the bad results.

1:07:31	SPEAKER_01
 So you...

1:07:33	SPEAKER_01
 Yeah.

1:07:35	SPEAKER_01
 You know, this...

1:07:37	SPEAKER_01
 Well, if we put everything, we improve a lot, compared to usual BTS, but the final result are not still good like the winner filter, for example.

1:07:55	SPEAKER_01
 I don't know, maybe it's possible.

1:07:58	SPEAKER_01
 It's somewhere to have the same result, I don't know exactly.

1:08:04	SPEAKER_01
 Because I have...

1:08:06	SPEAKER_02
 You have a better result.

1:08:08	SPEAKER_01
 What result in medium mismatch?

1:08:11	SPEAKER_02
 I have some results that are good for the high mismatch.

1:08:14	SPEAKER_01
 Yeah.

1:08:15	SPEAKER_01
 Or something.

1:08:16	SPEAKER_01
 I'm more or less similar, but are worse.

1:08:21	SPEAKER_01
 And still, I don't have the result for K-digit.

1:08:25	SPEAKER_01
 The program is running.

1:08:27	SPEAKER_01
 Maybe for this weekend, I will have the result for K-digit.

1:08:30	SPEAKER_01
 And I can't complete it.

1:08:32	SPEAKER_01
 I'm going to write this.

1:08:50	SPEAKER_07
 Right.

1:08:53	SPEAKER_01
 One thing that I know are not here in this result, but I spoke in before with Sunil, I improved my result using clean LDA filter.

1:09:07	SPEAKER_01
 If I use the LDA filter that are running with the noise speed, that hurts my result.

1:09:17	SPEAKER_06
 So what are these numbers here?

1:09:19	SPEAKER_06
 Are these with the cleaner with the noise?

1:09:21	SPEAKER_01
 With the noise, I have worse results that I didn't use.

1:09:29	SPEAKER_01
 Maybe because with this technique, we are using really clean speed.

1:09:36	SPEAKER_01
 The speed representation that goes to the HTK is really clean speed because it's from the dictionary.

1:09:44	SPEAKER_01
 They could move.

1:09:45	SPEAKER_01
 Maybe for that.

1:09:47	SPEAKER_01
 Because I think that it's an experiment using the two LDA filter, a noisard, doesn't matter to me.

1:09:59	SPEAKER_04
 Yeah, I did that, but it doesn't matter on the speech that car, but it matters a lot on the idgis.

1:10:08	SPEAKER_04
 It's better when you use the clean filter.

1:10:10	SPEAKER_04
 Yeah, it's much better when you use the clean derived LDA filter.

1:10:14	SPEAKER_07
 Yeah, it's clean.

1:10:19	SPEAKER_02
 But yeah, Sunil, you know, my result is with the noisard.

1:10:26	SPEAKER_02
 No, it's with the noisard.

1:10:29	SPEAKER_02
 It's not the clean LDA.

1:10:33	SPEAKER_02
 In the front sheet, I have like the summary.

1:10:36	SPEAKER_04
 And your result is with the clean LDA.

1:10:41	SPEAKER_02
 And in your case, it's all noisy.

1:10:44	SPEAKER_04
 All noisy.

1:10:45	SPEAKER_04
 Yeah, but I'm serving my case.

1:10:50	SPEAKER_04
 At least on speech that car, it doesn't matter, but the idgis is matters.

1:10:55	SPEAKER_04
 Like two or three percent absolute.

1:10:58	SPEAKER_04
 Absolutely.

1:10:59	SPEAKER_04
 So you really might want to.

1:11:03	SPEAKER_06
 Yeah, I would like to look at it.

1:11:07	SPEAKER_06
 Yeah, I could be sizable right there.

1:11:14	SPEAKER_03
 Maybe you're living in about two weeks.

1:11:22	SPEAKER_03
 Yeah.

1:11:23	SPEAKER_03
 So I mean, if I would put on the head of a project manager, I would say I'm the most.

1:11:31	SPEAKER_03
 So much time left.

1:11:33	SPEAKER_03
 So I mean, what I would do is I would pick the best consolation which you think.

1:11:42	SPEAKER_03
 And create all the results for the whole database that you get to the final number.

1:11:47	SPEAKER_03
 So no, didn't.

1:11:50	SPEAKER_03
 Maybe also to write somehow a document where you describe your approach.

1:11:57	SPEAKER_01
 I was thinking to do that this week.

1:12:00	SPEAKER_06
 I'll borrow the head back and agree.

1:12:06	SPEAKER_01
 Yeah, that's the.

1:12:07	SPEAKER_06
 Right.

1:12:08	SPEAKER_06
 In fact, actually, I guess the Spanish government requires that anyway they want some kind of report from everybody who's in the program.

1:12:16	SPEAKER_06
 So of course, we'd like to see it too.

1:12:22	SPEAKER_08
 So what do you think we should do the digits or skip it or?

1:12:27	SPEAKER_06
 We have them now.

1:12:30	SPEAKER_06
 Why don't we do it?

1:12:32	SPEAKER_06
 Just take a minute.

1:12:39	SPEAKER_06
 Oh, sorry.

1:12:45	SPEAKER_08
 So I guess I'll go ahead.

1:13:06	SPEAKER_08
 It was mentioned.

1:13:23	SPEAKER_08
 5458895

1:13:28	SPEAKER_01
 Transcript L-303-136084-010 10401-238-4673-7474-3061536-3911-321472417-818018387 7358894381 083734619

1:14:16	SPEAKER_02
 Transcript L-3041164800349 821974208 6291-26456761-482749558 6101109292 6703449512 0380274696 819163804

1:14:51	SPEAKER_03
 This is transcript L-3052421872083 310896351060801834788 91917067026595916040016661048985 29053636371425227031

1:15:36	SPEAKER_04
 Transcript L-3025785876209 7251630444 8930628276 87297015 83840504347 892661195736 623105907

1:16:16	SPEAKER_00
 71444222 8344222

1:16:26	None
 8344222 8344237404222 6571 54608550658916864078 012947781 94223648053

1:17:08	SPEAKER_06
 Transcript L-301 76698879925 2149198989 9411349543 8395604911 176734304 6469388185 12938212 175820090255

1:17:46	SPEAKER_05
 Transcript L-282 6730000596 733051850 0457555828 291515814306692073 8638177386 158196395967 5642534762

1:18:28	SPEAKER_08
 8396 476

1:18:43	None
 642R 71 7

1:18:56	None
 Thank you.

