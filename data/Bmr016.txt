0:00:00	SPEAKER_06
 And we already got the crash out of the way.

0:00:03	SPEAKER_06
 It did crash, so I feel much better earlier.

0:00:06	SPEAKER_06
 Interesting.

0:00:07	SPEAKER_07
 Get the door.

0:00:13	SPEAKER_05
 Hey.

0:00:14	SPEAKER_05
 So I did collect an agenda.

0:00:16	SPEAKER_06
 I did collect an agenda.

0:00:18	SPEAKER_06
 So I'm going to go first.

0:00:20	SPEAKER_06
 Well, it shouldn't take too long.

0:00:22	SPEAKER_06
 So we're pretty much out of digits.

0:00:24	SPEAKER_06
 We've gone once through the set.

0:00:26	SPEAKER_06
 So the only thing I have to do, that's right.

0:00:29	SPEAKER_06
 So I just have to go through them and pick out the ones that have problems and either correct them or have them reread.

0:00:39	SPEAKER_06
 So we probably have like four or five more forms to be read to be once through the set.

0:00:44	SPEAKER_06
 I've also extracted out about an hour's worth.

0:00:47	SPEAKER_06
 We have about two hours worth.

0:00:49	SPEAKER_06
 I extracted about an hour's worth, which are the digits for which whose speaker have speaker forms, have filled out speaker forms.

0:00:57	SPEAKER_06
 Not everyone's filled out a speaker form.

0:00:58	SPEAKER_06
 So I extracted one for speakers who have speaker forms and for meetings in which the key file and the transcript files are possible.

0:01:07	SPEAKER_06
 Some of the early key files it looks like were done by hand.

0:01:10	SPEAKER_06
 And so they're not automatically possible, and I have to go back and fix those.

0:01:13	SPEAKER_06
 So what that means is we have about an hour of transcribed digits that we can play with.

0:01:22	SPEAKER_07
 Liz.

0:01:23	SPEAKER_07
 I think two hours is the total value.

0:01:25	SPEAKER_07
 Yeah.

0:01:26	SPEAKER_07
 Yeah.

0:01:27	SPEAKER_07
 And you can go to the question, all these different things that are not quite right, but you can go to the other three or the other hour.

0:01:33	SPEAKER_06
 Yes, absolutely.

0:01:34	SPEAKER_06
 So that's just a question of a little hand editing of some files and then waiting for more people to turn in their speaker forms.

0:01:40	SPEAKER_06
 I have this web-based speaker form, and I sent mail to everyone who hadn't filled out a speaker form, and they're slowly trickling in.

0:01:47	SPEAKER_07
 So the relevance of the speaker form here

0:01:49	SPEAKER_06
 is for labeling the extracted audio files. Oh, OK.

0:01:53	SPEAKER_06
 By speaker ID and microphone type.

0:01:56	SPEAKER_07
 Permission to use their digits.

0:01:57	SPEAKER_06
 No, I spoke with Jane about that, and we sort of decided that it's probably not an issue, that we edit out any of the errors anyway.

0:02:05	SPEAKER_06
 So there are no errors in the digits.

0:02:07	SPEAKER_06
 You always read the string correctly.

0:02:10	SPEAKER_06
 So I can't imagine why anyone would care.

0:02:13	SPEAKER_06
 So the other topic with digits is, Liz would like to elicit different prosotics.

0:02:21	SPEAKER_06
 And so we tried last week with them written out in English, and it just didn't work at all, because no one grouped them together.

0:02:29	SPEAKER_06
 So it just sounded like many, many more lines instead of anything else.

0:02:33	SPEAKER_06
 So in conversations with Liz and Jane, we decided that if you wrote them out as numbers instead of words, it would elicit more phone number, social security number, like readings.

0:02:45	SPEAKER_06
 The problem with that is it becomes numbers instead of digits.

0:02:48	SPEAKER_06
 When I look at this, that first line is 61, 62, 18, 86, 10.

0:02:53	SPEAKER_06
 And so the question is, does anyone care?

0:02:56	SPEAKER_06
 I've already spoken with Liz, and she feels that, correct me if I'm wrong, that for her connected numbers is fine, as opposed to connected digits.

0:03:05	SPEAKER_06
 I think two hours is probably fine for test set, but it may be a little short if we actually want to do training and adaptation and all that other stuff.

0:03:13	SPEAKER_07
 Yeah.

0:03:15	SPEAKER_07
 Do you want different prasadics?

0:03:18	SPEAKER_07
 So if you always had the same group, things you wouldn't like that, is that correct?

0:03:22	SPEAKER_04
 Well, we actually figured out a way to do the groupings are randomly generated.

0:03:26	SPEAKER_07
 No, but I was asking if that was something you really cared about, because if it wasn't, it seems to me if you made it really specifically telephone groupings that maybe people wouldn't bring with a number so much.

0:03:41	SPEAKER_07
 You know, if it is a bit...

0:03:42	SPEAKER_04
 They may still do it.

0:03:44	SPEAKER_04
 Maybe some.

0:03:45	SPEAKER_08
 What about putting a hyphen between the numbers in the group?

0:03:48	SPEAKER_07
 So if you have six-1, you mean?

0:03:51	SPEAKER_07
 If you go six-6-6-2931.

0:03:57	SPEAKER_04
 Well, OK, it might help.

0:03:59	SPEAKER_04
 I would like to get away from having only one specific grouping.

0:04:04	SPEAKER_04
 So if that's your question.

0:04:06	SPEAKER_04
 But it seems to me that at least for us, we can learn to read the math digits.

0:04:12	SPEAKER_04
 If that's what people want.

0:04:13	SPEAKER_04
 I don't think that'd be that hard.

0:04:15	SPEAKER_04
 I agree.

0:04:15	SPEAKER_04
 To read the math single digits.

0:04:18	SPEAKER_04
 And it seems like that might be better for you guys, since then you'll have just more digit data.

0:04:24	SPEAKER_04
 And that's always a good thing.

0:04:26	SPEAKER_04
 It's a little bit better for me, too, because the digits are easier to recognize.

0:04:30	SPEAKER_04
 They're better trained than the numbers.

0:04:31	SPEAKER_06
 So we could just put in the instructions

0:04:35	SPEAKER_04
 with the math digits. Right.

0:04:37	SPEAKER_04
 Read the math single digits.

0:04:38	SPEAKER_04
 So 61 was read as 6-1.

0:04:40	SPEAKER_04
 And if people make a mistake, we...

0:04:42	SPEAKER_06
 So versus 0.

0:04:44	SPEAKER_07
 I mean, the other thing is we could just beg it because it's worrying about it.

0:04:48	SPEAKER_07
 I mean, because we do have digits training data that we have from OGI.

0:04:53	SPEAKER_07
 I'm sorry, it's numbers training data that we have from OGI.

0:04:56	SPEAKER_07
 We've done lots and lots of studies with that.

0:04:58	SPEAKER_07
 And...

0:04:59	SPEAKER_04
 But it's nice to get it in this room with the...

0:05:02	None
 Yeah.

0:05:02	SPEAKER_04
...accus.

0:05:03	SPEAKER_07
 No, no, I guess what I'm saying is that...

0:05:05	SPEAKER_06
 Just let them read it.

0:05:06	SPEAKER_07
 How they read it.

0:05:07	SPEAKER_07
 Just read it.

0:05:08	SPEAKER_07
 How they read it.

0:05:09	SPEAKER_07
 And just means we have to expand our vocabulary out to...

0:05:13	SPEAKER_04
 Well, that's fine with me.

0:05:14	SPEAKER_04
 As long as it's just that I didn't want to cause the people who would have been collecting digits the other way to not have the digits.

0:05:21	SPEAKER_04
 So...

0:05:22	SPEAKER_07
 We can go back to the other thing later.

0:05:24	SPEAKER_07
 I mean, we...

0:05:25	SPEAKER_07
 OK.

0:05:26	SPEAKER_07
 We can do this for a while and then go back to digits for a while.

0:05:29	SPEAKER_07
 OK.

0:05:31	SPEAKER_07
 Yeah, I mean, you want this...

0:05:34	SPEAKER_07
 Do you need training data or adaptation data or this?

0:05:36	SPEAKER_07
 How much of this do you need with the...

0:05:41	SPEAKER_04
 It's actually unclear right now.

0:05:43	SPEAKER_04
 I just thought, well, if we're collecting digits and add them, it's that we were running out of the TI forms.

0:05:48	SPEAKER_04
 I thought it'd be nice to have them in groups.

0:05:51	SPEAKER_04
 And probably, all else being equal, it'd be better for me to just have single digits since...

0:05:56	SPEAKER_04
 OK.

0:05:57	SPEAKER_04
...you know, I recognize it's going to do better on those anyway.

0:06:01	SPEAKER_04
 And it's more predictable.

0:06:02	SPEAKER_04
 So we can know from the transcript what the person said and the transcriber in general.

0:06:06	SPEAKER_04
 But if they make mistakes, it's no big deal.

0:06:08	SPEAKER_04
 If people say 100 instead of 100 and also maybe we can just let them choose 0 versus 0 as they like.

0:06:16	SPEAKER_04
 Because even the same person sometimes says 0 and sometimes 0 in different contexts and that's sort of interesting.

0:06:23	SPEAKER_04
 So I don't have a specific need because if I did, I'd probably try to collect it without bothering this group.

0:06:31	SPEAKER_04
 But if we can try...

0:06:33	SPEAKER_06
 So I can just add to the instructions to read it as digits.

0:06:36	SPEAKER_04
 Right.

0:06:36	SPEAKER_04
 And you can give an example like, you know, 6-61 would be read as 6-1.

0:06:42	SPEAKER_04
 Right.

0:06:43	SPEAKER_00
 And actually, it's no more artificial than what we've been doing with words.

0:06:46	SPEAKER_00
 I'm sure people can adapt to this.

0:06:48	SPEAKER_00
 Right.

0:06:48	SPEAKER_00
 It's simple.

0:06:49	SPEAKER_00
 The space is already biased toward being separated.

0:06:52	SPEAKER_00
 Right.

0:06:52	SPEAKER_00
 And I know I'm going to find this easier than words.

0:06:54	SPEAKER_06
 Oh, yeah, absolutely.

0:06:55	SPEAKER_06
 Cognitively, it's much easier.

0:06:56	SPEAKER_04
 I also had a hard time with the words.

0:06:58	SPEAKER_04
 But then we went back and forth.

0:06:59	SPEAKER_04
 OK, so let's give that a try.

0:07:01	SPEAKER_06
 And is the spacing all right or do you think there should be more space between digits and groups?

0:07:06	SPEAKER_04
 I mean, what do other people think because you guys are reading them?

0:07:09	SPEAKER_00
 I think that it's fine.

0:07:10	SPEAKER_00
 To me, it looks like you've got the idea of grouping and you have the idea of separation.

0:07:14	SPEAKER_00
 And it's just a matter of the instructions.

0:07:18	SPEAKER_00
 That's right.

0:07:18	SPEAKER_00
 OK.

0:07:19	SPEAKER_06
 And I think there are about 10 different grouping patterns.

0:07:21	SPEAKER_06
 Isn't that right, Liz?

0:07:23	SPEAKER_04
 Right.

0:07:23	SPEAKER_04
 Right.

0:07:24	SPEAKER_04
 And you just, they're randomly generated and randomly assigned to digits.

0:07:28	SPEAKER_04
 I did.

0:07:29	SPEAKER_07
 So what?

0:07:30	SPEAKER_07
 I was just going to say, so we have, we've sent you 40 hours of recordings now.

0:07:36	SPEAKER_07
 And you're saying two hours is digits.

0:07:38	SPEAKER_07
 That's for the ratio.

0:07:39	SPEAKER_07
 Yeah.

0:07:40	SPEAKER_07
 20 to 1, which I guess makes sense.

0:07:43	SPEAKER_07
 So if we did another 40 hours of recordings, then we could get a couple hours.

0:07:47	SPEAKER_07
 Right.

0:07:49	SPEAKER_07
 Yeah, like you say, I think a couple hours for a test sense, OK?

0:07:53	SPEAKER_07
 It'd be nice to get more later because we're going to use this up in some sense.

0:08:00	SPEAKER_07
 Right?

0:08:01	SPEAKER_00
 I also would like to argue for that because it seems to me that there's a real strength in having the same test replicated a whole bunch of times and adding to that basic test bank.

0:08:09	SPEAKER_00
 Right?

0:08:10	SPEAKER_00
 Because then you have more and more chances to get away from random errors.

0:08:16	SPEAKER_00
 And I think the other thing too is that right now, we have sort of a stratified sample with reference to dialect groups.

0:08:22	SPEAKER_00
 And there might be an argument to be made for for replicating all of the digits that we've done, which were done by non-native speakers, so that we have a core that totally replicates the original data set, which is totally American speakers.

0:08:35	SPEAKER_00
 And then we have these stratified additional language groups overlapping certain aspects of the database.

0:08:40	SPEAKER_06
 I think that trying to duplicate, spending too much effort trying to duplicate the existing TI digits probably isn't too worthwhile because the recording situation is so different.

0:08:52	SPEAKER_06
 It's going to be very hard to be comparable.

0:08:54	SPEAKER_00
 Except that if you have a stimuli comparable, then it says something about the contribution of setting.

0:09:01	SPEAKER_07
 But the other differences are so major.

0:09:03	SPEAKER_07
 OK.

0:09:04	SPEAKER_07
 Yeah.

0:09:04	SPEAKER_07
 Red versus not.

0:09:05	SPEAKER_07
 It's a very serious thing.

0:09:07	SPEAKER_00
 What's an example of some of the other differences?

0:09:10	SPEAKER_00
 Any other differences?

0:09:11	SPEAKER_07
 Well, individual human glottis is going to be different.

0:09:16	SPEAKER_06
 You know, there's so many things.

0:09:18	SPEAKER_06
 And not just that.

0:09:19	SPEAKER_06
 I mean, the corpus itself, we're collecting it in a red digit in a particular list.

0:09:26	SPEAKER_06
 And I'm sure that they're doing more specific stuff.

0:09:29	SPEAKER_06
 I remember correctly, it was like postman reading zip codes and things like that.

0:09:33	SPEAKER_06
 The idea did it suppose?

0:09:34	SPEAKER_06
 I thought so.

0:09:35	SPEAKER_07
 Was it red?

0:09:36	SPEAKER_07
 Yeah, I think the reading zip code stuff, you think you're going to do.

0:09:38	SPEAKER_07
 Oh, I may well be.

0:09:39	SPEAKER_07
 Yeah, not TI digits was red in red.

0:09:41	SPEAKER_06
 I haven't ever listened to TI digits.

0:09:44	SPEAKER_06
 So I don't really know how to compare this.

0:09:46	SPEAKER_06
 But regardless, it's going to be hard to compare cross-corpus.

0:09:49	SPEAKER_07
 It's different people.

0:09:50	SPEAKER_07
 This is a different thing.

0:09:51	SPEAKER_07
 And they're different circumstances, different recording, and so forth.

0:09:55	SPEAKER_07
 So it's really pretty different.

0:09:56	SPEAKER_07
 But I think the idea of using a set thing was just to give you some sort of framework so that even though you couldn't exact comparison, this is what these valid, something like group is doing.

0:10:06	SPEAKER_07
 Some kind of reference.

0:10:09	SPEAKER_08
 OK, what do the groupings represent?

0:10:12	SPEAKER_08
 You said there's like 10 different groupings.

0:10:14	SPEAKER_04
 Right, just groupings in terms of number of groups in a line and number of digits in a group and the pattern of groupings.

0:10:22	SPEAKER_08
 Are the patterns based on anything there?

0:10:27	SPEAKER_04
 I just roughly looked at what kinds of digit strings are out there, and they're usually grouped into either two, three, or four digits at a time.

0:10:35	SPEAKER_04
 And they can have, I mean, actually, things are getting longer and longer.

0:10:40	SPEAKER_04
 In the old days, you probably only had three sequences.

0:10:44	SPEAKER_04
 Telephone numbers were less and so forth.

0:10:47	SPEAKER_04
 So there's between, well, if you look at it, there are between like three and five groups.

0:10:52	SPEAKER_04
 And each one has between two and four groupings.

0:10:56	SPEAKER_04
 I purposely didn't want them to look like they're in any kind of pattern.

0:11:02	SPEAKER_06
 And which group appears as picked randomly and what the numbers are are picked randomly?

0:11:07	SPEAKER_06
 So unlike the previous one, which I simply replicated to T.I. digits, this is generated randomly.

0:11:12	SPEAKER_08
 Oh, OK.

0:11:15	SPEAKER_04
 But I think it would be great to be able to compare digits, whether it's these digits or T.I. digits to speakers, and compare that to their spontaneous speech.

0:11:24	SPEAKER_04
 And then we do need a fair amount of digit data because you might be wearing a different microphone.

0:11:31	SPEAKER_04
 So it's nice to have the digits replicated many times, especially for speakers that don't talk a lot.

0:11:40	SPEAKER_04
 So for adaptation, no, I'm serious.

0:11:43	SPEAKER_04
 So we have a problem with acoustic adaptation.

0:11:46	SPEAKER_04
 And we're not using the digit data now, but not for adaptation.

0:11:52	SPEAKER_04
 We were running adaptation only on the data that we ran recognition on.

0:11:56	SPEAKER_04
 And as soon as someone started to read transcript number, that's red speech.

0:11:59	SPEAKER_04
 And I thought, well, we're going to do better on that.

0:12:01	SPEAKER_04
 It's not fair to use.

0:12:03	SPEAKER_04
 Oh, yeah, that's true.

0:12:03	SPEAKER_04
 Absolutely.

0:12:04	SPEAKER_04
 It might be fair to use the data for adaptation.

0:12:07	SPEAKER_04
 So those speakers who are very quiet shy.

0:12:11	SPEAKER_04
 Right.

0:12:11	SPEAKER_04
 Like adapting on, yeah.

0:12:13	SPEAKER_04
 Well, I mean, it's the same microphone.

0:12:15	SPEAKER_04
 See, the nice thing is we have that in the same meeting.

0:12:18	SPEAKER_04
 Right.

0:12:19	SPEAKER_04
 Same acoustic, same channels.

0:12:21	SPEAKER_04
 Right.

0:12:21	SPEAKER_04
 And so I still like the idea of having some kind of good.

0:12:25	SPEAKER_07
 Yeah, I mean, for the acoustic research, for the signal processing, far field stuff, I see it as the place that we started.

0:12:35	SPEAKER_07
 But I mean, it'd be nice to have 20 hours of digit data.

0:12:39	SPEAKER_07
 But the truth is, I'm hoping that the stuff that you guys have been doing is continue that.

0:12:47	SPEAKER_07
 We get the best we can do on this spontaneous stuff.

0:12:53	SPEAKER_07
 And then we do a lot of the testing of the algorithms on the digits for the far field.

0:13:00	SPEAKER_07
 At some point, when we feel it's mature, and we understand what's going on, we can then we have to do the spontaneous data with the far field.

0:13:09	SPEAKER_04
 The only thing that we don't have, I know this sounds weird.

0:13:13	SPEAKER_04
 And maybe it's completely stupid.

0:13:14	SPEAKER_04
 But we don't have any overlapping digits.

0:13:17	SPEAKER_06
 Yeah.

0:13:18	SPEAKER_06
 We talked about that a couple of times.

0:13:19	SPEAKER_04
 I know it's weird.

0:13:20	SPEAKER_06
 But the problem I see with trying to do over lapping digits is the cognitive load.

0:13:26	SPEAKER_04
 I know everybody's laughing.

0:13:27	SPEAKER_04
 OK.

0:13:28	SPEAKER_04
 No, it's stupid.

0:13:29	SPEAKER_04
 It's just, I'm just talking for the stuff that I can't do.

0:13:31	SPEAKER_04
 You try to do it.

0:13:32	SPEAKER_04
 I mean, here, let's try it.

0:13:34	SPEAKER_06
 You read the line.

0:13:35	SPEAKER_06
 I'll read the first line.

0:13:37	SPEAKER_04
 These are all the same forms.

0:13:39	SPEAKER_04
 OK.

0:13:39	SPEAKER_06
 So you read the last line.

0:13:41	SPEAKER_06
 I'll read the first line.

0:13:42	SPEAKER_06
 You plug your ears.

0:13:43	SPEAKER_06
 Oh, I guess you plug your ears.

0:13:44	SPEAKER_06
 You could do it.

0:13:44	SPEAKER_06
 But then you don't get the same effects.

0:13:47	SPEAKER_04
 Well, what I mean is actually not the overlaps that are well governed linguistically, but the actual fact that there's speech coming from two people, beam forming stuff, all the acoustic stuff that like Dan Ellison and company want to do, digits are nice and well-behaved.

0:14:04	SPEAKER_04
 I mean, anyway, it's just a thought.

0:14:07	SPEAKER_04
 I think so.

0:14:07	SPEAKER_04
 It would go faster.

0:14:10	SPEAKER_04
 We take one over and.

0:14:12	SPEAKER_08
 It's the remake of DigitRea.

0:14:13	SPEAKER_04
 Well, looking a little strife.

0:14:16	SPEAKER_04
 I mean, I was sort of serious, but I really, I mean, I don't feel strongly enough that it's a good idea.

0:14:22	SPEAKER_06
 I do the last line.

0:14:23	SPEAKER_06
 I'll do the first line.

0:14:25	SPEAKER_06
 6-1-6-2-1-8-6-1-0.

0:14:28	SPEAKER_06
 That's not bad.

0:14:30	SPEAKER_06
 No, I can do it.

0:14:31	SPEAKER_04
 And that probably was great.

0:14:33	SPEAKER_04
 By the way, I think it was numbers, but I'm not sure.

0:14:35	SPEAKER_04
 It just sort of sounded like a duet or something.

0:14:39	SPEAKER_08
 Performance, OK.

0:14:40	SPEAKER_07
 Let's try three.

0:14:41	SPEAKER_07
 You'll pick one in the middle.

0:14:43	SPEAKER_04
 OK.

0:14:45	SPEAKER_06
 6-1-6-2-1-8-6-1-0.

0:14:48	SPEAKER_06
 I'm sorry.

0:14:50	SPEAKER_06
 I mean, I think it was doable.

0:14:52	SPEAKER_06
 Of course, transcribers.

0:14:53	SPEAKER_04
 So we could have a round where you do two at a time, and then the next person picks up when the first hit is done

0:14:58	SPEAKER_00
 or something.

0:14:59	SPEAKER_04
 Like a, what do you call it? This pair was.

0:15:01	SPEAKER_04
 Around.

0:15:02	SPEAKER_04
 Like, yeah.

0:15:02	SPEAKER_04
 Yeah, like that.

0:15:05	SPEAKER_04
 Then it would go like twice as fast.

0:15:08	SPEAKER_04
 A third is fast.

0:15:09	SPEAKER_04
 Anyway, it's just a thought.

0:15:10	SPEAKER_04
 I'm actually sort of serious if it would help people do that.

0:15:13	SPEAKER_04
 But the people who want to work in it, we should talk to them.

0:15:16	SPEAKER_07
 I don't think we're going to say the best amount of data that way.

0:15:20	SPEAKER_07
 Having a little bit might at least be fun for somebody like Dan.

0:15:24	SPEAKER_06
 I think maybe if we wanted to do that, we would do it as a separate session, something like that, rather than doing a real meeting and, you know, do two people at a time, then three people at a time, and things like that.

0:15:34	SPEAKER_04
 Can try it out.

0:15:35	SPEAKER_04
 If we have nothing.

0:15:35	SPEAKER_04
 So you see what Dan says.

0:15:36	SPEAKER_04
 We have no agenda.

0:15:37	SPEAKER_07
 Do it some week.

0:15:39	SPEAKER_07
 OK.

0:15:39	SPEAKER_07
 It's been the whole time reading.

0:15:41	SPEAKER_07
 I thought this was going to happen.

0:15:42	SPEAKER_00
 Another question about this.

0:15:43	SPEAKER_00
 So there are these digits, which are detached digits.

0:15:46	SPEAKER_00
 But there are other words that contain the same general phoneme sequences, like wonderful, has one in it.

0:15:54	SPEAKER_00
 And Victor Borja had a piece on this where he inflated the digits.

0:15:59	SPEAKER_00
 Well, I wonder if there would be a value in having digits that are in essence embedded in real words to compare in terms of the articulation of one and wonderful versus one as a digit being read.

0:16:14	SPEAKER_07
 That's too bad.

0:16:18	SPEAKER_04
 I'm all for it.

0:16:20	SPEAKER_01
 Not after I ate that.

0:16:25	SPEAKER_07
 I don't know what work is well, isn't it?

0:16:30	SPEAKER_07
 How does nine work in it?

0:16:32	SPEAKER_05
 Nine.

0:16:33	SPEAKER_05
 You scream in German?

0:16:34	SPEAKER_01
 Yes, there's a German.

0:16:35	SPEAKER_01
 Oh.

0:16:38	SPEAKER_03
 Ellis, I was good when you scream at them.

0:16:41	SPEAKER_07
 Everybody's a little punchy here.

0:16:43	SPEAKER_00
 Well, I mean, I just wanted to offer that as a possible task because we were to each read this embedded numbers words in sentences because it's like an entire sketchy does.

0:16:53	SPEAKER_00
 And I wouldn't take the inflated version.

0:16:55	SPEAKER_00
 So he talks about the woman being two to fall in.

0:16:59	SPEAKER_00
 But if it were to be deflated just the normal word, it would be like a little story that we could read.

0:17:06	SPEAKER_00
 I don't know if that would be useful for comparison, but it's embedded numbers.

0:17:12	SPEAKER_06
 I think for something like that would be better off doing like Tim, it.

0:17:16	SPEAKER_07
 Well, I think the question is what the research is.

0:17:18	SPEAKER_07
 So I mean, I presume that the reason that you wanted to have these digits this way is because you wanted to actually do some research looking at the exotic form here.

0:17:29	SPEAKER_04
 Right.

0:17:29	SPEAKER_07
 Yeah.

0:17:31	SPEAKER_07
 So if somebody wanted to do that, if they wanted to look at the difference in the phones and the digits in the context or a non-digit word versus in the digit word, that would be a good thing to do.

0:17:45	SPEAKER_07
 But I think someone would have to express interest in that.

0:17:47	SPEAKER_07
 I see.

0:17:48	SPEAKER_07
 OK.

0:17:50	SPEAKER_07
 Maybe you were interested in doing that.

0:17:53	None
 OK.

0:17:53	SPEAKER_00
 Thank you.

0:17:54	SPEAKER_06
 Yeah, we know digits.

0:17:59	SPEAKER_06
 We have ASR results from Liz transcripts asked from Jane and disk space and storage formats from Don.

0:18:05	SPEAKER_06
 Do we have any preference on which way we want to go?

0:18:10	SPEAKER_04
 Well, I was actually going to skip the ASR results part in favor of getting the transcription stuff talked about since I think that's more important to moving forward.

0:18:20	SPEAKER_04
 But I mean, Morgan has this paper copy.

0:18:23	SPEAKER_04
 And if people have questions, it's pretty preliminary in terms of ASR results because we didn't do anything fancy.

0:18:30	SPEAKER_04
 But I think just having the results there and pointing out some main conclusions, like it's not the speaking style that differs.

0:18:41	SPEAKER_04
 It's the fact that there's overlap, that causes recognition errors.

0:18:45	SPEAKER_04
 And the fact that it's almost all insertion errors, which you would expect.

0:18:50	SPEAKER_04
 But you might also think that in the overlap regions, you would get substitutions and so forth, leads us to believe that doing a better segmentation like your channel-based segmentation or some kind of echo cancellation to get basically back down to the individual speaker utterances would be probably all that we would need to be able to do good recognition on the close documents.

0:19:16	SPEAKER_06
 Why don't you have a hard copy?

0:19:18	SPEAKER_06
 Why don't you email it to the list?

0:19:20	SPEAKER_04
 But this is Morgan has this paper.

0:19:23	SPEAKER_04
 Oh, it's in the paper.

0:19:24	SPEAKER_04
 It's that paper.

0:19:25	SPEAKER_04
 Yeah.

0:19:26	SPEAKER_04
 Everybody's going to know.

0:19:27	SPEAKER_04
 OK, then it's already done.

0:19:28	SPEAKER_04
 Basically did a lot of work on that.

0:19:31	SPEAKER_04
 And it's, let's see, I guess the other neat thing is it shows for sure that the lapel within speaker is bad.

0:19:41	SPEAKER_04
 And it's bad because it picks up the overlapping speech.

0:19:44	SPEAKER_02
 So your results were run on the channel synchronized?

0:19:50	SPEAKER_04
 Yes, because that's all that had been transcribed at the time.

0:19:54	SPEAKER_04
 But as we, I mean, I wanted to hear more about the transcription, if we can get the channel asynchronous or the closer to that would be very interesting for us.

0:20:05	SPEAKER_07
 Because we use the part from which you had about the all over the channels or mixed channels.

0:20:13	SPEAKER_08
 So if there was a segment of speech this long,

0:20:17	SPEAKER_06
 someone said, oh, in the front. Oh, in the front.

0:20:19	SPEAKER_08
 Oh, the whole thing was passed to the record.

0:20:22	SPEAKER_04
 That's right.

0:20:22	SPEAKER_04
 In fact, I pulled out a couple classic examples in case you want to use them in your talk of Chuck on the lapel.

0:20:29	SPEAKER_04
 So Chuck wore the lapel three out of four times.

0:20:31	SPEAKER_04
 I noticed that Chuck was early on.

0:20:34	SPEAKER_04
 And I wore the lapel once.

0:20:35	SPEAKER_04
 And for me, the lapel was OK.

0:20:38	SPEAKER_04
 I mean, I still, and I don't know why.

0:20:40	SPEAKER_04
 But for you, it was for who was next to me.

0:20:45	SPEAKER_03
 And where you were sitting probably affected.

0:20:47	SPEAKER_04
 Right.

0:20:48	SPEAKER_04
 But when Chuck wore the lapel and Morgan was talking, there are a couple of really long utterances where Chuck is saying a few things inside.

0:20:55	SPEAKER_04
 And it's picking up all of Morgan's words pretty well.

0:20:58	SPEAKER_04
 And so the error rates, because of insertions aren't bounded.

0:21:03	SPEAKER_04
 So with a one word utterance and 10 insertions, you've got huge error rate.

0:21:08	SPEAKER_04
 And that's where the problems come in.

0:21:09	SPEAKER_04
 So this is sort of what we expected.

0:21:11	SPEAKER_04
 But it's nice to be able to show it.

0:21:13	SPEAKER_04
 And also, I just wanted to mention briefly that Andreas, when I called up Dan, Alice, who's still stuck in Switzerland.

0:21:21	SPEAKER_04
 We were going to ask him if there was out there in terms of echo cancellation and things like that, not that we were going to do it, but we wanted to know what would need to be done.

0:21:32	SPEAKER_04
 And we've given him the data we have so far.

0:21:35	SPEAKER_04
 So these synchronous cases where there are overlap.

0:21:38	SPEAKER_04
 And he's going to look into trying to run some things that are out there and see how all it can do.

0:21:45	SPEAKER_04
 Because right now, we're not able to actually report on recognition in a real paper, like a Euro-Speed Paper, because it would look sort of premature.

0:21:53	SPEAKER_08
 So the idea is that you would take this big hunk where somebody's only speaking a small amount in it, and then try to figure out where they're speaking based on.

0:22:04	SPEAKER_04
 Right.

0:22:04	SPEAKER_04
 Or at any point in time, who's the foreground speaker, who's the background speaker?

0:22:08	SPEAKER_06
 I thought we were just going to move the boundary.

0:22:10	SPEAKER_06
 Well, that's sort of hand stuff.

0:22:11	SPEAKER_06
 So there's, how would you do that automatically?

0:22:14	SPEAKER_02
 Well, there's actually done some experiments with cross correlation.

0:22:18	SPEAKER_02
 And it seems to work pretty well to get that sort of thing.

0:22:22	SPEAKER_04
 Yeah, exactly.

0:22:23	SPEAKER_08
 So why do you want to do echo cancellation?

0:22:28	SPEAKER_04
 It would be techniques used from adaptive echo cancellation, which I don't know enough about to talk about.

0:22:33	SPEAKER_04
 It's just a journey to remove cross-down.

0:22:35	SPEAKER_04
 But right.

0:22:37	SPEAKER_04
 And that would be similar to what you're also trying to do, but using more than energy.

0:22:43	SPEAKER_04
 I don't know what exactly would go into it.

0:22:46	SPEAKER_04
 So the idea is to basically run this on the whole meeting and get the locations, which gives you also the time of dreams.

0:22:53	SPEAKER_08
 To do sort of what he's already, what he's trying to do.

0:22:55	SPEAKER_04
 Right.

0:22:56	SPEAKER_04
 Except that there are many techniques for the kinds of cues that you can use to do that.

0:23:02	SPEAKER_04
 I see.

0:23:02	SPEAKER_04
 Yeah.

0:23:03	SPEAKER_07
 If Dave is also going to be using the foreground with echo cancellation for the near field, far field stuff.

0:23:11	SPEAKER_04
 And I guess S-pen?

0:23:13	SPEAKER_04
 Is he here too?

0:23:14	SPEAKER_04
 May also be.

0:23:15	SPEAKER_04
 So that's really the next step, because we can't do too much in terms of recognition results, knowing that this is a big problem, until we can do that kind of processing.

0:23:28	SPEAKER_04
 And so once we have some reviewers and we'll move on.

0:23:34	SPEAKER_08
 I think this also ties in to one of the things that Jane's going to talk about, too.

0:23:38	SPEAKER_06
 I also want to say I have done all this chopping up of digits.

0:23:43	SPEAKER_06
 So I have some naming conventions that we should try to agree on.

0:23:46	SPEAKER_04
 Oh, right.

0:23:46	SPEAKER_04
 So let's do that offline.

0:23:47	SPEAKER_04
 We don't do it during the year.

0:23:48	SPEAKER_04
 Right.

0:23:48	SPEAKER_04
 Definitely.

0:23:50	SPEAKER_06
 And I've scripts that will extract it out from key files and do all the naming automatically.

0:23:55	SPEAKER_06
 So I'll do it by hand.

0:23:57	SPEAKER_03
 Great.

0:23:58	SPEAKER_03
 So let's do this.

0:23:58	SPEAKER_03
 You compile the list of speaker names.

0:24:01	SPEAKER_03
 And OK.

0:24:02	SPEAKER_03
 Not names, but.

0:24:03	SPEAKER_03
 Yep.

0:24:03	SPEAKER_06
 Not names.

0:24:04	SPEAKER_06
 Names to IDs.

0:24:05	SPEAKER_06
 So you do it.

0:24:06	SPEAKER_06
 And it does all sorts of matches, because the way people fill out names is different on every single file.

0:24:11	SPEAKER_04
 So it does a very fuzzy sort of match.

0:24:13	SPEAKER_04
 So at this point, we can sort of finalize the naming and so forth.

0:24:16	SPEAKER_04
 And we're going to basically rewrite out these waveforms that we did, because as you notice in the paper, your MO4 and one meeting and MO2 and another meeting, and we just need to standardize the.

0:24:27	SPEAKER_04
 That was my fault.

0:24:28	SPEAKER_04
 No.

0:24:30	SPEAKER_04
 No, I didn't notice that.

0:24:31	SPEAKER_04
 That's why those comments are in there.

0:24:33	SPEAKER_06
 So I now have a script that you could just say, basically, look up Morgan, and it will give you a second.

0:24:39	SPEAKER_04
 Great.

0:24:39	SPEAKER_06
 Great.

0:24:40	SPEAKER_06
 Terrific.

0:24:42	SPEAKER_06
 All right.

0:24:43	SPEAKER_06
 Do we, Dawn, you had disk space and storage formats?

0:24:46	SPEAKER_06
 Is that something we need to talk about at the meeting, or should you just talk with Chuck?

0:24:51	SPEAKER_03
 At some other time.

0:24:51	SPEAKER_03
 I had some general questions just about the compression algorithms of shortening waveforms.

0:24:57	SPEAKER_03
 And I don't know exactly who to ask.

0:24:59	SPEAKER_03
 I thought maybe you would be the person to talk to.

0:25:02	SPEAKER_03
 So is it a lossless compression when you compress?

0:25:05	SPEAKER_03
 So entropy coding.

0:25:07	SPEAKER_03
 It just uses entropy coding.

0:25:08	SPEAKER_03
 OK.

0:25:09	SPEAKER_03
 So I mean, I guess my question would be, is I just got this new 18 gig drive installed.

0:25:15	SPEAKER_03
 Yeah.

0:25:16	SPEAKER_06
 And I think half of it is scratch and half of it is.

0:25:19	SPEAKER_03
 I'm not exactly sure how they partitioned it.

0:25:21	SPEAKER_03
 Yeah.

0:25:22	SPEAKER_03
 Yeah.

0:25:23	SPEAKER_03
 I don't know what's typical here, but it's local, though.

0:25:26	SPEAKER_06
 So that doesn't matter.

0:25:28	SPEAKER_06
 But you can access it from anywhere in XC.

0:25:31	SPEAKER_06
 OK.

0:25:32	SPEAKER_03
 In fact, how do you do that?

0:25:34	SPEAKER_04
 Drive versus the thing is the 18 gig.

0:25:36	SPEAKER_04
 It was a spare that day pattern.

0:25:38	SPEAKER_06
 Slash N slash machine name slash XC.

0:25:41	SPEAKER_03
 OK.

0:25:42	SPEAKER_03
 All right.

0:25:43	SPEAKER_06
 I didn't know.

0:25:44	SPEAKER_06
 So the only question is how much of it, the distinction between scratch and non-scratch is whether it's backed up or not.

0:25:49	SPEAKER_06
 Right.

0:25:50	SPEAKER_06
 So what you want to do is use the scratch for stuff that you can regenerate.

0:25:53	SPEAKER_06
 OK.

0:25:54	SPEAKER_06
 So stuff that isn't backed up, it's not a big deal because disks don't crash very frequently as long as you can regenerate it.

0:26:00	SPEAKER_03
 Right.

0:26:01	SPEAKER_03
 I mean, all the stuff can be regenerated.

0:26:02	SPEAKER_06
 It's just going to put it all on scratch because where XC is model next to buy back up.

0:26:07	SPEAKER_06
 Yeah.

0:26:08	SPEAKER_04
 So all the transcripts should be backed up.

0:26:11	SPEAKER_04
 But all the waveforms should not be backed.

0:26:14	SPEAKER_03
 Right.

0:26:15	SPEAKER_03
 The ones that you write out.

0:26:16	SPEAKER_03
 OK.

0:26:17	SPEAKER_03
 So I mean, I guess the other question was, then, should we shorten them, downsample them, or keep them in their original form?

0:26:22	SPEAKER_06
 It just depends on your tools.

0:26:24	SPEAKER_06
 I mean, because it's not backed up and it's just on scratch, if your tools can't take short and format, I would leave them expanded.

0:26:31	SPEAKER_06
 So you don't have to un-shorten them every single time you want to do anything.

0:26:34	SPEAKER_03
 OK.

0:26:35	SPEAKER_04
 We can downsample them.

0:26:36	SPEAKER_03
 Do you think that would be OK?

0:26:38	SPEAKER_03
 Yeah.

0:26:39	SPEAKER_04
 To downsample them.

0:26:40	SPEAKER_04
 Yeah, we get the same performance.

0:26:41	SPEAKER_04
 OK.

0:26:42	SPEAKER_04
 I mean, the front end on the SRI recognize are just downsamples them on the fly.

0:26:45	SPEAKER_03
 Yeah.

0:26:46	SPEAKER_03
 I guess the only argument against downsampling is to preserve just the original files in case we want to experiment with different filtering techniques.

0:26:51	SPEAKER_07
 Yeah.

0:26:52	SPEAKER_07
 I'm sorry.

0:26:53	SPEAKER_07
 Yeah.

0:26:54	SPEAKER_07
 Overall, our data, we want to not downsample.

0:26:56	SPEAKER_04
 You want to not.

0:26:57	SPEAKER_04
 OK.

0:26:58	SPEAKER_04
 So what we're doing is we're writing out, I mean, this is just a question.

0:27:00	SPEAKER_04
 We're writing out these individual segments that wherever there's a time boundary from T-load or James transcribers, we chop it there.

0:27:09	SPEAKER_04
 And the reason is that we can feed it to the recognizer and throw out ones that we're not using and so forth.

0:27:14	SPEAKER_04
 And those are the ones that we're storing.

0:27:16	SPEAKER_04
 Yeah.

0:27:17	SPEAKER_06
 So it's regenerateable.

0:27:18	SPEAKER_06
 Yeah.

0:27:19	SPEAKER_06
 What I would do is take downsample it and compress it.

0:27:23	SPEAKER_06
 However, the SRI recognize or wants to take it in.

0:27:26	SPEAKER_06
 So we can't shorten them.

0:27:27	SPEAKER_04
 We can downsample them.

0:27:28	SPEAKER_04
 Yeah, I mean, I'm sorry.

0:27:29	SPEAKER_07
 As long as there is a form that we can come from again, that's not downsample.

0:27:33	SPEAKER_04
 Yeah, that's why we need more dis space because we're basically duplicating the originals.

0:27:38	SPEAKER_04
 That's fine.

0:27:39	SPEAKER_07
 But for future research, we're doing different microphones.

0:27:42	SPEAKER_04
 Oh, yeah.

0:27:43	SPEAKER_04
 No, we always have the original long ones.

0:27:44	SPEAKER_08
 So the SRI front end won't take a large audio file name and then a list of segments to chop out from that large audio file.

0:27:54	SPEAKER_08
 They actually have to be chopped out already.

0:27:57	SPEAKER_04
 It's better if they're chopped out and it will be, yeah.

0:28:02	SPEAKER_04
 We could probably write something to do that, but it's actually convenient to have them chopped out.

0:28:06	SPEAKER_04
 Because you can run them in different orders.

0:28:09	SPEAKER_04
 You can actually move them around.

0:28:11	SPEAKER_04
 And that's a whole point of opinion.

0:28:12	SPEAKER_04
 You can get rid of vengeance.

0:28:13	SPEAKER_04
 It's a lot faster.

0:28:14	SPEAKER_06
 Yeah, it's a lot faster.

0:28:15	SPEAKER_06
 English speaking.

0:28:16	SPEAKER_06
 All the native speakers and all the non-adjustable.

0:28:17	SPEAKER_06
 You can grab everything with the word that we're in.

0:28:19	SPEAKER_04
 And it's a lot quicker than actually trying to access the way file each time, find the time boundaries.

0:28:25	SPEAKER_04
 So in principle, yeah, you could do that.

0:28:27	SPEAKER_04
 Well, that's really right.

0:28:28	SPEAKER_08
 But it's not right now.

0:28:30	SPEAKER_05
 It's just not right now.

0:28:32	SPEAKER_05
 These are long.

0:28:33	SPEAKER_01
 These are long.

0:28:34	SPEAKER_06
 So for example, what if you wanted to run all the native speakers?

0:28:40	SPEAKER_06
 So if you did it that way, you would have to generate a program that looks in a database somewhere or extracts out the language, finds the time marks for that particular one, do it that way.

0:28:50	SPEAKER_06
 The way they're doing it, you have that already extracted and it's embedded in the file name.

0:28:54	SPEAKER_06
 And so you know, you just say.

0:28:56	SPEAKER_06
 Yeah, that's part of it.

0:28:57	SPEAKER_06
 So that's part of it.

0:29:00	SPEAKER_06
 You just say, you know, asterisk eAsterisk.wave and you get what you want.

0:29:02	SPEAKER_04
 Right.

0:29:03	SPEAKER_04
 And the other part is just that once they're written out, it is a lot faster to process it.

0:29:07	SPEAKER_04
 Rather than doing seeks.

0:29:09	SPEAKER_06
 So.

0:29:10	SPEAKER_06
 Through the file.

0:29:11	SPEAKER_04
 Otherwise, you're just accessing.

0:29:12	SPEAKER_06
 This is all just temporary access.

0:29:13	SPEAKER_06
 So I don't, I think it's all just, it's fine.

0:29:15	SPEAKER_06
 You know.

0:29:16	SPEAKER_06
 You're wanting to do it however is convenient.

0:29:18	SPEAKER_06
 Right.

0:29:19	SPEAKER_07
 I mean, it just depends up if the file is file-sits in memory you can do it.

0:29:22	SPEAKER_04
 The other thing is that believe it or not, I mean, we have some, so we're also looking at these in waves like for the alignment.

0:29:29	SPEAKER_04
 And so forth.

0:29:30	SPEAKER_04
 You can't load an hour of speech into x-waves.

0:29:32	SPEAKER_04
 Yeah.

0:29:33	SPEAKER_04
 You need to have these small files.

0:29:34	SPEAKER_04
 And in fact, even for the transcriber program.

0:29:37	SPEAKER_08
 Yeah, you can give waves a start in an end time.

0:29:40	SPEAKER_04
 Yeah, if you try to load really long waveform into x-waves, you'll be waiting there.

0:29:44	SPEAKER_04
 No, I'm not suggesting you load a long waveform.

0:29:46	SPEAKER_08
 I'm just saying you give it a start in an end time.

0:29:48	SPEAKER_08
 And it'll just go and pull out that section.

0:29:51	SPEAKER_06
 The transcribers didn't have any problem with that. Did they, Jane?

0:29:54	SPEAKER_00
 What's the loading process? They load it to some problem.

0:29:57	SPEAKER_06
 It takes a very long time.

0:29:59	SPEAKER_02
 Yeah, just to load the transcription to a little bit.

0:30:02	SPEAKER_02
 Right. It takes a long time.

0:30:03	SPEAKER_02
 But not to the waveform.

0:30:04	SPEAKER_02
 The waveform is there immediately.

0:30:06	SPEAKER_02
 Yeah.

0:30:07	SPEAKER_06
 Are you talking about transcriber or x-waves?

0:30:09	SPEAKER_06
 Yeah.

0:30:10	SPEAKER_04
 Actually, you're talking about transcriber, right?

0:30:12	SPEAKER_04
 Yeah.

0:30:13	SPEAKER_04
 There's also true of the digit test, which is what it's supposed to do.

0:30:15	SPEAKER_06
 We need x-waves to do the digits.

0:30:16	SPEAKER_06
 Yeah.

0:30:17	SPEAKER_06
 And they were loading the form x-waves in and it didn't seem to be any problem.

0:30:20	SPEAKER_04
 I agree.

0:30:21	SPEAKER_04
 Well, we have a problem with that time wise.

0:30:24	SPEAKER_04
 It's a lot slower to load in a long file.

0:30:27	SPEAKER_04
 It seems really good.

0:30:28	SPEAKER_04
 And also to check the file.

0:30:30	SPEAKER_04
 So if you have a transcript.

0:30:32	SPEAKER_04
 Well, regardless, it's still there.

0:30:34	SPEAKER_04
 I mean, it's, I think overall you could get everything to work by accessing the same waveform and trying to find two, you know, the beginning and end times.

0:30:45	SPEAKER_04
 But I think it's more efficient if we have the storage space.

0:30:48	SPEAKER_04
 To have the small ones.

0:30:51	SPEAKER_06
 And it's no problem, right?

0:30:52	SPEAKER_06
 Because it's not backed up.

0:30:53	SPEAKER_04
 Yeah.

0:30:54	SPEAKER_06
 So it's just, if we don't have a spare to sitting around, we go out and we buy ourselves an 80 gigabyte drive and make it all scratch space.

0:31:00	SPEAKER_06
 It's not a big deal.

0:31:03	SPEAKER_00
 You're right about the backup being a bottleneck.

0:31:05	SPEAKER_00
 It's good to.

0:31:06	SPEAKER_00
 Yeah, so these won't be scratch.

0:31:07	SPEAKER_04
 It's a first batch.

0:31:08	SPEAKER_04
 Yeah.

0:31:09	SPEAKER_06
 Right.

0:31:10	SPEAKER_06
 So remind me afterward and I'll, and we'll look at your disk.

0:31:13	SPEAKER_06
 You can see where to put stuff.

0:31:14	SPEAKER_06
 All right.

0:31:16	SPEAKER_03
 And I can just do it to a, do you on it?

0:31:18	SPEAKER_03
 Right.

0:31:19	SPEAKER_03
 And just see which, how much is on each?

0:31:20	SPEAKER_03
 Yep.

0:31:21	SPEAKER_06
 Each partition.

0:31:22	SPEAKER_06
 And you want to use either XA or scratch.

0:31:24	SPEAKER_06
 Okay.

0:31:25	SPEAKER_06
 Well, X question mark.

0:31:26	SPEAKER_06
 Anything starting with X is scratch.

0:31:28	SPEAKER_06
 Okay.

0:31:29	SPEAKER_00
 With two digits.

0:31:30	SPEAKER_00
 Two digits, right?

0:31:31	SPEAKER_06
 XA, XB, XC.

0:31:35	SPEAKER_06
 Okay.

0:31:36	SPEAKER_00
 Jane.

0:31:37	SPEAKER_00
 Okay. So I got a little print on here.

0:31:39	SPEAKER_00
 So three on this side.

0:31:40	SPEAKER_00
 Three on this side.

0:31:42	SPEAKER_00
 And I stable them.

0:31:45	None
 Okay.

0:31:48	SPEAKER_00
 All right.

0:31:49	SPEAKER_00
 So first of all, there was an interest in the transcribe transcription checking procedures.

0:31:57	SPEAKER_00
 And I can tell you first to go through the steps, although you've probably seen them.

0:32:03	SPEAKER_00
 As you might imagine, when you're dealing with, really, a fair number of words and natural speech, which means self-repairs and all these other factors that there are lots of things to be standardized and streamlined and checked on.

0:32:20	SPEAKER_00
 And so I did a bunch of checks.

0:32:26	SPEAKER_00
 And the first thing I did was obviously a spell check.

0:32:29	SPEAKER_00
 And at that point, I discovered certain things like accommodate with one M, that kind of thing.

0:32:35	SPEAKER_00
 And then in addition to that, I did an exhaustive listing of the forums in the data file, which included detecting things like faulty punctuation and things.

0:32:44	SPEAKER_08
 I'm sorry to interrupt you.

0:32:45	SPEAKER_08
 Could I just back up a little bit?

0:32:46	SPEAKER_08
 Sure, please, please, please.

0:32:47	SPEAKER_00
 So you're doing these.

0:32:48	SPEAKER_08
 So the whole process is that the transcribers get the conversation and they do their pass over it.

0:32:55	SPEAKER_08
 Yes.

0:32:56	SPEAKER_08
 And then when they're finished with it, it comes to you and you begin these.

0:32:59	SPEAKER_08
 Exactly.

0:33:00	SPEAKER_00
 I do these checks.

0:33:01	SPEAKER_00
 These quality checks.

0:33:02	SPEAKER_00
 Uh-huh, exactly.

0:33:03	SPEAKER_00
 Yeah, thank you.

0:33:04	SPEAKER_00
 And so do an exhaustive listing of the forums.

0:33:07	SPEAKER_00
 Actually, I will go through this in order.

0:33:09	SPEAKER_00
 So if we can maybe wait and stick.

0:33:11	SPEAKER_00
 Keep that for a second because we're not ready for that.

0:33:13	SPEAKER_00
 So on the fifth page.

0:33:14	SPEAKER_00
 Exactly, exactly.

0:33:16	SPEAKER_00
 All right.

0:33:17	SPEAKER_00
 So, uh, spelling check first.

0:33:19	SPEAKER_00
 Then an exhaustive listing of the, uh, all the forums in the data with punctuation attached.

0:33:24	SPEAKER_00
 And at that point, I pick up things like, oh, you know, word followed by two commas.

0:33:28	SPEAKER_00
 And then, uh, another check involves, uh, being sure that every utterance has an identifiable speaker.

0:33:34	SPEAKER_00
 And if not, then that gets checked.

0:33:36	SPEAKER_00
 Then there's this issue of glossing, so-called spoken forums.

0:33:40	SPEAKER_00
 So they're- most for the most part, we're keeping it standard, we're-we're level transcription.

0:33:45	SPEAKER_00
 But there's- and that's done with the assumption that pronunciation variants can be handled.

0:33:50	SPEAKER_00
 So for things like, and the fact that someone doesn't say the D, uh, that's not important enough to capture in the transcription because of a good pronunciation, uh, you know, model, we'll be able to handle that.

0:34:01	SPEAKER_00
 However, things like, because, where you're lacking an entire very prominent for a syllable.

0:34:05	SPEAKER_00
 And furthermore, it's a forum that's specific to spoken language.

0:34:09	SPEAKER_00
 Those are reasons- for- for those reasons, I-I kept that separate and used the convention of using C, U, Z for that forum.

0:34:16	SPEAKER_00
 However, glossing it so that it's possible with a script to plug in the full orthographic forum for that one.

0:34:22	SPEAKER_00
 And a couple of others, not many.

0:34:24	SPEAKER_00
 So, Wana is another one going- Gona is another one with just the assumption again that this- these are things which it's not really fair to consider expected at pronunciation model to handle.

0:34:34	SPEAKER_00
 And Chuck, you- you indicated that, and this is- is one of those that's handled in a different way also.

0:34:39	SPEAKER_00
 Didn't you? Did I?

0:34:40	SPEAKER_00
 I don't remember.

0:34:41	SPEAKER_00
 Okay, so I was- it might not have been- it might not have been you.

0:34:44	SPEAKER_00
 But someone told me that in fact, Cuzz has treated differently in, um, in this context because of that reason that, um, it's a little bit farther than a pronunciation variant.

0:34:54	SPEAKER_00
 Okay, so after that, let's see.

0:34:56	SPEAKER_08
 Um, so that was part of the spell check or is that- that was after the spell check?

0:35:00	SPEAKER_00
 Well, so when I get the exhaust- so the spell check picks up those words because they're not in the dictionary, so it gets Cuzz and Wana and that-

0:35:07	SPEAKER_06
 And then you gloss them.

0:35:08	SPEAKER_00
 Yeah, I've run it through- I have a said, you know, so I do a side script saying whenever you see Gona- convert it to Gona, you know, gloss equals quote, going to quote, you know.

0:35:18	SPEAKER_00
 And with all of these things being in curly brackets, so they're always distinctive.

0:35:22	SPEAKER_00
 Okay, I also wrote a script which will, um, retrieve anything in curly brackets or anything which I've classified as an acronym and it pronounced acronym.

0:35:34	SPEAKER_00
 And the way I take- pronounced acronyms is that I have underscores between the component.

0:35:39	SPEAKER_00
 So if it's ACL, then it's A underscores C underscore L.

0:35:43	SPEAKER_00
 And-

0:35:44	SPEAKER_06
 So your list here are these ones that actually occurred in the meetings?

0:35:47	SPEAKER_00
 Yes, huh? Yeah.

0:35:49	SPEAKER_00
 Okay, so now- We are asking-

0:35:51	SPEAKER_04
 Can I ask a question about the glossing of the before we go on? So for a word like, because is it that it's always predictably because- I mean, is CUSE always meaning because?

0:36:04	SPEAKER_00
 Yes, but not the reverse.

0:36:05	SPEAKER_00
 So sometimes people will say because in the meeting.

0:36:07	SPEAKER_00
 And if they actually said because, then it's written as because with no- with cause doesn't even figure into the equation.

0:36:14	SPEAKER_00
 Because-

0:36:15	SPEAKER_07
 But not eating as people don't say, hey, cause. Right, right, right, right, yeah.

0:36:19	SPEAKER_04
 Yeah.

0:36:20	SPEAKER_04
 So, I guess so from the point of view of- The only problem is that with- For the recognition we map it to B cause.

0:36:30	SPEAKER_04
 And so we know that CUSE is the- Well, don't have the gloss.

0:36:32	SPEAKER_06
 But you have the gloss forms, you always replace it.

0:36:35	SPEAKER_06
 Exactly.

0:36:36	SPEAKER_06
 If that's what you want to do.

0:36:37	SPEAKER_00
 Uh-huh.

0:36:38	SPEAKER_00
 And Don knows this, and he's been- Yeah, I replaced the cause with B cause if it's lost.

0:36:41	SPEAKER_04
 Right, but- If it's okay.

0:36:43	SPEAKER_04
 But then there are other glosses that we don't replace, right?

0:36:47	SPEAKER_00
 Because- Yes, and that's why there are different tags on the glosses.

0:36:50	SPEAKER_00
 Okay, so- On the different types of comments, which we'll see in just a second.

0:36:54	SPEAKER_00
 So the pronounceable acronyms get underscores.

0:36:57	SPEAKER_00
 The things in curly brackets are viewed as comments.

0:36:59	SPEAKER_00
 They're comments of four types.

0:37:00	SPEAKER_00
 So it's a good time to introduce that.

0:37:02	SPEAKER_00
 Four types.

0:37:03	SPEAKER_00
 And maybe we'll expand that.

0:37:04	SPEAKER_00
 But the- But the comments are- Four types, mainly right now.

0:37:08	SPEAKER_00
 One of them is- Um, the gloss type we just mentioned.

0:37:12	SPEAKER_00
 Another type is-

0:37:14	SPEAKER_06
 So are we done with acronyms? Because I had a question on what- What does this mean?

0:37:18	SPEAKER_00
 I'm still doing the overview.

0:37:19	SPEAKER_00
 I haven't actually gotten here yet.

0:37:20	SPEAKER_00
 Awesome.

0:37:21	SPEAKER_00
 Okay, so glosses things like- glosses things like replacing the full form with the, um, more abbreviated one to the left.

0:37:30	SPEAKER_00
 Then you have- If it's- There's a couple different types of elements that can happen that aren't really properly words.

0:37:36	SPEAKER_00
 And some of them are laughs and breeze.

0:37:39	SPEAKER_00
 So we have- That's prepended with a tag of VOC.

0:37:42	SPEAKER_00
 And the non-vulgones are like door slams and tapping.

0:37:45	SPEAKER_00
 And that's prepended with a- So the non-vulgination- So the end being curly braces or something else?

0:37:50	SPEAKER_00
 Oh yeah, so this would- Let's just take one example.

0:37:53	SPEAKER_00
 Oh, oh, oh.

0:37:54	SPEAKER_00
 And then the non-vulgization would be something like a door slam.

0:37:58	SPEAKER_00
 They always end.

0:37:59	SPEAKER_00
 So it's like they're paired curly brackets.

0:38:01	SPEAKER_00
 And then the third type right now is things that fall in the category of comments about what's happening.

0:38:08	SPEAKER_00
 So it could be something like, you know, referring to so-and-so, talking about such and such, you know, looking at so-and-so.

0:38:15	SPEAKER_00
 So on the middle-

0:38:16	SPEAKER_08
 So in the first case that gloss applies to the word to the left. Yeah.

0:38:20	SPEAKER_00
 And this gets so- In the middle two, it's not applying anything, right?

0:38:23	SPEAKER_00
 No, they're events.

0:38:24	SPEAKER_00
 They're actually- The quality-

0:38:26	SPEAKER_06
 The quality is applying to the left.

0:38:28	SPEAKER_08
 Right, I just meant the middle two.

0:38:30	SPEAKER_00
 Yeah. Well, and actually it is true that with respect to laugh, there's another one which is while laughing.

0:38:38	SPEAKER_00
 And that is- An argument could be made for this turning that into a qualitative statement because it's talking about the thing that preceded it.

0:38:47	SPEAKER_00
 But at present we haven't been coding the exact scope of laughing, you know?

0:38:53	SPEAKER_00
 And so to have while laughing, you know that it happened somewhere in there, which could well mean that it occurred separately and following, or, you know, including some of the utterances to the left.

0:39:02	SPEAKER_00
 Haven't been awfully precise about that.

0:39:04	SPEAKER_00
 But I have here- Now we're about to get to this now.

0:39:06	SPEAKER_00
 I have frequencies.

0:39:07	SPEAKER_00
 So you'll see how often these different things occur.

0:39:10	SPEAKER_00
 But the very front page deals with this final aspect of standardization which has to do with the spoken forms like mm-hmm, and ha, and uh-uh, and all these different types.

0:39:24	SPEAKER_00
 And someone pointed out to me- This might have been Chuck.

0:39:29	SPEAKER_00
 About how a recognizer if it's looking for mm-hmm with 3M's, and it's transcribed with 2M's, that it might increase the air rate, which should really be a shame, because I personally would not be able to make a claim that those are dramatically different items.

0:39:48	SPEAKER_00
 So right now I've standardized across all the existing data with these spoken forms.

0:39:52	SPEAKER_00
 I should say all existing data except 30 minutes which got found today.

0:39:57	SPEAKER_00
 So I know- I'm going to check.

0:39:59	SPEAKER_00
 Yeah, actually, yeah, it was stored in a place I didn't expect.

0:40:03	SPEAKER_00
 So, and we reconstructed how to happen.

0:40:08	SPEAKER_00
 And this would be great.

0:40:11	SPEAKER_00
 So I'll be able to get through that tonight and then actually later today, really.

0:40:15	SPEAKER_00
 And so then we'll have everything following these conventions.

0:40:17	SPEAKER_00
 But notice it's a really rather small set of these kinds of things.

0:40:21	SPEAKER_00
 And I made it so that these are- With a couple exceptions, but things that you wouldn't find in the spell checker so that they'll show up really easily.

0:40:29	SPEAKER_03
 And- Jane, can I ask you a question?

0:40:34	SPEAKER_00
 Well, does that very last one correspond to?

0:40:35	SPEAKER_00
 Yeah, yeah.

0:40:36	SPEAKER_00
 That's only hers once and I'm thinking of changing that.

0:40:38	SPEAKER_00
 Is that like someone's warning or something?

0:40:40	SPEAKER_00
 I haven't heard it actually.

0:40:41	SPEAKER_00
 I need to listen to that.

0:40:42	SPEAKER_04
 Actually, we gave this to our pronunciation person.

0:40:44	SPEAKER_04
 She's like, I don't know what that is either.

0:40:46	SPEAKER_04
 Did she actually hear it?

0:40:48	SPEAKER_04
 No, we had- We gave her a list of words that weren't in our dictionary.

0:40:52	SPEAKER_04
 And so of course it picked up stuff like this.

0:40:54	SPEAKER_04
 And she just didn't listen.

0:40:55	SPEAKER_04
 So if she didn't know, we're just waiting on it.

0:40:58	SPEAKER_00
 Yeah, I'm curious to see what it is, but I didn't want to change it to something else until- You can't hear it.

0:41:02	SPEAKER_00
 Well, you know-

0:41:03	SPEAKER_03
 But that's not really like- Yeah.

0:41:05	SPEAKER_03
 No one really says arg.

0:41:06	SPEAKER_03
 Right, no- It's a- I said the highest ass, that's right.

0:41:11	SPEAKER_05
 That's a big problem when we talk about that.

0:41:12	SPEAKER_05
 We're going to never recognize this meeting.

0:41:13	SPEAKER_05
 Money ties on the art.

0:41:14	SPEAKER_06
 Well, yeah.

0:41:16	SPEAKER_06
 Well, or if you're a see programmer.

0:41:18	SPEAKER_04
 Yeah, that's right.

0:41:19	SPEAKER_04
 The art, see, and art, see, and art.

0:41:20	SPEAKER_04
 That's right.

0:41:21	SPEAKER_04
 It has a different pros.

0:41:22	SPEAKER_06
 It has arch-max, arch-max.

0:41:24	SPEAKER_05
 So Jane, what's-

0:41:25	SPEAKER_04
 Maybe tie- So I have one question about the EH versus like the AH and U-A.

0:41:31	SPEAKER_00
 That's partly a non-native native thing, but I have found EH and the native speakers too.

0:41:36	SPEAKER_00
 But it's mostly non-native.

0:41:37	SPEAKER_00
 Okay.

0:41:38	SPEAKER_00
 That's A versus A.

0:41:39	SPEAKER_04
 A.

0:41:40	SPEAKER_04
 A, yeah, right, because there were some speakers that did definite A's, but right now we- There were the Canadians, right?

0:41:50	SPEAKER_04
 So it's actually probably good for us to know the difference between the real A and the one that- Exactly.

0:41:56	SPEAKER_04
 Because in switchboard you would see all of these forms, but they all were like, ah.

0:42:02	SPEAKER_06
 I mean, just the single letter A has in the particles group.

0:42:07	SPEAKER_04
 No, no, I mean like the UH or the UH EH were all the same.

0:42:13	SPEAKER_04
 And then we have this additional non-native version of A.

0:42:17	SPEAKER_03
 All the EHs I've seen have been like that.

0:42:19	SPEAKER_03
 They've been like, eh, like that has been transcribed to EH.

0:42:23	SPEAKER_03
 And sometimes it's stronger, like A, which is like closer to EH, but- Yeah.

0:42:30	SPEAKER_06
 I'm just these poor transcribers, I know.

0:42:32	SPEAKER_00
 Well, we're not doing- We're not doing- We're not doing clause for us.

0:42:35	SPEAKER_00
 That's right.

0:42:36	SPEAKER_00
 Who knows?

0:42:37	SPEAKER_04
 And your native German speaker, so not a- Not an issue for-

0:42:43	SPEAKER_06
 It's only- Thick-thick Canadians.

0:42:45	SPEAKER_04
 Not only if you don't have black swallows, I guess, right?

0:42:50	SPEAKER_00
 That's my sense.

0:42:53	SPEAKER_00
 That's my sense.

0:42:54	SPEAKER_00
 That's my sense.

0:42:55	SPEAKER_00
 Yeah, and so, you know, I mean, I have- There are some Americans who are using this A2, and I haven't listened to it systematically.

0:43:02	SPEAKER_00
 Maybe with some of them, they'd end up being us, but- My spot checking has made me think that we do have A and also American data represented here.

0:43:12	SPEAKER_00
 But, in any case, this is reduced down from really quite a long- Much longer list.

0:43:16	SPEAKER_00
 Yeah, this is great.

0:43:17	SPEAKER_00
 This is really, really helpful.

0:43:18	SPEAKER_00
 Functionally pretty, you know, also.

0:43:19	SPEAKER_00
 It was fascinating.

0:43:20	SPEAKER_00
 I was listening to some of these, I guess, two nights ago, and it's just hilarious to listen to- To do a search for the m-hms, and you get m-hm, and do- Everybody's doing it.

0:43:29	SPEAKER_00
 Just doing it.

0:43:30	SPEAKER_00
 I think it would be fun to make a montage of it, because- Performance are just a extract.

0:43:35	SPEAKER_00
 Right.

0:43:36	SPEAKER_00
 It's really, it's really fun to listen.

0:43:38	SPEAKER_00
 All these different vocal tracks, you know, but it's the same item, it's very interesting.

0:43:42	SPEAKER_00
 Okay.

0:43:43	SPEAKER_00
 Then the acronyms, and the ones in parentheses are ones which the transgarber wasn't sure of, and I haven't been able to listen to it to clarify.

0:43:49	SPEAKER_00
 But you can see that the parentheses convention makes it very easy to find them, because it's the only question mark for- The question mark is punctuation, so they said that- Oh.

0:43:58	SPEAKER_00
 D-C?

0:43:59	SPEAKER_00
 So it's PLP?

0:44:00	SPEAKER_00
 Exactly.

0:44:01	SPEAKER_00
 Exactly.

0:44:02	SPEAKER_00
 Yeah, so the only- Well, and I do have a stress marker here.

0:44:06	SPEAKER_00
 Sometimes the contrast to a stress is showing up, and-

0:44:08	SPEAKER_07
 That's right, I got lost here. What's the difference between the parenthesis acronym and the non-prenthesis?

0:44:13	SPEAKER_00
 The parenthesis is something that the transgarber thought was A and N, but wasn't entirely sure.

0:44:18	SPEAKER_00
 So I'd need to go back, or someone needs to go back and say, you know, yes or no, and then get rid of the parentheses.

0:44:23	SPEAKER_00
 But the parentheses are used only in that context in the transcripts of- I've noticed- Noticing that there's something uncertain.

0:44:29	SPEAKER_00
 Yeah, I mean, they have no idea right.

0:44:31	SPEAKER_04
 If you hear CTPD, I mean, they do pretty well, but it's- I don't recognize- You know, how are they gonna know?

0:44:37	SPEAKER_06
 I think a lot of them are the networks we think.

0:44:39	SPEAKER_00
 I think that's true.

0:44:40	SPEAKER_00
 Yeah, absolutely.

0:44:41	SPEAKER_00
 In fact, a lot of these are coming from them.

0:44:43	SPEAKER_00
 I listen to some of that.

0:44:44	SPEAKER_03
 Although we don't have that many acronyms, comparatively.

0:44:47	SPEAKER_03
 In this meeting, it's not a bad thing.

0:44:49	SPEAKER_00
 And robustness is a fair amount, but the NSA group is just very, very many.

0:44:53	SPEAKER_04
 The recognizeer is funny.

0:44:55	SPEAKER_04
 kept getting PTA for PTA.

0:44:57	SPEAKER_04
 This is supposed to rain, and the PTA wasn't these topics about children.

0:45:03	SPEAKER_04
 That's interesting.

0:45:05	SPEAKER_00
 Is the PTA working?

0:45:08	SPEAKER_00
 Sometimes I mean, you see a couple of these are actually OK's.

0:45:11	SPEAKER_00
 So it's- it's- it's maybe that they got to the point where it was low enough, understandable- and stand-ability that they weren't entirely sure the person said OK.

0:45:18	SPEAKER_00
 You know, so it isn't really necessarily a- an undes ifable acronym, but it just needs to be double-checked.

0:45:23	SPEAKER_00
 Now we get to the comments.

0:45:24	SPEAKER_07
 The number to the left is the number of consonants.

0:45:26	SPEAKER_00
 The number of times out of the entire database, except for that last 30 minutes I haven't checked yet.

0:45:30	SPEAKER_06
 So CTS is really good.

0:45:32	SPEAKER_02
 Yeah, I wonder what it is.

0:45:34	SPEAKER_02
 So what is- I just between papers, rostling and drostling papers.

0:45:37	SPEAKER_00
 I'd have to listen.

0:45:38	SPEAKER_00
 I- I agree.

0:45:39	SPEAKER_00
 I'd like to standardize these down farther, but, um, to me that sounds equivalent.

0:45:46	SPEAKER_00
 I'm a little hesitant to- to collapse cross categories unless I actually listen to them.

0:45:51	SPEAKER_06
 Oh, I'm sure we've said XML more than five times.

0:45:56	SPEAKER_06
 Well, at least now.

0:45:58	SPEAKER_01
 That's a least six times.

0:46:01	SPEAKER_01
 OK, well- I'm so preferential.

0:46:07	SPEAKER_04
 Yes, it's very bad.

0:46:08	SPEAKER_04
 Well, this is exactly how people will prove that these meetings do differ because we're recording, right?

0:46:11	SPEAKER_04
 Yes.

0:46:12	SPEAKER_04
 Normally you don't go around saying, now you've said it six times.

0:46:17	SPEAKER_00
 But you notice that there were 785 instances of OK.

0:46:20	SPEAKER_00
 Yeah.

0:46:21	SPEAKER_00
 And that's not the right one.

0:46:22	SPEAKER_00
 And that's not the right one.

0:46:23	SPEAKER_00
 And that's not the right one.

0:46:24	SPEAKER_00
 The first question.

0:46:25	SPEAKER_00
 So, yeah.

0:46:27	SPEAKER_00
 On the page two acronyms.

0:46:28	SPEAKER_03
 Yeah.

0:46:29	SPEAKER_03
 Is this after- Like, did you do some replacements for all the different forms of OK to this?

0:46:33	SPEAKER_00
 OK.

0:46:34	SPEAKER_00
 So, that's the single existing convention for OK.

0:46:37	SPEAKER_08
 Wait a minute.

0:46:38	SPEAKER_08
 It's not worth a 788.

0:46:40	SPEAKER_03
 Although, there's one with a slash after it.

0:46:43	SPEAKER_03
 Yeah.

0:46:44	SPEAKER_00
 That's kind of disturbing.

0:46:45	SPEAKER_00
 I look for that one.

0:46:46	SPEAKER_00
 I actually explicitly look for that one.

0:46:48	SPEAKER_00
 And I think that I'm not exactly sure about that.

0:46:51	SPEAKER_08
 Is that somewhere where they were going to say new speakers or something?

0:46:54	SPEAKER_00
 No, I look for that.

0:46:55	SPEAKER_00
 That doesn't actually exist.

0:46:57	SPEAKER_00
 And maybe- I can't explain that.

0:46:59	SPEAKER_03
 That's all right.

0:47:00	SPEAKER_00
 It's only- It's the only pattern that has a slash after it.

0:47:03	SPEAKER_00
 And I think it's not-

0:47:04	SPEAKER_06
 I was just looking at the bottom of page three. Is that 2B or not 2B?

0:47:07	SPEAKER_06
 Yeah.

0:47:08	SPEAKER_01
 There's no tilde in front of it.

0:47:11	SPEAKER_01
 That's funny.

0:47:12	SPEAKER_00
 Yeah.

0:47:13	SPEAKER_00
 OK.

0:47:14	SPEAKER_00
 Anyways.

0:47:16	SPEAKER_06
 There is one.

0:47:17	SPEAKER_06
 There is one.

0:47:18	SPEAKER_06
 It's no on topic, Adam.

0:47:19	SPEAKER_00
 Well, let's- Let's legitimate- So, now, comments you can see they're listed again.

0:47:25	SPEAKER_00
 Same deal with the exhaustive listing of everything found and everything except for these final 30 minutes.

0:47:29	SPEAKER_06
 OK. So, on some of these quals- Yeah.

0:47:34	SPEAKER_06
 Are they really quals or are they glosses?

0:47:36	SPEAKER_06
 So, like, there's a- Qual TCL?

0:47:39	SPEAKER_00
 TCL. Where do you see that?

0:47:41	SPEAKER_00
 Uh-oh.

0:47:42	SPEAKER_00
 The reason is because it was said tickle.

0:47:45	SPEAKER_06
 Oh, I see, I see.

0:47:46	SPEAKER_06
 So, it's not gloss.

0:47:47	SPEAKER_06
 OK, I see.

0:47:48	SPEAKER_06
 Yeah.

0:47:49	SPEAKER_03
 It wasn't said TCL.

0:47:50	SPEAKER_03
 Should it be called TIC-KLE or something?

0:47:52	SPEAKER_03
 Like, it's not-

0:47:53	SPEAKER_00
 In the actual script, in the actual transcript, I-so this happens in the very first one.

0:47:59	SPEAKER_00
 I actually wrote it as tickle.

0:48:01	SPEAKER_00
 OK.

0:48:02	SPEAKER_00
 Because they didn't say TCL, they said tickle.

0:48:04	SPEAKER_00
 Yeah.

0:48:05	SPEAKER_00
 And then, following that is, Qual TCL.

0:48:07	SPEAKER_00
 Oh, I see.

0:48:08	SPEAKER_03
 OK.

0:48:09	SPEAKER_03
 I forget what's Qual.

0:48:10	SPEAKER_00
 Qualifier.

0:48:11	SPEAKER_00
 Just comment about what they said.

0:48:13	SPEAKER_08
 Comment.

0:48:14	SPEAKER_00
 Yeah.

0:48:15	SPEAKER_00
 Comment, dirt, text, your comment.

0:48:16	SPEAKER_08
 So, they didn't mean tickle as in, Elmo, then tickle.

0:48:21	SPEAKER_08
 But at some point, we probably-

0:48:23	SPEAKER_04
 We should add it to the dictionary. No, it's the pronunciation model.

0:48:27	SPEAKER_04
 What did I say?

0:48:28	SPEAKER_06
 Language.

0:48:29	SPEAKER_06
 Well, both.

0:48:30	SPEAKER_06
 We can add it to the language model.

0:48:32	SPEAKER_04
 Yeah, but it's the pronunciation model.

0:48:35	SPEAKER_04
 It has to have a pronunciation of TIC-KLE.

0:48:38	SPEAKER_06
 Well, TIC-KLE was pronounced TIC-KLE.

0:48:40	SPEAKER_06
 Right.

0:48:41	SPEAKER_06
 What do you say?

0:48:42	SPEAKER_06
 It's pronounced the same as the verb.

0:48:45	SPEAKER_06
 So, I think it's the language model that makes it different.

0:48:48	SPEAKER_06
 Oh, sorry.

0:48:49	SPEAKER_04
 What I meant is that there should be a pronunciation tickle for TCL as a word.

0:48:55	SPEAKER_04
 And that word stays in the language model wherever it was.

0:48:58	SPEAKER_04
 Right.

0:48:59	SPEAKER_04
 Yeah, you never would put tickle in the language model in that form.

0:49:02	SPEAKER_04
 Right.

0:49:03	SPEAKER_04
 There's actually a bunch of cases like this.

0:49:05	SPEAKER_08
 So, how would there be a problem for doing the language model and then with our transcripts over here?

0:49:09	SPEAKER_04
 Yes.

0:49:10	SPEAKER_04
 Yeah.

0:49:11	SPEAKER_04
 Yeah, so there's a few cases like that where the word needs to be spelled out in a consistent way as it would appear in the language, but there's not very many of these.

0:49:23	SPEAKER_04
 Tickles one of them.

0:49:24	SPEAKER_04
 And you'll have to do it synchronously.

0:49:26	SPEAKER_04
 Right.

0:49:27	SPEAKER_06
 So, whoever's creating the new models will have to also go through the transcripts and choose them synchronously.

0:49:34	SPEAKER_04
 Right.

0:49:35	SPEAKER_04
 We have this, there is this thing I was going to talk to you at some point about, you know, what do we do with the dictionary as we're updating the dictionary?

0:49:43	SPEAKER_04
 These changes have to be consistent with what's in the, like spelling people's names and so forth.

0:49:49	SPEAKER_04
 If we make a spelling correction to their name, like someone had Deborah Tannen's name, Miss Bell, and since we know who that is, you know, we can correct it, but we need to make sure we have the misspell, if it doesn't get corrected, we have to have a pronunciation as a misspell word in the dictionary, it's like that.

0:50:05	SPEAKER_00
 Well, of course now the, the Tannen, the spelling, I pick those up in the frequency check.

0:50:11	SPEAKER_00
 Right.

0:50:12	SPEAKER_04
 Right.

0:50:13	SPEAKER_04
 So, if there's things that get corrected before we get them, it's not an issue.

0:50:16	SPEAKER_04
 If there's things that we change later, then we always have to keep our dictionary up to date.

0:50:24	SPEAKER_04
 And then, yeah, in the case of tickle, I guess we would just have a word TCL, which, which normally would be an acronym, you know, TCL, but just has another pronunciation.

0:50:35	SPEAKER_04
 Yeah.

0:50:36	SPEAKER_00
 XCs is one of those that sometimes people pronounce and sometimes they say I see a sign.

0:50:40	SPEAKER_00
 So, those that are listed in the acronyms, I actually know they were said as letters.

0:50:45	SPEAKER_00
 The others, those really do need to be listened to, because I haven't been able to go to all the XC things.

0:50:52	SPEAKER_00
 And until they've been listened to, they stay as ICSI.

0:50:54	SPEAKER_00
 Right.

0:50:55	SPEAKER_07
 Don and I were just noticing, love this one over on page three.

0:51:00	SPEAKER_07
 Vocal gesture mimicking sound, obscuring something to head to whole blanket place.

0:51:05	SPEAKER_07
 It's great.

0:51:06	SPEAKER_07
 It was me.

0:51:08	SPEAKER_06
 It was, in fact, it was.

0:51:10	SPEAKER_06
 Yeah.

0:51:11	SPEAKER_06
 A lot of these are me.

0:51:12	SPEAKER_06
 He said he said he said with a high pitch and lengthening.

0:51:15	SPEAKER_06
 That was the, I was imitating beeping out.

0:51:18	SPEAKER_06
 Perfect.

0:51:19	SPEAKER_04
 Oh, there is something.

0:51:20	SPEAKER_04
 I spelled out BEEE.

0:51:21	SPEAKER_04
 Yeah.

0:51:22	SPEAKER_04
 That's been changed.

0:51:23	SPEAKER_04
 Thank you.

0:51:24	SPEAKER_04
 Because he was saying, how many of these do I have to allow?

0:51:27	SPEAKER_03
 You need a lot of qualification in it.

0:51:29	SPEAKER_03
 That's been changed.

0:51:30	SPEAKER_00
 So, exactly.

0:51:31	SPEAKER_00
 That's where the lengthening comment can't get in.

0:51:33	SPEAKER_00
 Right.

0:51:34	SPEAKER_00
 Right.

0:51:35	SPEAKER_00
 So, the vocalization.

0:51:36	SPEAKER_00
 And those, of course, get picked up on the frequency check, because CBE, and you know, I mean, it gets kicked out in the spelling and also gets kicked out in the frequency listing.

0:51:45	SPEAKER_00
 And I have the various things like breathe versus breath versus inhale.

0:51:49	SPEAKER_00
 And, you know, I don't know.

0:51:51	SPEAKER_00
 I think they don't have any implications for anything else.

0:51:54	SPEAKER_00
 So, it's like I'm tempted to leave them for now.

0:51:56	SPEAKER_00
 And it's easy enough to find them when they're in curly brackets.

0:51:58	SPEAKER_00
 We can always get an exhaustive listing of these things and find them and change them.

0:52:01	SPEAKER_07
 Things finale types on.

0:52:03	SPEAKER_07
 Yeah.

0:52:04	SPEAKER_00
 This is the first meeting.

0:52:05	SPEAKER_00
 Yeah, but I don't actually remember what it was, but that was Eric did that.

0:52:09	SPEAKER_06
 Yeah.

0:52:10	SPEAKER_06
 So, on.

0:52:11	SPEAKER_06
 Ta-da.

0:52:12	SPEAKER_00
 I think maybe something like that.

0:52:13	SPEAKER_00
 Maybe, yeah.

0:52:14	SPEAKER_00
 I'll take a call if I want.

0:52:16	SPEAKER_06
 On the glosses for numbers.

0:52:18	SPEAKER_00
 Yeah.

0:52:19	SPEAKER_06
 It seems like they're lost in different ways it's being done.

0:52:23	SPEAKER_00
 Yes.

0:52:24	SPEAKER_00
 Okay.

0:52:25	SPEAKER_00
 Now, first of all, very important.

0:52:26	SPEAKER_00
 Check, check lead to refinement here, which is to add numbs if these are parts of the red numbers.

0:52:31	SPEAKER_00
 Now, you already know that I had places where they hadn't transcribed numbers, put numbers in place of any kind of numbers, but there were places where they, this convention came later and at the very first digits task in some transcripts, they actually transcribed numbers and, um, check point out that this is a red speech and it's nice to have the option of ignoring it for certain other pop things.

0:52:55	SPEAKER_00
 And that's why there's this other tag here which occurs a 105, or 305 times right now, which is just, well, and numbs by itself, which means this is part of the numbers task.

0:53:04	SPEAKER_00
 I may change it to digits.

0:53:05	SPEAKER_00
 I mean, with the said command, you can really just change it however you want because it's systematically encoded.

0:53:10	SPEAKER_00
 Yeah.

0:53:11	SPEAKER_00
 You have to think about what's the best for the overall purposes, but in any case, numbers and numbs are part of this digits task thing.

0:53:19	SPEAKER_00
 Now, then I have these numbers that have quotation marks around them.

0:53:23	SPEAKER_00
 I didn't want to put them in its gloss comments because then you get the substitution.

0:53:27	SPEAKER_00
 And actually, the reason I did it this way was because I initially started out with the other version.

0:53:33	SPEAKER_00
 You have the numbers and you have the full form and the print of these.

0:53:35	SPEAKER_00
 However, sometimes people stumble over these numbers they're saying.

0:53:38	SPEAKER_00
 So you say, 78.2 or whatever.

0:53:42	SPEAKER_00
 And there's no way of capturing that if you're putting the numbers off to the side.

0:53:45	SPEAKER_00
 So what's the whole left of these?

0:53:47	SPEAKER_00
 The left is, so example, the very first one, it would be spelled out in words.

0:53:52	SPEAKER_06
 Okay, that's what I was asking.

0:53:54	SPEAKER_00
 0.5.

0:53:55	SPEAKER_00
 Right.

0:53:56	SPEAKER_00
 Only it's spelled out in words.

0:53:58	SPEAKER_00
 So this is also spelled out in words.

0:54:00	SPEAKER_00
 0.5.

0:54:01	SPEAKER_00
 Good.

0:54:02	SPEAKER_00
 And then in here, numbs.

0:54:04	SPEAKER_00
 So it's not going to be mistaken as a gloss.

0:54:07	SPEAKER_00
 It comes out as numbs.

0:54:09	SPEAKER_00
 Quote.5.

0:54:10	SPEAKER_06
 Okay, now the other example is in the glosses right there.

0:54:14	SPEAKER_06
 Gloss.1.1-130.

0:54:16	SPEAKER_06
 Oh, no.

0:54:17	SPEAKER_00
 What's the left of that?

0:54:18	SPEAKER_00
 In that case, it's people saying things like 1.1.1-so-so or they're saying 2.0, whatever.

0:54:26	SPEAKER_00
 And in that case, it's part of the numbers task and it's not going to be included in the red digits anyway.

0:54:31	SPEAKER_00
 So there will be a numbs tag on those lines?

0:54:33	SPEAKER_08
 There is.

0:54:34	SPEAKER_00
 Yeah.

0:54:35	SPEAKER_00
 I've added that all now too.

0:54:36	SPEAKER_00
 There's a numbers tag.

0:54:37	SPEAKER_03
 I'm sorry, I didn't follow that last thing.

0:54:39	SPEAKER_00
 So gloss.

0:54:40	SPEAKER_00
 In the same line that would have a gloss, quote, 1.1.1-130.

0:54:43	SPEAKER_00
 Right.

0:54:44	SPEAKER_00
 You'd have a gloss at the end of the line saying curly bracket, numbs curly bracket.

0:54:48	SPEAKER_00
 So if you did a graph minus V numbs, so you get rid of anything that was red.

0:54:54	SPEAKER_04
 So there wouldn't be something like, if somebody said something like, boy, I'm really tired, OK, and then started reading.

0:55:01	SPEAKER_04
 That would be in a separate line.

0:55:02	SPEAKER_04
 Yes.

0:55:03	SPEAKER_04
 OK, great.

0:55:04	SPEAKER_04
 Because I was doing the graph minus V quick and dirty and looked like that was working OK.

0:55:08	SPEAKER_04
 Good.

0:55:09	SPEAKER_04
 Great.

0:55:10	SPEAKER_04
 Now, why do we, what's the reason for having like the 0.5 have the numbs on it?

0:55:15	SPEAKER_04
 Is it just like when they're talking about their data or something?

0:55:17	SPEAKER_00
 This is more because, yeah, oh, these are all these, the numbs point side.

0:55:21	SPEAKER_00
 These are all where they're saying point.

0:55:23	SPEAKER_00
 It's something or other.

0:55:24	SPEAKER_00
 And the other thing too is for readability, the transcript.

0:55:27	SPEAKER_00
 I mean, if you're trying to follow this while you're reading it, it's really hard to read.

0:55:31	SPEAKER_00
 So in the data column 5 has 1.5 compared to 79.6.

0:55:38	SPEAKER_00
 It's like, when you see the words, it's really hard to follow the argument.

0:55:41	SPEAKER_00
 And this is just really a way of someone who would handle the data in a more discoracy way to be able to follow what's being said.

0:55:48	SPEAKER_00
 So this is where it chucks overall architecture comes in, where we're going to have a master file of the channelized data.

0:55:57	SPEAKER_00
 There will be scripts that are written to convert it into these main two uses.

0:56:01	SPEAKER_00
 And some scripts will take it down into a format that's usable for the recognizer.

0:56:07	SPEAKER_00
 Other scripts will take it to a form that's usable for linguistics and discourse analysis.

0:56:13	SPEAKER_00
 And the implication that I have is that the master copy will stay unchanged.

0:56:18	SPEAKER_00
 These will just be things that are generated.

0:56:20	SPEAKER_00
 And by using scripts, when things change, then the script will change.

0:56:24	SPEAKER_00
 But there won't be stored copies in different versions of things.

0:56:28	SPEAKER_04
 So I guess I'd have one request here, which is just maybe to make it more robust, that the tag, whatever you would choose for this type of numbs, where it's inside the spontaneous speech is different than the tag that you use for the red speech.

0:56:42	SPEAKER_04
 That would argue for changing the other ones.

0:56:44	SPEAKER_04
 That way, if we make a mistake parsing or something, we don't see the.5 or it's not there, then we just, and actually for things like 7-8th, or people do fractions too, I guess, maybe you want one overall tag for sort of that would be similar to that.

0:57:00	SPEAKER_04
 Or as long as there's different strings that will make our processing more robust, because we really will get rid of everything that has the numbs string in it.

0:57:10	SPEAKER_08
 I suppose what you could do is just make sure that you get rid of everything that has curly brace numbs, curly brace.

0:57:16	SPEAKER_08
 Exactly. That would be that. That was my motivation.

0:57:19	SPEAKER_00
 And these can be changed, like I said.

0:57:22	SPEAKER_00
 As I said, I was considering changing it to digits.

0:57:25	SPEAKER_00
 And it's just a matter of deciding on whatever it is and being sure the scripts know.

0:57:29	SPEAKER_04
 It would probably be safer if you're willing to have a separate tag, just because then we know for sure, and we can also do counts on them without having to do the processing.

0:57:38	SPEAKER_04
 But you're right, we could do it this way. It should work.

0:57:41	SPEAKER_04
 Yeah, and it makes it, I guess, the thing about... Probably not hard for a person to tell the difference, because one's in the context of a transcribed word.

0:57:50	SPEAKER_00
 The thing is you can get really so minute with these things and increase the size of the files and decrease of readability such an extent by simply something like percent.

0:57:59	SPEAKER_00
 Now, I could have adopted a similar convention for percent, but somehow percent is not so hard.

0:58:04	SPEAKER_00
 When you have these points and you're trying to figure out where the decimal voices are, percent's easy to detect. Point, however, is a word that has a couple different meanings, and you'll find both of those in one of these meetings.

0:58:15	SPEAKER_00
 We're saying the first point I want to make is so-and-so on.

0:58:17	SPEAKER_00
 Those two four points and also has all these decimals.

0:58:20	SPEAKER_08
 So, Liz, what does the recognizer do?

0:58:23	SPEAKER_08
 What is the SRA recognizer output for things like that?

0:58:26	SPEAKER_08
 7.5. Does it output the word...

0:58:28	SPEAKER_08
 7.5.

0:58:29	SPEAKER_04
 Right, the word 7?

0:58:30	SPEAKER_08
 The number 7?

0:58:31	SPEAKER_08
 The word 7.

0:58:32	SPEAKER_08
 Yeah.

0:58:33	SPEAKER_04
 And actually, you know, the language...

0:58:34	SPEAKER_04
 What we talk about point...

0:58:35	SPEAKER_04
 The same point, actually, the word 2 and the word...

0:58:38	SPEAKER_04
 They're going to and to go to.

0:58:41	SPEAKER_04
 Those are two different twos.

0:58:43	SPEAKER_04
 So, there's no distinction there.

0:58:45	SPEAKER_04
 It's just the word point.

0:58:47	SPEAKER_04
 Every word has only one version, even if it's...

0:58:55	SPEAKER_04
 Actually, even like the word read and read, those are two different words.

0:58:59	SPEAKER_04
 They're spelled the same way.

0:59:01	SPEAKER_04
 They're still going to be transcribed as R-E-A-D.

0:59:04	SPEAKER_04
 So, yeah, I like the idea of having this in there.

0:59:07	SPEAKER_04
 I was a little bit worried that the tag for removing the red speech.

0:59:12	SPEAKER_04
 Because what if we have like red letters or red...

0:59:15	SPEAKER_04
 We might want to just send them to the tag.

0:59:17	SPEAKER_01
 It says it's red.

0:59:18	SPEAKER_04
 Yeah, basically.

0:59:20	SPEAKER_04
 But other than that, it sounds great.

0:59:23	SPEAKER_06
 Okay.

0:59:24	SPEAKER_06
 Are we done?

0:59:25	SPEAKER_00
 Well, I wanted to say also regarding the channelized data that...

0:59:29	SPEAKER_00
 Yeah.

0:59:30	SPEAKER_00
 We requested that we get some segments done by hand to reduce the size of the time.

0:59:36	SPEAKER_00
 It's what was Chuck was mentioning earlier.

0:59:39	SPEAKER_00
 That if you said, oh, and it was in part of a really long complex overlapping segment, that the same starting end times would be held for that one, for the longer utterances.

0:59:51	SPEAKER_06
 We did that for one meeting, right?

0:59:53	SPEAKER_06
 So, you have that data, don't you?

0:59:54	SPEAKER_06
 Yeah, that's a training data.

0:59:56	SPEAKER_00
 He requested that there be similar samples done for five minute stretches, involving a variety of speakers and overlapping sections.

1:00:04	SPEAKER_00
 He gave me...

1:00:05	SPEAKER_00
 He did the very nice...

1:00:06	SPEAKER_00
 He did some shopping through the data and found segments that would be useful.

1:00:09	SPEAKER_00
 And at this point, all four of the ones that he specified have been done in addition.

1:00:13	SPEAKER_00
 I have the transcribers expanding the amount that they're doing, actually.

1:00:17	SPEAKER_00
 So, right now, I know that as of today, we got an extra 15 minutes of that type.

1:00:22	SPEAKER_00
 And I'm having them expand the realm on either side of these places where they've already started.

1:00:27	SPEAKER_02
 Okay.

1:00:28	SPEAKER_00
 But if...

1:00:29	SPEAKER_00
 And he's going to give me some more sections that he thinks would be useful for this purpose.

1:00:33	SPEAKER_00
 Because it's true.

1:00:34	SPEAKER_00
 I mean, if we could do the more fine grain tuning of this using an algorithm, that would be so much more efficient.

1:00:41	SPEAKER_00
 And so, this is going to be...

1:00:44	SPEAKER_02
 I thought we should perhaps try to start with those channelized versions, just to try to give one transcriber the channelized version of my speech and on speech detection.

1:00:58	SPEAKER_02
 And look, if that's helpful for them or just let them try, if that's better.

1:01:05	SPEAKER_02
 You mean to start from scratch and brand new transcriber?

1:01:07	SPEAKER_00
 That'd be excellent.

1:01:08	SPEAKER_00
 Yeah, that'd be really great.

1:01:09	SPEAKER_00
 As it stands, we're still on the phase of sort of cleaning up the existing data, getting things in more tightly, time in the line.

1:01:17	SPEAKER_00
 I also want to tell...I also want to bring the issue that...

1:01:20	SPEAKER_00
 Okay, so there's this idea we're going to have this master copy, the transcript, it's going to be modified by scripts into these two different functions.

1:01:26	SPEAKER_00
 And actually the master...

1:01:28	SPEAKER_00
 Two or more to...

1:01:29	SPEAKER_00
...to our more.

1:01:30	SPEAKER_00
 And the master is going to be the channelized version.

1:01:32	SPEAKER_00
 Right.

1:01:33	SPEAKER_00
 So right now, we've taken this initial one.

1:01:34	SPEAKER_00
 It was a single channel, basically, the way it was input.

1:01:37	SPEAKER_00
 And now, thanks to the advances made in the interface, we can, from now on, use the channelized part and any changes that are made in the channelized version, anything.

1:01:47	SPEAKER_00
 But I wanted to get all the finishes and the checks.

1:01:49	SPEAKER_00
 So that has implications for your scripts.

1:01:50	SPEAKER_03
 So have those...the 10 hours that have been transcribed already, have those been channelized?

1:01:56	SPEAKER_03
 Yes they have.

1:01:57	SPEAKER_00
 And I've seen they've been channelized.

1:01:59	SPEAKER_00
 Except for the missing 30 minutes.

1:02:01	SPEAKER_03
 Right.

1:02:02	SPEAKER_03
 And they've been...has the time...have the time marking been adjusted?

1:02:05	SPEAKER_00
 For a total of like 20...for the total of the C-Pros, total of about 30 minutes, that's been the case.

1:02:14	SPEAKER_00
 And plus the training.

1:02:15	SPEAKER_03
 I guess, I mean, I don't know if we should talk about this now or now.

1:02:18	SPEAKER_03
 But that's just where...

1:02:19	SPEAKER_03
 Missing T.

1:02:20	SPEAKER_03
 Yeah, I know.

1:02:21	SPEAKER_03
 No, but I mean my question is, like, should I wait until all of those are processed and channelized like the time markings are adjusted before I do all the processing?

1:02:28	SPEAKER_03
 And we start like branching off into the...into our layer of...

1:02:32	SPEAKER_00
 Well, you know, the problem is that some...

1:02:35	SPEAKER_00
 some of the adjustments that they're making are to bring...

1:02:38	SPEAKER_00
 are to combine bins that were...

1:02:40	SPEAKER_00
 time bins, which were previously separate.

1:02:42	SPEAKER_00
 And the reason they do that is sometimes there's a word that's cut off.

1:02:45	SPEAKER_00
 Right.

1:02:46	SPEAKER_00
 And so it's true that it's likely to be adjusted in the way that the words are more complete.

1:02:51	SPEAKER_00
 And...

1:02:52	SPEAKER_00
 Okay.

1:02:53	SPEAKER_00
 No, I know that adjusting those things is going to make it better.

1:02:56	SPEAKER_03
 Yeah.

1:02:57	SPEAKER_03
 I'm going to be more reliable in that.

1:02:58	SPEAKER_03
 I'm not sure.

1:02:59	SPEAKER_03
 I'm not sure.

1:03:00	SPEAKER_03
 Yeah.

1:03:01	SPEAKER_03
 I'm going to be more reliable in that.

1:03:02	SPEAKER_00
 It's going to make it better.

1:03:03	SPEAKER_00
 Yeah.

1:03:04	SPEAKER_00
 I'm going to be more reliable in that.

1:03:05	SPEAKER_00
 Yeah.

1:03:06	SPEAKER_00
 And it will be to apply an algorithm because...

1:03:08	SPEAKER_00
 Yeah.

1:03:09	SPEAKER_00
 This takes time.

1:03:10	SPEAKER_00
 You know, it takes a couple hours to do 10 minutes.

1:03:13	SPEAKER_03
 Yeah, I don't doubt it.

1:03:15	SPEAKER_03
 So...

1:03:17	SPEAKER_08
 So right now, what you're doing is you're taking the...

1:03:21	SPEAKER_08
 the original version and you're sort of channelizing yourself.

1:03:24	SPEAKER_08
 Yeah.

1:03:25	SPEAKER_03
 I'm doing it myself.

1:03:26	SPEAKER_03
 I mean, if the time markings aren't different across channels, like the channelized version really doesn't have any more information.

1:03:32	SPEAKER_03
 So I was just... I mean, originally I had done it before, like the channelized versions were coming out.

1:03:38	SPEAKER_03
 Right.

1:03:39	SPEAKER_03
 And so it's a question of...

1:03:41	SPEAKER_08
 I think probably the way it'll go is that, you know, when we make this first general version and then start working on the script, that script that will be made, you know, primarily come from what you've done, we'll need to work on a channelized version of those originals.

1:03:57	SPEAKER_08
 And so it should be pretty much identical to what you have to...

1:04:01	SPEAKER_08
 except for the one that they've already tightened the boundaries.

1:04:04	SPEAKER_08
 Right.

1:04:05	SPEAKER_08
 Yeah.

1:04:06	SPEAKER_08
 So...

1:04:07	SPEAKER_08
 And then probably what will happen is as the transcribers finish tightening more and more, you know, that original version will get updated and we'll rerun the script and produce better versions.

1:04:17	SPEAKER_08
 Okay.

1:04:18	SPEAKER_08
 But I guess the effect for you guys, because you're pulling out the little waveforms into separate ones, that would mean these boundaries are constantly changing.

1:04:26	SPEAKER_08
 You definitely constantly rerun that.

1:04:28	SPEAKER_08
 Right.

1:04:29	SPEAKER_04
 But that's not hard.

1:04:31	SPEAKER_04
 I think the harder part is making sure that the transcription...

1:04:35	SPEAKER_04
 So if you merge two things, then you know that it's a sum of the transcripts.

1:04:39	SPEAKER_04
 But if you split inside something, you don't know where the word, which words moved.

1:04:44	SPEAKER_04
 And that's where it becomes a little bit having to rerun the processing.

1:04:49	SPEAKER_04
 The cutting of the waveform is pretty trivial.

1:04:52	SPEAKER_03
 I mean, as long as it can all be done automatically, I mean, then that's not a concern.

1:04:56	SPEAKER_03
 So if I just have to run three scripts to extract it, I'll let it run on my computer for an hour and a half, or however long it takes to parse and create all the reference files, it's not a problem.

1:05:07	SPEAKER_03
 So yeah, as long as we're at that point, and I know exactly what steps, what work, what's going on in the editing process.

1:05:14	SPEAKER_03
 Okay.

1:05:17	SPEAKER_00
 So that's...

1:05:18	SPEAKER_00
 I mean, I could...

1:05:19	SPEAKER_00
 There were other checks that I did, but it's...

1:05:20	SPEAKER_00
 I think that we...

1:05:21	SPEAKER_00
 Unless you think there's anything else I think that I covered it.

1:05:23	SPEAKER_00
 I can't give...

1:05:24	SPEAKER_02
 Any other...

1:05:26	None
 Okay.

1:05:27	None
 Okay.

1:05:28	None
 Okay.

1:05:29	SPEAKER_01
 Oh.

