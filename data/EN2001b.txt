0:00:30	SPEAKER_01
 It's with cameras!

0:00:35	SPEAKER_01
 It looks quite funny!

0:00:41	SPEAKER_00
 This is the first look lake...

0:00:48	SPEAKER_00
 I saw that...

0:00:49	SPEAKER_00
 Nice.

0:00:56	SPEAKER_00
 That's the way I see it.

0:00:58	SPEAKER_02
 Yeah.

0:01:05	SPEAKER_03
 Yeah, yes.

0:01:10	SPEAKER_00
 You see, I never get this.

0:01:11	SPEAKER_00
 What's the point of this is famous?

0:01:13	SPEAKER_00
 If this trap is supposed to go behind, I'm obviously doing this wrong.

0:01:17	SPEAKER_00
 Obviously failing this, like, I said, what a calling center.

0:01:21	SPEAKER_01
 If you have a...

0:01:22	SPEAKER_01
 Going behind your ears.

0:01:23	SPEAKER_01
 Like this.

0:01:24	SPEAKER_00
 Yeah.

0:01:25	SPEAKER_00
 Which is good.

0:01:27	SPEAKER_00
 Yeah, you know what this shit has to do now.

0:01:29	SPEAKER_00
 Yeah.

0:01:36	SPEAKER_00
 Okay.

0:01:37	SPEAKER_00
 Okay.

0:01:45	SPEAKER_00
 Yeah, so, um, let's just realize that I don't have power.

0:01:50	SPEAKER_00
 Let me just switch on here.

0:01:51	SPEAKER_00
 I know what you're going to run out.

0:01:57	SPEAKER_03
 Okay.

0:01:58	SPEAKER_03
 Okay.

0:02:02	SPEAKER_00
 So...

0:02:04	SPEAKER_00
 There's probably not much to talk about at the moment in terms of, like, talking about each other's stuff.

0:02:11	SPEAKER_00
 I mean, beyond what we've been talking about yesterday.

0:02:13	SPEAKER_00
 Yes, too.

0:02:14	SPEAKER_00
 So what I've been thinking is maybe if we try to really make sense together of the XML format, to be sure that we can all produce the data that we are producing in a way, or at least, I mean...

0:02:28	SPEAKER_00
 I guess my data will probably load in a completely different way anyway because it's matrix, but all the stuff that goes to the notation that we have in the right format, maybe if you just sort of pool what we know about the XML format and try to make sense of it.

0:02:42	SPEAKER_00
 I don't at all know how to go about this.

0:02:50	SPEAKER_00
 What I did just now is I downloaded...

0:02:53	SPEAKER_00
 I downloaded some files, some XML files.

0:03:00	SPEAKER_00
 And I was thinking if we maybe just should go through some of them and, like, try to see if you understand the general structure and pull together what we think about the structure, what we think the things mean, and then talk about how the annotation for information density and stuff should maybe be structured in a similar way.

0:03:28	SPEAKER_00
 But I don't really have an idea like what otherwise what we would do today in this meeting.

0:03:34	SPEAKER_02
 Yeah, you haven't got that much to talk about.

0:03:37	SPEAKER_01
 Just maybe talk about how you would give your data file.

0:03:42	SPEAKER_01
 Yeah.

0:03:43	SPEAKER_00
 Yes, what's that?

0:03:45	SPEAKER_00
 What's that part?

0:03:47	SPEAKER_01
 That's the interface between having the topic segment and calculating the information and port and support.

0:03:57	SPEAKER_01
 So I would need separate files for each segment or just maybe have delimitres in between.

0:04:05	SPEAKER_02
 Yeah, well, that's the way it works.

0:04:07	SPEAKER_02
 It's called delimitres and what the boundary is about.

0:04:10	SPEAKER_01
 Yeah, if you have to do that.

0:04:11	SPEAKER_02
 And you send you need a label for each segment.

0:04:16	SPEAKER_02
 No, I don't.

0:04:17	SPEAKER_02
 You don't need the one.

0:04:18	SPEAKER_02
 I could give you an ID, but you've got a type of topic title.

0:04:22	SPEAKER_01
 I just need a title from the file.

0:04:25	SPEAKER_01
 It doesn't matter what it is.

0:04:27	SPEAKER_02
 Okay.

0:04:28	SPEAKER_02
 Yeah, that's no problem.

0:04:32	SPEAKER_00
 Yes, so does anyone have a good idea where to start?

0:04:34	SPEAKER_00
 Like which what?

0:04:35	SPEAKER_00
 So what is it we're talking about getting in at the moment?

0:04:37	SPEAKER_00
 We're basically just because the two of you will merge data together, right?

0:04:41	SPEAKER_00
 In some way, like in the end, it will result in one annotation.

0:04:45	SPEAKER_00
 So the only thing we're trying to tie in is just an additional annotation which is similar to the annotation about what would be most similar to simply to the segmentation information.

0:04:59	SPEAKER_01
 Yes, I mean they're all very, very similar.

0:05:03	None
 Oh, that was ex- I had a look at the, for example, A's.

0:05:11	SPEAKER_00
 See, that's what I was thinking.

0:05:15	SPEAKER_00
 I'm not sure what software I have at the moment.

0:05:19	SPEAKER_00
 Hello?

0:05:21	SPEAKER_00
 Anyone know any good standard software that displays XML?

0:05:33	SPEAKER_00
 Sure.

0:05:34	SPEAKER_00
 Take Mozilla?

0:05:36	SPEAKER_00
 Yeah, but I'm afraid only Firefox and Firefox doesn't have an i6 node view anymore.

0:05:42	SPEAKER_00
 I think I don't have Mozilla.

0:05:52	SPEAKER_00
 I think I'll just do a next thing.

0:05:57	SPEAKER_01
 So what we have done when we are mixing our values together, is it a value for each expression for each sentence or something?

0:06:09	SPEAKER_01
 Yeah, I think that would be, I mean, for me it's quite difficult to say on, you know, what scope one annotation would have.

0:06:24	SPEAKER_01
 I think it would be certainly more than one word and I think would work best with a trans or a sequence.

0:06:34	SPEAKER_01
 Yeah, I would just end up with values for each word, so I wouldn't have any boundaries for segments at all.

0:06:46	SPEAKER_01
 I just would have the words and then how we, how long each expression would be, I don't know.

0:06:54	SPEAKER_00
 But going from a work business wouldn't it be to then go back and calculate for each other and?

0:07:00	SPEAKER_01
 Yeah, but what is an utterance?

0:07:04	SPEAKER_01
 The segments as they are segmented and for example, what we would fit in into the XML file would be a value for each utterance.

0:07:17	SPEAKER_01
 I think so.

0:07:23	SPEAKER_01
 And you would probably still need your values for the words and perhaps for the keywords that are displayed when you pick up something.

0:07:35	SPEAKER_01
 So now we would have to fit in more than just one value.

0:07:40	SPEAKER_01
 Yeah, but that's another representation then I think for the importance.

0:07:46	SPEAKER_00
 Does anyone know in which file the actual, what's it called, the splitting into the utterance?

0:07:52	SPEAKER_00
 It's not segmented.

0:07:55	SPEAKER_02
 It's called dialogue.

0:07:58	SPEAKER_01
 No, it's not.

0:08:00	SPEAKER_01
 For example, there's BDB001C point.

0:08:05	SPEAKER_00
 What does it end with sex?

0:08:09	SPEAKER_00
 Does that look like it?

0:08:12	SPEAKER_01
 I can't see anything.

0:08:15	SPEAKER_02
 I think that's it.

0:08:22	SPEAKER_00
 You've all got an ID for each utterance.

0:08:27	SPEAKER_00
 That's actually just a very K-right.

0:08:33	SPEAKER_00
 It's a bit better to see, I guess, a white white white white white.

0:08:41	SPEAKER_00
 It's super cool.

0:08:48	None
 Okay.

0:08:55	SPEAKER_01
 So, okay, so, here is for this segment.

0:09:05	SPEAKER_01
 It's really all segments.

0:09:12	SPEAKER_01
 It can be words or topics or anything, I think, in these.

0:09:16	SPEAKER_01
 That's why it's, for example, time provenance.

0:09:21	SPEAKER_01
 Time provenance segment or time provenance.

0:09:25	SPEAKER_02
 Yeah, let's go to different files.

0:09:29	SPEAKER_00
 What is this?

0:09:30	SPEAKER_00
 This doesn't contain any content like any text.

0:09:33	SPEAKER_00
 No, it just points to the words.

0:09:37	SPEAKER_00
 Oh, wait, somebody explained it slowly.

0:09:40	SPEAKER_01
 So, yeah, some of them point to the words, other points to the dialogue acts.

0:09:49	SPEAKER_01
 So, that's kind of the noble thing that ties together.

0:09:55	SPEAKER_00
 What do all these things in this file have in common?

0:09:57	SPEAKER_00
 What are they?

0:10:00	SPEAKER_01
 Yeah, they have their night ID at the time.

0:10:05	SPEAKER_00
 So, they are segments in what sense, what's the...

0:10:08	SPEAKER_02
 The other answer is, but it also includes things like...

0:10:12	SPEAKER_01
 The segment is what is displayed in one line.

0:10:18	SPEAKER_00
 And that's usually dialogue.

0:10:20	SPEAKER_00
 What's the difference between the words?

0:10:23	SPEAKER_01
 Yeah, it looks... the segment thing looks into the words.

0:10:31	SPEAKER_01
 I think it's...

0:10:35	SPEAKER_00
 In a different...

0:10:36	SPEAKER_00
 Dialogue act annotations of dialogue act.

0:10:38	SPEAKER_00
 Is that just another representation of text?

0:10:40	SPEAKER_01
 No, they're annotation of dialogue acts.

0:10:43	SPEAKER_01
 And one segment can have one of those word strings that are presented in one line can have several dialogue acts annotated on it.

0:10:54	SPEAKER_01
 That's why...

0:10:58	SPEAKER_00
 Just so you can get these files somewhere.

0:11:00	SPEAKER_00
 So, the stuff that's called segment here, do we know which file this is pulling from?

0:11:07	SPEAKER_00
 From words, XML is that what it's saying here?

0:11:11	SPEAKER_00
 Let me see if I have that word, section of file.

0:11:15	SPEAKER_00
 So, let's, for example, look at...

0:11:20	SPEAKER_01
 Do we need a value label for each of those segments that are not dialogue acts?

0:11:29	SPEAKER_01
 Well, although it's their point to the actual words...

0:11:34	SPEAKER_00
 Let me just try to get the more different screen.

0:11:39	SPEAKER_00
 Just, I'm trying to arrange them so that we have one above the other, so to make some sense of that.

0:11:56	None
 So, not here we had.

0:12:03	SPEAKER_01
 And I think these segments were supposed to not exactly what we were looking at, because that's just one tying all the others together.

0:12:18	SPEAKER_01
 And the information, or I mean we're going to create a file that looks more like the words file.

0:12:25	SPEAKER_01
 I think...

0:12:27	SPEAKER_00
 Well, I'm just trying to understand what the segment's file is about.

0:12:31	SPEAKER_00
 Like, it's referencing here, it's referencing to a certain position in the words file.

0:12:42	SPEAKER_02
 Yeah, it looks cool.

0:12:47	SPEAKER_00
 So, is that non-vocal sound one here?

0:12:50	SPEAKER_00
 That's the mic noise, okay?

0:12:54	SPEAKER_00
 But does it always just...

0:12:56	SPEAKER_00
 No, it's referencing to several words.

0:12:59	SPEAKER_00
 So, this would be basically be a sequence, right?

0:13:03	SPEAKER_00
 Yes.

0:13:04	SPEAKER_00
 So, that's from W52.

0:13:09	SPEAKER_00
 Are they not ordered?

0:13:11	SPEAKER_00
 Yeah.

0:13:12	SPEAKER_00
 W52 down to W, what are we talking about?

0:13:17	SPEAKER_00
 Yeah.

0:13:18	SPEAKER_01
 To this course marker, this F marker, 0.5.

0:13:24	SPEAKER_01
 Yeah, that's...

0:13:26	SPEAKER_01
 No, no, up above.

0:13:28	SPEAKER_01
 Yeah, right.

0:13:30	SPEAKER_00
 Okay.

0:13:32	SPEAKER_00
 So, this is somebody saying it doesn't.

0:13:36	SPEAKER_00
 If we have any confirmation, do we actually see from this file who's doing it just in interest?

0:13:42	SPEAKER_01
 This is all speaker D.

0:13:45	SPEAKER_00
 Oh, sorry, in speaker D's file.

0:13:48	SPEAKER_00
 So, this is where he, like, time stops.

0:13:52	SPEAKER_00
 And then it only starts at a later time because, sorry, you don't see when I'm pointing at screen interest.

0:13:57	SPEAKER_00
 So, then it starts here.

0:13:58	SPEAKER_00
 This time I can speak a D because in between there's somebody else.

0:14:01	SPEAKER_01
 Yes.

0:14:02	SPEAKER_01
 You can see whether there's somebody else or not.

0:14:04	SPEAKER_01
 You can see that in the W point.

0:14:08	SPEAKER_01
 First it's W point 54 and then it's 76.

0:14:16	SPEAKER_00
 So, there's a number of addresses of others because of me too.

0:14:19	SPEAKER_00
 Okay.

0:14:20	SPEAKER_00
 So, the file with annotations for information density, what would that be like?

0:14:25	SPEAKER_00
 Would that be like the segments file giving a start, word and end, word or...

0:14:30	SPEAKER_00
 Or would that...

0:14:32	SPEAKER_00
 How would that be to best tie in with the system?

0:14:36	SPEAKER_01
 I think we would also need two of those.

0:14:39	SPEAKER_01
 Sorry.

0:14:40	SPEAKER_01
 Yeah, I think we would have to have the same structure, one that points to it where we tie it together all our information.

0:14:47	SPEAKER_01
 So, we would have to have to...

0:14:50	SPEAKER_00
 Something like this or where you give sort of a reference to a beginning and an end position.

0:14:56	SPEAKER_00
 Yes.

0:14:57	SPEAKER_01
 And then another one that would perhaps give the actual probability value.

0:15:03	SPEAKER_00
 Or would that be in the same file, wouldn't it would just...

0:15:06	SPEAKER_00
 Yeah, it could be like...

0:15:08	SPEAKER_01
 Probably in the same file.

0:15:10	SPEAKER_00
 I guess we could introduce a different...

0:15:12	SPEAKER_01
 If you have several layers, then...

0:15:16	SPEAKER_01
 Kind of within the modern same file.

0:15:20	SPEAKER_00
 Well, for now, if we just do something which for every segment in here attaches...

0:15:26	SPEAKER_00
 Actually, can we not tie it to the segments file?

0:15:28	SPEAKER_00
 Would that not be the way how they would want it to have to do as if we...

0:15:31	SPEAKER_00
 In the end, you want to attach to each of those segments one number for now.

0:15:37	SPEAKER_00
 Do they have an idea?

0:15:40	SPEAKER_00
 Yeah, I guess they do.

0:15:42	SPEAKER_00
 So, this is the idea for specific segment, right?

0:15:44	SPEAKER_01
 In segment point one, I'm not a landlord.

0:15:48	SPEAKER_00
 Yeah, so, wouldn't it...

0:15:49	SPEAKER_00
 I mean, the problem is they may have looked at the exact inner workings of the engineer, but you'd think that the easiest way, the way how it's intended to be would be just...

0:16:01	SPEAKER_00
 If we have here a link to the segment, like an ID for that segment, that we just create another file which links to the segment and then have an additional value, which is the number.

0:16:13	SPEAKER_01
 So, you mean an attribute?

0:16:16	SPEAKER_01
 Yeah, yeah.

0:16:18	SPEAKER_01
 Yeah, that's what I'm gonna do.

0:16:20	SPEAKER_00
 Yeah, sorry.

0:16:21	SPEAKER_00
 I thought you were talking about having two files.

0:16:24	SPEAKER_00
 I was thinking...

0:16:26	SPEAKER_00
 Yeah, I think I understood wrong.

0:16:27	SPEAKER_00
 I thought you were wanting to have two different XML files.

0:16:30	SPEAKER_00
 We want the reference and one just the number.

0:16:32	SPEAKER_00
 I was thinking that's probably what you meant just having, like for each sort of hour segment, having just the ID, which is referencing to these segments here, and another attribute which is the value.

0:16:48	SPEAKER_00
 So, this whole information we would then store in this...

0:16:51	SPEAKER_00
 That I don't have access to, because I didn't download it like this.

0:16:54	SPEAKER_00
 This one meta information file where it describes the structure of all the files and describes which attributes they bring in.

0:17:01	SPEAKER_00
 So, we would add that to that file, saying that sort of we bring in information density, and then we would create a file of that type which we probably couldn't call it segment.

0:17:15	SPEAKER_00
 I'm not sure.

0:17:16	SPEAKER_00
 We probably might have to have a different word for it.

0:17:18	SPEAKER_00
 We would definitely travel with it repeating.

0:17:21	SPEAKER_01
 Wouldn't it be easiest to just incorporate a new attribute in this file?

0:17:28	SPEAKER_01
 In the existing segments file.

0:17:29	SPEAKER_01
 Yeah, I know that's probably not very nice, but would be quite easy.

0:17:35	SPEAKER_00
 Yeah, I reckon actually if you make a copy of it.

0:17:38	SPEAKER_01
 But, I mean, there's not all the information that is in the corpus in the segment file.

0:17:44	SPEAKER_01
 I think that is just the things that are loaded every time, but we have lazy loading, so it can load more than that.

0:17:54	SPEAKER_01
 First we could just try to...

0:17:58	SPEAKER_01
 Now to make our file one of those lazy loaded, but I have no idea how that works.

0:18:05	SPEAKER_00
 What are you saying about the...

0:18:08	SPEAKER_00
 Doesn't the lazy loading apply to everything?

0:18:10	SPEAKER_00
 I mean, that is sort of dynamic loads.

0:18:12	SPEAKER_01
 Yes, but it has a basic thing that it loads, I think.

0:18:17	SPEAKER_01
 So, for example, every time it loads the segment things, it can't.

0:18:22	SPEAKER_01
 It can't not display words, I think.

0:18:27	SPEAKER_00
 I think it loads the whole of the segments file every time.

0:18:31	SPEAKER_01
 I think so.

0:18:33	SPEAKER_01
 That's how I understood it.

0:18:35	SPEAKER_00
 The segment is split up.

0:18:37	SPEAKER_01
 Because otherwise in the other things, there's no information about what the participant name is and so on.

0:18:44	SPEAKER_01
 So, in the segments, it's really very basic that have to be displayed for anything.

0:18:54	SPEAKER_01
 But they display the segments in...

0:18:58	SPEAKER_01
 Or that the utterances in their user interface as well, they display the words I displayed.

0:19:07	SPEAKER_01
 So, they have...

0:19:09	SPEAKER_01
 Their utterances displayed in their interface.

0:19:13	SPEAKER_01
 So, they access probably this file and then they display the words.

0:19:18	SPEAKER_01
 So, why shouldn't they be able to do that?

0:19:21	SPEAKER_00
 I think it's too early to really discuss that in detail because we don't all understand at the moment how the internal data structure, like how the loading works.

0:19:30	SPEAKER_00
 Maybe if we go ahead, do you think it would be possible for you to do something like segments?

0:19:35	SPEAKER_00
 Or maybe just a copy of segments which has an attribute for each segment, which is with a value, with a density value.

0:19:45	SPEAKER_01
 Yeah, I mean, it wouldn't be difficult to create a file of a red shape.

0:19:53	SPEAKER_00
 Would it be easier because all your methods are sort of not working with their whole time frame structure there?

0:19:59	SPEAKER_00
 So, would it be easy for you to tie the things together?

0:20:02	SPEAKER_00
 Like, if you're doing it on the word basis, here are those words that in the end, you then tie it back into the right segment here.

0:20:09	SPEAKER_00
 I mean, probably have to do a bit.

0:20:11	SPEAKER_01
 Yeah, I don't know how about you with your words.

0:20:14	SPEAKER_01
 But for my segment with the F0 measurements and all those ways I get from there, I always store the big start and end time with everything I calculated there.

0:20:28	SPEAKER_01
 So, I would just have to put it up.

0:20:31	SPEAKER_00
 You're doing a time-based development.

0:20:32	SPEAKER_00
 Yes.

0:20:33	SPEAKER_00
 So, this isn't directly having time references, but you can get that, oh, it is actually here.

0:20:38	SPEAKER_00
 Okay.

0:20:41	SPEAKER_00
 So, if you slice it up by time, you'd probably be able to just like attach, like, just some attribute of info file just to each of those segments.

0:20:54	SPEAKER_01
 Yeah, actually, but actually my segments are not always the same as their segments, because in their segments, they're a process sometimes.

0:21:07	SPEAKER_02
 You can just use those ones blank.

0:21:11	SPEAKER_01
 Yes, but yeah, I mean, one segment of theirs is sometimes two segments of mine.

0:21:16	SPEAKER_02
 That's just what they meant.

0:21:19	SPEAKER_00
 Okay.

0:21:22	SPEAKER_00
 I don't understand enough of the data structures.

0:21:25	SPEAKER_00
 It's probably would be a lot easier.

0:21:26	SPEAKER_00
 Would I really understand how they are handling the data internally?

0:21:29	SPEAKER_00
 Because then I could say, oh, it's easy to just tie it in.

0:21:31	SPEAKER_00
 If you just have a time stamp, just reference by word, stuff.

0:21:35	SPEAKER_00
 But at the moment.

0:21:46	SPEAKER_00
 So, you're doing a word-by-word phase.

0:21:49	SPEAKER_01
 Yeah, the problem is probably that I extract all the words, and then I don't use an idea or something for it, so it would be difficult to write it back to the right position.

0:22:04	SPEAKER_00
 But every word, does the word picking, like, does it always have the same information value in your thing?

0:22:09	SPEAKER_00
 Does it depend on its position?

0:22:12	SPEAKER_00
 It depends on the position.

0:22:17	SPEAKER_00
 You're doing this via some software that's like external software, so you can't.

0:22:23	SPEAKER_01
 I could use another different approach.

0:22:27	SPEAKER_00
 So, if you get the results from that software, and you go back over it, then with that file sort of, you write an algorithm which then goes back, because they're in the right order still and stuff.

0:22:36	SPEAKER_00
 So, that shouldn't be a problem.

0:22:38	SPEAKER_00
 But this is by speaker here, which makes it slightly more difficult.

0:22:46	SPEAKER_00
 The problem is that actually NightX may provide a lot of the tools that you need to do there.

0:22:51	SPEAKER_01
 Yeah, the question I made a file that contains just the start times.

0:22:55	SPEAKER_01
 It could contain end times and words for all speakers of all meetings.

0:22:58	SPEAKER_01
 I mean, that's just the same thing as I gave to you, but just playing also started end times of every word.

0:23:09	SPEAKER_01
 So, you could perhaps use it to match with your additional information.

0:23:14	SPEAKER_02
 What did you use to make that file?

0:23:17	SPEAKER_02
 That's good.

0:23:18	SPEAKER_02
 You didn't use our next file password.

0:23:20	SPEAKER_03
 No, no.

0:23:21	SPEAKER_02
 Okay.

0:23:22	SPEAKER_01
 What do you think it would make sense to just take files by speaker?

0:23:29	SPEAKER_01
 It doesn't matter what input I give to Rainbow.

0:23:36	SPEAKER_01
 So, I just could use the files as they are.

0:23:39	SPEAKER_01
 I don't know if that's...

0:23:41	SPEAKER_00
 The information density algorithm still makes sense if you split them up because I mean the whole thing is that you look at the frequency of a word in that specific how often a word occurs in a certain topic versus how of a middle course over the whole corpus that from that it calculates.

0:23:55	SPEAKER_01
 No, I think it's not the whole corpus.

0:23:59	SPEAKER_01
 It's...

0:24:01	SPEAKER_01
 You have certain categories.

0:24:04	SPEAKER_01
 And you measure which words have the highest information for one category.

0:24:13	SPEAKER_01
 So, it's the categories across each other.

0:24:16	SPEAKER_01
 But would you then not get the typical words for every speaker?

0:24:21	SPEAKER_01
 If you...

0:24:23	SPEAKER_01
 Probably, yeah.

0:24:26	SPEAKER_01
 But because it's more than good ideas.

0:24:28	SPEAKER_00
 I mean, it can't be that difficult. If you already have in the right order all the words with a score to them, you have a file which has each word and a timestamp.

0:24:41	SPEAKER_00
 So, those two types together have each word and it's time and its value.

0:24:49	SPEAKER_00
 Yeah.

0:24:50	SPEAKER_01
 What the problem is, I don't know, I think the information game in Rainbow is ordered by the value of the information game not...

0:25:01	SPEAKER_01
 I am not sure if I can get the right order and the values.

0:25:06	SPEAKER_01
 That's the problem.

0:25:07	SPEAKER_01
 So, they are at the moment.

0:25:09	SPEAKER_01
 If the order stays the same, it's no problem at all to just write back again.

0:25:14	SPEAKER_01
 But if it's ordered by information game, I don't know where the words come from because it has a back of words for presentation.

0:25:23	SPEAKER_00
 The person with the rainbow was made for something quite different.

0:25:26	SPEAKER_01
 Yes, it is.

0:25:27	SPEAKER_01
 It was made for text classification.

0:25:29	SPEAKER_01
 So, how could we put our information again?

0:25:32	SPEAKER_01
 Yeah, that's the problem.

0:25:34	SPEAKER_00
 I actually like...

0:25:35	SPEAKER_00
 I'm...

0:25:36	SPEAKER_00
 I actually sure that Rainbow is doing a measure...

0:25:39	SPEAKER_00
 Like, is returning a measure of what we are trying to measure because it seems to me that it sounds like something quite different in my aspects.

0:25:47	SPEAKER_01
 Yeah, what it actually does is that you put in some documents and you have several documents per category and you have several categories.

0:25:59	SPEAKER_01
 And then it measures which words are typical for a certain category.

0:26:06	SPEAKER_01
 And if you get a new document, it will compare which words are in that new document.

0:26:15	SPEAKER_01
 And if there are a lot of words that are typical for one category, it will assign it to that category.

0:26:23	SPEAKER_01
 And if it's typical for another one, it will assign it to that one.

0:26:27	SPEAKER_00
 But where do you have the original category information from?

0:26:30	SPEAKER_01
 Yeah, it's because you have different files.

0:26:37	SPEAKER_01
 If this is your directory, you have a diagram, a directory 1, 2, and 3.

0:26:45	SPEAKER_01
 And this represents the category.

0:26:48	SPEAKER_01
 Everything that's in there is in category 1.

0:26:50	SPEAKER_00
 So, where do you have them from at the moment?

0:26:52	SPEAKER_00
 They split up?

0:26:53	SPEAKER_01
 Yeah, just split it up.

0:26:54	SPEAKER_01
 So, that's the topic.

0:26:55	SPEAKER_00
 Oh, yeah, that's the topic information.

0:27:01	SPEAKER_00
 In the topics, in their human topic.

0:27:04	SPEAKER_01
 So, you've split it up by topic at the moment.

0:27:07	SPEAKER_01
 No, I've just split them up somehow by...

0:27:13	SPEAKER_01
 There are several documents for each meeting.

0:27:20	SPEAKER_01
 So, it's not very sensible at the moment because I'm waiting for the topic statement.

0:27:26	SPEAKER_00
 Okay, okay.

0:27:28	SPEAKER_00
 I was just thinking that doesn't make sense at all, but yeah, if that's just while you're waiting.

0:27:32	SPEAKER_00
 Okay.

0:27:34	SPEAKER_00
 Have you ever looked into different ways of calculating?

0:27:37	SPEAKER_00
 Because I was just thinking, I mean, for example, the info, what's it called?

0:27:42	SPEAKER_00
 The entropy calculation.

0:27:44	SPEAKER_00
 Is that your box on that simple calculation that you could probably write the script in no time at all?

0:27:49	SPEAKER_01
 Maybe it's better if I write it myself because otherwise it's too easy to just split things up into bins.

0:27:57	SPEAKER_01
 It wouldn't be any work at all in terms of programming or something.

0:28:01	SPEAKER_00
 Yeah, I was just like, I think that probably the entropy value at the moment for a word is closer to what we're at moment looking for.

0:28:08	SPEAKER_00
 I can just like, I can sit together with you for 20 minutes and just show you the entropy code that I wrote for my other project.

0:28:15	SPEAKER_00
 And it's probably, we should work together because we have to use the same matrix as I'm using in my latent semantic analysis.

0:28:23	SPEAKER_00
 You'd use to calculate entropy scores.

0:28:25	SPEAKER_00
 And then we'd have a score which actually, which would be the same for the word in each position.

0:28:33	SPEAKER_00
 So in that sense, it's doing something a bit different.

0:28:35	SPEAKER_00
 And like, basically the score that I'm talking about is a conditional entropy score which just checks how much information.

0:28:43	SPEAKER_00
 And the fact that there's one word tells you about what would be the next word.

0:28:46	SPEAKER_00
 But that's a relatively good measure of whether that's a very specific word, in which case, they usually words would tell you quite a lot or a very general word which usually doesn't tell you quite a lot.

0:28:54	SPEAKER_01
 How do the calculate that actually?

0:28:57	SPEAKER_00
 It's basically the standard entropy formula.

0:29:01	SPEAKER_01
 So how sure and sure you are about what's following of what your context is?

0:29:07	SPEAKER_00
 Yes, yes, and I think the official description before it tells you is how much that the fact that a given word occurs tells you about what's the next word is going to be.

0:29:18	SPEAKER_00
 Which doesn't sound too exciting, but it just works out in the way that words which are promiscuous and which occur with everything all over the place.

0:29:25	SPEAKER_00
 And also usually end up being the words which are least expressive and contain less information or a function word.

0:29:37	SPEAKER_00
 Yeah, a function word such as very general nouns, which is probably like for example the word computer in that context.

0:29:43	SPEAKER_00
 You could imagine it to like being all in all the contexts.

0:29:46	SPEAKER_01
 Do we have enough data for that it gives us sensitive things because I mean the words we're really looking for appear not too often and if they appear five times in the meeting and they have each time different.

0:30:05	SPEAKER_01
 Yes, so we wouldn't do it five words.

0:30:08	SPEAKER_00
 Sorry, okay, I was I was getting that actually sorry I was getting that wrong I was getting it from what I did my project now in this case, we would do it by per me words per meeting.

0:30:22	SPEAKER_01
 Yeah, that's almost similar to what I'm doing because words that are in every class that are not very informative, but which that only one class are very informative for that class.

0:30:37	SPEAKER_00
 Yes, it's probably doing it's probably doing quite the same thing in the end.

0:30:40	SPEAKER_00
 I'm just saying like with that thing you would easily have an algorithm which at the moment provides you for each word with a score which we can use.

0:30:50	SPEAKER_00
 Now, I was I was describing the wrong thing in this case we wouldn't be doing how much it tells you about another word in this case we would be doing given that you know a word how good is it predicting from which a specific topic that was.

0:31:04	SPEAKER_01
 So that would yeah, and that's the same thing. Yeah, I bet both give the same value for one word every time I mean for specific word.

0:31:15	SPEAKER_01
 Yeah, yeah, first then it would be quite easy to integrate it.

0:31:20	SPEAKER_01
 Yes, the same word.

0:31:24	SPEAKER_01
 The word yesterday would be would have the same score all over the place.

0:31:36	SPEAKER_01
 But in that category with the same value at each place.

0:31:55	SPEAKER_00
 So, the category thing depends on that we not just have topic segments but also that these topic segments we have them in categories.

0:32:08	SPEAKER_01
 That would be best.

0:32:11	SPEAKER_01
 Will it work without that at all.

0:32:16	SPEAKER_01
 Works with several categories with each word on the limit each.

0:32:26	SPEAKER_00
 Yeah, I mean, so in our case basically every every topic would be its own category.

0:32:32	SPEAKER_00
 The question is does the algorithm still make any sense.

0:32:35	SPEAKER_00
 I don't understand the algorithm enough for that.

0:32:38	SPEAKER_00
 Because the entry because I am so simple. Maybe we should look into making that score just as a preliminary score that we have.

0:32:48	SPEAKER_00
 It's a very it gives you like I've looked at the result it gives you basically something in the end which vaguely tells you just whether words are very specific word.

0:32:56	SPEAKER_00
 Or a very general word.

0:32:59	SPEAKER_00
 And I like there is some hope that probably having just sentences with us lots of very specific words if you mark them as being more interesting than the words which are only very general words that they would get us somewhere.

0:33:13	SPEAKER_01
 And what or what score would work get that just across once in all the corpus for example.

0:33:21	SPEAKER_00
 Probably 1.0 is very high information value.

0:33:25	SPEAKER_01
 Even though there are all the other same topics where doesn't occur.

0:33:30	SPEAKER_00
 Yeah, because this would.

0:33:33	SPEAKER_00
 Yeah, in a sense, I mean, this is a bit like the what like document frequency over total frequency measure is sort of just going by.

0:33:44	SPEAKER_01
 So would it be higher scored than a word that occurs in every sequence of the same topic.

0:33:58	SPEAKER_00
 Or do you mean every sequence is the same.

0:34:00	SPEAKER_01
 I mean, we have several topics. For example, we have 20 topics and for one of these topics, there are 5 occurrences.

0:34:11	SPEAKER_00
 And within within the topics are like topic, when you say topic, you mean like just like from from a beginning to end point like within one meeting, there are several topics.

0:34:21	SPEAKER_01
 Yes, but across meetings, there will be the same topic several times.

0:34:27	SPEAKER_00
 But we don't have that information anywhere.

0:34:30	SPEAKER_01
 Okay.

0:34:31	SPEAKER_01
 I thought that was what you were doing.

0:34:35	SPEAKER_02
 Well, when it splits the topics up, it does do it on regular words that.

0:34:41	SPEAKER_02
 Yeah, but that doesn't tell you what they are.

0:34:44	SPEAKER_01
 But also segment similarity, I think that was.

0:34:48	SPEAKER_00
 I'm doing one on segment similarity in the end.

0:34:51	SPEAKER_00
 Yeah, I'm doing like finding similar segments based on semantic analysis.

0:34:55	SPEAKER_00
 But like for now, like your segmentation is just splitting a meeting up into different blocks.

0:35:05	SPEAKER_01
 And they are not related then to our blocks of.

0:35:09	SPEAKER_00
 Not from what columns to what I know.

0:35:12	SPEAKER_00
 No, it's only that I'm writing an algorithm with it, which then tries to also again based on word occurrence patterns try to link together.

0:35:19	SPEAKER_00
 Maybe different ones of those.

0:35:21	SPEAKER_01
 Okay, so yeah, how would it work?

0:35:29	SPEAKER_01
 I mean, what would his information then be useful for in Rainbow?

0:35:36	SPEAKER_01
 I thought the point about that was that we would put into several categories of the segments of the same topic.

0:35:51	SPEAKER_01
 Something else that we just split, I need somewhere to split and that splitting a topic boundary is a nice thing to do other than just splitting somewhere.

0:36:07	SPEAKER_02
 Yeah, suppose it's quite an entity.

0:36:10	SPEAKER_00
 Yeah, I'm also a bit like I'm not 100% sure about Rainbow being the right thing because it seems that Rainbow does in its structure quite rely on having different examples of the same categories.

0:36:20	SPEAKER_01
 Yeah, but I think it should work for just one document because it compares between the categories and if you just have one document, it still can find out which words are informative for that category which are not.

0:36:39	SPEAKER_01
 So if you have just one document in each category and there are a lot of occurrences of the weather in each one, so this will be not very informative across the categories.

0:36:52	SPEAKER_01
 So it should work for one, but I'm not sure how exactly it calculates everything.

0:36:58	SPEAKER_01
 I think it's not possible to look that up.

0:37:01	SPEAKER_00
 You know what, as a byproduct of my LSA, I'll provide a vocabulary like sort of a dictionary which for each word gives an entropy score, entropy score, which just tells you of how much information the presence of a word tells you about which topic it is, not which category like I'm not lumping together separate topic segments into categories, but just like how much this word tells you about how likely that with the occurrence of that word makes it that it's a specific segment, topic segment, which is some measure already of how widespread this word is versus how specific to certain segments that is.

0:37:40	SPEAKER_00
 And I'll just provide that because that's just not much more work than just the usual thing and then we can see how we can tie that in with the other stuff.

0:37:49	SPEAKER_00
 So if you keep on working on rainbow meanwhile and try to find a way how to tie your rainbow stuff into some way that we can attach it to a certain time segment.

0:38:02	SPEAKER_01
 Maybe it's possible to have a list that is ordered by.

0:38:11	SPEAKER_00
 Just thinking, is each word completely unique, like sort of does it treat each word, each occurrence of words, a completely unique event or does it, I mean, no, it has to mean, basically the form of the word is important, right?

0:38:27	SPEAKER_00
 We can't just replace the word pen arbitrary string.

0:38:30	SPEAKER_00
 Because it looks if the same word occurs again and stuff.

0:38:34	SPEAKER_00
 Yeah, it has to work.

0:38:42	SPEAKER_00
 I think it's a stupid question.

0:38:45	SPEAKER_00
 It has to work on the word.

0:38:48	SPEAKER_00
 I was thinking whether if we replace the word by something uniquely identifiable, then it would make the difference which order it is, but that wouldn't work because it needs the word because that's all it's working on.

0:38:53	SPEAKER_00
 It's the word and it looks if that word occurs again and versus how often that word occurs in other contexts.

0:38:58	SPEAKER_00
 So we can't attach some type of information to the word, just to the word string itself, making it underscore and making the time or something that wouldn't work.

0:39:06	SPEAKER_01
 You can use some kind of truncation.

0:39:13	SPEAKER_01
 Maybe if you attach a number to each word and say that it should omit the last part.

0:39:19	SPEAKER_00
 If you wanted to have that in the untrancated version, then would the output be the untrancated version?

0:39:30	SPEAKER_01
 Probably not.

0:39:38	SPEAKER_01
 No, I don't think it would.

0:39:45	SPEAKER_00
 Yeah, for now, I mean really just like, yeah, I think if we work together on an entropy-based score, let me see if I can demonstrate.

0:39:58	SPEAKER_00
 Let's just keep on talking me and I'll try to start that up.

0:40:04	SPEAKER_00
 It's a very simple thing, but it basically just does something which tells you how specific a word is.

0:40:11	SPEAKER_00
 In a sense, it's basically just to a high degree really telling you how rare a word is or how common a word is.

0:40:20	SPEAKER_00
 But as the first step, that's probably for a prototype for next week, that's probably not a bad thing.

0:40:26	SPEAKER_00
 I mean, if it's just that, if you have segments where lots of rare words occur, highlighted in darker red, then segments where all the very common words occur, that's just that somewhere to start from.

0:40:38	SPEAKER_00
 And it's a bit more sophisticated in that, but then the factor just ends up doing that, obviously, from what I figured out.

0:40:48	SPEAKER_00
 Actually, I think I'm not going to start that now.

0:40:58	SPEAKER_00
 That's probably the best way to take too long.

0:41:02	SPEAKER_00
 So, if we get it on a word-by-word basis, whatever you do, it'll probably appear on a word-by-word basis, what you hit us on a sort of segment but not quite segment-based.

0:41:15	SPEAKER_01
 Yes.

0:41:16	SPEAKER_01
 Yeah, I mean, I haven't really decided on how to really get the information out of this now because when I have, for example, the increased speaker overlap that applies to several terms, of course.

0:41:32	SPEAKER_01
 But I could give the information about how important this is to each of our segments.

0:41:42	SPEAKER_00
 Okay, what about the following model? I mean, this is a very unscientific way of doing it in some sense, but what if we take time as the standard unit for now and sort of like make a massive one-second split super array because everything you're doing can in one way or the other be tied down to actual time.

0:41:59	SPEAKER_00
 So, if for each one second time slot, we could attach a value.

0:42:04	SPEAKER_00
 And then it would be easy to then go back if we have the time marks here and remap that on to the length of a segment.

0:42:10	SPEAKER_00
 You know what I mean?

0:42:11	SPEAKER_00
 So, if you have, for each word, say, and we know that word starts at this second and ends at that second, and you have for some time period, the overlap in that period or the F1s in that period or something.

0:42:24	SPEAKER_00
 So, you also have a value which can be tied down to a time.

0:42:27	SPEAKER_00
 And then we could just, in MATLAB or in something, just create some massive super array of things for each fridge, like sort of time sampling slot and calculate the value for this.

0:42:42	SPEAKER_00
 And once we have this array, we can go with the script and sort of go for each segment to the starting and end times and say, okay, this is from our time segment here to this time segment there.

0:42:53	SPEAKER_00
 So, we take the sum of those and divide them by the number of something, create the average and put it in as the value for the segment.

0:42:59	SPEAKER_00
 You know what I mean?

0:43:00	SPEAKER_01
 But how can we get to know what makes sense as a function for joining everything together?

0:43:08	SPEAKER_00
 Oh, that's a fiddling plane. The end for that problem we'll always have.

0:43:14	SPEAKER_00
 Because we don't have a useful way of automatically evaluating...

0:43:18	SPEAKER_00
 You don't have a way of fusically evaluating automatically what's good and what's bad.

0:43:26	SPEAKER_00
 So, it's probably always going to be a question of looking at it and saying, okay, running it with different factor loadings and saying, okay, this way works that well.

0:43:39	SPEAKER_01
 First, what you proposed? We should break that down to have the smallest unity of time duration should be one word.

0:43:53	SPEAKER_01
 I mean, that would be because that would be what naturally came out of her thing.

0:43:59	SPEAKER_00
 But it would probably be more difficult for map to map for you to map it on.

0:44:04	SPEAKER_01
 Yeah, sure. But I could then, if I have the value for a segment, I would perhaps just give all the important words.

0:44:16	SPEAKER_01
 You could always find out how many words there are.

0:44:22	SPEAKER_00
 So you say that having an array where each cell is one word, and then you would map your information on two individual words.

0:44:36	SPEAKER_01
 Yeah, someone would have to break it down.

0:44:41	SPEAKER_01
 I would probably somehow have to break it down to whatever.

0:44:45	SPEAKER_00
 Would you be able to find out which word that is?

0:44:49	SPEAKER_01
 Yes, sure.

0:44:53	SPEAKER_00
 Okay, and then we could have some type of point in the end where the one scores from all the individual word cells get multiplied all with, like, for each utterance or whatever you have, get all multiplied with the same value, all the ones that are within that utterance, that's sort of the combination of the two scores.

0:45:12	SPEAKER_00
 Okay, so we'll just try to check that out.

0:45:20	SPEAKER_00
 And then we'd have to go back again and then put that back into that segment mode here.

0:45:25	SPEAKER_01
 So that we, because in the end we don't want it on a per word basis, but probably on a per segment base.

0:45:31	SPEAKER_01
 Yeah, then, okay, but at that moment it would be better for me to just make it on a per segment basis right away and that's where I adapt it also to do.

0:45:35	SPEAKER_00
 Oh yeah, actually that's true so that it's easier if you are able to, I think that's probably back to where we started with this.

0:45:43	SPEAKER_00
 But you said it's more complicated because your segments aren't those segments exactly.

0:45:48	SPEAKER_01
 Yeah, I mean mine are only more, but they have the same stud and point.

0:45:53	SPEAKER_01
 Sometimes there are two segments and one with the gap in between that and they have, they don't overlap.

0:46:02	SPEAKER_00
 And their segments do overlap.

0:46:04	SPEAKER_01
 No, no, they don't, but those two of those don't.

0:46:08	SPEAKER_01
 I mean, my segments overlap in the same way as there are two, but sometimes I have split one of the segments into two segments, but it's easy to match the start and end times.

0:46:23	SPEAKER_00
 So you could, on their granularity, you could on their granularity create a score for each of their segments.

0:46:36	SPEAKER_00
 Well, I guess I mean for you, if you know for each word, if you find that out, then it has to be possible because if you know sort of this is going from word to word or if this is going from time to time and then there has to be a way then for you say, okay, this concerns these words and then just make a simple mean over them.

0:46:55	SPEAKER_00
 I think an interesting thing is if we don't combine your two scores in the XML file yet, but if we do that in the software, then we can probably make ways of playing with it in the software and sort of, you know, like, adapting some sort of control, like playing around with different weightings for the utterance based one versus the word based one and sort of look at it dynamically.

0:47:21	SPEAKER_00
 You know what I mean?

0:47:23	SPEAKER_00
 Like, playing around sort of figuring out what's the best way of combining them by playing around looking at the results.

0:47:29	SPEAKER_01
 We could look at different measures if they come up with the same kind of...

0:47:40	SPEAKER_00
 Yeah, we could probably make a graphical display initially at least for experimenting, which displays them in different ways and then see how they interact with each other.

0:47:50	SPEAKER_01
 Yeah, I mean, that's what I'm already doing with my...

0:47:54	SPEAKER_00
 Okay, that's it.

0:47:55	SPEAKER_00
 So, do you think, like, both of you then can map something onto their segments?

0:48:01	SPEAKER_00
 Just each of you provide one value, like double value or whatever, like one decimal value or whatever onto exactly their segments?

0:48:11	SPEAKER_01
 I think if I can provide something for the words as they are, it's stated from where to where the segments go, which is it?

0:48:20	SPEAKER_01
 It's stated both...

0:48:21	SPEAKER_00
 It's stated even which words it is.

0:48:23	SPEAKER_00
 It's done both in terms of words and in terms of sections.

0:48:26	SPEAKER_00
 It's a bit sad sort of that we do this before we've truly figured out how the night egg smell works because now we're doing it all by hand and, like, parsing and unpartsing and it's all part of the framework.

0:48:37	SPEAKER_00
 Yeah.

0:48:41	SPEAKER_00
 How much easier would it be if we truly understood this?

0:48:44	SPEAKER_02
 Well, it should be quite straightforward similar to us.

0:48:46	SPEAKER_02
 It's good.

0:48:47	SPEAKER_02
 You know, and really understands that I do what I smell.

0:48:51	SPEAKER_02
 Parsing.

0:48:52	SPEAKER_00
 I might just change my order of which I do things and, like, forget my latent smell analysis stuff until the weekend and try to really make sense of the night data system now so that maybe as soon as I've understood that we find ways of doing that within the night framework already so that we don't manually have to parse times and entire things together.

0:49:17	SPEAKER_01
 You mean by matching strings?

0:49:19	SPEAKER_01
 Yeah.

0:49:20	SPEAKER_00
 Well, at the moment what you would do, like, to solve this problem is you would sort of, like, write some Perl script or something that gets this time value out of here.

0:49:28	SPEAKER_01
 What I've done is parse it and make some out of the way you can get the start times.

0:49:34	SPEAKER_01
 Okay.

0:49:35	SPEAKER_01
 So that's quite easy because it's an attribution.

0:49:39	SPEAKER_01
 You just say that you want values of those attributes.

0:49:42	SPEAKER_00
 So provided that you get your words in the right order, do you think it is an easy task for you? It's a relatively feasible task for you to get just a single value per segment.

0:49:51	SPEAKER_01
 I don't know how long it takes me.

0:49:55	SPEAKER_01
 Okay.

0:49:56	SPEAKER_00
 And you say you think you're able as well to map onto those segments.

0:50:00	SPEAKER_03
 Yeah.

0:50:01	SPEAKER_00
 And if you're both able to map onto those segments, then we should be able to get one file where we have, like, whatever two values value, A and value B, both as attributes for.

0:50:11	SPEAKER_00
 So, for this.

0:50:17	SPEAKER_00
 And that we could load into a prototype and see what types of ways of displaying this information are there.

0:50:24	SPEAKER_01
 Yeah.

0:50:30	SPEAKER_01
 I hope to have some value quite soon that I just work. I mean, I just calculated the values for the average of the rules.

0:50:43	SPEAKER_01
 And they're what's, I mean, I didn't have a look at the data yet, but they vary quite widely, even for the same speaker cross meetings.

0:50:53	SPEAKER_01
 So, one speaker had an average of about 100, one meeting and 160, another meeting that's really strange.

0:51:05	SPEAKER_01
 I mean, perhaps it's because of laughter or something. That's what I was thinking, but I didn't have.

0:51:11	SPEAKER_00
 There's probably also social interaction factors in that they sometimes just a meeting, like, if people adapt their series to each other, then they sometimes.

0:51:19	SPEAKER_01
 Yeah, that's what I read in one of those papers.

0:51:25	SPEAKER_01
 Yeah, that could mess up the square, because it would be.

0:51:29	SPEAKER_00
 Can you do something like just like not measuring the F0, the absolute robot, like the variance of F0 within a certain timeframe and like sort of like just have some part where it's very low variance with a more or less talking the same F0 and one where there's a lot of more variance.

0:51:43	SPEAKER_01
 I don't know about that. Yeah, but all this is quite, you know, data-intensive.

0:51:51	SPEAKER_01
 When I am led, they just calculate the average F0 levels.

0:51:58	SPEAKER_01
 I think it made it more than half an hour, considering more than half an hour to do it for our meetings.

0:52:05	SPEAKER_01
 Yeah, we have 75 hours per average of six speakers, and they measure every 0.016 seconds, and that gives us quite a lot of variance.

0:52:22	SPEAKER_00
 Okay.

0:52:26	SPEAKER_00
 So at the moment, you're just measuring the F0's relative to the average for the speaker.

0:52:36	SPEAKER_01
 Yeah, what I did at the moment is, I got the F0 values from for each speaker for his headphone, and I only take those that were required at the time where he was actually speaking.

0:52:52	SPEAKER_01
 So I calculated the average.

0:52:58	SPEAKER_01
 So that gave me now one value per speaker per meeting.

0:53:06	SPEAKER_00
 Okay.

0:53:10	SPEAKER_00
 So what you would be feeding in would be just like one value per speaker per meeting.

0:53:14	SPEAKER_00
 No, no, that's just the average.

0:53:16	SPEAKER_00
 That's your average baseline.

0:53:17	SPEAKER_00
 Okay.

0:53:18	SPEAKER_00
 So that would show you how much relative to how he's performing generally in that meeting relative to that, how he's in a specific segment.

0:53:29	SPEAKER_01
 Yes, I mean, I just needed to have this value now to relate.

0:53:35	SPEAKER_01
 Yeah.

0:53:36	SPEAKER_00
 Yeah.

0:53:37	SPEAKER_00
 And for you, that would be quite easy to relate to those segments.

0:53:41	SPEAKER_00
 Yeah, I guess I passed in 2015.

0:53:44	SPEAKER_01
 It's after I'm not able to take it.

0:53:48	SPEAKER_01
 I'm going to take that and I'll maybe take it after after.

0:53:53	SPEAKER_01
 I mean, I actually have to look at the data what causes these, because it's quite funny to have a male speaking at 200.

0:54:04	SPEAKER_00
 Oh, they do exist.

0:54:06	SPEAKER_01
 Yeah, sure.

0:54:09	SPEAKER_00
 The castra, the core of the international computer science institute.

0:54:14	SPEAKER_00
 I'm afraid I have to go soon.

0:54:17	SPEAKER_00
 No, I'm not quite sure I'm interested in anything more.

0:54:20	SPEAKER_00
 We have to talk about it anyway.

0:54:22	SPEAKER_01
 Maybe we need the weekend.

0:54:27	SPEAKER_00
 Yeah.

0:54:28	SPEAKER_00
 See, as soon as I'm halfway through my LSA, basically, as soon as I have the matrix built of the document by Word stuff, it's very easy to then calculate for each word a score.

0:54:41	SPEAKER_00
 And I can just give you those scores and you can do them whatever you want.

0:54:45	SPEAKER_01
 So, how about the prototype?

0:54:48	SPEAKER_01
 If we want to show him something on Monday, we definitely have to work together.

0:54:53	SPEAKER_01
 Some of us at least have to work together to get her running.

0:54:57	SPEAKER_00
 Yeah, I think Colin Dave and me will actually work on the Java stuff in it.

0:55:01	SPEAKER_00
 And we'll just see whatever you would, whatever you'd supply us, we'll try to tie in and visualize in some way or another.

0:55:09	SPEAKER_00
 I'll ask Jonathan if we can postpone the meeting to one o'clock.

0:55:15	SPEAKER_00
 So that would give us a chance of meeting for an hour before that to discuss the questions that we had.

0:55:22	SPEAKER_02
 Yeah, you just send us an email.

0:55:25	SPEAKER_02
 What's happening?

0:55:26	SPEAKER_00
 Yeah, I haven't gotten my confirmation that Wednesday is fine, I'm not sure if I'm supposed to expect a confirmation from my confirmation from him now.

0:55:34	SPEAKER_00
 But I'll just email him again and ask him if we can maybe make it one, sorry, reset 12 and I'm asking if we can make one.

0:55:41	SPEAKER_00
 This is a bit frustrating at the moment, as much as possible, it is so difficult to get to the point where you understand enough to really feel that.

0:55:52	SPEAKER_00
 I'm not feeling that I'm really working at the moment, I'm not just trying to make sense.

0:55:57	SPEAKER_00
 It's a bit too far into the meeting for that.

0:56:00	SPEAKER_01
 And I'm at the moment feeling around with my data, I'm not quite seeing how I get to a sense of abstraction level.

0:56:09	SPEAKER_01
 From my very...

0:56:12	SPEAKER_00
 I guess as soon as we have a framework in the type of the prototype where each of us can tie in their stuff and see how it looks like and how it performs.

0:56:21	SPEAKER_00
 It probably makes it a lot easier then, but if it's a bootstrapping problem, for the prototype we need some type of data, but to develop the data it would be a lot easier to have the prototype.

0:56:31	SPEAKER_00
 Anyway, I've got to go.

0:56:33	SPEAKER_01
 So I mean, you will be happy with some data even if it doesn't make much sense.

0:56:37	SPEAKER_00
 Yes, but if it's in a form which is easy to read in at the moment, that would be fine.

0:56:41	SPEAKER_00
 Basically, if we have something like this segments file, but for each of you, just have one attribute, I think it's really easy if we don't merge them beforehand, but if we let them...

0:56:50	SPEAKER_00
 If we combine them in the prototype or don't at the moment, because then we can easily display them individually, contrast them to each other and play around with how to combine them.

0:57:01	SPEAKER_01
 And also we don't have to recalculate it.

0:57:04	SPEAKER_00
 Just one.

0:57:06	SPEAKER_00
 Yeah.

0:57:07	SPEAKER_00
 And I mean, computationally multiplying two integers or doubles or whatever shouldn't be the thing that...

0:57:12	SPEAKER_01
 If it's already on segment space, that's not too much.

0:57:15	SPEAKER_00
 Yeah.

0:57:16	SPEAKER_00
 Alright.

