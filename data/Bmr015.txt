0:00:00	SPEAKER_06
 We're not crashing anymore.

0:00:14	SPEAKER_06
 It really bothers me.

0:00:16	SPEAKER_06
 I crashed.

0:00:17	SPEAKER_06
 You crashed this morning?

0:00:18	SPEAKER_06
 I did not crash this morning.

0:00:19	SPEAKER_05
 Oh, well, maybe it's just how many times you crashed in a day.

0:00:25	SPEAKER_05
 First time in the day.

0:00:26	SPEAKER_09
 Maybe it's one to do enough meeting to a crash.

0:00:31	SPEAKER_09
 No matter of experience.

0:00:33	SPEAKER_04
 Yeah.

0:00:34	SPEAKER_05
 That's great.

0:00:35	SPEAKER_05
 Do we have an agenda?

0:00:37	SPEAKER_05
 I have an address.

0:00:38	SPEAKER_05
 Can't come.

0:00:39	SPEAKER_06
 I have a agenda and it's all me because no one sent me anything else.

0:00:43	SPEAKER_09
 Did they send the messages to you?

0:00:45	SPEAKER_06
 I have no idea, but I just got a few minutes ago, right when you were in my office it arrived.

0:00:52	SPEAKER_06
 Does anybody have any agenda items other than me?

0:00:56	SPEAKER_06
 I have one more also which is to talk about the digits.

0:00:59	SPEAKER_05
 Great.

0:01:00	SPEAKER_05
 I'm just going to talk briefly about the NSFITR.

0:01:03	SPEAKER_05
 Oh, great.

0:01:04	SPEAKER_05
 You won't see much, but you said one time about digits.

0:01:10	SPEAKER_06
 I have a short thing about digits and then I want to talk a little bit about naming conventions, although it's unclear whether this is the right place to talk about it.

0:01:18	SPEAKER_06
 Maybe just talk about it very briefly and take the details to the people for whom it's relevant.

0:01:23	SPEAKER_02
 I could always say something about transcription.

0:01:28	SPEAKER_05
 Well, if we, yeah, we shouldn't add things and just add things in.

0:01:31	SPEAKER_05
 I actually pre-visit you, so if we're short meeting, would we find?

0:01:36	SPEAKER_06
 So the only thing I want to say about digits is we are pretty much done with the first test set.

0:01:41	SPEAKER_06
 There are probably forms here and there that are marked as having been read that weren't really read.

0:01:46	SPEAKER_06
 So I won't really know until I go through all the transcriber forms and extract out pieces that are an error.

0:01:52	SPEAKER_06
 So two things.

0:01:53	SPEAKER_06
 The first is what should we do about digits that were misread?

0:01:57	SPEAKER_06
 My opinion is we should just throw them out completely and have them read again by someone else.

0:02:04	SPEAKER_06
 The grouping is completely random, so it's perfectly fine to put a group together again of errors and have them read just to finish out the test set.

0:02:13	SPEAKER_06
 The other thing you could do is change the transcript to match what they really said.

0:02:20	SPEAKER_06
 So there's the two options.

0:02:22	SPEAKER_05
 But there's often things where people do false starts.

0:02:24	SPEAKER_05
 I know I've done it where I say, say, yeah.

0:02:26	SPEAKER_06
 What the transcribers did with that is if they did a correction and they eventually did read the right string, you extract the right string.

0:02:33	SPEAKER_06
 Wait, were they completely wrong?

0:02:34	SPEAKER_06
 Yeah, didn't correct.

0:02:35	SPEAKER_06
 And didn't notice, which happens in a few places.

0:02:38	SPEAKER_06
 So, so.

0:02:39	SPEAKER_02
 So, so.

0:02:44	None
 Correct.

0:02:44	SPEAKER_06
 And so the two options are change the transcript to match what they really said.

0:02:49	SPEAKER_06
 But then the transcript isn't the error test set anymore.

0:02:53	SPEAKER_06
 I don't think that really matters because the conditions are so different.

0:02:57	SPEAKER_06
 And that would be a little easier.

0:02:58	SPEAKER_09
 How many are, how often is that happen?

0:03:00	SPEAKER_06
 Five or six times.

0:03:01	SPEAKER_09
 Oh, so it's not very much.

0:03:02	SPEAKER_09
 No, it's not much at all.

0:03:04	SPEAKER_09
 There's a question just change the transcript.

0:03:06	SPEAKER_09
 Yeah.

0:03:07	SPEAKER_05
 Okay.

0:03:09	SPEAKER_05
 Yeah, it's five or six times out of thousands.

0:03:11	SPEAKER_05
 Four thousand.

0:03:12	SPEAKER_05
 Four thousand.

0:03:13	SPEAKER_05
 Yeah, I would do the easy way.

0:03:16	SPEAKER_05
 Okay.

0:03:17	SPEAKER_05
 Yeah.

0:03:18	SPEAKER_05
 It's kind of nice.

0:03:19	SPEAKER_05
 I mean, who knows what studies people will be doing on speaker dependent things.

0:03:23	SPEAKER_05
 And so I think having having it all the speakers who we had is least interesting.

0:03:29	SPEAKER_09
 So, how many digits have been transferred?

0:03:33	SPEAKER_06
 And so, I think that's a thousand lines in each line is between one and about ten digits.

0:03:38	SPEAKER_06
 I didn't compute the average.

0:03:39	SPEAKER_06
 I think the average was around four or five.

0:03:41	SPEAKER_05
 So that's a couple hours of speech probably.

0:03:44	SPEAKER_05
 Yeah.

0:03:45	SPEAKER_05
 Which is a reasonable, reasonable test set.

0:03:49	SPEAKER_06
 And Jane, I do have a set of forms which I think you have copies of somewhere.

0:03:54	SPEAKER_06
 Oh, you do.

0:03:55	SPEAKER_06
 Oh, okay, good.

0:03:56	SPEAKER_06
 Good.

0:03:57	SPEAKER_06
 I thought I had had all of them back from you.

0:03:59	SPEAKER_06
 And then the other thing is that the forms in front of us here that we're going to read later, were suggested by Liz because she wanted to elicit some different prosotics from digits.

0:04:08	SPEAKER_06
 And so, I just wanted people to take a quick look at the instructions and the way it worked and see if it makes sense.

0:04:14	SPEAKER_06
 And if anyone has any comments on it.

0:04:19	SPEAKER_05
 I see.

0:04:23	SPEAKER_05
 And the decision here was to continue with the words rather than the numerics.

0:04:32	SPEAKER_06
 Yes, although we could switch it back.

0:04:35	SPEAKER_06
 The problem was 0 and 0.

0:04:38	SPEAKER_06
 Although we could switch it back and tell them always to say 0 or always to say 0.

0:04:42	SPEAKER_05
 Or neither, but it's just two things ways that you can say it.

0:04:46	SPEAKER_05
 Sure.

0:04:51	SPEAKER_05
 That's the only thought I have because if you start talking about these, you know, she's trying to get it natural groupings.

0:04:58	SPEAKER_05
 But there's nothing natural about reading numbers this way.

0:05:03	SPEAKER_05
 I mean, if you saw telephone number, you would never see it this way.

0:05:06	SPEAKER_06
 The problem also is she did want to stick with digits.

0:05:08	SPEAKER_06
 I mean, I'm speaking for her.

0:05:09	SPEAKER_06
 She's not here.

0:05:10	SPEAKER_06
 But the other problem we were thinking about is if you just put the numerals, they might say 43 instead of 43.

0:05:19	SPEAKER_02
 Well, the space though between them.

0:05:22	SPEAKER_02
 When you space them out, they don't look like 43 anymore.

0:05:25	SPEAKER_06
 Well, she and I were talking about it.

0:05:27	SPEAKER_06
 And she felt that it's very, very natural to do that sort of.

0:05:31	SPEAKER_06
 She's right.

0:05:32	SPEAKER_05
 It's a different problem.

0:05:34	SPEAKER_05
 I mean, it's an interesting problem.

0:05:36	SPEAKER_05
 I mean, we've done stuff with numbers before.

0:05:38	SPEAKER_05
 And yeah, sometimes people, if you say 3981, sometimes people will say 3981 or 3891.

0:05:45	SPEAKER_05
 I don't think they'd say that.

0:05:47	SPEAKER_05
 Not very frequently.

0:05:48	SPEAKER_05
 But certainly could.

0:05:49	SPEAKER_05
 Yeah.

0:05:50	SPEAKER_05
 3891 is probably how they do that.

0:05:53	SPEAKER_06
 So, I mean, this is something that Liz and I spoke about.

0:05:56	SPEAKER_06
 Nice.

0:05:57	SPEAKER_06
 This was something that Liz asked for specifically.

0:06:01	SPEAKER_06
 I think we need to defer to her.

0:06:03	SPEAKER_05
 Okay. Well, we're probably going to be collecting meetings for a while.

0:06:05	SPEAKER_05
 If we decide we still want to do some digits later, we might be able to do some different versions.

0:06:09	SPEAKER_05
 But this is the next suggestion.

0:06:11	SPEAKER_05
 Okay.

0:06:18	SPEAKER_05
 Okay. So, I guess, let me get my short thing out about the NSF.

0:06:23	SPEAKER_05
 I said this.

0:06:25	SPEAKER_05
 Actually, this is maybe a little side thing.

0:06:27	SPEAKER_05
 I sent to what I thought we had in some previous mail as the right joint thing to send to.

0:06:35	SPEAKER_05
 It was.

0:06:36	SPEAKER_05
 MTG, our CDR hyphen joint.

0:06:38	SPEAKER_05
 Yep.

0:06:39	SPEAKER_05
 But then I got some sort of funny mail saying that the moderator was going to.

0:06:44	SPEAKER_06
 That's because they set the one up at UW.

0:06:46	SPEAKER_06
 That's not on our side.

0:06:47	SPEAKER_06
 That's on the UW website.

0:06:48	SPEAKER_06
 Oh.

0:06:49	SPEAKER_06
 And so UW set it up as a moderated list.

0:06:51	SPEAKER_06
 Oh.

0:06:52	SPEAKER_06
 And I have no idea whether it actually ever goes to anyone.

0:06:55	SPEAKER_06
 So you might want to just mail to Mari.

0:06:57	SPEAKER_05
 No, I got a little excited notes from Mari and Jeff and so on.

0:07:01	SPEAKER_05
 Okay. Good.

0:07:02	SPEAKER_06
 Yeah.

0:07:03	SPEAKER_06
 So the moderator actually did repost it.

0:07:04	SPEAKER_06
 Yeah.

0:07:05	SPEAKER_06
 Because I had sent one earlier.

0:07:06	SPEAKER_06
 Actually, the same thing happened to me.

0:07:07	SPEAKER_06
 I had sent one earlier.

0:07:09	SPEAKER_06
 The message says you'll be informed and then I was never informed.

0:07:11	SPEAKER_06
 But I got replies from people indicating that they had gotten it.

0:07:14	SPEAKER_06
 Right.

0:07:15	SPEAKER_06
 It's just to prevent spam.

0:07:17	SPEAKER_06
 I see.

0:07:18	SPEAKER_05
 Yeah.

0:07:19	SPEAKER_05
 So, okay.

0:07:20	SPEAKER_05
 Anyway, I guess everybody here, you are on that list, right?

0:07:23	SPEAKER_05
 So you got to know.

0:07:24	SPEAKER_05
 Yeah.

0:07:25	SPEAKER_05
 Okay.

0:07:26	SPEAKER_05
 So this was a proposal that we put in before on more, more higher level issues in meetings from, I guess, higher level from my point of view.

0:07:38	SPEAKER_05
 Yeah.

0:07:39	SPEAKER_05
 And meeting mappings.

0:07:41	SPEAKER_05
 And so it was a proposal for the ITR program, the Information Technology Research Program, as part of the National Science Foundation.

0:07:52	SPEAKER_05
 It's the second year of there doing these grants.

0:07:56	SPEAKER_05
 There are a lot of them, some of them anyway, but they're larger grants than usual, small NSF grants.

0:08:03	SPEAKER_05
 So they're very competitive and they have a first phase where you put in pre-proposals and we got through that.

0:08:11	SPEAKER_05
 And so the next phase will be, you will actually be doing a larger proposal.

0:08:15	SPEAKER_05
 And I hope to be doing very little of it, which was also true for the pre-proposals.

0:08:22	SPEAKER_05
 So, there are a bunch of people working on it.

0:08:26	SPEAKER_06
 When's the full proposal, Tim?

0:08:28	SPEAKER_05
 I think April 9th or something.

0:08:30	SPEAKER_05
 So that's about a month.

0:08:33	SPEAKER_06
 And they said, end of business day, you could check on the reviewer forms.

0:08:37	SPEAKER_05
 Tomorrow.

0:08:38	SPEAKER_05
 Tomorrow, March 2nd.

0:08:39	SPEAKER_06
 Might be in a day off all week.

0:08:41	SPEAKER_06
 I guess that's a good thing, because I mean, I got my papers on.

0:08:46	SPEAKER_05
 So it's amazing you showed up at this meeting.

0:08:47	SPEAKER_06
 It is, it is actually quite amazing.

0:08:49	SPEAKER_09
 Let me just see the reviewers comment.

0:08:52	SPEAKER_09
 Yeah.

0:08:53	SPEAKER_05
 Yeah.

0:08:54	SPEAKER_05
 My favorite is when one reviewer says, this should be far more detailed.

0:08:59	SPEAKER_05
 And the next reviewer says, there's way too much detail.

0:09:02	SPEAKER_05
 Yes.

0:09:03	SPEAKER_06
 This is way too general.

0:09:06	SPEAKER_06
 The other reviewer says this is way too specific.

0:09:09	SPEAKER_06
 Yeah.

0:09:10	SPEAKER_06
 It's way too hard.

0:09:11	SPEAKER_05
 Way too easy.

0:09:12	SPEAKER_05
 We'll see.

0:09:13	SPEAKER_06
 Maybe there'll be something useful.

0:09:14	SPEAKER_06
 Well, it sounded like the first gate was pretty easy.

0:09:18	SPEAKER_06
 Is that right?

0:09:19	SPEAKER_06
 That they didn't reject a lot of the pre-proposals.

0:09:21	SPEAKER_05
 Do you know anything about the numbers?

0:09:23	SPEAKER_09
 No.

0:09:24	SPEAKER_09
 I don't think that's true.

0:09:27	SPEAKER_09
 He said the next phase will be very competitive because we didn't want to weed out much in the first phase.

0:09:34	SPEAKER_09
 Well, I have to see what the numbers are.

0:09:38	SPEAKER_09
 Yeah.

0:09:39	SPEAKER_09
 But they have to weed out enough so that they have enough reviewers.

0:09:44	SPEAKER_05
 Right.

0:09:45	SPEAKER_05
 So maybe they weed out as much as they want.

0:09:49	SPEAKER_05
 But it's usually pretty.

0:09:54	SPEAKER_05
 Yeah, it's certainly not.

0:09:56	SPEAKER_05
 I'm sure that it's not down to one and two or something.

0:09:59	SPEAKER_05
 Right.

0:10:00	SPEAKER_05
 It was left.

0:10:01	SPEAKER_05
 I'm sure it's.

0:10:02	SPEAKER_06
 How many awards are there?

0:10:04	SPEAKER_05
 Well, there's different numbers of awards for different size.

0:10:07	SPEAKER_05
 They have three size grants.

0:10:09	SPEAKER_05
 Let's find this one.

0:10:10	SPEAKER_05
 Let's see.

0:10:12	SPEAKER_05
 The small ones are less than 500,000 total over three years.

0:10:16	SPEAKER_05
 And that they have a fair number of them.

0:10:19	SPEAKER_05
 And the large ones are.

0:10:22	SPEAKER_05
 Oh, I forget.

0:10:23	SPEAKER_05
 I think more than.

0:10:26	SPEAKER_05
 More than a million and a half, more than two million or something like that.

0:10:31	SPEAKER_05
 And we're in the middle.

0:10:33	SPEAKER_05
 Middle category.

0:10:34	SPEAKER_05
 I think we're.

0:10:35	SPEAKER_05
 I forget it was.

0:10:37	SPEAKER_05
 But.

0:10:38	SPEAKER_05
 I don't remember.

0:10:39	SPEAKER_05
 But it's probably.

0:10:41	SPEAKER_05
 I don't remember.

0:10:42	SPEAKER_05
 But it's probably along the line.

0:10:46	SPEAKER_05
 I could be wrong in this.

0:10:47	SPEAKER_05
 It would probably along lines of 15, that they'll find the 20.

0:10:50	SPEAKER_05
 I mean, when they, do you know how many they funded when they've been in, in, in Chucks?

0:10:54	SPEAKER_05
 They got.

0:10:55	SPEAKER_05
 I see.

0:10:56	SPEAKER_05
 Yeah.

0:10:57	SPEAKER_06
 I thought it was smaller and that was like four or five.

0:11:00	SPEAKER_06
 Well, they fun.

0:11:01	SPEAKER_05
 They, yeah.

0:11:02	SPEAKER_05
 I mean, we'll find out one more.

0:11:05	SPEAKER_05
 Yeah.

0:11:06	SPEAKER_05
 I mean, last time I think they just had two category small and big.

0:11:09	SPEAKER_05
 And this time they came up with a middle one.

0:11:11	SPEAKER_05
 So it'll, they'll be more of them that they fund than of the big.

0:11:15	SPEAKER_09
 If we end up getting.

0:11:17	SPEAKER_09
 What will it be in the context in terms of where will the money go to what we'll be doing with it?

0:11:25	None
 Exactly.

0:11:26	SPEAKER_06
 We say in the proposal.

0:11:28	SPEAKER_09
 I mean, I was far enough.

0:11:30	SPEAKER_05
 You know, none of it will go for the yachts that we've been talking about.

0:11:39	SPEAKER_05
 Well, you know, I mean, it's just for the research.

0:11:42	SPEAKER_09
 It's extending the research, right?

0:11:46	SPEAKER_06
 Because the other higher level stuff than we've been talking about for a record.

0:11:50	SPEAKER_05
 Yeah.

0:11:51	SPEAKER_05
 Yeah.

0:11:52	SPEAKER_05
 Yeah.

0:11:53	SPEAKER_05
 The other things that we have been working on with the communicator, especially with the newer things, with the more acoustically oriented things, are lower level.

0:12:03	SPEAKER_05
 And this is dealing with mapping on the level of the conversation, mapping the conversation to different kind of planes.

0:12:14	SPEAKER_05
 So.

0:12:15	SPEAKER_05
 But so it's all stuff that none of us are doing right now.

0:12:21	SPEAKER_05
 None of us are funded for.

0:12:22	SPEAKER_05
 So it's, so it's, it would be new.

0:12:24	SPEAKER_09
 So assuming everybody's busy now.

0:12:26	SPEAKER_09
 I mean, it's going to be higher more students.

0:12:29	SPEAKER_05
 Well, there's evenings in this room.

0:12:34	SPEAKER_05
 Yeah, there would be, there would be cars.

0:12:37	SPEAKER_05
 And there would be expansion.

0:12:39	SPEAKER_05
 But also, there's always, for everybody, there's always things that are dropping off, grants that are renting or other things.

0:12:45	SPEAKER_05
 So there's a continual need to bring in new things.

0:12:49	SPEAKER_05
 But there definitely would be new students and so forth, both of them.

0:12:54	SPEAKER_06
 Are there any students in your class who are expressing interest?

0:12:58	SPEAKER_05
 Not clear yet.

0:13:01	SPEAKER_05
 Other than the one who's already here.

0:13:03	SPEAKER_05
 I mean, we got, yeah, two in the, two in the, two in the class already here.

0:13:08	SPEAKER_05
 And then, and then there's a third who's doing a project here.

0:13:13	SPEAKER_05
 But he won't be in the country that long.

0:13:16	SPEAKER_05
 Maybe another one.

0:13:18	SPEAKER_05
 Yeah, actually, there's one other guy who's looking at that, that, that, Jeremy, I think.

0:13:25	SPEAKER_05
 Anyway, yeah, that's, that's how I was going to say is that, that's, you know, that's nice and we're sort of proceeding to next step.

0:13:31	SPEAKER_05
 And it'll mean some more work, you know, in March and getting a proposal out.

0:13:35	SPEAKER_05
 And then it's, you know, we'll see what happens.

0:13:40	SPEAKER_05
 The last one was that he had their whistle naming.

0:13:44	SPEAKER_06
 Yeah, it just, we've been cutting up sound files and, for both digits and for doing recognition.

0:13:51	SPEAKER_06
 And Liz had some suggestions on naming and it just brought up the whole issue that hasn't really been resolved about naming.

0:13:57	SPEAKER_06
 So one thing she would like to have is for all the names to be the same length.

0:14:02	SPEAKER_06
 So that sorting is easier.

0:14:06	SPEAKER_06
 Same number of characters so that when you're sorting file names, you can easily extract out bits and pieces that you want.

0:14:12	SPEAKER_06
 That's easy enough to do.

0:14:13	SPEAKER_06
 And I don't think we have so many meetings that that's a big deal just to change the names.

0:14:16	SPEAKER_06
 So that means instead of calling it MR1, MR2, you call it MRM001, MRM002, things like that, just so that they're all the same length.

0:14:27	SPEAKER_02
 But you know, when you do things like that, you can always, as long as you have, you can always search from the beginning of the end of the string.

0:14:35	SPEAKER_06
 The problem is that there are a lot of fields.

0:14:38	SPEAKER_06
 Right, so we have, we're going to have the speaker ID, the session, information on the microphones, information on the channels and all that.

0:14:49	SPEAKER_06
 And so if each one of those is a fixed length, the sorting comes a lot easier.

0:14:53	SPEAKER_01
 She wanted to keep the same length across different meetings also.

0:14:57	SPEAKER_01
 So like the NSA meeting links, file names are going to be the same length as the media recording meeting names.

0:15:02	SPEAKER_06
 And as I said, we just don't have that many that that's a big deal.

0:15:06	SPEAKER_06
 And so at some point we have to sort of take a few days off, like the transcribers have a few days off, make sure no one's touching the data and reorganize the file structures.

0:15:16	SPEAKER_06
 And when we do that, we can also rationalize some of the naming.

0:15:19	SPEAKER_02
 I would think though that the transcribes themselves wouldn't need to have such lengthy names.

0:15:25	SPEAKER_02
 So I mean, you're dealing with a different domain there, I mean, with starting n times and all that, channels and stuff.

0:15:31	SPEAKER_06
 So the only thing we would change with that is just the directory names, I would change them to match.

0:15:36	SPEAKER_06
 So instead of being MR1, it would be MRM001, but I don't think it's a big deal.

0:15:40	SPEAKER_06
 So for the meetings, we were thinking about three letters and three numbers for meeting IDs, for speakers, M or F, and then three numbers.

0:15:49	SPEAKER_06
 And that also brings up the point that we have to start assembling a speaker database so that we get those links back and forth and keep it consistent.

0:16:00	SPEAKER_06
 And then the microphone issues, we want some way of specifying more than looking in the key file, what channel and what mic, what channel, what mic, and what broadcast, or I don't know how to say it.

0:16:16	SPEAKER_06
 So with this one, it's this particular headset, with this particular transmitter, as a wireless, and you know, that one is a different headset and different channel.

0:16:25	SPEAKER_06
 And so we just need some naming conventions on that. And that's going to be come especially important once we start changing the microphone setup.

0:16:35	SPEAKER_06
 We have some new microphones that I'd like to start trying out once I test them, and then we'll need to specify that somewhere.

0:16:42	SPEAKER_06
 So I was just going to do a fixed list of microphones and types.

0:16:48	SPEAKER_05
 As I said, yeah. I'm sure it's such a short agenda list, I guess I will ask how are the transcription skills.

0:16:57	SPEAKER_02
 But the news is that I switched to start my news sense. I switched to doing the channel by channel transcriptions to provide a tighter time bins for partly for use in Teal's work and also its environments and other people in the project.

0:17:15	SPEAKER_02
 And I discovered in the process a couple of interesting things, which one of them is that it seems that there are time lags involved in doing this using an interface that has so much more complexity to it.

0:17:34	SPEAKER_02
 And I wanted to maybe ask Chuck to help me with some of the questions and efficiency. I was thinking maybe the best way to do this in the long run, maybe to give them single channel parts and then piece them together later.

0:17:45	SPEAKER_02
 And I have a script I can piece them together. So it's like I know that I can take them apart and put them together and end up with the representation, which is where the real power of that interface is.

0:17:53	SPEAKER_02
 And it may be it's faster to transcribe the channel at a time with only one sound violin, one set of utterances to check through.

0:18:03	SPEAKER_05
 I'm a little confused. I thought that that one of the reasons we thought we were so much faster than than the other transcription thing was that that we were using the mix.

0:18:16	SPEAKER_02
 Oh yes. Okay. But with the mix, when you have an overlap, you only have a choice of one start and end time for that entire overlap, which means that you're not tightly tuning the individual parts of that overlap by your foot speaker.

0:18:31	SPEAKER_02
 So someone may have only said two words in that entire big chunk of overlap. And for purposes of things like, well, some things like training the speech non speech segmentation thing.

0:18:43	SPEAKER_02
 It's necessary to have it more tightly tuned than that. And you know, it would be wonderful if it's possible then to use that algorithm to more tight be tying all the channels after that.

0:18:54	SPEAKER_02
 But I don't know exactly where that's going at this point, but I was experimenting with doing this by hand. And I really do think that it's wise that we've had them start the way we have with working off the mix signal, having the interface that doesn't require them to do the type, the type in every single channel.

0:19:17	SPEAKER_02
 The entire interaction. I did discover a couple other things by doing this though. And one of them is that once in a while a back channel will be overlooked by the transgarber as you might expect because when a back channel could well happen in a very densely populated overlap.

0:19:35	SPEAKER_02
 And if we're going to study types of our laps, which is what I want to do analysis of that, then that really tests require listening to every single channel all the way through the entire length for all the different speakers. Now, for only four speakers, that's not going to be too much time. But if it's nine speakers, then that is more time.

0:19:50	SPEAKER_02
 So it's like, you know, kind of wondering. And I think again, it's like this, it's really valuable that he was working on the speech non-speech segmentation because maybe we can close it out without having to actually go to the time that would take to listen to every single channel from start to finish the every single need.

0:20:05	SPEAKER_07
 Yeah, but those spectacles will always be a problem. I think, especially if they're really short and they're not very loud. And so it can, it will always happen that also the automatic detection system will miss some of them.

0:20:19	SPEAKER_02
 Also, then maybe the answer is to listen, especially densely in places of overlap, just so that there is not a overlooked because of that and count on accuracy during the sparse faces.

0:20:31	SPEAKER_02
 Because there are large spaces at a, that's a good point. There are large spaces where there's no overlap at all. Someone's giving a presentation.

0:20:37	SPEAKER_02
 Yeah. Whatever. That's a good, that's a good point. And let's see, there was only a thing I was going to say.

0:20:42	SPEAKER_02
 I think it's really interesting data to work with. I have to say it's very enjoyable. Really, not a problem spending time with these data.

0:20:49	SPEAKER_02
 I'm not just because I'm in there.

0:20:52	SPEAKER_05
 Well, I think it's a short meeting. You're still on the midst of what you're doing from the script last time, I assume.

0:21:06	SPEAKER_03
 I have a result, but I'm continuing working with the mix side now, after the last experience.

0:21:15	SPEAKER_03
 And I tried to adjust to improve in our own city, the test, that I implement.

0:21:28	SPEAKER_03
 But I have a problem because I get very much harmonics now.

0:21:35	SPEAKER_03
 I'm only possible harmonics. And now I'm trying to find some kind of help using the energy to distinguish between possible harmonics and other frequency picks.

0:21:57	SPEAKER_03
 And I have to talk with you, with the group, about the instantaneous frequency, because I have an algorithm.

0:22:10	SPEAKER_03
 And I get similar results, like the paper that I am following. But the rules that people use in the paper to distinguish the harmonics doesn't work well.

0:22:30	SPEAKER_03
 And I'm not sure that the way to obtain the instantaneous frequency is right. It's not right.

0:22:42	SPEAKER_03
 I haven't enough feeling to distinguish what happened.

0:22:48	SPEAKER_05
 I'd like to talk with you about it. If I don't have enough time, and you want to discuss with someone else, besides us, that you might want to talk to, might be Stefan.

0:23:06	SPEAKER_09
 I'm not going to do experience for this. The experience is not enough.

0:23:21	SPEAKER_03
 I don't process the fundamental. I calculate the phase derivate using the F50. The algorithm said that if you change the frequency X using the instantaneous frequency, you can find how in several frequencies, the rest of the frequency picks, the frequency picks, the frequency harmonic, and if you compare the instantaneous frequency of the continuous filters, the use to get the instantaneous frequency is probably to you can find that instantaneous frequency for continuous output continuous filters are brilliant.

0:24:30	SPEAKER_05
 I'd have to look at that and think about it. I haven't worked with that either. The simple-minded way I suggested was what Doug was just saying is that you can make a sieve.

0:24:48	SPEAKER_05
 Let's hypothesize that it's this frequency. Maybe you could use some other cute methods to shortcut it by making some guesses.

0:25:07	SPEAKER_05
 I mean, you could make some guesses from the autocorrelation or something, but then, given those guesses, try only looking at the energy at multiples of that frequency and seeing how much it takes to one that's maximum.

0:25:26	SPEAKER_03
 Using the energy of the multiples of frequencies. You have to do some kind of low pass filter before you do that. I don't use.

0:25:38	SPEAKER_03
 I know many people use low pass filter to get the pitch.

0:25:58	SPEAKER_09
 I'm going to try the vocal track, the response of the vocal track. Just looking at the energy and those, that's the harmonic.

0:26:10	SPEAKER_05
 The thing is that this is for a...

0:26:32	SPEAKER_05
 I don't need to get rid of it. I mean, that'd be nice, but I don't know if it's essential. I mean, because I think the main thing is that you're trying... what are you doing this for?

0:26:45	SPEAKER_05
 You're trying to distinguish between the case where there are more than one speaker. And the case where there's only one speaker.

0:27:04	SPEAKER_05
 You're not distinguishing voice to non-voice. If you don't care about that, see if you also want to determine whether it's on voice, then I think you want to look at high frequencies also because the fact that there's more energy in high frequencies is going to be sort of obvious cue that it's on voice.

0:27:27	SPEAKER_05
 But other than that, I guess, as far as the one person versus two persons, it would be primarily low frequency phenomenon.

0:27:37	SPEAKER_05
 And if you look at the low frequencies, yes, the higher frequencies are going to be a spectral slope. The higher frequencies would be lower energy.

0:27:47	SPEAKER_03
 I would be there for the next week, all my results about the Dharmonicity and we try to comment on this case here because I have enough feeling to understand what happened with so many peaks.

0:28:10	SPEAKER_03
 I see Dharmonics in many times, but there are a lot of peaks that have no harmonics.

0:28:18	SPEAKER_03
 I have to discover what is the best way to...

0:28:25	SPEAKER_05
 I don't think you're not going to be able to look at every frame. I really thought that the best way to do it, and I'm speaking with no experience on this to a good point, but my impression was the best way to do it was however you use instantaneous frequency, however you clope with your candidates, you want to see how much of the energy is in that.

0:28:48	SPEAKER_05
 It's supposed to all of the total energy. And if it's voiced, I guess so. So I think maybe you do need a voiced and voiced determination too, but if it's voiced and the fraction of the energy that's in the harmonic sequence that you're looking at is relatively low, then it should be more likely to be an overlap.

0:29:15	SPEAKER_03
 This is the idea I had to compare the ratio of the energy of the harmonics with the total energy in the spectrum, try to get the ratio to distinguish between overlap and speech.

0:29:32	SPEAKER_05
 But you're looking at... let's take a second of this. You're looking at the phase derivative in what domain... I mean this is in bands or...

0:29:49	SPEAKER_03
 No, no, no. Just overall...

0:29:52	SPEAKER_03
 The band is from 0 to 4 kilohertz. You just take the instantaneous frequency.

0:30:02	SPEAKER_03
 I use two methods. One, basically, on FFT to FFT to obtain the... or to study the harmonics from the spectrum directly, and to study the energy and the multiples of frequency. And another... another algorithm I have is the instantaneous frequency.

0:30:23	SPEAKER_03
 I use FFT to calculate the phase derivative in the time. I mean, I have two algorithms. But in my opinion, the instantaneous frequency, the behavior was very interesting, because I saw how the spectrum concentrates around the harmonic.

0:30:49	SPEAKER_03
 When I apply the rule of the instantaneous frequency of the continuous filter, the rule that people propose in the paper doesn't work, and I don't know why.

0:31:04	SPEAKER_05
 The instantaneous frequency wouldn't give you something more like the central frequency of the way most of the energy is. I mean, I think, why would it correspond to pitch?

0:31:19	SPEAKER_03
 I'm not sure. I try to... First, I calculate using the FFT, I get the spectrum, I represent all the frequency.

0:31:42	SPEAKER_03
 When I obtain the instantaneous frequency, and I change the disease using the instantaneous frequency here.

0:31:55	SPEAKER_03
 I use a scaling along that axis according to the instantaneous frequency. I use this frequency. The range is different, and the resolution is different.

0:32:12	SPEAKER_03
 More or less, seeing like this. And the paper said that these frequencies are probably harmonics.

0:32:30	SPEAKER_03
 But they used a rule based on the... Because to calculate the instantaneous frequency, they used a handing window.

0:32:48	SPEAKER_03
 They said that if these big harmonics, the instantaneous frequency of the continuous filters are very near.

0:33:05	SPEAKER_03
 I don't know what is the distance. I try to put different distance, to put different length of the window, different frequency.

0:33:29	SPEAKER_05
 I guess I'm not following enough. I'm not going to have time to do any of these.

0:33:44	SPEAKER_02
 I get it in the return of the transition. There's one third thing I wanted to raise is an issue, which is how to handle breaths.

0:34:01	SPEAKER_02
 The reason I asked the question is, aside from the fact that there are times when we took code, the fact that I have the indication from down ellis in the email that I sent to you.

0:34:15	SPEAKER_02
 I think that the question is, whether it would be possible to eliminate them from the audio signal, which would be the ideal situation.

0:34:34	SPEAKER_02
 I don't think it would be ideal. We're dealing with real speech. We're trying to have these real as possible and breaths are part of real speech.

0:34:49	SPEAKER_02
 We're hearing you breathing as if you're hearing our ear. It's like, I mean, breath is natural, but not...

0:35:04	SPEAKER_06
 I think the BDA application would have to cope with breath. The BDA might not have to, but more people than just BDA users are interested in this corpus.

0:35:19	SPEAKER_06
 We could remove it, but I think we don't want to remove it from the corpus in terms of delivering it because people will want it in there.

0:35:29	SPEAKER_05
 If it gets in the way of what somebody is doing with it, then you might want to have some method which will allow you to block it, but it's real data.

0:35:41	SPEAKER_05
 If there's a little bit of noise out there and somebody is talking about something they're doing, that's part of what we accept is part of a real meeting.

0:35:50	SPEAKER_05
 We have the fan and the projector up there. This is actual stuff that we want to work with.

0:36:01	SPEAKER_02
 This is very interesting because it shows very clearly the contrast between speech recognition research and discourse research.

0:36:10	SPEAKER_02
 Discourse in linguistic research is what's communicative. Once in a while, breath is communicative, but very rarely.

0:36:21	SPEAKER_02
 I had a discussion with Chuck about the data structure and the idea is that the transcripts will get stored as a master.

0:36:27	SPEAKER_02
 There will be a master transcript which has in it everything that's needed for both of these uses.

0:36:31	SPEAKER_02
 The one that's used for speech recognition will be processed by a script. Don's been writing scripts and two processes for speech recognition side.

0:36:40	SPEAKER_02
 Discourse side will have this side over here. The discourse side will have a script which will strip away the things which are non-communicative.

0:36:51	SPEAKER_02
 Let's think about the practicalities of how we get to that master copy with reference to breaths. What I would wonder is would it be possible to encode those automatically?

0:37:04	SPEAKER_02
 Could we get a breath detector?

0:37:07	SPEAKER_06
 Just to save the transcribers.

0:37:09	SPEAKER_02
 You just have no idea. If you're getting a breath several times every minute and just simply the keystrokes it takes to negotiate to put the boundaries in to type it in, it's just a huge amount of time.

0:37:22	SPEAKER_02
 You want to be sure it's used and you want to be sure it's done as efficiently as possible and it's done automatically. That would be ideal.

0:37:27	SPEAKER_05
 What if you put it in but put the boundaries?

0:37:32	SPEAKER_02
 You just know it's between these other things. The time boundaries could mark off words from non-words. That would be extremely time effective if that's sufficient.

0:37:45	SPEAKER_05
 If it's too hard for us to annotate the breaths per se, we are going to be building up models for these things and these things are somewhat self-aligning.

0:37:55	SPEAKER_05
 If we say there is some kind of a thing which we call a breath or a breath in or breath out, the models will learn that sort of thing.

0:38:03	SPEAKER_05
 But you do want them to point them at some region where the breaths really are.

0:38:08	SPEAKER_02
 That would maybe include a pause as well and that wouldn't be a problem.

0:38:12	SPEAKER_05
 There's this dynamic tension between marking absolutely everything and marking just a little bit and touting on the statistical methods.

0:38:23	SPEAKER_05
 Basically the more we can mark the better. But if there seems to be a lot of effort for a small amount of reward in some area, this might be one like this.

0:38:30	SPEAKER_05
 Although I'd be interested to get input from those Andreas on this to see if they've got lots of experience with breaths in...

0:38:37	SPEAKER_05
 I have lots of experience breathing.

0:38:40	SPEAKER_05
 Well, yes, they do but we can handle that without it here. But you're going to say something about that.

0:38:46	SPEAKER_09
 I think one possible way to handle it is that as the transcribers are going through and if they get a hunk of speech, they're going to transcribe it.

0:38:58	SPEAKER_09
 They're going to transcribe it because there's words in there or whatnot.

0:39:01	SPEAKER_09
 If there's a breath in there, they could transcribe that.

0:39:05	SPEAKER_02
 That's what they've been doing.

0:39:06	SPEAKER_02
 So within overlap segments.

0:39:08	SPEAKER_09
 But if there's a big hunk of speech, let's say on Morgan's mic where he's not talking at all, don't worry about that.

0:39:16	SPEAKER_09
 So what we're saying is there's no guarantee that...

0:39:20	SPEAKER_09
 So for the chunks that are transcribed, everything's transcribed.

0:39:23	SPEAKER_09
 But outside of those boundaries, there could have been stuff that wasn't transcribed.

0:39:27	SPEAKER_09
 So you just... somebody can't rely on that data and say that's perfectly clean data.

0:39:32	SPEAKER_09
 Do you see what I'm saying?

0:39:34	SPEAKER_09
 I haven't said, don't tell the transcribe anything that's outside of...

0:39:38	SPEAKER_05
 That sounds like a reasonable compromise.

0:39:41	SPEAKER_08
 And that's quite a corresponds to the way I try to train the speech and speech detector.

0:39:48	SPEAKER_08
 I really try not to detect those breaths, which are not with a speech-strung, but with just an silence region.

0:39:59	SPEAKER_08
 So they hopefully won't be mocked in those channel-specific files.

0:40:05	SPEAKER_05
 I wanted to comment a little more just for clarification about this business, about the different purposes.

0:40:10	SPEAKER_05
 In a way, this is a really key point.

0:40:12	SPEAKER_05
 That for speech recognition research, it's not just a minor part.

0:40:20	SPEAKER_05
 In fact, I would say the core thing that we're trying to do is to recognize the actual meaningful component.

0:40:28	SPEAKER_05
 The meaningful components in the midst of other things that are not meaningful.

0:40:33	SPEAKER_05
 So it's critical, it's not just incidental, it's critical for us to get these other components that are not meaningful.

0:40:40	SPEAKER_05
 Because that's what we're trying to pull the other out. That's our problem.

0:40:44	SPEAKER_05
 If we had only linguistically relevant things, if we only had changes in the spectrum that were associated with words with different spectral components, and we didn't have noise, we didn't have convolutional errors, we didn't have extraneous behaviors and so forth, moving your head and all these sorts of things, then actually speech recognition isn't that bad right now.

0:41:08	SPEAKER_05
 I mean, you know, it's the technology has come along pretty well.

0:41:12	SPEAKER_05
 The reason we so complain about it is because when you have more realistic conditions, then things fall apart.

0:41:19	SPEAKER_02
 Okay, I guess what I was wondering is what at what level does the breathing aspect enter into the problem?

0:41:26	SPEAKER_02
 Because if it were likely that a PDA would be able to be built, which would get rid of the breathing, so it wouldn't even have to be processed at this computational, it would have to be computationally processed, rid of it.

0:41:37	SPEAKER_02
 But if there were likely on the frontier, a good breath extractor, then...

0:41:43	SPEAKER_02
 So that's a research question, you know?

0:41:46	SPEAKER_05
 I've seen that's what I wouldn't know. And we don't either.

0:41:49	SPEAKER_05
 So the thing is, right now it's just data that we're collecting, and so we don't want to presuppose that people will be able to get rid of particular degradation, because that's actually the research that we're trying to feed.

0:42:00	SPEAKER_05
 So, you know, maybe in five years it'll work really well, and it'll only mess up 10% of the time, but then we would still want to account for that 10%.

0:42:09	SPEAKER_02
 I guess there's another aspect which is that as we've improved our micro-technique, we have a lot less breadth in the more recent recordings. So it's in a way it's an artifact that there's so much on the earlier ones.

0:42:20	SPEAKER_09
 I see.

0:42:21	SPEAKER_09
 One of the... just to add to this, one of the ways that we will be able to get rid of breath is by having models, I mean that's what a lot of people do now.

0:42:29	SPEAKER_09
 In order to build a model, you need to have some amount of it, right?

0:42:33	SPEAKER_09
 I don't think we need to worry a lot about breaths that are happening outside of a conversation.

0:42:41	SPEAKER_09
 You don't have to go and search for them to mark them at all, but they're there while they're transcribing some comfort that put them in possible.

0:42:50	None
 Okay.

0:42:51	SPEAKER_02
 It's also the fact that they do for a lot in one channel to the other because of the way the microphone suggests.

0:43:01	SPEAKER_05
 Should we do a diddys?

0:43:02	SPEAKER_05
 Yep.

0:43:03	SPEAKER_06
 Okay, this is transcript. L173, 4368, 136593, 7308, 591761, 56010, 6395, 038510, 868, 64651, 878, 873, 482434, 6432, 0259, 42086, 289, 671, 2916, 4399, 76303, 277, 556, 390.

0:43:56	SPEAKER_09
 Transcript L-257, 6200, 0129, 0236, 7034, 6368, 463, 236, 418, 0649, 58, 2316, 775, 907, 724, 4, 014, 264, 845, 1, 877, 45, 872, 2, 495, 41015, 5105, 022, 0206, 6556, 1, 858,

0:44:54	SPEAKER_03
 1, 888, 1, 877, 1, 847, 234, 603, 939, 25, 666, 640, 3, 8, 8, 8, 8, 975, 3-4, 6-0-3, 9-39-25, 6-6, 6-4-0, 3-5-13, 9-8, 6-5-3, 3-7-1-3-0, 5-6-0-1, 4-9-8-7, 7-29, 6-1-1, 4-6-3, 4-3-5, 1-6-9-1-0, 0-2, 9-0, 0-0, 3-1, 7-3.

0:45:51	SPEAKER_08
 Transcript L559, 4-2, 9-1, 8-8, 4-2, 2-9, 5-2, 3-5, 2-8, 3-6, 3-8, 6-8, 4-9, 1-4, 7-1, 5-6, 4-8-3, 7-2, 4-1-8-0, 0-1-1-3, 5-2-1-6, 3-4, 7-5-07, 3-5-20, 1-19-1, 0-9, 7-0-5-1, 2-5-1-3, 5-2-7, 3-4-6-3, 5-3-0-7, 4-0-1-2, 1-8-0, 5-9-5, 9-3-9.

0:46:47	SPEAKER_05
 Transcript L493, 9-3-4, 6-8, 5-2-6-8, 0-4-3, 8-6-4, 2-3-9-5, 4-9-2, 1-1-0, 8-7-1-0, 9-5-3, 0-3-0, 6-8-4, 8-5-7-1, 5-0-9-2, 9-3-8-9, 8-3-2-1, 3-1-2-9, 2-7-3-6, 9-9-8-9, 9-5-7-4, 7-3-0-5-4-3-5-3-3-1, 6-6-1-3-9-5-5-4-2, 6-5-1-9-5-8-9-3-8-5.

0:47:41	SPEAKER_00
 Transcript L-31, 3-271-9-6-6-5, 6-08-3-1-6-8-8-5-1-1, 7-09-4-9-2-1-6-9-7, 4-7-01-4-9-9-0-2-5, 3-7-9-2-4-2-7-9-0, 8-6-1-6-4-0-7-3-8, 5-8-6-4-4-3-8-7-7, 2-8-7-6-8-5-9-9-2, 4-8-6-8-5, 0-8-1-6-3-9-1-6-8-9.

0:48:33	SPEAKER_02
 Transcript L-6-2-1, 0-2-3-1-9-5-8-5-4, 1-5-0-1-1-8-8-3, 9-6-6-3-2-5-7-8-7-9, 2-0-6-4-3-4-6-6-0, 3-6-2-3-6-8-3-5-2-4, 1-7-2-6-1-9-7-2-6-5, 8-9-8-7-3-2-2-1-3-8, 2-3-3-7-7-1-9-5, 4-8-8-7-6-1-3-5-3-3-5-7, 9-5-8-5-1-5-4-2-2.

