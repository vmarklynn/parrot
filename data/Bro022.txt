0:00:00	SPEAKER_04
 I think for two years we were two months away from being done.

0:00:06	SPEAKER_06
 And what was that Morgan?

0:00:10	SPEAKER_06
 What project?

0:00:12	SPEAKER_04
 The Taurant chip.

0:00:13	SPEAKER_04
 Oh yeah.

0:00:14	SPEAKER_04
 We went through, Jim and I went through all the emails at one point and for two years there was this thing saying yeah we were two months away from being done.

0:00:25	SPEAKER_04
 It was very believable schedules.

0:00:28	SPEAKER_04
 We went through and schedule some years.

0:00:31	SPEAKER_04
 Oh yeah, it was very true.

0:00:35	SPEAKER_06
 So should we just do the same kind of deal where we go around and do status report kind of things?

0:00:42	SPEAKER_06
 Okay, and I guess when Sunil gets here he can do his last or something.

0:00:47	SPEAKER_04
 So we probably should wait for him to come before we do his.

0:00:50	SPEAKER_06
 Okay, good idea.

0:00:52	SPEAKER_06
 Any objection?

0:00:53	SPEAKER_06
 All in favor.

0:00:55	SPEAKER_06
 Do you want to start Morgan?

0:00:57	SPEAKER_06
 Do you have anything?

0:00:58	SPEAKER_04
 I don't do anything.

0:01:00	SPEAKER_04
 No, I mean I have involved in discussions with people about what they're doing but I think they're since they're here they can talk about it themselves.

0:01:10	SPEAKER_03
 Okay, so should I go so that you go ahead and talk about where we're at stuff for sake.

0:01:17	SPEAKER_03
 Okay.

0:01:18	SPEAKER_03
 Well this past week I've just been getting down and dirty into writing my proposal.

0:01:25	SPEAKER_03
 I just finished a section on talking about these to really categories that classify as a little step.

0:01:40	SPEAKER_03
 And I hope to get this full rough draft by Monday and you're tomorrow.

0:01:48	SPEAKER_06
 When is your meeting?

0:01:51	SPEAKER_03
 My meeting with oh you mean the cool ones.

0:01:55	SPEAKER_03
 Are the calls are happening in July 25th?

0:01:59	SPEAKER_06
 Oh, soon.

0:02:00	SPEAKER_06
 Yeah, D-Day.

0:02:02	SPEAKER_06
 Yeah.

0:02:03	SPEAKER_06
 So the idea you're going to do this paper and then you pass it out to everybody ahead of time.

0:02:08	SPEAKER_03
 Right, right.

0:02:09	SPEAKER_03
 So you write up a proposal and give it to people ahead of time and you have a short presentation.

0:02:17	SPEAKER_03
 And then everybody asks you questions.

0:02:22	SPEAKER_06
 Yeah, I remember now.

0:02:26	SPEAKER_06
 Yeah, so I was just going to ask you want to say any a little bit about it or a little bit about what you're going to you said you're talking about the features that you're looking

0:02:39	SPEAKER_03
 at. Right.

0:02:41	SPEAKER_03
 Well, I was I think one of the perplexing problems is for a while I was thinking that I had to come up with a complete set of intermediate features and intermediate categories to classify right away.

0:02:56	SPEAKER_03
 But what I'm thinking now is I would start with a reasonable set something like a regular phonetic features just to just to start off that way.

0:03:10	SPEAKER_03
 And do some phone recognition, build a system that classifies these these features of these intermediate categories using multi band techniques, combine them and do phone phoneme recognition.

0:03:28	SPEAKER_03
 Look at then I would look at the errors produced in the phoneme recognition and say, okay, well, I could probably reduce the errors if I included this extra feature or this extra intermediate category that would that would reduce certain confusions over other confusions.

0:03:45	SPEAKER_03
 And then and then reiterate build the intermediate classifiers and do phoning recognition, look at the errors and then postulate new or remove intermediate categories and then do it again.

0:04:01	SPEAKER_06
 So you're going to use Timit?

0:04:04	SPEAKER_03
 Or that for that part of the process here, I used Timit and then after doing Timit, right, that's just the phone recognition task.

0:04:22	SPEAKER_03
 I want to take a look at things that I can model within Word.

0:04:27	SPEAKER_03
 So I would then shift the focus to something like switchboard where I would be able to model intermediate categories that span across phonemes and just within the phonemes themselves.

0:04:44	SPEAKER_03
 And then do the same things as there on a large regular task like switchboard.

0:04:53	SPEAKER_03
 And for that part, I would use the SRI recognizer.

0:04:59	SPEAKER_03
 So it's already set up for a switchboard and I run some sort of tandem style processing with intermediate classifiers.

0:05:08	SPEAKER_06
 So that's why you were interested in getting your own features into the SRI files?

0:05:12	SPEAKER_03
 That's why I was asking about that.

0:05:14	SPEAKER_03
 I guess that's it.

0:05:25	SPEAKER_03
 Any questions?

0:05:26	None
 Sounds good.

0:05:27	SPEAKER_06
 You just have a few more weeks.

0:05:32	SPEAKER_03
 It's about a month from now.

0:05:37	SPEAKER_03
 It's a month and a week.

0:05:43	SPEAKER_06
 So you want to go next, David?

0:05:45	SPEAKER_06
 Oh, OK, sure.

0:05:46	SPEAKER_05
 So last week I finally got results from the SRI system about this means subtraction approach.

0:05:55	SPEAKER_05
 And we got an improvement in Word, error rate, training on the TI digits, data set, and testing on meeting recorded digits of 6% to 4.5% on the far mic data using PCMF.

0:06:12	SPEAKER_05
 But the near mic performance worsened from 1.2% to 2.4%.

0:06:22	SPEAKER_05
 And why would that be considering that we actually got an improvement in near mic performance using HDK?

0:06:31	SPEAKER_05
 So with some input from Andreas, I have a theory in two parts.

0:06:36	SPEAKER_05
 First of all, the SRI system is doing channel adaptation.

0:06:41	SPEAKER_05
 And so, HDK wasn't.

0:06:44	SPEAKER_05
 So this means subtraction approach will do a channel normalization.

0:06:49	SPEAKER_05
 And so that might have given the HDK use of it a boost that wouldn't have applied in the SRI case.

0:06:54	SPEAKER_05
 And also, the Andreas pointed out the SRI system is using more parameters.

0:07:00	SPEAKER_05
 It's got finer grain acoustic models.

0:07:03	SPEAKER_05
 So those finer grain acoustic models could be more sensitive to the artifacts in the recenthasized audio.

0:07:11	SPEAKER_05
 And me and Barry were listening to the recenthasized audio.

0:07:13	SPEAKER_05
 And sometimes it seems like you get a bit of an echo of speech in the background.

0:07:19	SPEAKER_05
 And so it seems like it could be difficult for training because you could have different phones lined up with a different foreground phone, depending on the timing of the echoes.

0:07:31	SPEAKER_05
 So I'm going to try training on a larger data set.

0:07:37	SPEAKER_05
 And then the system will have seen more examples of these artifacts.

0:07:39	SPEAKER_05
 And hopefully, it will be more robust to them.

0:07:41	SPEAKER_05
 So I'm trying to use the microphone set of red speech.

0:07:46	SPEAKER_04
 And I have another thought just now, which is, remember we were talking before about, we were talking in our meeting about some of the other stuff that Evernano did where they were getting rid of low energy sections.

0:08:05	SPEAKER_04
 If you did a high pass filtering as Hirsch did late 80s to reduce some of the effects of reverberation, Evernano and Hermansky were arguing that perhaps one of the reasons for that working was that it may not have even been filtering so much, but the fact that when you filter an all positive power spectrum, you get some negative values and you've got to figure out what to do with them.

0:08:30	SPEAKER_04
 If you continue treating this as a power spectrum, so what Hirsch did was set them to zero, set the negative values to zero.

0:08:38	SPEAKER_04
 So if you imagine a waveform that's all positive, which is the time trajectory of energy, and shifting it downwards and then getting rid of the negative parts, that's essentially throwing away the low energy things.

0:08:52	SPEAKER_04
 That's the low energy parts of the speech where the reverberation is most audible.

0:08:57	SPEAKER_04
 You have reverberation from higher energy things showing up in.

0:09:00	SPEAKER_04
 So in this case, you have some artificially imposed reverberation like that.

0:09:05	SPEAKER_04
 I mean, you're getting rid of some of the other effects of reverberation, but because you have these non-calls or windows, you're getting these funny things coming in.

0:09:16	SPEAKER_04
 What if you did, I mean, there's nothing to say that the processing for this recynthesis has to be restricted to trying to get it back to the original according to some equation.

0:09:26	SPEAKER_04
 I mean, you also could just try to make it nicer.

0:09:31	SPEAKER_04
 And one of the things you could do is you could do some sort of VAD-like thing.

0:09:35	SPEAKER_04
 You actually could take very low energy sections and set them to some very low or near zero value.

0:09:43	SPEAKER_04
 I mean, I'm just saying if in fact it turns out that these echoes that you're hearing are pre-echos, whichever they are, are part of what's causing the problem.

0:09:55	SPEAKER_04
 You actually can get rid of them.

0:09:57	SPEAKER_07
 Uh-huh.

0:10:00	SPEAKER_04
 Be pretty simple.

0:10:03	None
 Okay.

0:10:04	SPEAKER_04
 You can do it in a pretty conservative way so that if you made a mistake, you were more likely to keep in an echo than to throw out speech.

0:10:11	SPEAKER_01
 What is the reverberation time like in this room?

0:10:18	SPEAKER_01
 The one in the speech that you were using?

0:10:22	SPEAKER_05
 Yeah.

0:10:23	SPEAKER_05
 I don't know.

0:10:24	SPEAKER_05
 So is this room?

0:10:25	SPEAKER_04
 It's this room.

0:10:26	SPEAKER_04
 So is this just a microphone?

0:10:29	SPEAKER_04
 This microphone, a close microphone and a distant microphone.

0:10:31	SPEAKER_04
 He's doing these different tests on.

0:10:34	SPEAKER_04
 We should do measurement here.

0:10:35	SPEAKER_04
 I think we never have.

0:10:36	SPEAKER_04
 I think it's, I would guess, 0.7.8 seconds, RT60, something like that.

0:10:42	SPEAKER_04
 But it's, you know, it's this room.

0:10:47	SPEAKER_04
 But the other thing is he's putting in, I was using word reverberation in two ways.

0:10:52	SPEAKER_04
 He's also putting in a, he's taking out some reverberation, but he's putting in something because he has averages over multiple windows stretching out the 12 seconds, which are then being subtracted from the speech.

0:11:06	SPEAKER_04
 And since, you know, what you subtract, sometimes you'll be subtracting from some larger number and sometimes you won't.

0:11:13	SPEAKER_04
 So you can end up with some components in it that are affected by things that are seconds away.

0:11:19	SPEAKER_04
 And if it's a low energy comp, portion, you might actually hear some funny things.

0:11:27	SPEAKER_05
 One thing I noticed is that the mean subtraction seems to make the PZM signals louder after they've been recenticized.

0:11:36	SPEAKER_05
 So I was wondering, is it possible that one reason it helped with the Aurora baseline system is just as a kind of gain control because some of the PZM signals sound pretty quiet if you don't amplify them?

0:11:50	SPEAKER_02
 I don't see why you're signally louder after processing because you...

0:11:54	SPEAKER_05
 Yeah, I don't know why either.

0:11:57	SPEAKER_04
 I don't think just multiplying the signal by two would have any effect.

0:12:01	SPEAKER_05
 Oh, okay.

0:12:02	SPEAKER_04
 Yeah.

0:12:03	SPEAKER_04
 I mean, I think if you really have louder signals, what you mean is that you have better signalized ratio.

0:12:10	SPEAKER_04
 So if what you're doing is improving the signalized ratio, then it would be better, but just it being bigger with the same signalized ratio.

0:12:16	SPEAKER_04
 It would have effect.

0:12:17	SPEAKER_04
 Okay.

0:12:18	SPEAKER_02
 Well, the system is...

0:12:20	SPEAKER_02
 You use the absolute energy, so it's a little bit dependent on the signal level, but not so much.

0:12:29	SPEAKER_04
 Well, yeah, but it's trained and tested on the same thing.

0:12:31	SPEAKER_04
 So if you change in both training and test, the absolute level by factor too, it will matter no effect.

0:12:38	SPEAKER_06
 So if you add this data to the training site for the Aurora, or you just test it on this, did I...

0:12:47	SPEAKER_05
 What, sorry?

0:12:48	SPEAKER_06
 When we're going to just saying that as long as you do it in both training and testing, you can't have any effect.

0:12:52	SPEAKER_06
 But I was sort of under the impression that you just tested with this data.

0:12:55	SPEAKER_06
 You didn't train at all.

0:12:56	SPEAKER_05
 Right, I trained on clean TI digits.

0:12:59	SPEAKER_05
 I did the mean subtraction on clean TI digits, but I didn't...

0:13:02	SPEAKER_05
 I see.

0:13:03	SPEAKER_05
 But it made the clean TI digits any louder.

0:13:08	SPEAKER_05
 I only remember noticing it made the PCM signal louder.

0:13:12	SPEAKER_04
 Okay, well, I don't understand then.

0:13:15	SPEAKER_05
 I don't know.

0:13:16	SPEAKER_05
 If it's trying to find a reverberation filter, it could be that this reverberation filter is making things quieter, and then if you take it out, that...

0:13:25	SPEAKER_05
 Taking it out makes things louder.

0:13:29	SPEAKER_04
 Are you...

0:13:33	SPEAKER_04
 No.

0:13:34	SPEAKER_04
 I mean, there's nothing inherent about removing...

0:13:40	SPEAKER_04
 If you're really removing...

0:13:42	SPEAKER_04
 I mean, then I don't see how it makes it louder.

0:13:46	SPEAKER_04
 So I should maybe let this stuff get...

0:13:48	SPEAKER_04
 Yeah, it might just be some artifact of the processing that...

0:13:52	SPEAKER_04
 If you're...

0:13:54	SPEAKER_04
 Yeah.

0:13:55	SPEAKER_04
 I don't know.

0:13:56	None
 Okay.

0:13:57	SPEAKER_06
 I wonder if there could be something like...

0:14:03	SPEAKER_06
 For the PCM data, if occasionally somebody hits the table or something, you could get a spike.

0:14:11	SPEAKER_06
 I'm just wondering if there's something about the...

0:14:16	SPEAKER_06
 You know, doing the mean normalization where it could cause you to have better signal of noise ratio.

0:14:24	SPEAKER_04
 Well, you know, there is this, right?

0:14:27	SPEAKER_04
 It may be...

0:14:30	SPEAKER_04
 If subtracting the mean log spectrum is like dividing by a spectrum.

0:14:37	SPEAKER_04
 So depending what you divide by, if your estimate is often sometimes you're getting a small number, you could make it bigger.

0:14:48	SPEAKER_04
 So it's just a question of...

0:14:51	SPEAKER_04
 It could be that there's some normalization that's missing or something to make it...

0:14:57	SPEAKER_04
 You think it shouldn't be larger, but maybe in practice it is.

0:15:00	SPEAKER_04
 That's something to think about.

0:15:01	SPEAKER_07
 I don't know.

0:15:02	SPEAKER_02
 I had a question about the system, the SRI system.

0:15:07	SPEAKER_02
 So you trained it on TI digits, but except this, it's exactly the same system as the one that was tested before and that was trained on microphone, right?

0:15:18	SPEAKER_02
 So on TI digits it gives you 1.2% error rate and on microphone it's still 0.8.

0:15:26	SPEAKER_02
 But is it exactly the same system?

0:15:29	SPEAKER_05
 I think so.

0:15:30	SPEAKER_05
 If you're talking with the microphone results that Andreas had about a week and a half ago, I think it's the same system.

0:15:35	SPEAKER_02
 So you use VTA vocal track length normalization and like MLLR transformation also.

0:15:44	SPEAKER_04
 I'm sorry, was his 0.8% result on testing on microphone or training?

0:15:50	SPEAKER_02
 Training on microphone and testing on meeting digits.

0:15:54	SPEAKER_04
 So that was done already.

0:15:55	SPEAKER_04
 So it's 0.8.

0:16:00	None
 Okay.

0:16:03	SPEAKER_02
 Yeah, I've just been testing the new Aurora front end with...

0:16:10	SPEAKER_02
 Well, the system actually, so front end and HTK acoustic models on the meeting digits and it's a little bit better than the previous system.

0:16:20	SPEAKER_02
 We have 2.7% error rate and before with the system that was proposed, it was 3.9.

0:16:28	SPEAKER_02
 Oh, that's a lot better.

0:16:30	SPEAKER_02
 Getting better.

0:16:32	SPEAKER_01
 So with the HTK back in what we have, the Aurora?

0:16:35	SPEAKER_02
 Yeah, 2.7.

0:16:36	SPEAKER_02
 On the meeting, we have 2.7.

0:16:41	SPEAKER_03
 That's with the new IIR shelters.

0:16:44	SPEAKER_02
 Yeah, yeah.

0:16:46	SPEAKER_02
 So yeah, we have the new L.E. filters and I think maybe I didn't look, but one thing that makes different is this DC offset compensation.

0:16:59	SPEAKER_02
 Did you have a look at the meeting digits if they have DC component or...?

0:17:06	SPEAKER_05
 I didn't know.

0:17:09	SPEAKER_01
 No, the DC component could benefit from it if you have recording it through a mic coming.

0:17:18	SPEAKER_01
 All the mics have the DC remote, some capacity to receive right?

0:17:22	SPEAKER_04
 Yeah, but this...

0:17:23	SPEAKER_04
 No, because there's a sampling hold in the A to D and these periods these typically do have a DC offset and they can be surprisingly large.

0:17:36	SPEAKER_01
 It depends on the electronics.

0:17:38	SPEAKER_04
 The microphone isn't going to pass in a DC, but actually there are instrumentation mics that do pass go down to DC, but no, it's the electronics.

0:17:52	SPEAKER_04
 And then there's amplification afterwards and you can get...

0:17:56	SPEAKER_04
 I think it was in the Wall Street Journal data that I can't remember one of the darker things that was this big DC offset.

0:18:05	SPEAKER_04
 We didn't know about it for a while.

0:18:06	SPEAKER_04
 We were messing with it.

0:18:07	SPEAKER_04
 We were getting these terrible results.

0:18:08	SPEAKER_04
 We're talking to somebody and they said, oh yeah, everybody knows that.

0:18:12	SPEAKER_04
 There's all this DC offset.

0:18:14	SPEAKER_04
 So yes, you can get DC offset in the data.

0:18:19	SPEAKER_06
 Was that everything, Dave?

0:18:21	SPEAKER_05
 Oh, and I also did some experiments about normalizing the phase.

0:18:28	SPEAKER_05
 So I came up with a web page that people can take a look at.

0:18:33	SPEAKER_05
 And the interesting thing that I tried was Adam and Morgan had this idea since my original attempts to take the mean of the phase spectra over time and normalize using that by subtracting that off didn't work.

0:18:49	SPEAKER_05
 So we thought that might be due to problems with the arithmetic of phases.

0:18:55	SPEAKER_05
 They added this module to Pi way and there's reason to believe that that approach of taking the mean of the phase spectrum wasn't really mathematically correct.

0:19:05	SPEAKER_05
 So what I did instead is I took the mean of the FFT spectrum without taking the log or anything.

0:19:12	SPEAKER_05
 And I took the phase of that and I subtracted that phase off to normalize that didn't work either.

0:19:22	SPEAKER_04
 So we have a different interpretation of this.

0:19:24	SPEAKER_04
 He says it doesn't work.

0:19:25	SPEAKER_04
 I think it works magnificently, but just not for the task we intended.

0:19:29	SPEAKER_04
 It gets rid of the speech.

0:19:33	SPEAKER_04
 What does it leave?

0:19:34	SPEAKER_04
 At least, you know, it leaves the junk.

0:19:35	SPEAKER_04
 I mean, I think it's tremendous.

0:19:37	SPEAKER_04
 All he has to do is go back and reverse what he did before.

0:19:40	SPEAKER_04
 Well, could you take what was left over?

0:19:43	SPEAKER_04
 Exactly.

0:19:44	SPEAKER_04
 Yeah, you got it.

0:19:46	SPEAKER_04
 So it's a general rule.

0:19:48	SPEAKER_04
 Just listen very carefully to what I say and do the opposite.

0:19:52	SPEAKER_04
 Including what I just said.

0:19:55	SPEAKER_07
 And yeah, that's everything.

0:20:03	SPEAKER_06
 Do you want to go step on?

0:20:08	SPEAKER_02
 Yeah, maybe concerning this still is meeting digits.

0:20:14	SPEAKER_02
 I'm interested in trying to figure out what's still the difference between the SRI system and the overall system.

0:20:22	SPEAKER_02
 Yeah, so I think I will maybe train gender-dependent models because this is also one big difference between the two systems.

0:20:36	SPEAKER_02
 The other difference is where the fact that maybe the acoustic models of the SRI and the SRI system are more complex.

0:20:45	SPEAKER_02
 But Chuck, you did some experiment with this.

0:20:48	SPEAKER_02
 It didn't seem to happen.

0:20:50	SPEAKER_02
 Did you have some improvement with this?

0:20:54	SPEAKER_04
 What sounds like they also have, he's saying they have all these tumor kinds of adaptation, their channel adaptation, their speaker adaptation.

0:21:02	SPEAKER_06
 But there's also the normalization, like they do, I'm not sure how they do it when they're working with the digits.

0:21:08	SPEAKER_06
 But like in the switchboard, there's conversation side normalization for the non-C0 components and then utterance normalization for the C0 components.

0:21:20	SPEAKER_02
 Yeah, this is another difference.

0:21:23	SPEAKER_02
 The normalization works on utterance levels, but we have to do it, we have a system that does it online, so it might be better, it might be worse if the channel is constant.

0:21:41	SPEAKER_01
 And the acoustic models are like a triple model, so the whole world is a SRI.

0:21:49	SPEAKER_02
 Yeah, I guess it's tri-fold.

0:21:52	SPEAKER_04
 I think it's probably more than that.

0:21:54	SPEAKER_04
 So I think they use these genome things, so there's these kind of pooled models and they can go out to all sorts of dependencies.

0:22:07	SPEAKER_01
 It's like the tight states.

0:22:09	SPEAKER_04
 They have tight states and I think, I'm just guessing here, but I think they don't just have tri-phones, I think they have a range of dependencies.

0:22:22	SPEAKER_02
 Yeah, well, the first thing I want to do is just maybe these gender things.

0:22:31	SPEAKER_02
 Maybe see with Andreas, I don't know how much it helps.

0:22:40	SPEAKER_06
 So the stuff on the numbers you got, the 2.7 is that using the same training data that the SRI system used and got 1.2?

0:22:48	SPEAKER_02
 That's right.

0:22:49	SPEAKER_02
 So it's a clean DIDGIT training set.

0:22:52	SPEAKER_06
 So exact same training data.

0:22:54	SPEAKER_06
 Okay.

0:22:55	SPEAKER_02
 I guess you used the clean training set.

0:22:58	SPEAKER_05
 Right.

0:22:59	SPEAKER_05
 With the SRI system, the Aurora baseline is set up with this version of the clean training set that's been filtered with its D712 filter and to train the SRI system under SUs, the original TI digits under you, Dr. Speech Data, TI digits, which don't have this filter, but I don't think there's any other difference.

0:23:29	SPEAKER_04
 So are these results comparable?

0:23:31	SPEAKER_04
 So you are getting with the Aurora baseline, something like 2.4% on clean TI digits when training the SRI system with clean TRI digits, right?

0:23:48	SPEAKER_04
 And so is your 2.7 comparable where you're using the submitted system?

0:23:56	SPEAKER_02
 Yeah, I think so.

0:23:58	SPEAKER_04
 Okay.

0:23:59	SPEAKER_04
 So it's about the same.

0:24:01	SPEAKER_05
 It was 1.2 with the SRI system.

0:24:05	SPEAKER_02
 I'm sorry.

0:24:06	SPEAKER_02
 Complete SRI system is 1.

0:24:07	SPEAKER_04
 You were HDK.

0:24:08	SPEAKER_04
 Right.

0:24:09	SPEAKER_04
 Okay.

0:24:10	SPEAKER_04
 That's right.

0:24:11	SPEAKER_04
 Okay.

0:24:12	SPEAKER_04
 So the comparable number than for what you were talking about, then SRI would be the 2.5.

0:24:23	SPEAKER_02
 It was 4.0 something, right?

0:24:25	SPEAKER_02
 The HDK system with the SRI system, right?

0:24:30	SPEAKER_05
 The baseline Aurora 2 system, trained on TI digits, tested on meeting record in year.

0:24:34	SPEAKER_05
 I think we saw it today and it was about 6.6%.

0:24:37	SPEAKER_04
 Right.

0:24:38	SPEAKER_04
 Right.

0:24:39	SPEAKER_04
 So, yeah.

0:24:41	SPEAKER_04
 It's different between this and this.

0:24:46	SPEAKER_02
 Okay.

0:24:47	SPEAKER_04
 Good.

0:24:48	SPEAKER_04
 So they are helping.

0:24:49	SPEAKER_04
 That's good.

0:24:50	SPEAKER_04
 Yeah.

0:24:51	SPEAKER_02
 And another thing I maybe like to do is to just test the SRI system that's trained on microphone, tested on the NoECTI digits.

0:25:03	SPEAKER_02
 I'm still wondering where this improvement comes from when you train on microphone, it seems better on meeting digits.

0:25:13	SPEAKER_02
 But I wonder if it's just because maybe microphone is acoustically closer to the meeting digits than TI digit is, which is, TI digits are very clean recorded digits.

0:25:25	SPEAKER_06
 It would also be interesting to see, to do the regular Aurora test, but use the SRI system instead of the same.

0:25:35	SPEAKER_02
 Yeah, that's what I wanted just to, yeah.

0:25:38	SPEAKER_02
 So just using the SRI system, test, did some, and tested on Aurora TI digits, right?

0:25:45	SPEAKER_06
 When at the full Aurora test?

0:25:49	SPEAKER_02
 Yeah, there is this problem of multilinguality, so we don't, you have to train the SRI system

0:25:56	SPEAKER_04
 with all the different languages.

0:25:58	SPEAKER_06
 Yeah, that's what I mean. So you'll have to work.

0:26:00	SPEAKER_06
 Yeah.

0:26:01	SPEAKER_06
 Well, I mean, I guess the work would be into getting the files in the right formats or something, right?

0:26:14	SPEAKER_06
 Yeah, because when you train up the Aurora system, you're also training on all the data.

0:26:20	SPEAKER_06
 That's right.

0:26:21	SPEAKER_06
 Yeah, I mean, it's...

0:26:22	SPEAKER_02
 Yeah, yeah, yeah, yeah, yeah, yeah, yeah.

0:26:25	SPEAKER_02
 Right, I see what you mean.

0:26:26	SPEAKER_04
 That's true, but I think that also when we've had these meetings, we have to wake off in times people have not done the full range of things because on whatever is they're trying because it's a lot of work, even just with the HTK.

0:26:39	SPEAKER_04
 So it's a good idea, but it seems like it makes sense to do some pruning first with a test or two that makes sense for you and then take the likely candidates to go further.

0:26:54	SPEAKER_02
 But just testing on TI digit already gave us some information about what's going on.

0:27:06	SPEAKER_02
 Oh, yeah, okay.

0:27:11	SPEAKER_02
 The next thing is this VAD problem, but...

0:27:22	SPEAKER_02
 So I'm just talking about the curve that I sent.

0:27:25	SPEAKER_02
 I sent you.

0:27:26	SPEAKER_02
 So that shows that when the SNR decreases, the current VAD approach doesn't drop much frames for some particular noises, which might be the noises that are closer to speech.

0:27:45	SPEAKER_04
 Just clarify something for me.

0:27:47	SPEAKER_04
 They were supposedly in the next evaluation, they're going to be supplying us with boundaries.

0:27:52	SPEAKER_04
 So does any of this matter?

0:27:53	SPEAKER_04
 I mean, other than our interest in it.

0:27:57	SPEAKER_02
 Well, first of all, the boundaries might be like we would have 200 milliseconds before an after speech.

0:28:10	SPEAKER_02
 So removing more than that might still make a difference in the results.

0:28:15	SPEAKER_04
 Do we...

0:28:16	SPEAKER_04
 I mean, there's some reason that we think that's the case.

0:28:20	SPEAKER_02
 No, because we don't...

0:28:24	SPEAKER_02
 That much at that.

0:28:25	SPEAKER_02
 Still, I think it's an interesting problem.

0:28:29	SPEAKER_02
 Oh, yeah.

0:28:30	SPEAKER_02
 Yeah.

0:28:31	SPEAKER_04
 But maybe we'll get some insight on that when the gang gets back from CREAT because there's lots of interesting problems, of course.

0:28:41	SPEAKER_04
 And the thing is, if they really are going to have some means of giving us fairly tight boundaries, then that won't be so much the issue.

0:28:50	SPEAKER_01
 Yeah, so we were wondering whether that VAD is going to be like a realistic one or is it going to be some manual segmentation?

0:29:00	SPEAKER_01
 And they're like, if that VAD is going to be a realistic one, then we can as well use their markers to shift the point around, I mean, the way we want to find the...

0:29:09	SPEAKER_01
 Rather than keeping the 20 frames, we can actually go to the markers point, which we find more suitable for us.

0:29:16	SPEAKER_01
 But that is going to be something like a manual segmenter.

0:29:19	SPEAKER_01
 Then we couldn't use that information anymore because that's not going to be the one that is used in the final evaluation.

0:29:24	SPEAKER_01
 Right.

0:29:25	SPEAKER_01
 So we don't know what is the type of VAD, if they're going to provide.

0:29:31	SPEAKER_02
 And actually, there's...

0:29:33	SPEAKER_02
 Yeah, there's...

0:29:34	SPEAKER_02
 I think it's still for...

0:29:35	SPEAKER_02
 Even for the evaluation, it might still be interesting to work on this because the boundary is a part that they would provide is just starting off speech and end of speech at the utterance level.

0:29:53	SPEAKER_01
 With some gap, I mean, with some passes in the center, provided they meet that order at the hangover time, which is...

0:30:00	SPEAKER_02
 Yeah, but when you have like five or six frames, both...

0:30:04	SPEAKER_01
 Yeah, they'll just fill it up.

0:30:06	SPEAKER_01
 It twists, yeah.

0:30:07	SPEAKER_01
 Yeah.

0:30:08	SPEAKER_04
 So if you could get at some of that, all of that papers.

0:30:11	SPEAKER_02
 Yeah, for like, not this animation and not other things that we want to work on.

0:30:18	None
 Okay.

0:30:19	None
 But...

0:30:20	SPEAKER_02
 Yeah, so I did...

0:30:22	SPEAKER_02
 I just started to test putting together two VAD, which was not much work, actually.

0:30:29	SPEAKER_02
 I implemented VAD that's very close to the energy-based VAD that the other or guys use.

0:30:40	SPEAKER_02
 So, which is just putting a threshold on the noise energy, detecting the first group of four frames that have energy that's about this threshold.

0:31:02	SPEAKER_02
 From this point, tagging the frames are a speech.

0:31:06	SPEAKER_02
 So it removes the first silent portion of each utterance.

0:31:12	SPEAKER_02
 And it really removes it.

0:31:14	SPEAKER_02
 Still, on the noises where our MADVAD doesn't work a lot.

0:31:25	SPEAKER_04
 And so I would have thought that having some kind of spectral information, you know, when you'll days people would use energy in zero crossings, for instance, would give you some better performance, right?

0:31:39	SPEAKER_04
 Because you're meant of low energy, fricatives, or stop consonants or something like that.

0:31:49	SPEAKER_02
 Yeah.

0:31:50	SPEAKER_02
 So your point is way between...

0:31:55	SPEAKER_04
 Oh, that if you use purely energy and don't look at anything spectral, then you don't have a good way of distinguishing between low energy speech components and non-speech.

0:32:06	SPEAKER_04
 And just as a gross generalization, many non-speech noises have a low-pass kind of characteristic, some sort of slope.

0:32:16	SPEAKER_04
 And most low energy speech components that are unvoiced have a high-pass kind of characteristic and upward slope.

0:32:25	SPEAKER_04
 So having some kind of a, you know, the beginning of an S sound, for instance, just starting in, it might be pretty low energy, but it will tend to have this high frequency component whereas a lot of rumble and background noises and so forth will be predominantly low-fruicing.

0:32:44	SPEAKER_04
 You know, by itself, it's not enough to tell you, but it plus energy is sort of...

0:32:49	SPEAKER_04
 It plus energy plus timing information is sort of...

0:32:52	SPEAKER_04
 And if you look up in Rebeanor and Schaeff for like 25 years ago, or something, that's sort of what they were using then.

0:32:58	SPEAKER_02
 So it might be that what I did is...

0:33:03	SPEAKER_02
 So it removes like low energy speech frames because the way it is said just combined the two decisions, so the one from the MLB and the one from the energy based is with the end operator.

0:33:21	SPEAKER_02
 So I only keep the frames where to agree that it's speech.

0:33:28	SPEAKER_02
 So if the energy based dropped, dropped low energy speech, they are lost.

0:33:37	SPEAKER_02
 But still the way it's done right now, it helps on the noises where it seems to help on the noises where RVU was not very good.

0:33:49	SPEAKER_04
 Well, I guess I mean, one could imagine combining them in different ways, but I guess what you're saying is that the MLB based one has the spectral information.

0:33:59	SPEAKER_02
 Yeah, so...

0:34:01	SPEAKER_02
 But the way it's combined is maybe the...

0:34:07	SPEAKER_02
 Well, you can imagine...

0:34:09	SPEAKER_02
 The way you use the end operator is...

0:34:13	SPEAKER_02
 The frames that are dropped by the energy based system are dropped even if the MLB decides to give them.

0:34:22	SPEAKER_04
 Right, and that might not be optimal, but I mean, I guess principle what you'd want to do is have a probability estimated by each one and put them together.

0:34:33	SPEAKER_06
 Something that I've used in the past is when just looking at the energy is to look at the derivative and you make your decision when the derivative is increasing for so many frames, then you say that's beginning of speech.

0:34:47	SPEAKER_06
 But I'm trying to remember if that requires that you keep some amount of speech and a buffer.

0:34:54	SPEAKER_06
 I guess it depends on how you do it, but that's been a useful thing.

0:35:02	SPEAKER_01
 I mean, you're everywhere as a delay associated with it, you still have to keep the buffer.

0:35:08	SPEAKER_01
 There only make a decision because it's still needed to smooth the decision further.

0:35:13	SPEAKER_01
 That's always there.

0:35:16	SPEAKER_06
 Yeah, okay.

0:35:17	SPEAKER_02
 Well, actually, I don't maybe don't want to work too much on it right now.

0:35:23	SPEAKER_02
 I just wanted to see if it's what I observed as a ghost by this really problem.

0:35:31	SPEAKER_02
 It seems to be the case.

0:35:36	SPEAKER_02
 The second thing is the spectral subtraction, which I just started yesterday to launch a bunch of 25 experiments with different values for the parameters that are used.

0:35:58	SPEAKER_02
 So it's the Michael type spectral subtraction which use an overestimation factor.

0:36:03	SPEAKER_02
 So I subtract more noise than the noise spectra that is estimated on the noise portion of the utterances.

0:36:18	SPEAKER_02
 Should I try several overestimation factors?

0:36:24	SPEAKER_02
 And after subtraction, I also add a constant noise and I also try different noise values.

0:36:36	SPEAKER_02
 And we'll see what happened.

0:36:45	SPEAKER_02
 But still, when we look at the value depends on the parameters that you use.

0:36:51	SPEAKER_02
 More moderate overestimation factors and moderate noise level that you add, you have a lot of musical noise.

0:37:00	SPEAKER_02
 On the other hand, when you subtract more and when you add more noise, you get rid of this musical noise, but maybe you distort a lot of speech.

0:37:12	SPEAKER_02
 Well, until now it doesn't seem to have.

0:37:23	SPEAKER_02
 So the next thing maybe I will try to do is just to try to smooth the smooth the result of the subtraction to get rid of the musical noise using some kind of filter.

0:37:44	SPEAKER_01
 Can smooth the SNR estimate also?

0:37:47	SPEAKER_02
 Yeah, right.

0:37:48	SPEAKER_01
 You filter is a function of SNR.

0:37:53	SPEAKER_02
 Yeah.

0:37:54	SPEAKER_02
 So to get something that would be closer to what you try to do with inner filtering.

0:37:58	SPEAKER_02
 Yeah.

0:37:59	SPEAKER_02
 Actually, maybe you can, I think, let's see it for me.

0:38:16	SPEAKER_01
 So I've been playing with this inner filter like, and there were some bugs in the programs I was initially trying to clear them up.

0:38:26	SPEAKER_01
 Because one of the bugs was, I was assuming that always the bad initial frames were silence.

0:38:32	SPEAKER_01
 It always started in the silence state, but it was in for some utterances.

0:38:35	SPEAKER_01
 So it was in estimating the noise initially and then it never estimated because I assumed that it was always silence.

0:38:42	SPEAKER_02
 So this is on speech at Karyatalian?

0:38:44	SPEAKER_01
 Yeah, speech at Karyatalian.

0:38:45	SPEAKER_01
 So in some cases, there are a few cases actually, which I found later.

0:38:50	SPEAKER_01
 So that was one of the bugs that was there in estimating the noise.

0:38:54	SPEAKER_01
 And so once we were clear, the ran a few experiments with different ways of smoothing the estimated clean speech and how estimated the noise and smoothing of the SNR also.

0:39:09	SPEAKER_01
 And so the trend seems to be like smoothing the current estimate of the clean speech for deriving the SNR, which is like deriving the inner filter, seems to be helping then updating it quite fast using a very small time constant.

0:39:26	SPEAKER_01
 So I have like few results where the estimating the most smoothing is helping.

0:39:33	SPEAKER_01
 But still it's like it's still comparable to the baseline.

0:39:36	SPEAKER_01
 I haven't caught anything beyond the baseline, but that is like not using any inner filter.

0:39:41	SPEAKER_01
 And so I'm trying a few more experiments with different time constants for smoothing the noise spectrum and smoothing the clean speech and smoothing SNR.

0:39:51	SPEAKER_01
 So there are three time constant that I have.

0:39:53	SPEAKER_01
 So I'm just playing around.

0:39:55	SPEAKER_01
 So one is fixed in the line like smoothing the clean speech is helping.

0:39:58	SPEAKER_01
 So I'm not going to change that much.

0:40:00	SPEAKER_01
 But the way I'm estimating the noise and the way I'm estimating the SNR, I'm just trying a little bit.

0:40:06	SPEAKER_01
 So that and the other thing is like putting a floor on the SNR because that if some in some cases the clean speech is like when it's estimated it goes to very low value.

0:40:18	SPEAKER_01
 So the SNR is like pretty low.

0:40:21	SPEAKER_01
 So that actually creates a lot of variance in the low energy region of the speech.

0:40:25	SPEAKER_01
 So thing of like putting a floor also for the SNR so that it doesn't vary a lot in the low energy regions.

0:40:33	SPEAKER_01
 And so the results are like so far I've been testing only with the baseline which is which doesn't have any LDA filtering and online analysis that I just want to separate that the contributions out.

0:40:44	SPEAKER_01
 So it's just VAD plus, the VINOR filter plus the baseline system which is just the spectral I mean the male frequency coefficient.

0:40:57	SPEAKER_01
 And the other thing that I tried was by I just took one of those Carlos filters which he needed had to see whether it really helps or not.

0:41:07	SPEAKER_01
 It just ran to see whether it really degrades all of it helps.

0:41:10	SPEAKER_01
 It seems to be like it's not hurting a lot by just blindly picking up one filter which is nothing but a four hertz a band pass filter on the cubic root of the power spectrum.

0:41:24	SPEAKER_01
 So that was the filter that Carlos had.

0:41:29	SPEAKER_01
 And so just to see whether it really it's worth trying around.

0:41:33	SPEAKER_01
 So it doesn't seem to be degrading a lot on that.

0:41:35	SPEAKER_01
 So there must be something that I can be done with that type of noise compensation also because I have to ask Carlos about that.

0:41:44	SPEAKER_01
 I mean how he derived those filters and where he has any filters which are derived on co-GIS stories added with some type of noise which what we are using currently of something that so maybe we have.

0:41:55	SPEAKER_04
 This is cubic root of power spectrum.

0:41:57	SPEAKER_01
 Yeah, cubic root of power spectrum.

0:41:59	SPEAKER_04
 So if you have this band pass filter you probably get negative values right?

0:42:03	SPEAKER_01
 Yeah, and I'm like so it has like the spectrogram has like it actually enhances the onset and the offset of I mean the beginning and the end of the speech.

0:42:16	SPEAKER_01
 So it seems to be like deep valleys and the beginning and the end of like high energy regions because the filter has like a sort of mix again high type structure.

0:42:24	SPEAKER_01
 So those are the regions where the like when I look at the spectrogram there are those deep valleys on the beginning and the end of the speech but rest of it seems to be like pretty nice.

0:42:32	SPEAKER_01
 So that's something I observed using that filter and yeah there are few very not a lot of because the filter doesn't have a really deep negative portion so that it's not really creating a lot of negative values in the cubic root.

0:42:48	SPEAKER_01
 So I'll just continue with that for some maybe I'll ask Carlos later more about how to play with those filters and while making this we have that yeah that's it.

0:43:06	SPEAKER_04
 Last week you were also talking about building up the subspace.

0:43:09	SPEAKER_01
 Yeah I would actually didn't get enough time to work on the subspace last week was mostly about finding those bugs and yeah thanks.

0:43:19	SPEAKER_01
 I think about much on that.

0:43:26	SPEAKER_06
 How about you coming?

0:43:28	SPEAKER_00
 Well I'm still working with BTS and one of the things that last week say here that maybe the problem was with the deep because the signal have different level of energy and maybe talking with Stefan and with Sunil we decide that maybe it was interesting to apply your line normalization before applying BTS but then we decided that it doesn't work absolutely because we modified also the noise.

0:44:00	SPEAKER_00
 And well thinking about that with then we decide that maybe it's a good idea we don't know.

0:44:11	SPEAKER_00
 I didn't do the experiment yet to apply BTS in the castral domain.

0:44:23	SPEAKER_04
 The other thing is so and not and C0 would be a different so you could do different normalization for C0 than for other things anyway.

0:44:35	SPEAKER_04
 I mean the other thing I was going to suggest is that you could have two kinds of normalization with different time constants so you could do some normalization before the BTS and then do some other normalization after.

0:44:54	SPEAKER_04
 But C0 certainly acts differently than the others do so that's.

0:45:00	SPEAKER_00
 Well we decided to obtain the new expression if we work in the castral domain.

0:45:09	SPEAKER_00
 Well I am working in that now but I'm not sure if that would be useful.

0:45:16	SPEAKER_00
 I don't know it's quite a lot of work.

0:45:21	SPEAKER_00
 It's not too much but it's work and I want to know if we have some feeling that the result I would like to know if I don't have any feeling if this will work better than applying BTS in the castral domain will work better than applying in the filter packet of mine.

0:45:48	SPEAKER_00
 I'm not sure.

0:45:49	SPEAKER_00
 I don't know absolutely nothing.

0:45:51	SPEAKER_04
 Yeah well I think you're the first one here to work with BTS so we could call someone else up who has asking their opinion.

0:46:01	SPEAKER_04
 I don't have a good feeling for it.

0:46:05	SPEAKER_02
 Actually the BTS that you tested before was in the log domain and the code book is kind of dependent on the level of the speech signal.

0:46:20	SPEAKER_02
 So I expect it if you have something that's independent of this, I expect it to be a better model of speech.

0:46:29	SPEAKER_04
 You wouldn't even need to switch the capture right?

0:46:35	SPEAKER_02
 Just normalize the mean.

0:46:38	SPEAKER_02
 Remove the mean.

0:46:39	SPEAKER_04
 Yeah then you have one number which is very dependent on level because it is the level and the other which is not.

0:46:47	SPEAKER_02
 But here also we would have to be careful about removing the mean of speech and not of noise because it's like first doing general normalization and then noise removal which is.

0:47:00	SPEAKER_00
 Yeah we were thinking to estimate the noise with the first frames and then apply the VAD before the normalization.

0:47:17	SPEAKER_00
 I am thinking about that and working about that but I don't have this way.

0:47:25	SPEAKER_04
 I mean one of the things we talked about maybe might be time to start thinking about pretty soon is we look at the pros and cons of these different methods.

0:47:34	SPEAKER_04
 How do they fit in with one another because we talked about potentially doing some combination of a couple of them.

0:47:41	SPEAKER_04
 Maybe we may be pretty soon we'll have some sense of what their characteristics are so we can see what should be combined.

0:47:50	SPEAKER_04
 Is that it?

0:47:56	SPEAKER_04
 Okay.

0:47:57	SPEAKER_04
 Okay.

0:47:58	SPEAKER_04
 We read some digits.

0:47:59	SPEAKER_04
 Yeah.

0:48:00	SPEAKER_06
 Want to go ahead and mark?

0:48:01	None
 Sure.

0:48:02	None
 Transcript.

0:48:06	SPEAKER_04
 LDASH 212.

0:48:09	SPEAKER_04
 248829109.

0:48:20	SPEAKER_04
 7061782596.

0:48:25	SPEAKER_04
 858779619.

0:48:29	SPEAKER_04
 48441752.

0:48:33	SPEAKER_04
 2462721821.

0:48:36	SPEAKER_04
 35251.

0:48:40	SPEAKER_04
 50381177.

0:48:43	SPEAKER_04
 697496315.

0:48:49	SPEAKER_02
 Transcript LDASH 213.

0:48:52	SPEAKER_02
 2454437657.

0:48:57	SPEAKER_02
 318 O2O997.

0:49:01	SPEAKER_02
 317388313.

0:49:06	SPEAKER_02
 071724153985.

0:49:11	SPEAKER_02
 0989062173.

0:49:15	SPEAKER_02
 2995696699.

0:49:19	SPEAKER_02
 859946451.

0:49:23	SPEAKER_02
 2453759935.

0:49:30	SPEAKER_03
 Transcript LDASH 2147539591352.

0:49:37	SPEAKER_03
 53510101067.

0:49:40	SPEAKER_03
 170437155.

0:49:44	SPEAKER_03
 924681.

0:49:48	SPEAKER_03
 0710147667915.

0:49:57	SPEAKER_03
 219220956097.

0:50:04	SPEAKER_03
 0250858405.

0:50:10	SPEAKER_03
 34237491.

0:50:15	SPEAKER_06
 Transcript LDASH 215.

0:50:18	SPEAKER_06
 357165459919.

0:50:23	SPEAKER_06
 552085225.

0:50:26	SPEAKER_06
 137988958.

0:50:30	SPEAKER_06
 056540589.

0:50:34	SPEAKER_06
 34565268.

0:50:38	SPEAKER_06
 30182868.

0:50:42	SPEAKER_06
 8394407633.

0:50:47	SPEAKER_06
 507932030.

0:50:52	SPEAKER_01
 Transcript LDASH 216.

0:50:55	SPEAKER_01
 020132950.

0:50:59	SPEAKER_01
 013809626.

0:51:03	SPEAKER_01
 0274407591.

0:51:07	SPEAKER_01
 2472293233.

0:51:11	SPEAKER_01
 745114817.

0:51:15	SPEAKER_01
 6918953964.

0:51:20	SPEAKER_01
 66763799.

0:51:25	SPEAKER_01
 51700707811.

0:51:30	SPEAKER_05
 Transcript LDASH 217.

0:51:33	SPEAKER_05
 723954211.

0:51:37	SPEAKER_05
 9238523639.

0:51:42	SPEAKER_05
 047217119.

0:51:46	SPEAKER_05
 315592660584.

0:51:52	SPEAKER_05
 598848386934.

0:51:58	SPEAKER_05
 851149017.

0:52:03	SPEAKER_05
 03006587.

0:52:08	SPEAKER_05
 532425788.

0:52:14	SPEAKER_00
 Transcript LDASH 218.

0:52:18	SPEAKER_00
 8896023667.

0:52:23	SPEAKER_00
 7807172039.

0:52:28	SPEAKER_00
 064322851.

0:52:34	SPEAKER_00
 51559961.

0:52:39	SPEAKER_00
 4378766857.

0:52:45	SPEAKER_00
 036926029.

0:52:50	SPEAKER_00
 381558434.

0:52:54	SPEAKER_00
 415501528.

0:53:01	SPEAKER_00
 8378.

0:53:11	None
 8378.

0:53:16	None
 8378.

0:53:20	None
 8378.

