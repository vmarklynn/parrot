0:00:30	None
 Okay.

0:00:31	None
 Okay.

0:00:32	None
 Should I start?

0:00:33	None
 Yeah.

0:00:34	SPEAKER_05
 Maybe by presenting the project a little bit.

0:00:54	SPEAKER_05
 Okay.

0:00:55	SPEAKER_05
 Historically it was last year, Prof. D. Lambo, in his CSCW classes asked the student to design a table on all the students and Guillermo was a student of this class.

0:01:09	SPEAKER_05
 I was very excited to design such a table.

0:01:13	SPEAKER_05
 So he decided to make more research on this topic.

0:01:18	SPEAKER_05
 So the general topic is about interactive table, disappearing computer.

0:01:25	SPEAKER_05
 Okay.

0:01:26	SPEAKER_05
 That is the other one.

0:01:33	SPEAKER_05
 So in the general field of computer supported collaborative learning.

0:01:41	SPEAKER_05
 Okay.

0:01:42	SPEAKER_05
 So we have different people collaborating in a pedagogical purpose.

0:01:49	SPEAKER_05
 And we know that when we put a computer in front of them, it doesn't help focusing on collaboration.

0:01:57	SPEAKER_05
 Yeah.

0:01:58	SPEAKER_05
 So if we make the computing functionalities disappearing in the furniture, in the wall, or other things like that, we may more efficiently support collaboration than the learning.

0:02:15	SPEAKER_05
 So I arrived in June, something like that a couple of months ago.

0:02:22	SPEAKER_05
 Guillaume and Michael are two students that are working for months to the master project.

0:02:34	SPEAKER_05
 Okay.

0:02:35	SPEAKER_05
 And they start working on two different sub-projects.

0:02:39	SPEAKER_05
 So Guillaume is working on the noise sensitive table.

0:02:42	SPEAKER_05
 It's what we are discussing about today.

0:02:46	SPEAKER_05
 Okay.

0:02:47	SPEAKER_05
 So the idea is, okay, we have in the lab a notion about root mirroring.

0:02:55	SPEAKER_05
 The idea is if we can provide a feedback to people working together, it may help them self-regulating their activity, their collaboration.

0:03:04	SPEAKER_05
 So it could be normative or not.

0:03:08	SPEAKER_05
 In our own case, we want to have a table that would be accessible by students.

0:03:14	SPEAKER_05
 At the PFL we are...

0:03:17	SPEAKER_05
 Oh, hello.

0:03:20	SPEAKER_05
 Okay.

0:03:21	SPEAKER_05
 At PFL, the learning center will be built in a couple of years.

0:03:25	SPEAKER_05
 So the idea is we will have plenty of rooms, like in libraries or meeting rooms, where students will arrive and walk.

0:03:33	SPEAKER_05
 So if we have this table that is accessible to students, if they arrive, if we provide a feedback of who is talking instant at one moment or through time or what is the turn taking, maybe they will just by seeing an explicit feedback of that, they will take profit of it on the...

0:03:58	SPEAKER_02
 So do you know which way you give a feedback light or something like that?

0:04:06	SPEAKER_03
 Okay. For the Nonsense Tftable project, we decided to take the noise as input and give a feedback with lads on the table.

0:04:20	SPEAKER_03
 So this is one of the possibilities that were offered to us, but we decided to do it this way.

0:04:29	SPEAKER_05
 The idea is to have very, very, very cool information.

0:04:34	SPEAKER_05
 We don't want people to focus on what's going on the feedback.

0:04:39	SPEAKER_05
 So we don't want histogram or very precise information.

0:04:43	SPEAKER_05
 But we will have lads that will be 6 centimeters between each lads with a blurring glass.

0:04:51	SPEAKER_05
 The idea is to have more artistic feedback, to have a general feeling of what's going on, something about more.

0:05:02	SPEAKER_06
 Okay.

0:05:03	SPEAKER_06
 Well, I guess it's just a restriction we took.

0:05:07	SPEAKER_06
 So we don't depest the amount of money we have to spend. Otherwise, we could imagine to have a whole table of lads.

0:05:17	SPEAKER_06
 And then you can really start to assume some reach-ins on the table.

0:05:25	SPEAKER_02
 Maybe more complex.

0:05:26	SPEAKER_02
 Yeah.

0:05:27	SPEAKER_03
 Yeah.

0:05:28	SPEAKER_03
 The first idea of the project was to have the world table covered by nuts.

0:05:34	SPEAKER_03
 But for the type of radical reasons, this is not the way we implemented it now.

0:05:43	SPEAKER_02
 To the border, basically.

0:05:45	SPEAKER_03
 In fact, we kept one paper sheet.

0:05:49	SPEAKER_03
 Yes. There was the restriction that if we covered the table with lads, some won't be visible because you have, obviously.

0:05:59	SPEAKER_03
 So if there is information displayed under the sheets, it won't be very useful.

0:06:09	SPEAKER_03
 So we decided to have it, yes, 30 centimeters.

0:06:13	SPEAKER_03
 Okay.

0:06:14	SPEAKER_05
 So the first shape of the table, the shape of the table, obviously, is one of the factors that will change the collaboration.

0:06:21	SPEAKER_05
 So, but we don't want to start with too many parameters. So we start with a table that is approximately the table where we are now.

0:06:30	SPEAKER_05
 Yeah.

0:06:31	SPEAKER_05
 And we will have a square shape like this that will be here on the second one that would be there.

0:06:37	SPEAKER_05
 Yeah.

0:06:38	SPEAKER_05
 So we will have something like this.

0:06:39	SPEAKER_05
 Okay.

0:06:40	SPEAKER_05
 Like this. That will be our first real prototype.

0:06:43	SPEAKER_05
 Right.

0:06:44	None
 Okay.

0:06:45	SPEAKER_05
 Okay. And so these LED modules are being designed now.

0:06:52	SPEAKER_05
 We should have them in a couple of weeks.

0:06:56	SPEAKER_05
 And we will be able to start evaluating prototypes.

0:07:03	SPEAKER_05
 About the CSCW class that will start at the beginning of November.

0:07:12	SPEAKER_05
 So the student will be asked to design a table.

0:07:15	SPEAKER_05
 So to find the shape of the table to get hood and put that on table legs.

0:07:25	SPEAKER_05
 And we will... So at the beginning, we wanted to put these LED modules in the tables.

0:07:32	SPEAKER_05
 But we won't make it because for solidity region of the table, it's not very strong wood.

0:07:42	SPEAKER_05
 So we will rather beam the LED on the table.

0:07:46	SPEAKER_05
 So we come back to a more richer display, but we will restrict it to small to have the same display.

0:07:55	SPEAKER_05
 Lights.

0:07:56	SPEAKER_05
 Lights.

0:07:57	SPEAKER_05
 That will be distant six centimeters between legs.

0:08:01	SPEAKER_05
 Okay. So we will simulate...

0:08:03	SPEAKER_03
 This is for practical reason.

0:08:05	SPEAKER_03
 But don't matter of time because...

0:08:08	SPEAKER_02
 Yeah.

0:08:09	SPEAKER_02
 Not you think with a beam, also you have less problems with the sheets?

0:08:14	SPEAKER_03
 Yes, but there are other problems like...

0:08:18	SPEAKER_03
 Yes, the information will be under sheets.

0:08:21	SPEAKER_03
 Okay.

0:08:22	SPEAKER_05
 And we have the feeling that to have the information and bedgied in the table and make it part of the table, I don't know.

0:08:34	SPEAKER_05
 We will try.

0:08:35	SPEAKER_05
 We don't really know what will happen with this prototype.

0:08:40	SPEAKER_05
 We are very excited about that.

0:08:42	SPEAKER_05
 Okay.

0:08:43	SPEAKER_05
 Okay.

0:08:44	SPEAKER_05
 Maybe before going on this subject, we can talk a little bit about...

0:08:49	SPEAKER_06
 Yeah, I can just explain my project.

0:08:52	SPEAKER_06
 It's completely different from this one.

0:08:54	SPEAKER_06
 Well, it's also about tables.

0:08:56	SPEAKER_06
 But the idea is if several students come to a table with their laptops, they should be able to share information easily.

0:09:05	SPEAKER_06
 Okay.

0:09:06	SPEAKER_06
 And in fact, what we are doing now, we project another screen on the table.

0:09:13	SPEAKER_06
 Yeah.

0:09:14	SPEAKER_06
 And different people are able to use their mouse of their laptop to go to the project screen there.

0:09:22	SPEAKER_06
 Okay.

0:09:23	SPEAKER_06
 So the project screen is just another Windows machine that is running.

0:09:27	SPEAKER_06
 Yeah.

0:09:28	SPEAKER_06
 So you just have another computer more or less you can use, but you can use it with your own mouse and keyboard.

0:09:34	SPEAKER_02
 But physically, it's just something flat on the table again.

0:09:39	SPEAKER_02
 Yeah.

0:09:40	SPEAKER_06
 But in country, to have another keyboard and mouse, the only one person can use now, the different persons can use the screen at the same time with the mouse.

0:09:53	SPEAKER_05
 Okay.

0:09:54	SPEAKER_05
 So based on the fact that most of the PFL students have their own laptop, the idea is the similar idea is to, okay, people are coming and should be able to very easily use some resources offered to them.

0:10:12	SPEAKER_05
 Okay.

0:10:13	SPEAKER_05
 So the idea is to help them socializing, organizing their own work and not in a classroom setting, but in a social place where they could gather.

0:10:25	SPEAKER_02
 Okay.

0:10:27	SPEAKER_02
 Yeah.

0:10:28	SPEAKER_02
 So it's different, but still, yeah.

0:10:30	SPEAKER_06
 It's still the same subject.

0:10:33	SPEAKER_06
 Okay.

0:10:34	SPEAKER_06
 It's not collaborative work, but different directions.

0:10:37	SPEAKER_06
 Okay.

0:10:38	SPEAKER_06
 It has nothing to do with audio processing and LEDs.

0:10:42	SPEAKER_06
 Okay.

0:10:43	SPEAKER_06
 Okay.

0:10:44	SPEAKER_05
 Okay. So maybe we can focus a little bit more on what we have done about the noise sensitive table.

0:10:51	SPEAKER_05
 Yeah.

0:10:52	SPEAKER_05
 Tell you about what we're interested in.

0:10:58	SPEAKER_05
 So Guillaume started by developing the application that get the audio input.

0:11:07	SPEAKER_05
 So we wanted to have a modular architecture to be able to improve each layer separately.

0:11:14	SPEAKER_05
 Okay.

0:11:15	SPEAKER_05
 So the audio input is quite basic now.

0:11:18	SPEAKER_05
 We use sound cards to get the signals and to detect, and we have a threshold to detect when someone is talking, at least when noise is bigger than specific labels.

0:11:36	SPEAKER_05
 Then we get this information about people talking, talking to say, okay, this one is talking for x time or has been talking, x percent of the five last minutes or two people are talking together.

0:11:52	SPEAKER_05
 So this is more semantic layer.

0:11:55	SPEAKER_05
 We call that interaction models.

0:11:58	SPEAKER_05
 And so when different conditions are detected, we trigger an interaction event.

0:12:05	SPEAKER_05
 So a very simple one could be one person is talking.

0:12:09	SPEAKER_05
 So it's an easy one.

0:12:13	SPEAKER_03
 There is a lot of problems now about this implementation.

0:12:16	SPEAKER_03
 It's still in progress.

0:12:18	SPEAKER_03
 It's still in progress.

0:12:21	SPEAKER_03
 Almost done.

0:12:22	SPEAKER_06
 I think the details of the implementation is not that important.

0:12:26	SPEAKER_06
 It's more important that first one to have some events like two people are talking or one started and other started and more or less broke into the speech of the first person and so on.

0:12:41	SPEAKER_06
 And then you can start to visualize these different situations.

0:12:45	SPEAKER_05
 So the last layer is about this visualization.

0:12:48	SPEAKER_05
 We are thinking about visual grammar, meaning that when we have an interaction event that is fired, we will associate a way of visualizing it.

0:13:03	SPEAKER_05
 So for instance, if someone is talking, we can just have a light that will center on the point that is close to him.

0:13:12	SPEAKER_05
 That could be an instant feedback.

0:13:15	SPEAKER_05
 And if he has been talking maybe 70 percent of the last five minutes or two more minutes, it may be reflected as the intensity or size of a cycle.

0:13:30	SPEAKER_05
 Okay.

0:13:31	SPEAKER_05
 Center on the same point.

0:13:33	SPEAKER_05
 And then if they start taking, we can show waves of light going from me to you or from other people or using the center part of the table to show something more about the more general dynamic.

0:13:49	SPEAKER_06
 I guess it's first prototype.

0:13:53	SPEAKER_06
 You see, we start with people, do people talk or don't they?

0:13:59	SPEAKER_06
 Afterwards, I couldn't imagine that you, for example, you can detect that someone is a bit angry or is yelling and with different colors.

0:14:10	SPEAKER_06
 With different colors on the table, you could display this.

0:14:15	SPEAKER_02
 Also, you might have multiple colors.

0:14:19	SPEAKER_02
 Yes, that's how.

0:14:20	SPEAKER_02
 Sorry, don't get that.

0:14:23	SPEAKER_05
 So we have eight by eight, two times, leads.

0:14:29	SPEAKER_05
 Each lead is actually three leads.

0:14:33	SPEAKER_05
 N So this table is two different things.

0:14:47	SPEAKER_05
 It's one object that will provide feedback to the terminal users, people collaborating around the table.

0:14:54	SPEAKER_05
 But it's also a tool for us as a researcher to test both the interaction event we want to detect and to test the visualization.

0:15:07	SPEAKER_05
 So we will be able to edit some interaction rules and visualization grammar.

0:15:15	SPEAKER_05
 And we will be able to process, to process some conversation just to see what happens and to have these models and feedback working when people are using the terminal.

0:15:29	SPEAKER_01
 Okay.

0:15:36	SPEAKER_02
 It's quite clear.

0:15:40	SPEAKER_02
 So I guess you want to know what you could do with an array, maybe?

0:15:46	SPEAKER_06
 Yes.

0:15:47	SPEAKER_06
 Yes, everything from a chest range of audio and how you can analyze it, but information you can get out of speech and so on.

0:16:01	SPEAKER_03
 I have one or two questions. I don't know if you want to begin with the explanation about the arrays.

0:16:09	SPEAKER_05
 Or maybe we could summarize the question we were thinking about.

0:16:14	SPEAKER_02
 Yes, it's good idea.

0:16:16	SPEAKER_02
 Just give some questions.

0:16:18	SPEAKER_03
 So I have actually two questions that are just practical questions about my implementation now.

0:16:27	SPEAKER_05
 So basically what we want to know when R is to king, B is to king and the basic information we need.

0:16:35	SPEAKER_03
 So the first information is about the noise level. Not the noise level, the sound level.

0:16:45	SPEAKER_03
 Because what you get from the microphone is a curve. The way it is implemented now to detect, yes, I have packets of...

0:17:00	SPEAKER_03
 Let's say this is not fixed, but I have packets for about half a second or so. In this packet I want to know the sound level.

0:17:15	SPEAKER_03
 The average sound level.

0:17:18	SPEAKER_03
 So the way I do it now is to take each top of the curves, bottoms and just making an average of this.

0:17:31	SPEAKER_03
 But I don't know if it's not really the best way to do it, but I don't know if you made the top of the waveform.

0:17:40	SPEAKER_06
 Okay. Probably it would be a good idea if you have two things with results like books or webpages that give a lot of information on how this audio programming works.

0:17:54	SPEAKER_06
 Maybe you know some good book that's dealing with the stuff.

0:18:00	SPEAKER_05
 Maybe we can go through the different questions and then organize your own.

0:18:05	SPEAKER_05
 This is the first question. I would just add something. We are not interested so much in sound level, but in the level of the sound that corresponds to voice.

0:18:16	SPEAKER_03
 Yes, but I think this is two different problems. The filtering must be done before.

0:18:25	SPEAKER_03
 Okay. After that if you have a clean curve you can just apply it.

0:18:33	SPEAKER_03
 The second question was about filtering in FFT. What you can get from it.

0:18:43	SPEAKER_00
 Okay.

0:18:45	SPEAKER_05
 I would add one more. It's about because what we can record is sound origins, sound or sonic points.

0:18:59	SPEAKER_05
 But what we are interested in is people. The question is if someone is moving, I'm talking here, I stop talking, I'm going here, I'm talking how to detect that it's the same people.

0:19:14	SPEAKER_05
 If we want to integrate information to say, these people have spoken 70% of the time in the five last minutes.

0:19:22	SPEAKER_05
 Obviously we need to know that it's the same people. Right now our practical solution is to have one microphone close to every place where people are supposed to sit.

0:19:35	SPEAKER_05
 So we can infer that if a sound is coming in this area it's the same, it's a kind of trick.

0:19:45	SPEAKER_03
 For the beginning it's enough.

0:19:48	SPEAKER_03
 Yes, I'll just add something. Is there a way to from one stream to be two streams that correspond to the voice of fun people and the voice of the second one?

0:20:04	SPEAKER_02
 Yeah, it's a good separation.

0:20:08	SPEAKER_06
 And it's possible to do this in real time.

0:20:15	SPEAKER_05
 And a last question that is related to last if I don't find another one.

0:20:25	SPEAKER_05
 But people, if someone is leaving, or if someone, maybe it would be something quite complex for you.

0:20:35	SPEAKER_05
 If someone is staying here, but it's quiet or leaving, can we detect that someone is here but quiet?

0:20:44	SPEAKER_02
 Why do you need a camera?

0:20:46	SPEAKER_02
 I know, obviously.

0:20:48	SPEAKER_05
 What's the great information?

0:20:50	SPEAKER_05
 I mean, will you have a camera?

0:20:52	SPEAKER_02
 Not yet. Maybe later on.

0:20:55	SPEAKER_02
 Maybe you can detect breathing.

0:20:57	SPEAKER_05
 Or the weight and the...

0:20:59	SPEAKER_02
 Yeah, that you could do.

0:21:02	SPEAKER_02
 Or on the table, there should be...

0:21:06	SPEAKER_06
 Yeah, but what happens if someone is standing there?

0:21:09	SPEAKER_05
 Putting his bag on there.

0:21:12	SPEAKER_05
 Okay, but it was just too.

0:21:14	SPEAKER_05
 It's a question. I'm not sure we will talk too much about that today.

0:21:18	SPEAKER_03
 I'll try to answer some questions.

0:21:22	SPEAKER_03
 Some related questions.

0:21:23	SPEAKER_03
 Okay.

0:21:24	SPEAKER_05
 Not directly, but it's related.

0:21:31	SPEAKER_05
 So, in a couple of days, we will get the firewire box.

0:21:38	SPEAKER_05
 Okay.

0:21:39	SPEAKER_05
 So, we have chosen one that has eight line up.

0:21:44	SPEAKER_05
 So, we will be able to line in.

0:21:47	SPEAKER_05
 So, we will be able to plug up to eight microphones with jack plugs.

0:21:54	SPEAKER_05
 Okay.

0:21:55	SPEAKER_05
 To excel air with the possibility of extending with eight more excel air microphones.

0:22:01	SPEAKER_05
 So, you...

0:22:02	SPEAKER_02
 I think you said that's obtic, something like that.

0:22:04	SPEAKER_03
 Yes, the communication between the extension.

0:22:08	SPEAKER_02
 So, you need a different microphone with a device inside, right?

0:22:14	SPEAKER_06
 No, no, in fact...

0:22:15	SPEAKER_06
 How does it go?

0:22:17	SPEAKER_06
 No, no, no, it's not a thing, this obtic.

0:22:19	SPEAKER_05
 So, we have the computer.

0:22:21	SPEAKER_05
 We have the main box with the eight line in the firewire port.

0:22:27	SPEAKER_03
 It's very wide.

0:22:28	SPEAKER_03
 And it's very wide.

0:22:29	SPEAKER_03
 And it's an extension for this device.

0:22:32	SPEAKER_03
 Yeah.

0:22:33	SPEAKER_03
 Disconnected to it.

0:22:34	SPEAKER_03
 It's an obtic.

0:22:35	SPEAKER_05
 It's an obtic fiber.

0:22:36	SPEAKER_05
 To have eight more excel air.

0:22:38	SPEAKER_05
 If we need it.

0:22:39	SPEAKER_05
 Okay.

0:22:40	SPEAKER_05
 We're not sure to buy it now, but we can extend it.

0:22:42	SPEAKER_06
 Actually, it's not really an extension to the first box.

0:22:45	SPEAKER_06
 It's just an industry standard protocol between these two...

0:22:50	SPEAKER_02
 It's another firewire...

0:22:51	SPEAKER_02
 Well, not firewire, but...

0:22:53	SPEAKER_06
 Well, there's a special protocol to deliver audio signals and...

0:22:58	SPEAKER_02
 But quickly, you would use that to get higher quality signals.

0:23:04	SPEAKER_02
 Yes.

0:23:05	SPEAKER_02
 That's all.

0:23:06	SPEAKER_06
 Just to have the XLR...

0:23:09	SPEAKER_05
 Well, not sure about what kind of microphone we should use.

0:23:13	SPEAKER_05
 Okay.

0:23:14	SPEAKER_05
 So, we wanted to...

0:23:15	SPEAKER_05
 That's a fun thing.

0:23:16	SPEAKER_05
 So, we wanted to have open possibilities.

0:23:18	SPEAKER_05
 And secondly, maybe we will use this box, you know, to get that...

0:23:23	SPEAKER_05
 I don't know if...

0:23:24	SPEAKER_05
 In another experiment, maybe in another project, if we want to have comments of different people around the table or elsewhere...

0:23:32	SPEAKER_05
 I think the possibility of using XLR microphone could be needed.

0:23:39	SPEAKER_03
 Because for now, I'm just sampling the sound at 8000, so just something very...

0:23:47	SPEAKER_03
 I could even go to lower.

0:23:52	SPEAKER_03
 But this is just to get the noise to some level.

0:23:57	SPEAKER_03
 But if I want to record the conversation with a processing...

0:24:04	SPEAKER_02
 You might add kilo sampling for a currency.

0:24:08	SPEAKER_03
 Yes, to have a better sound quality.

0:24:11	SPEAKER_03
 Perhaps it's better to have an XLR.

0:24:14	SPEAKER_03
 Yeah.

0:24:15	SPEAKER_02
 Something like that.

0:24:16	SPEAKER_02
 We use 16, so that's 8 kilo bandwidth.

0:24:20	SPEAKER_02
 16 kilo sampling frequency.

0:24:23	SPEAKER_02
 It's not bad there.

0:24:24	SPEAKER_02
 It's quite decent.

0:24:26	SPEAKER_02
 Okay.

0:24:27	SPEAKER_02
 If you're answering the questions, there's also a point of precision of localization if you use an array.

0:24:37	SPEAKER_02
 So, if you use higher frequencies, you can get more precise localization.

0:24:42	SPEAKER_02
 Sure.

0:24:43	SPEAKER_03
 Maybe you don't need it.

0:24:45	SPEAKER_03
 What is the gain in the terminal position?

0:24:51	SPEAKER_02
 That I can't answer the entry.

0:24:55	SPEAKER_03
 Is it something that's more...

0:24:58	SPEAKER_02
 It depends on your setup.

0:25:00	SPEAKER_02
 Okay.

0:25:01	SPEAKER_02
 You have to test, basically.

0:25:04	SPEAKER_03
 What you get is the real position or just the angle at which the sound comes.

0:25:13	SPEAKER_02
 You get the angle.

0:25:16	SPEAKER_02
 The most precise one is the azimuth in the horizontal plane.

0:25:21	SPEAKER_02
 Then you also get elevation, but it's not very precise.

0:25:25	SPEAKER_02
 It's more of an indication.

0:25:27	SPEAKER_02
 And radius is very bad.

0:25:29	SPEAKER_02
 Okay.

0:25:30	SPEAKER_02
 If you use a planar geometry like this one.

0:25:32	SPEAKER_03
 Yes, sure.

0:25:33	SPEAKER_02
 Yeah.

0:25:34	SPEAKER_02
 You can use multiple ones and do some triangulation.

0:25:41	SPEAKER_03
 Yes.

0:25:42	SPEAKER_03
 Because there is just four microphones that are...

0:25:48	SPEAKER_02
 8.

0:25:49	SPEAKER_02
 There are only screws.

0:25:51	SPEAKER_02
 Okay, but they are in a plan.

0:25:53	SPEAKER_03
 Yeah.

0:25:54	SPEAKER_03
 Yeah.

0:25:55	SPEAKER_03
 Because at EPFL there is a land that is, has done almost the same thing.

0:26:00	SPEAKER_03
 But they have 8 microphones that are at...

0:26:03	SPEAKER_03
 Yes.

0:26:04	SPEAKER_03
 They eat a corner of a cube.

0:26:10	SPEAKER_02
 A cube?

0:26:11	SPEAKER_02
 Okay.

0:26:12	SPEAKER_02
 Then you might get a better direction in elevation.

0:26:18	SPEAKER_02
 But I'm not sure it's really relevant.

0:26:21	SPEAKER_02
 No, we are not.

0:26:22	SPEAKER_02
 The elevation?

0:26:23	SPEAKER_03
 No.

0:26:24	SPEAKER_03
 But it could be relevant.

0:26:26	SPEAKER_03
 It's not always the case with the...

0:26:30	SPEAKER_02
 I have people move forward.

0:26:32	SPEAKER_03
 Yes.

0:26:33	SPEAKER_03
 The position, the radius of the...

0:26:36	SPEAKER_02
 Ah, the radius.

0:26:38	SPEAKER_02
 Yes.

0:26:39	SPEAKER_02
 The problem is not the geometry.

0:26:41	SPEAKER_02
 You need more than one, basically.

0:26:45	SPEAKER_03
 Yes.

0:26:46	SPEAKER_02
 With one you will only get direction.

0:26:48	SPEAKER_05
 More than one...

0:26:49	SPEAKER_05
 Microfonary.

0:26:50	SPEAKER_02
 Yes, because...

0:26:51	SPEAKER_03
 Because the distance between the microphone is too...

0:26:58	SPEAKER_03
 Is too low to...

0:27:00	SPEAKER_03
 Well, sorry.

0:27:02	SPEAKER_06
 You say this one already works, to tell the direction.

0:27:05	SPEAKER_06
 The direction.

0:27:06	SPEAKER_06
 Yeah.

0:27:07	SPEAKER_06
 But it does work if you placed the microphones at the board of the table.

0:27:12	SPEAKER_06
 Oh.

0:27:13	SPEAKER_06
 You see now you have it quite essential.

0:27:15	SPEAKER_06
 Yeah.

0:27:16	SPEAKER_06
 And what happens if you put them here around the table?

0:27:20	SPEAKER_06
 Would it work as well?

0:27:21	SPEAKER_02
 It's a different option, yeah.

0:27:23	SPEAKER_02
 We just didn't try.

0:27:25	SPEAKER_06
 We haven't tried that.

0:27:27	SPEAKER_02
 Because we are not going towards a special kind of table.

0:27:31	SPEAKER_02
 More...

0:27:32	SPEAKER_02
 This is not a good example, but we have a box.

0:27:35	SPEAKER_02
 We just bring the box and put it.

0:27:37	SPEAKER_02
 Yeah.

0:27:38	SPEAKER_02
 So we could not consider that.

0:27:41	SPEAKER_02
 Yes, it could be interesting, yeah.

0:27:44	SPEAKER_02
 Unless people put something on the microphone.

0:27:47	SPEAKER_02
 Yes, sure.

0:27:48	SPEAKER_02
 But...

0:27:49	SPEAKER_05
 They won't have nice light lighting on in front of them.

0:27:54	SPEAKER_05
 Yes, they will be.

0:27:56	SPEAKER_03
 I think the most driven part is the other hardware that synchronize the microphones.

0:28:05	SPEAKER_02
 Right.

0:28:06	SPEAKER_02
 But I think after the meeting we can go and talk to Olivier about that.

0:28:12	SPEAKER_02
 Yes, I'm not the person for hardware.

0:28:15	SPEAKER_05
 So maybe you could present a different work you have done and I don't know how they are.

0:28:22	SPEAKER_02
 Yeah, I'll try to present...

0:28:24	SPEAKER_02
 I guess it corresponds to your questions.

0:28:27	SPEAKER_05
 So you told us it was different pieces more than one integrated device?

0:28:32	SPEAKER_02
 So the lowest layer would be the first two questions.

0:28:36	SPEAKER_02
 You asked about how to detect...

0:28:40	SPEAKER_02
 activity, currently you are thresholding the maximum of your waveform.

0:28:45	SPEAKER_03
 Not maximum, the average on the packets.

0:28:49	SPEAKER_02
 Okay.

0:28:50	SPEAKER_02
 And you are looking for a peak?

0:28:53	SPEAKER_03
 Yes, I take the...

0:28:57	SPEAKER_03
 When I go up to the curve, I'm at a local maximum.

0:29:02	SPEAKER_03
 Yeah.

0:29:03	SPEAKER_03
 I take it, then the next local minimum taking this...

0:29:09	SPEAKER_03
 Okay.

0:29:10	SPEAKER_05
 What would be the difference between detecting the average or detecting the maximum?

0:29:15	SPEAKER_01
 Yes.

0:29:17	SPEAKER_05
 What would be the difference?

0:29:20	SPEAKER_05
 What is the difference?

0:29:21	SPEAKER_03
 The difference is that if I just... it's kind of filtering already.

0:29:25	SPEAKER_05
 Yes.

0:29:26	SPEAKER_02
 Yeah.

0:29:27	SPEAKER_02
 And your second question was about FFT, what can be done with the FFT?

0:29:32	SPEAKER_02
 Yes.

0:29:33	SPEAKER_02
 So the approach we are taking here is to answer both questions.

0:29:38	SPEAKER_02
 At the same time, we use FFT to do detection.

0:29:43	SPEAKER_02
 We don't use the waveform, the row waveform.

0:29:48	SPEAKER_03
 So you are FFT implementation?

0:29:52	SPEAKER_02
 No.

0:29:53	SPEAKER_02
 We split the signal in small frames, like 16 million seconds.

0:29:59	SPEAKER_02
 Yes.

0:30:00	SPEAKER_02
 16.

0:30:01	SPEAKER_02
 Okay.

0:30:02	SPEAKER_02
 Each frame is taking 32 million seconds of signal, just to give an idea.

0:30:07	SPEAKER_02
 Yeah.

0:30:08	SPEAKER_02
 And there is one frame every 16 million seconds, and they overlap of 50%.

0:30:15	None
 Okay.

0:30:16	SPEAKER_05
 So it's 32 millisecond frames, they can each...

0:30:21	SPEAKER_02
 Yeah.

0:30:22	SPEAKER_02
 Each 16 million seconds.

0:30:24	SPEAKER_02
 Well, these are details, it's just to give...

0:30:27	SPEAKER_02
 An idea.

0:30:28	SPEAKER_02
 An idea.

0:30:29	SPEAKER_02
 Something like that.

0:30:31	SPEAKER_05
 So why are you overlapping?

0:30:34	SPEAKER_05
 Well, it's...

0:30:36	SPEAKER_05
 I have a rough idea, but...

0:30:38	SPEAKER_02
 Because usually when you do FFT, you're getting into details, but you apply a window to avoid an idea as an effect.

0:30:49	SPEAKER_02
 So the beginning and the end...

0:30:50	SPEAKER_02
 Yeah, it's kind of crappy.

0:30:52	SPEAKER_02
 It's not crappy, it's just not very much represented, because you apply a window which has this shape having window.

0:31:00	SPEAKER_02
 So you use the first and...

0:31:02	SPEAKER_05
 Last point to detect what is between.

0:31:06	SPEAKER_02
 No, I'm saying when you take your signal, you take one frame, you apply the window.

0:31:12	SPEAKER_02
 And the window is simply coefficients you give, and you give higher coefficients to the meter than to the extreme.

0:31:21	SPEAKER_02
 So if you don't do overlap...

0:31:23	SPEAKER_02
 You lose information.

0:31:24	SPEAKER_02
 You will lose information at the beginning and the end.

0:31:29	SPEAKER_03
 Okay.

0:31:30	SPEAKER_02
 But you don't have to do overlap.

0:31:32	SPEAKER_02
 I mean, it's...

0:31:34	SPEAKER_03
 Just...

0:31:36	SPEAKER_03
 Because we are using an open source framework to do this.

0:31:43	SPEAKER_03
 There is something...

0:31:45	SPEAKER_03
 I don't know if you know it.

0:31:47	SPEAKER_03
 I call it Sphinx.

0:31:49	SPEAKER_03
 That is doing...

0:31:51	SPEAKER_02
 Sorry.

0:31:53	SPEAKER_02
 Is it from CMU?

0:31:54	SPEAKER_03
 Yes.

0:31:55	SPEAKER_03
 Yeah.

0:31:56	SPEAKER_03
 Doing voice recognition.

0:31:59	SPEAKER_03
 Yeah.

0:32:00	SPEAKER_03
 And I just use it for the framework, for the microphone and the acquisition.

0:32:06	SPEAKER_03
 Right.

0:32:07	SPEAKER_03
 So there is already an FFT module implemented in it.

0:32:11	SPEAKER_03
 Yeah.

0:32:12	SPEAKER_03
 I didn't test it.

0:32:14	SPEAKER_03
 Yeah.

0:32:15	SPEAKER_03
 But...

0:32:16	SPEAKER_02
 FFT is only a tool.

0:32:18	SPEAKER_02
 Yeah, sure.

0:32:19	SPEAKER_02
 What we do really is a phase domain analysis.

0:32:24	SPEAKER_02
 We only use the phase between the microphones.

0:32:28	SPEAKER_03
 Yes, for the position.

0:32:31	SPEAKER_03
 Yeah, but also for detection.

0:32:34	SPEAKER_03
 Also for detection.

0:32:35	SPEAKER_03
 Yeah.

0:32:36	SPEAKER_02
 We have a way.

0:32:39	SPEAKER_02
 So...

0:32:41	SPEAKER_02
 I don't think I should get into details.

0:32:43	SPEAKER_02
 But basically the beginning is your signal, which you slice in two frames.

0:32:47	SPEAKER_02
 You do a FFT on each mic.

0:32:50	SPEAKER_02
 And the end is a number of frequency bins, which are used by each person to explain roughly.

0:33:02	SPEAKER_02
 So you are...

0:33:03	SPEAKER_02
 So when you speak, speech is wide-banded.

0:33:07	SPEAKER_02
 So the more active you are, the more bandwidth you use.

0:33:12	SPEAKER_02
 So you will get a large value of bandwidth for people who speak.

0:33:17	SPEAKER_02
 And for the others it will be random, it will be a small value.

0:33:22	SPEAKER_05
 Corresponding to breath on detail noise.

0:33:25	SPEAKER_02
 Or just background noise.

0:33:27	SPEAKER_02
 Okay.

0:33:29	SPEAKER_02
 So...

0:33:30	SPEAKER_05
 Okay.

0:33:31	SPEAKER_05
 But you are talking about the microphone array here.

0:33:34	SPEAKER_02
 Yeah.

0:33:35	SPEAKER_02
 Because one problem, if you use energy-based methods, which is probably all the things you have been using so far, is that it's not quite related to location.

0:33:46	SPEAKER_02
 Nope.

0:33:47	SPEAKER_02
 So you can have a...

0:33:49	SPEAKER_02
 Strong background noise.

0:33:51	SPEAKER_02
 For one person, you can have a high energy signal, which is difficult to locate and vice versa.

0:33:58	SPEAKER_02
 I think in your case you are quite interested in the location.

0:34:02	SPEAKER_02
 So I would advise to use more phase domain methods.

0:34:11	SPEAKER_06
 So phase...

0:34:13	SPEAKER_06
 That's something with FFTs.

0:34:15	SPEAKER_02
 Once you have the FFT, for each frequency you have the magnitude.

0:34:19	SPEAKER_02
 And the phase.

0:34:21	SPEAKER_02
 So you can compare the phase of the microphones.

0:34:24	SPEAKER_02
 And this is directly linked to the direction of the person.

0:34:29	SPEAKER_06
 So the magnitude you don't really use.

0:34:34	SPEAKER_02
 Sometimes we use it, but it's not the first thing we use.

0:34:39	SPEAKER_02
 I know it's a bit contour and tutile, but it will be good to the bell.

0:34:44	SPEAKER_06
 Yeah.

0:34:45	SPEAKER_06
 I did a speech first, I think, cos.

0:34:48	SPEAKER_06
 I'm not sure if they also learned that we are more used to phase than the magnitude.

0:34:55	SPEAKER_06
 Right.

0:34:56	SPEAKER_02
 For a single channel it's not very meaningful.

0:34:59	SPEAKER_02
 But here it's a relative phase between the microphones.

0:35:02	SPEAKER_02
 So I'll just try to...

0:35:05	SPEAKER_03
 You have to detect an event in one microphone and know when it happened in the other one.

0:35:11	SPEAKER_03
 No, that's what I don't do.

0:35:13	SPEAKER_02
 Okay.

0:35:14	SPEAKER_02
 This would be valid for speech recognition with a single channel.

0:35:22	SPEAKER_02
 That would be a very good idea.

0:35:24	SPEAKER_02
 But if you choose to use multiple channels...

0:35:28	SPEAKER_02
 Let's say you have four of them.

0:35:34	SPEAKER_02
 With FFT you can just, as I said, look at the phase between the microphones at a given frequency.

0:35:42	SPEAKER_05
 So the phase, the time between audio signals for this microphone.

0:35:51	SPEAKER_02
 It is linked to this value.

0:35:53	SPEAKER_02
 Okay.

0:35:54	SPEAKER_02
 Basically the time you're mentioning is this value.

0:35:59	SPEAKER_02
 And this is the frequency.

0:36:02	SPEAKER_02
 And this is an angle in radiance.

0:36:05	SPEAKER_04
 Okay.

0:36:06	SPEAKER_02
 So FFT gives you a measure of these values.

0:36:14	SPEAKER_02
 This, I can point to a paper.

0:36:16	SPEAKER_02
 I don't think this is the right place to explain everything.

0:36:19	SPEAKER_02
 But we'll give you, if you look at your table, what we have developed here is an approach where you divide the space in sectors.

0:36:33	SPEAKER_02
 For example, ten sectors around the table.

0:36:37	SPEAKER_02
 And in each sector you will get a value.

0:36:43	SPEAKER_03
 It's related to the number of microphones around.

0:36:46	SPEAKER_02
 No.

0:36:47	SPEAKER_02
 It's application dependent.

0:36:50	SPEAKER_02
 For example...

0:36:54	SPEAKER_02
 This is not...

0:36:59	SPEAKER_02
 On this one you could have a large value on those one small values.

0:37:07	SPEAKER_02
 These are number of frequencies which we estimate with several steps from these measures.

0:37:16	SPEAKER_02
 So to conclude, what we are doing is we estimate how much of the frequency spectrum you are occupying when you speak.

0:37:24	SPEAKER_02
 Or I am occupying in this direction when I speak.

0:37:28	SPEAKER_02
 And it turns out that this is quite good to do detection and localization at the same time.

0:37:38	SPEAKER_02
 Because you know in a sector of space there is this much activity.

0:37:45	SPEAKER_03
 Okay, this is a measure of the activity.

0:37:48	SPEAKER_01
 Yeah.

0:37:49	SPEAKER_01
 Yeah.

0:37:50	SPEAKER_02
 More recently...

0:37:55	SPEAKER_02
 I've worked on...

0:38:00	SPEAKER_02
 Prolongating this with the more precise direction evaluation to know where in the sector the person is.

0:38:09	SPEAKER_02
 So that's not much work.

0:38:12	SPEAKER_02
 Once you have done this, this can be done quite quickly.

0:38:16	SPEAKER_06
 What happens if two persons are talking at the same time, just get two sectors that are...

0:38:23	SPEAKER_02
 I use a value, but then you get two large values.

0:38:27	SPEAKER_05
 Yeah.

0:38:28	SPEAKER_05
 And do you get something about the distance of the guy that is talking?

0:38:33	SPEAKER_02
 No, just direction.

0:38:35	SPEAKER_02
 Just direction.

0:38:36	SPEAKER_03
 There is a distance that's not very effective.

0:38:41	SPEAKER_02
 Well, yeah, as you mentioned...

0:38:45	SPEAKER_02
 It's an in-ear-run problem to the geometry you use.

0:38:50	SPEAKER_02
 You can, for example, if you use another array, you can intersect lines of direction.

0:38:58	SPEAKER_03
 Okay.

0:38:59	SPEAKER_03
 And from this kind of information, you can, let's say, have a fingerprint of the user to know if this is the same user speaking.

0:39:11	SPEAKER_03
 So maybe...

0:39:21	SPEAKER_02
 I wouldn't trust it too much.

0:39:23	SPEAKER_02
 Classically, what you do is you extract the signal of the person.

0:39:29	SPEAKER_02
 One interesting thing is that these numbers are not arbitrary things.

0:39:34	SPEAKER_02
 They represent the number of frequencies where a given person is dominant.

0:39:39	SPEAKER_02
 So when you have two of them, which might be interesting for separation, you know already when you have done this processing, which part of the frequency of the spectrum belongs to this person and to that person.

0:39:53	SPEAKER_02
 And then it's easy to separate the signals.

0:39:56	SPEAKER_05
 You mean that each person will have a specific frequency because the way it's talking is localization?

0:40:03	SPEAKER_05
 No, it's small there.

0:40:05	SPEAKER_05
 So kind of...

0:40:06	SPEAKER_05
 Both.

0:40:07	SPEAKER_05
 No, it's small.

0:40:09	SPEAKER_02
 It's more an instant use.

0:40:11	SPEAKER_02
 This is still instant use.

0:40:13	SPEAKER_02
 This is for one time frame.

0:40:15	SPEAKER_03
 Yes, okay.

0:40:16	SPEAKER_02
 If you look at all your frequencies, for example, 0 to 4 kilohertz, you can split it and say all these parts belong to person 1 here.

0:40:35	SPEAKER_02
 And all the other parts belong to the other person.

0:40:38	SPEAKER_03
 This is a bit arbitrary because perhaps person 2 will have some frequencies in the range of...

0:40:46	SPEAKER_03
 That's correct.

0:40:47	SPEAKER_02
 But then you can look statistically. It will be negligible because of the difference level.

0:40:56	SPEAKER_03
 And if you reconstruct the stream from this range, you really get something that is...

0:41:02	SPEAKER_02
 Yeah, you can listen to it here.

0:41:05	SPEAKER_02
 And then you can do some higher level analysis where you get the pitch of the person.

0:41:13	SPEAKER_05
 And not really get your last diagram.

0:41:17	SPEAKER_05
 So it's at one given moment still.

0:41:20	SPEAKER_02
 Yeah, yeah.

0:41:21	SPEAKER_05
 And this is...

0:41:22	SPEAKER_05
 So you can say that this frequency belongs more to this person and this one more to this one.

0:41:27	SPEAKER_05
 Exactly.

0:41:28	SPEAKER_05
 So if the same frequency may... maybe are not used neither by the guy 1 or the guy 2.

0:41:34	SPEAKER_02
 Then it's random.

0:41:36	SPEAKER_02
 And that's why you get these values which are random.

0:41:41	SPEAKER_05
 And maybe they are using the same frequency.

0:41:43	SPEAKER_02
 Yeah.

0:41:44	SPEAKER_02
 So you need to... Yeah, but this is very rare.

0:41:46	SPEAKER_02
 Okay.

0:41:47	SPEAKER_02
 And when it happens, one is always masking the other in practice.

0:41:51	SPEAKER_02
 Okay.

0:41:52	SPEAKER_02
 So...

0:41:53	SPEAKER_05
 And can you detect if someone is laughing or angry or there's kind of signature?

0:42:00	SPEAKER_05
 Even if we can't really trust it.

0:42:03	SPEAKER_05
 No, no, but 100% of the time.

0:42:05	SPEAKER_02
 I've seen quite a few papers.

0:42:07	SPEAKER_02
 I've not done it myself and really on the lowest level.

0:42:11	SPEAKER_02
 But once you have done this, as I said, you can separate the signals.

0:42:20	SPEAKER_02
 And do processing.

0:42:25	SPEAKER_02
 Do processing.

0:42:28	SPEAKER_02
 Okay.

0:42:29	SPEAKER_02
 So you can get pitch, right of speech.

0:42:33	SPEAKER_02
 That's quite easy.

0:42:35	SPEAKER_02
 Pitch.

0:42:36	SPEAKER_02
 I'll show you this afterwards.

0:42:38	SPEAKER_02
 A tambre, for a second.

0:42:40	SPEAKER_02
 Right.

0:42:41	SPEAKER_02
 So for different person, it might be quite different.

0:42:44	SPEAKER_02
 At least for male, female.

0:42:46	SPEAKER_02
 And right of speech.

0:42:50	SPEAKER_02
 If somebody is talking in a very energetic manner, it might be quite fast.

0:42:57	SPEAKER_02
 Or just energy or so.

0:43:00	SPEAKER_03
 Okay.

0:43:01	SPEAKER_03
 This way you can filter perhaps some range that are just very low frequencies for perhaps noise.

0:43:09	SPEAKER_02
 Yeah.

0:43:10	SPEAKER_02
 That might be an issue if people are bringing laptops.

0:43:19	SPEAKER_03
 Yes, the fan.

0:43:20	SPEAKER_02
 They might be detected as another source.

0:43:26	SPEAKER_02
 So you would have to classify the sources as human or machine.

0:43:32	SPEAKER_02
 Okay.

0:43:33	SPEAKER_02
 But again, once you see the spectrum, if it's just pure and stable.

0:43:39	SPEAKER_06
 If you don't really detect the pitch, you can say that.

0:43:43	SPEAKER_02
 Oh, so yeah.

0:43:44	SPEAKER_02
 It does not reach.

0:43:46	SPEAKER_03
 Yes.

0:43:47	SPEAKER_03
 But this is very interesting because this way you can detect if someone is talking, if someone has some noise with perhaps putting his cup on the table.

0:44:01	SPEAKER_03
 Yeah.

0:44:02	SPEAKER_03
 Perhaps if there is a laptop in one position.

0:44:05	SPEAKER_02
 So all will go and be detected there.

0:44:08	SPEAKER_03
 And you can classify this.

0:44:10	SPEAKER_02
 Yeah.

0:44:11	SPEAKER_02
 Yes.

0:44:12	SPEAKER_02
 So what you're mentioning is the pain for us.

0:44:16	SPEAKER_02
 But for you it might be, because we are only interested in getting a speech.

0:44:20	SPEAKER_02
 But for you it might be quite good.

0:44:25	SPEAKER_02
 So I've tried to avoid filtering and smoothing.

0:44:30	SPEAKER_02
 Because as soon as you do that, you exclude some of the information.

0:44:35	SPEAKER_02
 Yes.

0:44:36	SPEAKER_02
 So it's better to keep it for the latest stage.

0:44:40	SPEAKER_02
 So on top of this, there's another part which is more linked to the tracking.

0:44:51	SPEAKER_02
 All this was for one time frame.

0:44:54	SPEAKER_03
 So in the length of the time frame as an influence of which parameters?

0:45:05	SPEAKER_02
 Yeah.

0:45:06	SPEAKER_02
 You can play with it.

0:45:09	SPEAKER_02
 In speech, it's a stationary of 10, 20 minutes ago.

0:45:14	SPEAKER_02
 And we make a stationary local stationary T assumption.

0:45:20	SPEAKER_02
 Which allows you to use FFT and blah, blah, blah.

0:45:25	SPEAKER_02
 Now in spite of that, I know some people use much longer windows, which is not a problem.

0:45:32	SPEAKER_03
 And let's say if you use one second window, it's a bit too much I think.

0:45:40	SPEAKER_03
 In fact the frame length will be very, very meaningful.

0:45:46	SPEAKER_06
 I'll let you do this.

0:45:49	SPEAKER_02
 Yes.

0:45:50	SPEAKER_02
 Some very small worlds, like yes, there might be 200 milliseconds or 300 milliseconds.

0:46:01	SPEAKER_03
 They won't be visible on the way.

0:46:05	SPEAKER_02
 There might be blood with silence.

0:46:09	SPEAKER_04
 Yes.

0:46:10	SPEAKER_02
 So yes, you might have to play with it just to save processing time.

0:46:16	SPEAKER_02
 Like you slightly longer frames.

0:46:18	SPEAKER_03
 But the longest frame you would lose would be 100.

0:46:24	SPEAKER_02
 Yeah, at most.

0:46:26	SPEAKER_03
 At most.

0:46:27	SPEAKER_02
 Okay.

0:46:31	SPEAKER_02
 Simply because I've used 100 as a minimum length of speech word.

0:46:37	SPEAKER_02
 Okay.

0:46:38	SPEAKER_02
 Yeah.

0:46:39	SPEAKER_02
 So.

0:46:42	SPEAKER_02
 Now assuming you have done this for each time.

0:46:47	SPEAKER_02
 If this is your data, I should use a different.

0:46:53	SPEAKER_02
 If this is your azimuth, at each time you get a direction.

0:46:57	SPEAKER_02
 What is azimuth?

0:46:58	SPEAKER_02
 So azimuth is your direction in horizontal plane, to the angle, like north, south, east, west.

0:47:05	SPEAKER_05
 So where you represent the phase?

0:47:08	SPEAKER_02
 Yeah.

0:47:09	SPEAKER_02
 No, no.

0:47:11	SPEAKER_02
 This is really different.

0:47:13	SPEAKER_02
 I'm just saying that once you have done this, for a given time frame, you can have a direction of the person.

0:47:20	SPEAKER_02
 Okay.

0:47:21	SPEAKER_02
 So at least in terms of sector.

0:47:24	SPEAKER_02
 And it's also possible to give a more precise direction quite quickly.

0:47:31	SPEAKER_02
 So this was kind of the lowest layer.

0:47:36	SPEAKER_02
 Now this is a layer just above it, which might interest you.

0:47:41	SPEAKER_02
 If you repeat that over time, you will see patterns.

0:47:48	SPEAKER_02
 For example, at two different locations.

0:47:52	None
 Okay.

0:47:53	SPEAKER_03
 So you can...

0:47:56	SPEAKER_02
 Two different person will speak.

0:47:58	SPEAKER_02
 Okay.

0:47:59	SPEAKER_02
 So you can cluster those.

0:48:01	SPEAKER_03
 One user, yes.

0:48:03	SPEAKER_02
 And you will see that if it's long enough, it's some significant event.

0:48:13	SPEAKER_02
 This can be done quite cheaply.

0:48:16	SPEAKER_03
 Yes, before I forget it.

0:48:19	SPEAKER_03
 Yeah.

0:48:20	SPEAKER_03
 I have one question.

0:48:22	SPEAKER_03
 You say you do the processing afterwards.

0:48:26	SPEAKER_03
 Yeah.

0:48:27	SPEAKER_03
 And what is the cost?

0:48:30	SPEAKER_03
 Because just the length, one one or a bit longer.

0:48:35	SPEAKER_02
 Well, I use Matlab, so it's not perfect.

0:48:38	SPEAKER_02
 It's like three.

0:48:39	SPEAKER_03
 This is what Matlab is very effective for matrices.

0:48:44	SPEAKER_02
 Yeah, but not everything is simple linear.

0:48:48	SPEAKER_02
 Okay.

0:48:49	SPEAKER_02
 Especially this part, it's definitely not linear because you're looking at the maximum energy in the frequency.

0:48:57	SPEAKER_02
 Kind of.

0:48:58	SPEAKER_02
 The most expensive part is here.

0:49:01	SPEAKER_02
 With Matlab, I have three, four times or eight times.

0:49:05	SPEAKER_02
 Okay.

0:49:06	SPEAKER_02
 You can do sub-optimal processing.

0:49:10	SPEAKER_02
 And for example, here I'm considering all possible pairs of microphones, which is 28.

0:49:21	SPEAKER_02
 And the processing is directly relative, proportional to that.

0:49:27	SPEAKER_02
 So you can save on that, but then you lose a little bit on precision.

0:49:37	SPEAKER_02
 So I'm using all these small frames with 50% overlap.

0:49:41	SPEAKER_02
 I don't think you really need absolutely to do that.

0:49:44	SPEAKER_03
 And even if you use four microphones, it's not that good in terms of direction.

0:49:50	SPEAKER_02
 Okay.

0:49:51	SPEAKER_02
 Yeah, I would be careful with that.

0:49:56	SPEAKER_02
 Okay.

0:49:57	SPEAKER_02
 Like five, six is decent.

0:49:59	SPEAKER_02
 Six, I would say.

0:50:03	SPEAKER_03
 And eight is good.

0:50:05	SPEAKER_02
 Eight, yeah, I get down now to one, two degrees, root mean square, error.

0:50:13	SPEAKER_02
 So.

0:50:14	SPEAKER_02
 Yes.

0:50:15	SPEAKER_02
 You might not need that.

0:50:16	SPEAKER_02
 That's what I mean.

0:50:17	SPEAKER_02
 Might not be.

0:50:19	SPEAKER_03
 Yes, one, two degrees.

0:50:20	SPEAKER_03
 Very, very small for our application because we really want to detect if this is the same person that is speaking or not.

0:50:30	SPEAKER_03
 If there is a error of, let's say, 10, 15 degrees, but it is capable of seeing it is two different person.

0:50:40	SPEAKER_03
 There is not problems about it.

0:50:42	SPEAKER_02
 Yeah.

0:50:43	SPEAKER_02
 So it could be sufficient to define enough sectors.

0:50:51	SPEAKER_03
 Okay.

0:50:52	SPEAKER_03
 And the number of sectors is not dependent on the number of microphones.

0:50:57	SPEAKER_02
 No.

0:50:58	SPEAKER_02
 So it's arbitrary.

0:50:59	SPEAKER_02
 I use 20 degree sectors because I had to choose a value, but it's up to you.

0:51:08	SPEAKER_06
 Otherwise, it could also just rely on the frequency band separation detected way, the different persons.

0:51:17	SPEAKER_06
 Yeah.

0:51:18	SPEAKER_06
 Yeah.

0:51:19	SPEAKER_06
 Then you don't really know where around the table is, but there.

0:51:22	SPEAKER_03
 Two persons in the same sector, you see.

0:51:27	SPEAKER_06
 Well, it depends on how you do it, but if you place the microphones.

0:51:32	SPEAKER_06
 So that's another way.

0:51:34	SPEAKER_02
 Yeah.

0:51:35	SPEAKER_02
 It's almost like having a lapel.

0:51:37	SPEAKER_02
 Yeah.

0:51:38	SPEAKER_06
 That way you can separate where voice louder or loud.

0:51:45	SPEAKER_02
 It's not necessarily a bad idea, actually.

0:51:47	SPEAKER_06
 It's quite a different thing and you don't really get an ankle, but...

0:51:53	SPEAKER_02
 Well, if you are able to calibrate your microphones, the ones who are closer to the person who will get more energy.

0:52:06	SPEAKER_02
 So you can compare that.

0:52:10	SPEAKER_02
 It's possible.

0:52:11	SPEAKER_06
 I think it depends a bit what you want.

0:52:15	SPEAKER_02
 Yeah.

0:52:18	SPEAKER_02
 I have experience with that.

0:52:22	SPEAKER_02
 On the side I've done some single channel work, which can maybe help.

0:52:30	SPEAKER_02
 Because it seems to me that you are not definite on geometry, right?

0:52:35	SPEAKER_03
 No.

0:52:36	SPEAKER_03
 Geometry is not... we have not thought a lot about it.

0:52:42	SPEAKER_02
 This part is quite specific to a microphone array, where they are concentrated in some place, like in the middle of the table.

0:52:52	SPEAKER_05
 Yes.

0:52:53	SPEAKER_05
 Because if we are distributing the microphone all around the table, then we come back to the energy solution.

0:52:59	SPEAKER_05
 Yeah.

0:53:00	SPEAKER_02
 But you can kind of come back to that also.

0:53:05	SPEAKER_05
 With the energy solution, or with the FFT too?

0:53:08	SPEAKER_05
 FFT or so.

0:53:10	SPEAKER_02
 Yeah.

0:53:12	SPEAKER_03
 But I think what is very important here is the synchronization of the microphones.

0:53:18	SPEAKER_03
 Right.

0:53:19	SPEAKER_02
 Yeah.

0:53:20	SPEAKER_02
 It has to be as good as possible.

0:53:23	SPEAKER_03
 I'm speaking about it because we wanted to do this table in a mid-tech way.

0:53:32	SPEAKER_03
 It's a cheap way.

0:53:34	SPEAKER_03
 Yeah.

0:53:35	SPEAKER_03
 You have not very expensive tables.

0:53:38	SPEAKER_03
 So I don't know if what I've seen on your website was that this installation was a bit expensive.

0:53:48	SPEAKER_03
 But I'm training to do many, many things.

0:53:52	SPEAKER_03
 To see what is very important and what is not...

0:53:56	SPEAKER_02
 You can also consider a directional microphone.

0:54:00	SPEAKER_02
 Yes.

0:54:01	SPEAKER_02
 You know... no.

0:54:03	SPEAKER_02
 So you can speak between the pattern is not the same depending on the direction where the person is.

0:54:14	SPEAKER_02
 So for example, if there was a directional microphone pointing there, you would get most of my energy but less from you.

0:54:22	SPEAKER_02
 Sure.

0:54:23	SPEAKER_02
 You can also do microphone arrays with directional microphones.

0:54:28	SPEAKER_03
 Yes.

0:54:29	SPEAKER_02
 I think you might not be relevant, but...

0:54:35	SPEAKER_05
 That would be the difference.

0:54:36	SPEAKER_05
 You will not compare each mic with all the other ones.

0:54:41	SPEAKER_05
 But just comparing this one with the...

0:54:45	SPEAKER_02
 More or less.

0:54:48	SPEAKER_02
 It depends on what you want.

0:54:51	SPEAKER_02
 I mean...

0:54:52	SPEAKER_06
 What are the other approach?

0:54:54	SPEAKER_05
 Yeah.

0:54:55	SPEAKER_05
 So what are these mic, for instance?

0:54:57	SPEAKER_00
 Electric mic?

0:54:58	SPEAKER_05
 Yeah.

0:54:59	SPEAKER_02
 Unidirectional.

0:55:00	SPEAKER_02
 Electric?

0:55:01	SPEAKER_02
 Okay.

0:55:02	SPEAKER_02
 I guess so.

0:55:04	SPEAKER_03
 These are... these are some kinds of...

0:55:08	SPEAKER_03
 It's the same.

0:55:09	SPEAKER_02
 Exactly the same.

0:55:10	SPEAKER_03
 Yeah.

0:55:11	SPEAKER_03
 Expensive?

0:55:12	SPEAKER_01
 Yeah.

0:55:13	SPEAKER_01
 Yeah.

0:55:14	SPEAKER_01
 Quite expensive.

0:55:15	SPEAKER_03
 Can you say now?

0:55:16	SPEAKER_02
 Because the quality of the...

0:55:17	SPEAKER_02
 Yeah.

0:55:18	SPEAKER_02
 There are high quality mics.

0:55:21	SPEAKER_03
 And they are plugging in an excellent...

0:55:25	SPEAKER_02
 I think we can leave this question for Olivier.

0:55:28	SPEAKER_02
 Yes.

0:55:29	SPEAKER_02
 Okay.

0:55:30	SPEAKER_03
 For the...

0:55:32	SPEAKER_05
 And when you were talking about comparing energy, in the case where a microphone would be distributed all around the table, you're comparing energy and the time delay?

0:55:42	SPEAKER_02
 No.

0:55:43	SPEAKER_02
 No.

0:55:44	SPEAKER_02
 You would...

0:55:45	SPEAKER_05
 Because the time delay is too short to be compared or can be neglected.

0:55:51	SPEAKER_02
 You would neglect it.

0:55:53	SPEAKER_02
 The time delay is very small.

0:55:55	SPEAKER_02
 It's only used for getting the direction when you have a microfenor.

0:56:00	SPEAKER_02
 Okay.

0:56:01	SPEAKER_02
 But in that case, it's not relevant.

0:56:04	SPEAKER_02
 You would assume that they are roughly synchronized, not necessarily very precisely, and compared the energy levels.

0:56:14	SPEAKER_02
 But I have no experience with that.

0:56:16	SPEAKER_05
 Okay.

0:56:17	SPEAKER_02
 Yeah.

0:56:18	SPEAKER_02
 No, I don't know.

0:56:21	SPEAKER_02
 You don't want to use...

0:56:22	SPEAKER_02
 It's almost...

0:56:23	SPEAKER_02
 Okay.

0:56:24	SPEAKER_03
 Let's have a break.

0:56:25	SPEAKER_03
 Yes.

0:56:26	SPEAKER_03
 Thanks.

0:56:27	SPEAKER_03
 Cooler.

0:56:35	None
 I wanna say that on any individual part.

0:56:41	None
 I have to open this Cheeseotherado postglue with cold oil, It's simple, it actually is also nicely Signs clicked.

