{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "KJGBxqSfJ8lifI18i061TN",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/python/envs/my310/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "from transformers import pipeline\n",
    "\n",
    "# Verify GPU is active\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "# Utility functions\n",
    "def run_with_gpu(function, *extra_args, gpu=True, which_gpu=\"/GPU:0\"):\n",
    "    \"\"\"\n",
    "    Runs functions with CUDA accelerator\n",
    "    \"\"\"\n",
    "    if gpu:\n",
    "        with tf.device(which_gpu):\n",
    "            return function(*extra_args)\n",
    "    else:\n",
    "        return function(*extra_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "8me9LMzTcjFz3FZrskjRkS",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# Taken from https://github.com/yinruiqing/pyannote-whisper\n",
    "# Converts rttm data from pyannote.audio to create transcription\n",
    "from pyannote.core import Segment, Annotation, Timeline\n",
    "\n",
    "\n",
    "def get_text_with_timestamp(transcribe_res):\n",
    "    timestamp_texts = []\n",
    "    for item in transcribe_res['segments']:\n",
    "        start = item['start']\n",
    "        end = item['end']\n",
    "        text = item['text']\n",
    "        timestamp_texts.append((Segment(start, end), text))\n",
    "    return timestamp_texts\n",
    "\n",
    "\n",
    "def add_speaker_info_to_text(timestamp_texts, ann):\n",
    "    spk_text = []\n",
    "    for seg, text in timestamp_texts:\n",
    "        spk = ann.crop(seg).argmax()\n",
    "        spk_text.append((seg, spk, text))\n",
    "    return spk_text\n",
    "\n",
    "\n",
    "def merge_cache(text_cache):\n",
    "    sentence = ''.join([item[-1] for item in text_cache])\n",
    "    spk = text_cache[0][1]\n",
    "    start = text_cache[0][0].start\n",
    "    end = text_cache[-1][0].end\n",
    "    return Segment(start, end), spk, sentence\n",
    "\n",
    "\n",
    "PUNC_SENT_END = ['.', '?', '!']\n",
    "\n",
    "\n",
    "def merge_sentence(spk_text):\n",
    "    merged_spk_text = []\n",
    "    pre_spk = None\n",
    "    text_cache = []\n",
    "    for seg, spk, text in spk_text:\n",
    "        if spk != pre_spk and pre_spk is not None and len(text_cache) > 0:\n",
    "            merged_spk_text.append(merge_cache(text_cache))\n",
    "            text_cache = [(seg, spk, text)]\n",
    "            pre_spk = spk\n",
    "\n",
    "        elif text[-1] in PUNC_SENT_END:\n",
    "            text_cache.append((seg, spk, text))\n",
    "            merged_spk_text.append(merge_cache(text_cache))\n",
    "            text_cache = []\n",
    "            pre_spk = spk\n",
    "        else:\n",
    "            text_cache.append((seg, spk, text))\n",
    "            pre_spk = spk\n",
    "    if len(text_cache) > 0:\n",
    "        merged_spk_text.append(merge_cache(text_cache))\n",
    "    return merged_spk_text\n",
    "\n",
    "\n",
    "def diarize_text(transcribe_res, diarization_result):\n",
    "    timestamp_texts = get_text_with_timestamp(transcribe_res)\n",
    "    spk_text = add_speaker_info_to_text(timestamp_texts, diarization_result)\n",
    "    res_processed = merge_sentence(spk_text)\n",
    "    return res_processed\n",
    "\n",
    "\n",
    "def write_to_txt(spk_sent, file):\n",
    "    with open(file, 'w') as fp:\n",
    "        for seg, spk, sentence in spk_sent:\n",
    "            line = f'{seg.start:.2f} {seg.end:.2f} {spk} {sentence}\\n'\n",
    "            fp.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "dqJQzKF7e37KJFnJa4c7Zg",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]\r",
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.63k/1.63k [00:00<00:00, 1.03MB/s]\n",
      "\r",
      "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/1.63G [00:00<?, ?B/s]\r",
      "Downloading (…)\"pytorch_model.bin\";:   3%|▎         | 52.4M/1.63G [00:00<00:03, 442MB/s]\r",
      "Downloading (…)\"pytorch_model.bin\";:   6%|▋         | 105M/1.63G [00:00<00:03, 441MB/s] \r",
      "Downloading (…)\"pytorch_model.bin\";:  10%|▉         | 157M/1.63G [00:00<00:03, 456MB/s]\r",
      "Downloading (…)\"pytorch_model.bin\";:  13%|█▎        | 210M/1.63G [00:00<00:03, 462MB/s]\r",
      "Downloading (…)\"pytorch_model.bin\";:  16%|█▌        | 262M/1.63G [00:00<00:03, 447MB/s]\r",
      "Downloading (…)\"pytorch_model.bin\";:  20%|█▉        | 325M/1.63G [00:00<00:02, 479MB/s]\r",
      "Downloading (…)\"pytorch_model.bin\";:  24%|██▍       | 388M/1.63G [00:00<00:02, 503MB/s]\r",
      "Downloading (…)\"pytorch_model.bin\";:  27%|██▋       | 440M/1.63G [00:00<00:02, 480MB/s]\r",
      "Downloading (…)\"pytorch_model.bin\";:  30%|███       | 493M/1.63G [00:01<00:02, 467MB/s]\r",
      "Downloading (…)\"pytorch_model.bin\";:  34%|███▎      | 545M/1.63G [00:01<00:02, 426MB/s]\r",
      "Downloading (…)\"pytorch_model.bin\";:  37%|███▋      | 598M/1.63G [00:01<00:02, 444MB/s]\r",
      "Downloading (…)\"pytorch_model.bin\";:  41%|████      | 661M/1.63G [00:01<00:02, 471MB/s]\r",
      "Downloading (…)\"pytorch_model.bin\";:  44%|████▍     | 713M/1.63G [00:01<00:01, 463MB/s]\r",
      "Downloading (…)\"pytorch_model.bin\";:  47%|████▋     | 765M/1.63G [00:01<00:01, 456MB/s]\r",
      "Downloading (…)\"pytorch_model.bin\";:  50%|█████     | 818M/1.63G [00:01<00:01, 461MB/s]\r",
      "Downloading (…)\"pytorch_model.bin\";:  54%|█████▍    | 881M/1.63G [00:01<00:01, 496MB/s]\r",
      "Downloading (…)\"pytorch_model.bin\";:  58%|█████▊    | 944M/1.63G [00:01<00:01, 515MB/s]\r",
      "Downloading (…)\"pytorch_model.bin\";:  61%|██████▏   | 996M/1.63G [00:02<00:01, 496MB/s]\r",
      "Downloading (…)\"pytorch_model.bin\";:  65%|██████▍   | 1.05G/1.63G [00:02<00:01, 482MB/s]\r",
      "Downloading (…)\"pytorch_model.bin\";:  68%|██████▊   | 1.10G/1.63G [00:02<00:01, 425MB/s]\r",
      "Downloading (…)\"pytorch_model.bin\";:  72%|███████▏  | 1.16G/1.63G [00:02<00:00, 462MB/s]\r",
      "Downloading (…)\"pytorch_model.bin\";:  75%|███████▍  | 1.22G/1.63G [00:02<00:00, 471MB/s]\r",
      "Downloading (…)\"pytorch_model.bin\";:  78%|███████▊  | 1.27G/1.63G [00:02<00:01, 348MB/s]\r",
      "Downloading (…)\"pytorch_model.bin\";:  81%|████████  | 1.31G/1.63G [00:02<00:00, 336MB/s]\r",
      "Downloading (…)\"pytorch_model.bin\";:  83%|████████▎ | 1.35G/1.63G [00:03<00:00, 311MB/s]\r",
      "Downloading (…)\"pytorch_model.bin\";:  86%|████████▌ | 1.39G/1.63G [00:03<00:00, 328MB/s]\r",
      "Downloading (…)\"pytorch_model.bin\";:  89%|████████▉ | 1.45G/1.63G [00:03<00:00, 357MB/s]\r",
      "Downloading (…)\"pytorch_model.bin\";:  92%|█████████▏| 1.50G/1.63G [00:03<00:00, 388MB/s]\r",
      "Downloading (…)\"pytorch_model.bin\";:  95%|█████████▌| 1.55G/1.63G [00:03<00:00, 414MB/s]\r",
      "Downloading (…)\"pytorch_model.bin\";:  99%|█████████▊| 1.60G/1.63G [00:03<00:00, 423MB/s]\r",
      "Downloading (…)\"pytorch_model.bin\";: 100%|██████████| 1.63G/1.63G [00:03<00:00, 432MB/s]\n",
      "\r",
      "Downloading (…)okenizer_config.json:   0%|          | 0.00/300 [00:00<?, ?B/s]\r",
      "Downloading (…)okenizer_config.json: 100%|██████████| 300/300 [00:00<00:00, 183kB/s]\n",
      "\r",
      "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]\r",
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 798k/798k [00:00<00:00, 2.37MB/s]\r",
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 798k/798k [00:00<00:00, 2.35MB/s]\n",
      "\r",
      "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]\r",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 1.35MB/s]\r",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 1.35MB/s]\n",
      "\r",
      "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]\r",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 239/239 [00:00<00:00, 170kB/s]\n"
     ]
    }
   ],
   "source": [
    "def baseline_summary(path_to_source):\n",
    "    \"\"\"\n",
    "    :param path_to_source Path to raw .txt files.\n",
    "    Creates a summary and writes in the result of the summary in .json format\n",
    "    \"\"\"\n",
    "    summarizer = pipeline(\"summarization\", model=\"philschmid/bart-large-cnn-samsum\", truncation=True)\n",
    "\n",
    "    if not os.path.exists(\"./baseline_sum\"):\n",
    "        os.mkdir(\"./baseline_sum\")\n",
    "    for filename in glob.glob(f\"{path_to_source}*.txt\"):\n",
    "        txt_raw = filename.split(\"/\")[2].split(\".\")[0]\n",
    "        result_dict = {}\n",
    "        with open(filename, encoding=\"unicode_escape\") as f:\n",
    "            read_data = f.read()\n",
    "            result_dict[\"filename\"] = filename\n",
    "            result_dict[\"transcript\"] = read_data\n",
    "            result_dict[\"summary\"] = run_with_gpu(summarizer, read_data)\n",
    "        with open(f\"./baseline_sum/{txt_raw}.json\", \"w\") as fp:\n",
    "            json.dump(result_dict, fp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "baseline_summary(\"./data/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "G5rmhMenJjlKZY83pr1VIB",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "my310",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [
    {
     "name": "tensorflow",
     "source": "PIP",
     "version": "2.11.0"
    },
    {
     "name": "pyannote.audio",
     "source": "PIP",
     "version": "2.1.1"
    },
    {
     "name": "openai-whisper",
     "source": "PIP",
     "version": "20230124"
    },
    {
     "name": "ffmpeg-python",
     "source": "GIT",
     "url": "https://github.com/kkroening/ffmpeg-python@master",
     "version": "master"
    }
   ],
   "version": 1
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
