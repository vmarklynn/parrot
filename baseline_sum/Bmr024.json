{"filename": "./data/Bmr024.txt", "transcript": "0:00:00\tSPEAKER_04\n So we're on.\n\n0:00:02\tSPEAKER_04\n And somewhere is my agenda.\n\n0:00:05\tSPEAKER_04\n I think the most important thing is Morgan wanted to talk about the ARPA demo.\n\n0:00:10\tSPEAKER_09\n Well, so here's the thing.\n\n0:00:13\tSPEAKER_09\n Why don't we start off with, again, I'll get it.\n\n0:00:19\tSPEAKER_09\n I think we want to start off with the agenda.\n\n0:00:22\tSPEAKER_09\n And then given that, listen, Andreas, we're going to be 10, 15 minutes late.\n\n0:00:30\tSPEAKER_09\n We can try to figure out what we can do most effectively without them here.\n\n0:00:33\tSPEAKER_09\n So one thing is, yeah, talk about demo.\n\n0:00:36\tSPEAKER_04\n IBM transcription status.\n\n0:00:39\tSPEAKER_09\n IBM transcription.\n\n0:00:45\tSPEAKER_09\n What else?\n\n0:00:46\tSPEAKER_09\n SmartCom.\n\n0:00:49\tSPEAKER_09\n SmartCom.\n\n0:00:50\tSPEAKER_04\n What's SmartCom?\n\n0:00:51\tSPEAKER_04\n We want to talk about, we want to add the data to the meeting recorder corpus.\n\n0:00:56\tSPEAKER_05\n The data which we are collecting here.\n\n0:01:00\tSPEAKER_09\n What are we collecting here?\n\n0:01:03\tSPEAKER_04\n So why don't we have that on the agenda and we'll get to it and talk about it.\n\n0:01:06\tSPEAKER_09\n Yeah, right.\n\n0:01:09\tSPEAKER_09\n Right.\n\n0:01:13\tSPEAKER_04\n Reorganization status.\n\n0:01:16\tSPEAKER_09\n Reorganization status.\n\n0:01:19\tSPEAKER_09\n Files and directories.\n\n0:01:22\tSPEAKER_04\n Absent, which is the multi-processor Unix Linux.\n\n0:01:31\tSPEAKER_04\n I think it was, Andreas wanted to talk about segmentation and recognition.\n\n0:01:41\tSPEAKER_04\n And update on SRI recognition experiments.\n\n0:01:50\tSPEAKER_04\n And then if there's time I want to talk about digits, but it looked like we were pretty full, so I can wait till next week.\n\n0:01:56\tSPEAKER_09\n Right.\n\n0:01:59\tSPEAKER_09\n Well, let's see.\n\n0:02:01\tSPEAKER_09\n I think the segmentation recognition we want to maybe focus on when Andreas is here, since that was particularly his.\n\n0:02:07\tSPEAKER_09\n And also the small, smartCom also.\n\n0:02:10\tSPEAKER_09\n Andreas.\n\n0:02:11\tSPEAKER_09\n Absent, I think also he has sort of been involved in a lot of things.\n\n0:02:15\tSPEAKER_09\n At least he'll probably be interested.\n\n0:02:19\tSPEAKER_09\n So I mean, I think they'll be interested in all this, but probably if we had to pick something that we would talk on for 10 minutes or so while they're coming here, I guess it would be your organization status.\n\n0:02:33\tSPEAKER_04\n Yeah, I mean, I think Chuck was the one who added up the agenda item.\n\n0:02:37\tSPEAKER_04\n I don't really have anything to say of them, and we still haven't done it.\n\n0:02:39\tSPEAKER_10\n Well, I mean, just basically that maybe I said, maybe we said this before, just that we met and we talked about it and we sort of have a plan for getting things organized.\n\n0:02:50\tSPEAKER_01\n And I think crucial for that is that he's not wanting to do it until right before the next level zero back up,\n\n0:02:56\tSPEAKER_10\n so that there won't be any change. Right.\n\n0:03:01\tSPEAKER_10\n That was basically it.\n\n0:03:02\tSPEAKER_04\n Although Dave basically said that if we want to do it, just tell him and he'll do it level zero then.\n\n0:03:08\tSPEAKER_10\n So maybe we should just go ahead and get everything ready.\n\n0:03:11\tSPEAKER_04\n So I think we do need to talk a little bit about, well, we don't need to do it during this meeting.\n\n0:03:16\tSPEAKER_04\n We have a little more to discuss, but we're basically ready to do it.\n\n0:03:22\tSPEAKER_04\n And I have some web pages on more of the background.\n\n0:03:27\tSPEAKER_04\n So naming conventions and things like that, I've been trying to keep actually up to date.\n\n0:03:32\tSPEAKER_04\n And I've been sharing them with you, UW folks also.\n\n0:03:38\tSPEAKER_04\n Sharing them with the UW folks.\n\n0:03:43\tSPEAKER_09\n Okay. Well, maybe, since I was pretty sure when maybe we should talk about the IBM transcription status, I'm feeling there's an address later.\n\n0:03:52\tSPEAKER_04\n Okay. So we did another version of the beeps where we separated each beeps with spoken digit.\n\n0:03:59\tSPEAKER_04\n Chuck came up here and recorded some, himself speaking some digits.\n\n0:04:03\tSPEAKER_04\n And so it just goes beep, one beep, and then the phrase, and then beep, two beep, and then the phrase.\n\n0:04:08\tSPEAKER_04\n And that seems pretty good. I think they'll have an easier time keeping track of where they are in the file.\n\n0:04:14\tSPEAKER_06\n Maybe we have to on the automatic segmentation.\n\n0:04:17\tSPEAKER_04\n And we did it with the automatic segmentation. And I don't think we didn't look at it in detail.\n\n0:04:21\tSPEAKER_04\n We just sent it to IBM. We sort of spot checked it.\n\n0:04:24\tSPEAKER_10\n I listened to probably five or ten minutes of it from the beginning.\n\n0:04:29\tSPEAKER_04\n Oh, really? Okay. And I sort of spot checked here and there, and it sounded pretty good.\n\n0:04:33\tSPEAKER_04\n So I think it will work. And we'll just have to see what we get back from them.\n\n0:04:41\tSPEAKER_10\n The main thing will be if we can align what they give us with what we sent them.\n\n0:04:47\tSPEAKER_10\n I mean, that's the crucial part. Right? And I think we'll be able to do that with this new beep format.\n\n0:04:54\tSPEAKER_04\n Yep. Well, I think it's also there much less likely to have errors.\n\n0:05:00\tSPEAKER_04\n So the problem with last time is that there were errors in the transcripts where they put beeps where there weren't any.\n\n0:05:06\tSPEAKER_04\n And they put in extraneous beeps.\n\n0:05:08\tSPEAKER_04\n Yeah. And with the numbers there, it's much less likely.\n\n0:05:11\tSPEAKER_10\n Yeah, one interesting note is a problem. I don't know if this was just because of how I play it back.\n\n0:05:17\tSPEAKER_10\n I say, uh, SND play in in the file. Every once in a while, like a beep sounds like it's cut into two beats.\n\n0:05:23\tSPEAKER_10\n Yeah, I don't know if that's a hard effect of playback.\n\n0:05:27\tSPEAKER_10\n I don't think it's probably in that original file. I recommend that too.\n\n0:05:31\tSPEAKER_04\n That's interesting. I didn't hear that. Yeah.\n\n0:05:33\tSPEAKER_10\n But with this new format that hopefully they're not hearing that.\n\n0:05:38\tSPEAKER_10\n And if they are, it shouldn't throw them.\n\n0:05:41\tSPEAKER_04\n So well, maybe Vera was to it again. Make sure. But I mean, certainly the software shouldn't do that.\n\n0:05:46\tSPEAKER_10\n Yeah, that's what I thought. It's probably just, you know, somehow the audio device gets pickups in 30 seconds.\n\n0:05:53\tSPEAKER_06\n So they have one number and they know that there's only one beat next one.\n\n0:05:58\tSPEAKER_04\n Yeah. Yeah. The only part that might be confusing is when Chuck is reading digits.\n\n0:06:02\tSPEAKER_04\n Right.\n\n0:06:03\tSPEAKER_04\n Seven, four, eight, beep, seven, beep, eight, three, two.\n\n0:06:09\tSPEAKER_04\n Yes. Because we don't cut those out.\n\n0:06:12\tSPEAKER_04\n In order to cut them out, we'd have to listen to it. And we wanted to avoid doing that.\n\n0:06:16\tSPEAKER_04\n So they are transcribing the digits.\n\n0:06:18\tSPEAKER_04\n Although we can tell them or it.\n\n0:06:20\tSPEAKER_04\n We could tell them if you hear someone reading a digit string, just say bracket digit bracket and don't bother actually computing the did writing down the digits.\n\n0:06:29\tNone\n That'd be what I'm having the transcript.\n\n0:06:31\tNone\n It's here to visit.\n\n0:06:33\tSPEAKER_04\n Yeah. And then I wanted to talk about, but as I said, we may not have time.\n\n0:06:37\tSPEAKER_04\n What we should do about digits. We have a whole pile of digits that haven't been transcribed.\n\n0:06:40\tSPEAKER_09\n Let's talk about it because that's that's something that I know Andreas is less interested in.\n\n0:06:45\tSPEAKER_04\n Okay. Do we have anything else to say about transcription about IBM stuff?\n\n0:06:50\tSPEAKER_10\n Brian, I sent, I sent Brian a message about the meeting and I haven't heard back yet.\n\n0:06:57\tSPEAKER_10\n So I hope he got it and hopefully he's maybe he's gone. I don't know.\n\n0:07:01\tSPEAKER_10\n He didn't even reply to my message. So I should probably ping him just to make sure that he got it.\n\n0:07:07\tSPEAKER_04\n Right.\n\n0:07:08\tSPEAKER_04\n So we have a whole bunch of digits. I pretty want to move on to digits.\n\n0:07:15\tSPEAKER_09\n Actually, I want to relate more related thing in transcription. So that's the IBM stuff. We got that sorted out.\n\n0:07:18\tSPEAKER_09\n How are we doing on the on the rest of it?\n\n0:07:20\tSPEAKER_01\n I'm doing well. I hire two extra people already expected to hire two more.\n\n0:07:25\tSPEAKER_01\n I've prepared a set of five, which I'm calling set to, which are now being edited by my head transcribed in terms of spelling here as well.\n\n0:07:35\tSPEAKER_01\n She's also checking through and monitoring the transcription of another transcribed.\n\n0:07:41\tSPEAKER_01\n She's going through out of these kinds of checks.\n\n0:07:43\tSPEAKER_01\n And I've moved on now to one of the calling sets. I sort of thought if I do it and set through supply, then I can have like sort of a terrible processing through the current.\n\n0:07:53\tSPEAKER_01\n And I knew indicated to me that we have a goal now for the dark but demo of 20 hours.\n\n0:08:01\tSPEAKER_01\n So I'm going to go up to 20 hours. Be sure that everything that's processed and released.\n\n0:08:07\tSPEAKER_01\n And that's what level is. Package of 20 hours right now.\n\n0:08:11\tSPEAKER_01\n And once that's done, we'll have to do that.\n\n0:08:13\tSPEAKER_09\n Yeah. So 20 hours, but I guess the other thing is that that's kind of 20 hours ASAP because the longer before the demo, we actually have 20 hours. The more time it'll be for people to actually do cool things with it.\n\n0:08:27\tSPEAKER_01\n I don't think it's possible.\n\n0:08:36\tSPEAKER_01\n Thank you for accuracy.\n\n0:08:40\tSPEAKER_09\n Yeah.\n\n0:08:42\tSPEAKER_09\n Yeah. I mean, I guess the difference if the IBM stuff works out, the difference in the job would be that they primarily would be checking through things that were already done by someone else.\n\n0:08:56\tSPEAKER_04\n Incorrected. Correcting. We'll expect that they'll have to move some time bins and do some corrections.\n\n0:09:02\tSPEAKER_01\n And I've also discovered so with a new transcriber.\n\n0:09:06\tSPEAKER_01\n So let me say that like.\n\n0:09:11\tSPEAKER_01\n So at present, people have been doing these transcriptions at the channel all the time.\n\n0:09:17\tSPEAKER_01\n And that sort of is useful.\n\n0:09:20\tSPEAKER_01\n And once in a while they'll have to refer to the other channels to create something.\n\n0:09:24\tSPEAKER_01\n Well, I realized that we're using the pre-segmented version.\n\n0:09:29\tSPEAKER_01\n And the pre-segmented version is extremely useful.\n\n0:09:33\tSPEAKER_01\n And wouldn't it be useful also to have the visual representation of those segments?\n\n0:09:38\tSPEAKER_01\n And so I trained the new one, the newest one, to use the visual from the channel that is going to be transcribed at any given time.\n\n0:09:51\tSPEAKER_01\n And that's just amazing, we helpful. Because what happens then is you scan across the signal.\n\n0:09:56\tSPEAKER_01\n And once in a while you'll find a blip that didn't show up in the pre-segmentation.\n\n0:09:59\tSPEAKER_01\n Oh, right. I see what you mean.\n\n0:10:02\tSPEAKER_01\n And it's something like a back channeler.\n\n0:10:04\tSPEAKER_01\n Sometimes it seems to be similar to the ones that are being picked up.\n\n0:10:08\tSPEAKER_01\n And they're rare events, but you can really go through a meeting very quickly.\n\n0:10:12\tSPEAKER_01\n You just scroll from screen to screen looking for blips.\n\n0:10:17\tSPEAKER_01\n I think that we're going to end up with better coverage of the back channels, but at the same time we're benefiting tremendously for the pre-segmentation.\n\n0:10:23\tSPEAKER_01\n Because there are huge places where it's just absolutely no activity at all.\n\n0:10:28\tSPEAKER_10\n And the audio quality is...\n\n0:10:30\tSPEAKER_10\n So they can scroll through that pretty quick.\n\n0:10:33\tSPEAKER_10\n Yeah.\n\n0:10:34\tNone\n That's great.\n\n0:10:35\tSPEAKER_01\n So I think that that's going to also see the efficiency of this process.\n\n0:10:43\tSPEAKER_09\n Okay. Yeah.\n\n0:10:48\tSPEAKER_09\n So, yeah, so let's talk about the digits in the interior.\n\n0:10:53\tSPEAKER_04\n So we have a whole bunch of digits that we've read and we have the forms and so on.\n\n0:10:57\tSPEAKER_04\n But only a small number of that...well, not a small number.\n\n0:11:00\tSPEAKER_04\n Only a subset of that has been transcribed.\n\n0:11:03\tSPEAKER_04\n And so we need to decide what we want to do.\n\n0:11:05\tSPEAKER_04\n And Liz and Andreas, actually, they're not here, but they did say at one point that they thought they could do a pretty good job of just doing a forced alignment.\n\n0:11:12\tSPEAKER_04\n And again, I don't think we'll be able to do with that alone because sometimes people correct themselves and things like that.\n\n0:11:21\tSPEAKER_04\n But so I was just wondering what people thought about how automated can we make the process of finding where the people read the digits, doing a forced alignment and doing the timing.\n\n0:11:31\tSPEAKER_09\n Well, forced alignment would be one thing. What about just actually doing recognition?\n\n0:11:35\tSPEAKER_04\n Well, we know what they read because we have the forms.\n\n0:11:38\tSPEAKER_04\n No, they make mistakes.\n\n0:11:39\tSPEAKER_04\n Right. But the point is that we want to get a set of clean digits.\n\n0:11:46\tSPEAKER_10\n You're talking about it's a pre-processing step, right, Morgan?\n\n0:11:50\tSPEAKER_09\n Is that what you're hearing?\n\n0:11:51\tSPEAKER_09\n I'm not quite sure what I'm talking about.\n\n0:11:53\tSPEAKER_09\n I mean, we're talking about digits now.\n\n0:11:56\tSPEAKER_09\n And so there's a bunch of stuff that hasn't been marked yet.\n\n0:12:03\tSPEAKER_09\n And it's the one option.\n\n0:12:10\tSPEAKER_09\n I was just asking you to start a curiosity.\n\n0:12:13\tSPEAKER_09\n If with the SRI recognized that we're getting 1% word error, would we do better?\n\n0:12:22\tSPEAKER_09\n So if you do a forced alignment, but the transcription you have is wrong because they actually made mistakes.\n\n0:12:28\tSPEAKER_09\n But that's pretty uncommon.\n\n0:12:29\tSPEAKER_09\n It's much less common than 1%.\n\n0:12:36\tSPEAKER_04\n If we could really get 1% on, well, I guess if we segmented it, we could get 1% on digits.\n\n0:12:43\tSPEAKER_09\n Yeah. So that's just my question.\n\n0:12:45\tSPEAKER_09\n I'm not saying it should be one way or the other, but it's...\n\n0:12:47\tSPEAKER_04\n Well, there are a couple different ways of doing it.\n\n0:12:49\tSPEAKER_04\n We could use the tools I've already developed and transcribe it.\n\n0:12:51\tSPEAKER_04\n Hire some people or use the transcribers to do it.\n\n0:12:53\tSPEAKER_04\n We could let IBM transcribe it.\n\n0:12:56\tSPEAKER_04\n They're doing it anyway, and unless we tell them different, they're going to transcribe it.\n\n0:13:00\tSPEAKER_04\n Or we could try some automated methods.\n\n0:13:04\tSPEAKER_04\n Well, my tendency right now is, well, if IBM comes back with this meeting and the transcript is good, just let them do it.\n\n0:13:12\tSPEAKER_09\n Yeah, you raised a point kind of...\n\n0:13:15\tSPEAKER_09\n You've missed it, but maybe it is a serious problem.\n\n0:13:18\tSPEAKER_09\n What will they do when they go?\n\n0:13:19\tSPEAKER_09\n Here beep, 7, beep, 7, 3, 5, 2...\n\n0:13:22\tSPEAKER_09\n I mean, you think though...\n\n0:13:26\tSPEAKER_12\n It's pretty distinct. The beeps are pre-ordered from mine.\n\n0:13:30\tNone\n I'll let me proceed by reading transcripts.\n\n0:13:32\tSPEAKER_04\n So also...\n\n0:13:33\tNone\n Yes.\n\n0:13:34\tSPEAKER_04\n I mean, it will be in the midst of a digit string.\n\n0:13:38\tSPEAKER_04\n Sure, there might be a place where it's beep, 7, beep, 8, beep, 8, beep.\n\n0:13:46\tSPEAKER_04\n But they're going to have macros for inserting the beep marks.\n\n0:13:50\tSPEAKER_04\n And so I don't think it will be a problem. We'll have to see it, but I don't think it's going to be a problem.\n\n0:13:54\tSPEAKER_09\n Okay. Well, I don't know. I think that if they are, in fact, going to transcribe these things, certainly any process that we'd have to correct them or whatever needs to be much less elaborate for digits.\n\n0:14:07\tSPEAKER_09\n Right.\n\n0:14:08\tSPEAKER_09\n For other stuff, so why not?\n\n0:14:12\tSPEAKER_09\n That was it?\n\n0:14:13\tSPEAKER_04\n That was it. Just what do we do with digits? We have so many of them.\n\n0:14:16\tSPEAKER_04\n That would be nice to actually do something with them.\n\n0:14:18\tSPEAKER_05\n Yeah.\n\n0:14:20\tSPEAKER_05\n Your mic is a little lower.\n\n0:14:22\tSPEAKER_09\n And Berkeley, yeah.\n\n0:14:24\tSPEAKER_09\n So...\n\n0:14:26\tSPEAKER_09\n You have to go early, right?\n\n0:14:29\tSPEAKER_07\n Well, I think about...\n\n0:14:32\tSPEAKER_07\n Speak 40.\n\n0:14:33\tSPEAKER_09\n All right. So let's make sure we do the ones that...\n\n0:14:36\tSPEAKER_09\n So there are some...\n\n0:14:38\tSPEAKER_09\n In...\n\n0:14:39\tSPEAKER_09\n In Adams's agenda list, he had something from you about segmentation in the last record.\n\n0:14:44\tSPEAKER_07\n Well, yeah. So this is just...\n\n0:14:48\tSPEAKER_07\n Partly to form everybody and help us to get input.\n\n0:14:52\tSPEAKER_07\n So we had a discussion...\n\n0:14:56\tSPEAKER_07\n And I had a discussion actually about how to proceed with...\n\n0:15:00\tSPEAKER_07\n With Don's work and...\n\n0:15:03\tSPEAKER_07\n And one of the obvious things that occurred to us was that...\n\n0:15:08\tSPEAKER_07\n We were, since we now have feelings, segmentation, and it works, you know, amazingly well.\n\n0:15:13\tSPEAKER_07\n We should actually basically re-evaluate the recognition...\n\n0:15:17\tSPEAKER_07\n And results using, you know, without cheating on segmentation.\n\n0:15:23\tSPEAKER_06\n And so...\n\n0:15:25\tSPEAKER_06\n And how do we find the transcripts for those?\n\n0:15:27\tSPEAKER_06\n So the...\n\n0:15:29\tSPEAKER_06\n Yeah. The reference is for the segment.\n\n0:15:31\tSPEAKER_06\n That's not that...\n\n0:15:33\tSPEAKER_02\n Yeah, again.\n\n0:15:34\tSPEAKER_07\n And once.\n\n0:15:36\tSPEAKER_07\n It's a very sophisticated scoring program.\n\n0:15:39\tSPEAKER_07\n That you can give a...\n\n0:15:43\tSPEAKER_07\n A time...\n\n0:15:45\tSPEAKER_07\n You know, you basically just give two time mark sequences of words.\n\n0:15:51\tSPEAKER_07\n And it computes...\n\n0:15:53\tSPEAKER_10\n You know, it does all the work for you.\n\n0:15:57\tSPEAKER_07\n So we just...\n\n0:15:59\tSPEAKER_07\n And we use that actually in half-five to do a scoring.\n\n0:16:03\tSPEAKER_07\n So what we've been using so far was sort of a simplified version of the scoring.\n\n0:16:07\tSPEAKER_07\n And we can handle the type of problem we have here.\n\n0:16:11\tSPEAKER_06\n So basically you give some time constraints for references and for the hypothesis.\n\n0:16:16\tSPEAKER_08\n Yeah, maybe the start of your speech in the end of it or something like that.\n\n0:16:20\tSPEAKER_07\n It does time constraint where you line up.\n\n0:16:22\tSPEAKER_07\n Okay.\n\n0:16:24\tSPEAKER_07\n So that should be possible.\n\n0:16:26\tSPEAKER_07\n I mean, that should be...\n\n0:16:28\tSPEAKER_07\n So that was the one thing and the other was that...\n\n0:16:32\tSPEAKER_07\n Of course, you got a problem. Oh, that Taylor wanted to use the recognize or linements to train up his speech detector.\n\n0:16:40\tSPEAKER_07\n So that you could use...\n\n0:16:43\tSPEAKER_07\n You know, there would be so much hand labeling that to generate training data.\n\n0:16:49\tSPEAKER_06\n Yeah, I'm just in progress of doing that.\n\n0:16:51\tSPEAKER_06\n And I think you're in the positive way that...\n\n0:16:53\tSPEAKER_10\n I'll give you a lot more data, too, I want it.\n\n0:16:56\tSPEAKER_06\n So it's basically, I think, eight meetings or something which I'm using.\n\n0:17:00\tSPEAKER_06\n Before it was 20 minutes of one meeting, so...\n\n0:17:04\tSPEAKER_06\n It should be a little bit more.\n\n0:17:06\tSPEAKER_07\n The alignment's already perfect.\n\n0:17:08\tSPEAKER_07\n Yeah, but it's probably still better than all this extra data.\n\n0:17:11\tSPEAKER_06\n We'll see that.\n\n0:17:16\tSPEAKER_08\n Actually, I had a question about that.\n\n0:17:18\tSPEAKER_08\n If you find that you can lower the false alarms that you get where there's no speech, that would be useful for us to know.\n\n0:17:27\tSPEAKER_08\n There were the false alarms.\n\n0:17:30\tSPEAKER_08\n Right now you get false speech regions when it's just like a breath or something like that.\n\n0:17:38\tSPEAKER_08\n And I'm interested to know that if you retrain, do those actually go down or not?\n\n0:17:43\tSPEAKER_06\n Yeah, I can make it comparison of the old system to the new...\n\n0:17:48\tSPEAKER_08\n Yeah, just to see if by doing nothing in the modeling of just having that training data, what happens?\n\n0:17:53\tSPEAKER_09\n Yeah, another one that we had on the Adams agenda that definitely involved you with something about SmartCom.\n\n0:18:02\tSPEAKER_04\n Right, so Rob Porzel and the...\n\n0:18:06\tSPEAKER_04\n Porzel and the SmartCom group are collecting some dialogues.\n\n0:18:10\tSPEAKER_04\n Basically, they have one person sitting in here looking at a picture and a wizard sitting in another room somewhere.\n\n0:18:17\tSPEAKER_04\n And they're doing a travel task.\n\n0:18:20\tSPEAKER_04\n And it involves starting. I believe starting with a...\n\n0:18:24\tSPEAKER_04\n It's always the wizard, but it starts where the wizard is pretending to be a computer and it goes through a speech generation system.\n\n0:18:31\tSPEAKER_06\n Yeah, actually it's changed to a synthesis system.\n\n0:18:34\tSPEAKER_04\n A synthesis system.\n\n0:18:36\tSPEAKER_04\n And then it goes to a real wizard and they're evaluating that.\n\n0:18:39\tSPEAKER_04\n And they wanted to use this equipment.\n\n0:18:41\tSPEAKER_04\n And so what the question came up is, well, here's some more data.\n\n0:18:44\tSPEAKER_04\n Should this be part of the corpus or not?\n\n0:18:46\tSPEAKER_04\n And my attitude was yes, because there might be people who are using this corpus for acoustics as opposed to just for language.\n\n0:18:54\tSPEAKER_04\n Or also for dialogue of various sorts.\n\n0:18:57\tSPEAKER_04\n So it's not a meeting, right, because it's two people and they're not face to face.\n\n0:19:01\tSPEAKER_09\n So I just wanted to understand, because I haven't quite followed this process.\n\n0:19:08\tSPEAKER_09\n So it's wizard in the usual sense that the person who is asking questions doesn't know that it's a machine.\n\n0:19:15\tSPEAKER_09\n At the beginning.\n\n0:19:17\tSPEAKER_07\n I don't know who came up with the flip, but I think it's a little out of the end.\n\n0:19:21\tSPEAKER_07\n We simulate a computer breakdown and go through the session.\n\n0:19:25\tSPEAKER_07\n So after that, the person's told that they're now talking to a...\n\n0:19:28\tSPEAKER_05\n To a human operator.\n\n0:19:30\tSPEAKER_04\n Of course they don't know that it's the same person both times.\n\n0:19:33\tSPEAKER_07\n Computer and computer data are the same.\n\n0:19:37\tSPEAKER_09\n You might want to try collecting it the other way around sometimes saying that the computer isn't up yet.\n\n0:19:45\tSPEAKER_09\n So then separate out whether it's the beginning or end.\n\n0:19:47\tSPEAKER_04\n I have to go now. You can talk to the computer.\n\n0:19:50\tSPEAKER_10\n So if you tell them that the computer part is running on a Windows machine, a breakdown thing kind of makes sense.\n\n0:19:57\tSPEAKER_11\n A birthday try fail.\n\n0:20:01\tSPEAKER_08\n So do they actually save the far field data?\n\n0:20:04\tSPEAKER_04\n That's the question. So they were saying they were not going to.\n\n0:20:07\tSPEAKER_04\n Well, let's silly if we're going to try to do it for a corpus.\n\n0:20:10\tSPEAKER_04\n There might be people who are interested in acoustics.\n\n0:20:13\tSPEAKER_06\n We were not saying we're not doing it.\n\n0:20:16\tSPEAKER_07\n We just wanted to do it.\n\n0:20:19\tSPEAKER_04\n I see no reason not to do all of them.\n\n0:20:21\tSPEAKER_04\n That if we have someone who is doing acoustic studies, it's nice to have the same for every recording.\n\n0:20:27\tSPEAKER_09\n So what is the purpose of this recording?\n\n0:20:30\tSPEAKER_09\n The acoustic and language model.\n\n0:20:36\tSPEAKER_09\n Training data for smart time.\n\n0:20:39\tSPEAKER_08\n We can have him vary the microphones.\n\n0:20:41\tSPEAKER_04\n For their usage, they don't need anything.\n\n0:20:44\tSPEAKER_05\n But I'm going to try about the legal aspect of that.\n\n0:20:47\tSPEAKER_05\n Is there some contract with smart come or something about the data?\n\n0:20:51\tSPEAKER_05\n Is that our data?\n\n0:20:53\tSPEAKER_09\n We've never signed anything that said that we couldn't use it.\n\n0:20:56\tSPEAKER_05\n That's the question.\n\n0:21:02\tSPEAKER_09\n That's not a problem.\n\n0:21:04\tSPEAKER_09\n It seems to me that if we're doing it anyway and we're doing it for the purposes that we have, and we have these distant mics, we should save it all as long as we've got this space.\n\n0:21:14\tSPEAKER_09\n This is pretty cheap.\n\n0:21:16\tSPEAKER_09\n We save it because it's potentially useful.\n\n0:21:20\tSPEAKER_09\n Now what do we do with it?\n\n0:21:23\tSPEAKER_09\n Anybody who's training something up could choose to include this or not.\n\n0:21:28\tSPEAKER_09\n I would not say it was part of the meetings corpus.\n\n0:21:31\tSPEAKER_09\n But it's some other data we have.\n\n0:21:33\tSPEAKER_09\n If somebody doing an experiment wants to train up including that, then they can.\n\n0:21:37\tSPEAKER_04\n I guess it begs the question of what is the meeting corpus.\n\n0:21:44\tSPEAKER_04\n If at UW, they start recording two person, how many conversations is that part of the meeting corpus?\n\n0:21:52\tSPEAKER_09\n I think the idea of two or more people conversing with one another is key.\n\n0:21:56\tSPEAKER_04\n Well this has two or more people conversing with each other.\n\n0:21:59\tSPEAKER_08\n We just give it a name.\n\n0:22:02\tSPEAKER_08\n That was my intention.\n\n0:22:03\tSPEAKER_08\n Later on some people will consider it a meeting.\n\n0:22:06\tSPEAKER_04\n That was my intention.\n\n0:22:07\tSPEAKER_04\n Part of the reason that I wanted to bring this up is do we want to handle it as a special case?\n\n0:22:12\tSPEAKER_04\n Or do we want to fold it in?\n\n0:22:14\tSPEAKER_04\n Would give everyone who's involved as their own user ID, give it session IDs, and all the tools that handle meeting record or handle it, or do we want a special case?\n\n0:22:23\tSPEAKER_04\n If we're going to special case it, who's going to do that?\n\n0:22:26\tSPEAKER_07\n It's the next answer to the handler with the same infrastructure since we don't want to do the meetings necessarily.\n\n0:22:32\tSPEAKER_07\n But as far as distributing it, we shouldn't label it as part of this meeting corpus.\n\n0:22:37\tSPEAKER_04\n I don't see why not.\n\n0:22:38\tSPEAKER_04\n It's just a different topic.\n\n0:22:40\tSPEAKER_01\n It's a scenario based.\n\n0:22:50\tSPEAKER_09\n It's human computer interface.\n\n0:22:53\tSPEAKER_09\n It's really pretty different.\n\n0:22:55\tSPEAKER_09\n But I have no problem with somebody folding it in for some experiment they're going to do.\n\n0:22:59\tSPEAKER_09\n But I don't think it doesn't match anything that we've described about meetings.\n\n0:23:03\tSPEAKER_09\n Whereas everything that we talked about them doing at UW and so forth really does.\n\n0:23:07\tSPEAKER_04\n So what does that mean for how we're going to organize things?\n\n0:23:11\tSPEAKER_09\n Again, as I think Andres was saying, if you want to use the same tools and the same conventions, there's no problem with that.\n\n0:23:19\tSPEAKER_09\n It's just that it's a different directory.\n\n0:23:21\tSPEAKER_09\n It's called something different.\n\n0:23:22\tSPEAKER_09\n It is different.\n\n0:23:24\tSPEAKER_09\n You can't just fold it in as if it's, I mean, digits are different too, right?\n\n0:23:27\tSPEAKER_04\n Yeah, but those are folded in and you just mark the transcripts differently.\n\n0:23:30\tSPEAKER_04\n So one option is you fold it in and just simply in the file, you mark somewhere that this is this type of interaction rather than another type of interaction.\n\n0:23:39\tSPEAKER_09\n Well, I wouldn't call reading digits meetings, right?\n\n0:23:43\tSPEAKER_09\n I mean, we have to do it.\n\n0:23:44\tSPEAKER_04\n But I put it under the same directory tree.\n\n0:23:47\tSPEAKER_04\n It's in user doctors, speech data, and more.\n\n0:23:49\tSPEAKER_08\n You just have to have it called like other stuff and other.\n\n0:23:52\tSPEAKER_08\n Well, I don't know.\n\n0:23:53\tSPEAKER_08\n I mean, I don't care what the directory is.\n\n0:23:55\tSPEAKER_09\n I mean, that's just.\n\n0:23:56\tSPEAKER_04\n My preference is to have a single procedure so that I don't have to think too much about things and just have a marking.\n\n0:24:03\tSPEAKER_04\n If we do it any other way, that means that we need a separate procedure.\n\n0:24:06\tSPEAKER_04\n If you're someone who has to do that.\n\n0:24:07\tSPEAKER_09\n And so whatever procedure you want that's convenient for you, all I'm saying is that there's no way that we're going to tell people that reading digits is meetings.\n\n0:24:13\tSPEAKER_09\n Right.\n\n0:24:14\tSPEAKER_09\n And similarly, we're not going to tell them that someone talking to a computer to get travel information is meetings.\n\n0:24:18\tSPEAKER_09\n Those aren't meetings.\n\n0:24:20\tSPEAKER_09\n But if it makes it easier for you to put fold them in the same procedures and have them on the same directory tree and act yourself out.\n\n0:24:25\tSPEAKER_10\n There's a couple other questions that I have too.\n\n0:24:28\tSPEAKER_10\n And one of them is what about consent issues?\n\n0:24:31\tSPEAKER_10\n And the other one is what about transcription?\n\n0:24:33\tSPEAKER_10\n Transcription is not a Munich.\n\n0:24:35\tSPEAKER_10\n Okay, so we don't have to worry about transcription.\n\n0:24:37\tSPEAKER_04\n So we will have to worry about format.\n\n0:24:39\tSPEAKER_07\n So that's an argument to keep it separate because it's going to follow the smart contrast description.\n\n0:24:43\tSPEAKER_07\n Oh, okay.\n\n0:24:44\tSPEAKER_07\n Okay, well, I didn't realize that.\n\n0:24:46\tSPEAKER_04\n That's a good point.\n\n0:24:48\tSPEAKER_09\n But I'm sure no one would have a problem with our folding it in for some acoustic modeling or something.\n\n0:24:54\tSPEAKER_09\n Do we have American-born folk reading German, German place names and so forth?\n\n0:25:04\tSPEAKER_09\n Yep, yep, yep.\n\n0:25:05\tSPEAKER_04\n Great.\n\n0:25:06\tSPEAKER_04\n They even have a reading bus.\n\n0:25:07\tSPEAKER_05\n That sounds good, right?\n\n0:25:09\tSPEAKER_05\n You can do that if you want.\n\n0:25:11\tSPEAKER_09\n I don't know if you want that.\n\n0:25:13\tSPEAKER_09\n So...\n\n0:25:14\tSPEAKER_09\n High-dollberg.\n\n0:25:18\tSPEAKER_04\n Disk might eventually be an issue.\n\n0:25:20\tSPEAKER_04\n So we might...\n\n0:25:21\tSPEAKER_04\n Yeah, I'd be pretty good.\n\n0:25:23\tSPEAKER_04\n We might need to get some more disk pretty soon.\n\n0:25:27\tSPEAKER_04\n We're about half way through our disk right now.\n\n0:25:31\tSPEAKER_04\n Are we only half?\n\n0:25:32\tSPEAKER_04\n I thought we were more than that.\n\n0:25:33\tSPEAKER_04\n We're probably a little more than that because we're using up some space that we shouldn't be on.\n\n0:25:37\tSPEAKER_04\n So once everything gets converted over to the disks we're supposed to be using, we'll be probably 75%.\n\n0:25:43\tSPEAKER_10\n Well, when I was looking for space for Tilo, I found one disk that had...\n\n0:25:48\tSPEAKER_10\n I think it was nine gigs and another one had 17.\n\n0:25:51\tSPEAKER_10\n And everything else was sort of committed.\n\n0:25:54\tSPEAKER_04\n Were those backed up or non-backed up?\n\n0:25:57\tSPEAKER_04\n Those were non-backed.\n\n0:25:59\tSPEAKER_04\n Right, so that's different.\n\n0:26:00\tSPEAKER_04\n So you're talking about backed up?\n\n0:26:02\tSPEAKER_04\n I'm much more concerned about the backed up than non-backed up.\n\n0:26:04\tSPEAKER_04\n I haven't looked to see how much of that is.\n\n0:26:06\tSPEAKER_04\n It's cheap.\n\n0:26:07\tSPEAKER_04\n I mean, if we need to, we can buy a disk, hang it off a workstation.\n\n0:26:10\tSPEAKER_04\n If it's not backed up, the citizens don't care too much.\n\n0:26:13\tSPEAKER_09\n Yeah, so I mean, pretty much anytime we need a disk we can get it at the right thing we're...\n\n0:26:17\tSPEAKER_07\n I'm sure we're saying this, but you can just...\n\n0:26:21\tSPEAKER_07\n You know, since the backed up so every night you can recycle the backed up.\n\n0:26:26\tSPEAKER_04\n Yeah, but that's risky.\n\n0:26:28\tSPEAKER_00\n Yeah, you really should say that.\n\n0:26:30\tSPEAKER_00\n I didn't say that.\n\n0:26:31\tSPEAKER_04\n Yeah, that's right.\n\n0:26:32\tSPEAKER_09\n Detail out.\n\n0:26:33\tSPEAKER_09\n We can't allow Dave to listen to these recordings.\n\n0:26:37\tSPEAKER_09\n Yeah, and there's been this conversation going on about getting another file server.\n\n0:26:43\tSPEAKER_09\n And we do that, we'll take the opportunity and get another big raft of disk, I guess.\n\n0:26:49\tSPEAKER_04\n Well, it's really the backup issue rather than the file server issue.\n\n0:26:53\tSPEAKER_07\n You can use our old file server for this to have data that is very fairly accessed.\n\n0:26:59\tSPEAKER_07\n And then have the fast new file server for data that is heavily...\n\n0:27:04\tSPEAKER_04\n My understanding is the issue isn't really the file server.\n\n0:27:07\tSPEAKER_04\n We could always put more disks on...\n\n0:27:09\tSPEAKER_04\n It's the backup system, which is near saturation, apparently.\n\n0:27:14\tSPEAKER_10\n So, I think the file server could become an issue as we get a whole bunch more new compute machines and we've got, you know, 50 machines trying to access data off of that.\n\n0:27:27\tSPEAKER_04\n But we're all right for now because the network's so slow.\n\n0:27:30\tSPEAKER_07\n I think we've tried more, and someone said this is not reliable.\n\n0:27:34\tSPEAKER_07\n We were going to do it back to the...\n\n0:27:36\tSPEAKER_07\n What about putting the stuff on me?\n\n0:27:38\tSPEAKER_04\n Yeah, that was me.\n\n0:27:40\tSPEAKER_04\n I was the one who said it was not reliable. They were out.\n\n0:27:44\tSPEAKER_04\n Yeah, the...\n\n0:27:45\tSPEAKER_04\n But they're out just from sitting on the shelf?\n\n0:27:47\tSPEAKER_04\n Yep, absolutely.\n\n0:27:48\tSPEAKER_04\n No.\n\n0:27:49\tSPEAKER_04\n Reading right don't hurt them too much unless you scratch them.\n\n0:27:51\tSPEAKER_04\n But the right ones and the read rights don't last.\n\n0:27:56\tSPEAKER_04\n So you don't want to put your un reproducible data on them.\n\n0:28:01\tSPEAKER_10\n We're out after what amount of time you're at two.\n\n0:28:05\tSPEAKER_09\n You're at two?\n\n0:28:07\tSPEAKER_07\n Wow.\n\n0:28:08\tSPEAKER_07\n But if that venue would...\n\n0:28:10\tSPEAKER_07\n Thank you, here much more, I'm planning about...\n\n0:28:13\tNone\n Yeah.\n\n0:28:14\tSPEAKER_07\n They're awesome.\n\n0:28:15\tNone\n I mean, yeah.\n\n0:28:16\tSPEAKER_04\n I don't know many people who do it on CD.\n\n0:28:19\tSPEAKER_04\n I mean, they're with the most...\n\n0:28:20\tSPEAKER_09\n All the LDC distributions are on CD, right?\n\n0:28:22\tSPEAKER_09\n They're on CD, but they're not...\n\n0:28:24\tSPEAKER_04\n That's not the only source. They have them on disk.\n\n0:28:27\tSPEAKER_04\n And they burn new ones every once in a while.\n\n0:28:29\tSPEAKER_04\n But if you go...\n\n0:28:30\tSPEAKER_08\n Or we have like 30, you know, from 10 years old?\n\n0:28:32\tSPEAKER_08\n No.\n\n0:28:33\tSPEAKER_00\n Yeah, 10 years old, 91.\n\n0:28:34\tSPEAKER_00\n And they're still all fine.\n\n0:28:35\tSPEAKER_08\n They're under where they press.\n\n0:28:37\tSPEAKER_08\n I both. I've burned them and they're still okay.\n\n0:28:38\tSPEAKER_04\n I mean, you...\n\n0:28:39\tSPEAKER_04\n The last ones last for...\n\n0:28:40\tSPEAKER_04\n Well, not forever. They've been finding even those degrade.\n\n0:28:42\tSPEAKER_04\n Oh, see.\n\n0:28:43\tSPEAKER_04\n But the burned ones...\n\n0:28:44\tSPEAKER_04\n I mean, when I say two or three years what I'm saying is that I have had disks which are gone in a year.\n\n0:28:49\tSPEAKER_04\n On the average, it'll probably be three or four years.\n\n0:28:53\tSPEAKER_04\n But you don't want to have your only copy on a media that fails.\n\n0:29:00\tSPEAKER_04\n And they do.\n\n0:29:01\tSPEAKER_04\n If you haven't professionally pressed, you know, they're good for decades.\n\n0:29:04\tSPEAKER_07\n So how about putting them on that plus, like, on that or some other media?\n\n0:29:10\tSPEAKER_04\n I think we can already put them on tape.\n\n0:29:14\tSPEAKER_04\n And the tape is very reliable.\n\n0:29:17\tSPEAKER_04\n So the only issue is then if we need access to them.\n\n0:29:20\tSPEAKER_04\n So that's fine if we don't need access to them.\n\n0:29:22\tSPEAKER_07\n Well, if they last say they actually last like five years.\n\n0:29:28\tSPEAKER_07\n And occasionally you might need to regrade one.\n\n0:29:31\tSPEAKER_07\n And then you get your tape on the other way or two.\n\n0:29:36\tSPEAKER_07\n And you just put them on.\n\n0:29:39\tSPEAKER_00\n So just archive it on the tape and then play them CDs one.\n\n0:29:44\tSPEAKER_04\n Oh, so you're just saying put them on CDs for normal access.\n\n0:29:48\tSPEAKER_04\n Yeah.\n\n0:29:49\tSPEAKER_04\n I mean, you can do that, but that's pretty annoying because the CDs are so slow.\n\n0:29:53\tSPEAKER_10\n Yeah.\n\n0:29:54\tSPEAKER_10\n It would be nice as a system that re-burned the CDs every year.\n\n0:29:57\tSPEAKER_10\n Every time it would.\n\n0:29:58\tSPEAKER_10\n The CDs are an obstacle.\n\n0:30:01\tSPEAKER_08\n Just before it goes bad.\n\n0:30:04\tSPEAKER_04\n The CD is an alternative to tape.\n\n0:30:06\tSPEAKER_04\n XC already has a perfectly good tape system and it's more reliable.\n\n0:30:09\tSPEAKER_04\n So for archiving, we'll just use tape.\n\n0:30:11\tSPEAKER_07\n I would think you're saying this.\n\n0:30:12\tSPEAKER_07\n If you have the data, if the meeting data is put on this exactly once.\n\n0:30:18\tSPEAKER_07\n And it's back that once and the backup system should never have to work with it.\n\n0:30:22\tSPEAKER_04\n Regardless, well, first of all, there was a problem with the archive in that I was every once in a while doing a Chimaud on all the directories, a recursive Chimaud and Chone because they weren't getting set correctly every once in a while.\n\n0:30:36\tSPEAKER_04\n And I was just doing a minus R star, not realizing that that caused it to be re-backed up.\n\n0:30:42\tSPEAKER_04\n But normally you're correct, but even without that, the backup system is becoming saturated.\n\n0:30:48\tSPEAKER_07\n But the backup system is smart enough to figure out that something hasn't changed.\n\n0:30:52\tSPEAKER_04\n Sure, but we still have enough changed that the nightly backups are starting to take too long.\n\n0:30:58\tSPEAKER_09\n I think at least the ones that you put it on.\n\n0:31:02\tSPEAKER_09\n It has nothing to do with the meeting.\n\n0:31:04\tSPEAKER_04\n It's just the general XC backup system is becoming saturated.\n\n0:31:07\tSPEAKER_07\n So what if we buy, what do they call this?\n\n0:31:11\tSPEAKER_04\n Why don't you have this conversation with Dave Johnson rather than with me?\n\n0:31:15\tSPEAKER_07\n Maybe something that we can do without involved in Dave and putting more work on that.\n\n0:31:20\tSPEAKER_07\n How about we buy one of these high density tape drives.\n\n0:31:24\tSPEAKER_07\n And we put the data actually on non-backed up disks.\n\n0:31:28\tSPEAKER_07\n And we do our own backup once and for all.\n\n0:31:31\tSPEAKER_04\n And then we don't have to embark on that.\n\n0:31:33\tSPEAKER_04\n Actually, you know, we could do that just with the tape, with the current tape.\n\n0:31:35\tSPEAKER_07\n I don't know what these tapes, at some point, I don't know what kind of tape I'm going to do.\n\n0:31:40\tSPEAKER_04\n I don't know, but it's an automatic robot, so it's very convenient.\n\n0:31:42\tSPEAKER_04\n You just run a program to restore them.\n\n0:31:44\tSPEAKER_04\n The one that we have.\n\n0:31:45\tSPEAKER_09\n Yeah.\n\n0:31:46\tSPEAKER_09\n Am I going to fit with their backups?\n\n0:31:47\tSPEAKER_09\n No, we have something that isn't used by the backup gang.\n\n0:31:52\tSPEAKER_09\n Don't we have something downstairs?\n\n0:31:54\tSPEAKER_09\n Kind of tapes drive.\n\n0:31:56\tSPEAKER_04\n But Andreas' point is a good one.\n\n0:31:58\tSPEAKER_04\n And we don't have to do anything ourselves to do that.\n\n0:32:00\tSPEAKER_04\n They're already right now on tape.\n\n0:32:02\tSPEAKER_04\n So your point is, and I think it's a good one, that we could just get more disk and put it there.\n\n0:32:07\tSPEAKER_04\n That's not a bad idea.\n\n0:32:10\tSPEAKER_09\n Yeah, that's basically what I was going to say is that disk is so cheap.\n\n0:32:15\tSPEAKER_09\n It's essentially close to free.\n\n0:32:18\tSPEAKER_09\n So one thing that costs is the backup issue into first order.\n\n0:32:22\tSPEAKER_09\n And we can take care of that by putting it on non-backed up drives and just backing it up once onto this thing.\n\n0:32:28\tSPEAKER_09\n I think that's a good idea.\n\n0:32:29\tSPEAKER_09\n Yeah, good.\n\n0:32:30\tSPEAKER_08\n So who's going to do these backups?\n\n0:32:32\tSPEAKER_08\n The people that collect it?\n\n0:32:33\tSPEAKER_04\n Well, I'll talk to Dave and see what the best way of doing that is.\n\n0:32:40\tSPEAKER_04\n It's a little utility that will manually burn a tape for you.\n\n0:32:44\tSPEAKER_04\n And that's probably the right way to do it.\n\n0:32:46\tSPEAKER_10\n Yeah, and we should probably make that part of the procedure for reporting the meetings.\n\n0:32:50\tSPEAKER_04\n Well, we're going to automate that.\n\n0:32:52\tSPEAKER_04\n My intention is to do a script that will do everything.\n\n0:32:54\tSPEAKER_04\n We're going to have to take in the drive.\n\n0:32:56\tSPEAKER_04\n No, it's all tape or a lot.\n\n0:32:57\tSPEAKER_04\n So you just sit down at your computer and you type a command.\n\n0:32:59\tSPEAKER_07\n Yeah, but then you're effectively using the resources when the backup system was at a different time.\n\n0:33:04\tSPEAKER_08\n But not at the same time.\n\n0:33:05\tSPEAKER_10\n But you would be anyway.\n\n0:33:07\tSPEAKER_10\n Right?\n\n0:33:08\tSPEAKER_10\n No, he's saying get a whole different drive.\n\n0:33:10\tSPEAKER_04\n But there's no reason to do that.\n\n0:33:11\tSPEAKER_04\n Well, we already have it there and it's.\n\n0:33:14\tSPEAKER_07\n And asking, can I use your tape for about, you will say, well, that's going to screw up our backup.\n\n0:33:19\tSPEAKER_07\n No, he won't.\n\n0:33:20\tSPEAKER_04\n He'll say, if that means that it's not going to be backed up standardly, great.\n\n0:33:27\tSPEAKER_09\n Dave has promoted this in the past.\n\n0:33:30\tSPEAKER_09\n Yeah, it's definitely no problem.\n\n0:33:32\tSPEAKER_09\n Yeah.\n\n0:33:33\tSPEAKER_08\n What about if the times overlap with the normal backup time?\n\n0:33:40\tSPEAKER_04\n It's just a utility which queues up.\n\n0:33:43\tSPEAKER_04\n Okay.\n\n0:33:44\tSPEAKER_04\n It just queues it up and when it's available, it will copy it.\n\n0:33:47\tSPEAKER_04\n And then you can tell it to then remove it from the disk or you can do it a few days later or whatever you want to do.\n\n0:33:52\tSPEAKER_04\n After you confirm that it's really backed up.\n\n0:33:57\tSPEAKER_04\n NW.\n\n0:33:58\tSPEAKER_04\n You're saying NW, okay?\n\n0:33:59\tSPEAKER_04\n NW archive, that's what it is.\n\n0:34:01\tSPEAKER_04\n Okay.\n\n0:34:02\tSPEAKER_02\n And if you did that during the day, it would never make it to the library.\n\n0:34:05\tSPEAKER_02\n Right.\n\n0:34:06\tSPEAKER_07\n Well, you have to put the data on the non-life disk to the game, right?\n\n0:34:13\tSPEAKER_07\n Right.\n\n0:34:14\tSPEAKER_01\n So that otherwise you don't have to...\n\n0:34:17\tSPEAKER_01\n You can have a non-backed disk NWRI.\n\n0:34:20\tSPEAKER_04\n Right.\n\n0:34:21\tSPEAKER_04\n And then it never...\n\n0:34:22\tSPEAKER_04\n Right.\n\n0:34:23\tSPEAKER_04\n Which I'm sure would make it.\n\n0:34:24\tSPEAKER_04\n The assessment's very happy.\n\n0:34:26\tSPEAKER_04\n So I think that's a good idea.\n\n0:34:27\tSPEAKER_04\n That's what we should do.\n\n0:34:28\tSPEAKER_04\n So that means we'll probably want to convert all those files, file systems to non-backed up media.\n\n0:34:35\tSPEAKER_10\n That sounds good.\n\n0:34:36\tSPEAKER_10\n Yeah.\n\n0:34:37\tSPEAKER_09\n Another thing on the agenda that says SRI recognition experience.\n\n0:34:42\tSPEAKER_09\n What was that?\n\n0:34:43\tSPEAKER_09\n Oh.\n\n0:34:44\tSPEAKER_09\n That wasn't me.\n\n0:34:45\tSPEAKER_04\n Well, we have lots of them.\n\n0:34:47\tSPEAKER_07\n I didn't know you talked to you having the updates.\n\n0:34:52\tSPEAKER_10\n I'm successfully increasing the error rate.\n\n0:34:57\tSPEAKER_10\n That's good.\n\n0:34:58\tSPEAKER_10\n That's the hair value approach.\n\n0:35:00\tSPEAKER_08\n Yeah.\n\n0:35:01\tSPEAKER_10\n So I mean, I'm just playing with the number of Gaussian's that we use in the recognizer.\n\n0:35:07\tSPEAKER_07\n You have to set...\n\n0:35:08\tSPEAKER_07\n You have to type people that you're trying the tenant features.\n\n0:35:11\tSPEAKER_07\n Yes, I'm using tenant features.\n\n0:35:12\tSPEAKER_10\n Oh, you are?\n\n0:35:13\tSPEAKER_07\n Cool.\n\n0:35:14\tSPEAKER_07\n And I still take my work to the PLP features.\n\n0:35:16\tSPEAKER_09\n Yeah, I got confused by the results because the meaning before you said, okay, we got it now and the way there...\n\n0:35:22\tSPEAKER_09\n That was on mail.\n\n0:35:23\tSPEAKER_09\n That was before I tried it on the females.\n\n0:35:25\tSPEAKER_09\n Oh.\n\n0:35:26\tSPEAKER_09\n It's the women of the problem.\n\n0:35:27\tSPEAKER_09\n Okay.\n\n0:35:28\tSPEAKER_08\n Well, let's just say that men are simple.\n\n0:35:31\tSPEAKER_08\n Hello.\n\n0:35:32\tSPEAKER_08\n Hello.\n\n0:35:33\tSPEAKER_08\n I had...\n\n0:35:34\tSPEAKER_02\n It was a quick response.\n\n0:35:37\tSPEAKER_02\n I'm well-rehearsed.\n\n0:35:38\tSPEAKER_07\n We had reached the point where the mail portion of the development set, one of the development sets, I think, that the mail error rate with the XCPRP features was pretty much identical with the SRI, which are the XCPRP.\n\n0:36:01\tSPEAKER_07\n So then I thought, oh, great.\n\n0:36:04\tSPEAKER_07\n I'll just let's make sure I think it works on the females and the error rate.\n\n0:36:09\tSPEAKER_07\n Yeah, there was a fee percent difference.\n\n0:36:12\tSPEAKER_08\n Is there less training data?\n\n0:36:14\tSPEAKER_08\n I mean, we don't...\n\n0:36:15\tSPEAKER_08\n This is more training data.\n\n0:36:16\tSPEAKER_08\n This is on just digits?\n\n0:36:17\tSPEAKER_08\n No, it's in a five.\n\n0:36:19\tSPEAKER_07\n Oh, okay.\n\n0:36:20\tSPEAKER_07\n I'll probably be able to...\n\n0:36:21\tSPEAKER_07\n I'll be tested as a moment, sort of.\n\n0:36:27\tSPEAKER_07\n So then...\n\n0:36:28\tSPEAKER_07\n Oh, and plus the vocal track length organization didn't actually make things worse.\n\n0:36:34\tSPEAKER_07\n So it's happening to me seriously.\n\n0:36:36\tSPEAKER_07\n So...\n\n0:36:37\tSPEAKER_07\n Okay.\n\n0:36:38\tSPEAKER_07\n So...\n\n0:36:39\tSPEAKER_09\n But see, now between the males and the females, there's certainly a much bigger difference in the scaling range than there is, say, just within the males.\n\n0:36:52\tSPEAKER_09\n And what you're using before was scaling factors that were just from the SRI front end.\n\n0:36:59\tSPEAKER_09\n And that worked fine.\n\n0:37:01\tSPEAKER_09\n Yeah.\n\n0:37:02\tSPEAKER_09\n But now you're looking over a larger range and it may not be so fine.\n\n0:37:07\tSPEAKER_07\n Well, so the one thing that I then tried was to put in the low pass filter, which we have in the...\n\n0:37:17\tSPEAKER_07\n So most...\n\n0:37:18\tSPEAKER_07\n Most have five systems actually band-limit at about 3700 hertz, although, you know, normally the channel goes to 4000, right?\n\n0:37:29\tSPEAKER_07\n So...\n\n0:37:30\tSPEAKER_07\n And that actually helped a little bit.\n\n0:37:35\tSPEAKER_07\n And it didn't hurt on the males, you know.\n\n0:37:37\tSPEAKER_07\n So... and I now try the...\n\n0:37:44\tSPEAKER_07\n Oh, and suddenly also the vocal track length organization only in the tests on the test data.\n\n0:37:48\tSPEAKER_07\n So you can do a vocal track length organization on the test data only or ongoing training in the test.\n\n0:37:54\tSPEAKER_07\n And you expect it to help a little bit if you do it only on the test and more if you do it on both training and...\n\n0:38:00\tSPEAKER_07\n Yes.\n\n0:38:01\tSPEAKER_07\n So it now helps you do it only on the test and I'm trying to retrain another set of models where it's both in the training and the test.\n\n0:38:10\tSPEAKER_07\n And then we will probably have hopefully a better one.\n\n0:38:13\tSPEAKER_07\n But it looks like there will still be some difference, maybe between one and two percent of the females.\n\n0:38:21\tSPEAKER_07\n And so, you know, I'm often doing suggestions.\n\n0:38:24\tSPEAKER_07\n And it is true that the...\n\n0:38:26\tSPEAKER_07\n You know, we are using the... but it can't be just the VTL because...\n\n0:38:32\tSPEAKER_07\n No, no, I'm not.\n\n0:38:33\tSPEAKER_07\n It's much worse, you know.\n\n0:38:35\tSPEAKER_07\n You know, the females are concerned with the reverse and the...\n\n0:38:39\tSPEAKER_07\n So that must be something else.\n\n0:38:42\tSPEAKER_08\n Well, what's the standard...\n\n0:38:43\tSPEAKER_08\n I thought the performance was actually a little better on females than males.\n\n0:38:47\tSPEAKER_08\n That's what I thought too.\n\n0:38:48\tSPEAKER_07\n That overall, yes, but on this particular development test, they're actually a little worse.\n\n0:38:55\tSPEAKER_07\n But that's beside the point we're looking at the discrepancy between the SRI system and the SRI system when training with each feature.\n\n0:39:03\tSPEAKER_08\n Right, I'm just wondering if that...\n\n0:39:06\tSPEAKER_08\n If you have any indication of your standard features, you know, if that's also different in the same direction or not.\n\n0:39:12\tSPEAKER_09\n Let me ask a more basic...\n\n0:39:14\tSPEAKER_09\n I mean, is this a iterative bound-multchtraining or is it a terribly training?\n\n0:39:19\tSPEAKER_07\n It's a lot of training.\n\n0:39:21\tSPEAKER_09\n And how do you determine when to stop iterating?\n\n0:39:25\tSPEAKER_07\n Well, actually, we just basically do a fixed number of iterations.\n\n0:39:33\tSPEAKER_07\n In this case, four.\n\n0:39:36\tSPEAKER_07\n Which we used to do only three and then we found out we can squeeze.\n\n0:39:41\tSPEAKER_07\n And it was basically...\n\n0:39:43\tSPEAKER_07\n We're keeping down the same side.\n\n0:39:45\tSPEAKER_07\n But you're right, it might be that one more iteration would help, but it's...\n\n0:39:50\tSPEAKER_09\n Or maybe you're doing one too many.\n\n0:39:53\tSPEAKER_07\n No, but this bound-multchtraining shouldn't be over there.\n\n0:39:58\tSPEAKER_09\n Well, there can be sure.\n\n0:40:00\tSPEAKER_09\n Well, you can try each one on a cross-order.\n\n0:40:02\tSPEAKER_09\n Some years ago, Bill Burndyla thing where he was looking at that and he showed that he could get it.\n\n0:40:07\tSPEAKER_09\n But...\n\n0:40:10\tSPEAKER_07\n Well, that's the easy one.\n\n0:40:12\tSPEAKER_07\n Because you've got all these immediate models.\n\n0:40:15\tSPEAKER_09\n In each case, how do you determine the usual fudge factors, the language scaling, acoustic scaling?\n\n0:40:27\tSPEAKER_07\n I'm actually re-optimizing them.\n\n0:40:32\tSPEAKER_07\n Although that hasn't shown to you.\n\n0:40:35\tSPEAKER_09\n Okay, and the question he was asking at one point about perning...\n\n0:40:43\tSPEAKER_09\n Remember that one?\n\n0:40:46\tSPEAKER_09\n It looked like the probability was getting out of PLP versus milk upstream.\n\n0:40:51\tSPEAKER_09\n They looked pretty different.\n\n0:40:53\tSPEAKER_10\n Yeah, the likelihood were lower.\n\n0:40:55\tSPEAKER_09\n And so there's the question.\n\n0:40:57\tSPEAKER_07\n For the PLP.\n\n0:40:59\tSPEAKER_07\n Did you see this in the SRI system?\n\n0:41:01\tSPEAKER_07\n Did this look into the log files?\n\n0:41:03\tSPEAKER_07\n Well, the likelihoods are...\n\n0:41:05\tSPEAKER_07\n You can't recognize them.\n\n0:41:07\tSPEAKER_07\n Because for every set of models, you compute a new normalization.\n\n0:41:11\tSPEAKER_07\n And so these log probabilities, they aren't directly...\n\n0:41:15\tSPEAKER_07\n...you have the normalization cost of the average model in the trial.\n\n0:41:19\tSPEAKER_09\n But still, there's a question.\n\n0:41:21\tSPEAKER_09\n If you have some thresholds somewhere in terms of beam search or something?\n\n0:41:24\tSPEAKER_09\n Well, yeah, that's what I was wondering.\n\n0:41:27\tSPEAKER_10\n I mean, if you have one threshold that works well because the range of your likelihoods is in this area.\n\n0:41:32\tSPEAKER_07\n Very conservatively.\n\n0:41:34\tSPEAKER_07\n I mean, as we saw with the meeting that we could probably tighten the pruning without really...\n\n0:41:40\tSPEAKER_07\n So we basically have a very open view.\n\n0:41:43\tSPEAKER_09\n But you're only talking about a percent or two, right?\n\n0:41:45\tSPEAKER_09\n Here, we're saying that with this G, there's this difference here.\n\n0:41:49\tSPEAKER_09\n And see, because there could be lots of things, right?\n\n0:41:52\tSPEAKER_09\n But let's suppose just for a second that we've sort of taken out a lot of the major differences between the two.\n\n0:42:03\tSPEAKER_09\n I mean, we're already sort of using the male scale and using the same style filter integration.\n\n0:42:08\tSPEAKER_09\n And we're making sure that the low and high...\n\n0:42:11\tSPEAKER_07\n So for the PLP features, we used the triangular filter shapes and for the NDSRI front, we used the triple-modal ones.\n\n0:42:18\tSPEAKER_04\n And what's the top frequency of each?\n\n0:42:21\tSPEAKER_07\n Well, now it's the same. It's 30, 700...\n\n0:42:24\tSPEAKER_04\n Yeah, one's triangular, one's trapezoidal.\n\n0:42:26\tSPEAKER_09\n So...\n\n0:42:27\tSPEAKER_09\n No, no, but...\n\n0:42:28\tSPEAKER_09\n Before, with straight PLP, it's trapezoidal, also, but then we had a slight difference in the scale.\n\n0:42:35\tSPEAKER_07\n So it's currently that the FICAD program doesn't allow me to change the filter shape independently of this.\n\n0:42:41\tSPEAKER_07\n Yeah.\n\n0:42:42\tSPEAKER_07\n I did the experiment on the NDSRI front, where I tried the...\n\n0:42:45\tSPEAKER_07\n...with the standards to be the as trapezoidal purpose.\n\n0:42:48\tSPEAKER_07\n You can actually continuously vary between the two.\n\n0:42:51\tSPEAKER_07\n And so I...\n\n0:42:52\tSPEAKER_07\n That's what I'm trying to...\n\n0:42:54\tSPEAKER_07\n Trying to do what's...\n\n0:42:55\tSPEAKER_07\n And it did slightly worse, but it's really a small difference.\n\n0:42:58\tSPEAKER_09\n So...\n\n0:42:59\tSPEAKER_09\n A couple of tensor representations.\n\n0:43:00\tSPEAKER_04\n Okay, so it's not just losing some frequency range.\n\n0:43:03\tSPEAKER_09\n Yeah. Right, so the other thing that...\n\n0:43:07\tSPEAKER_09\n So we've always viewed it anyway, is the major difference between the two is actually in the smoothing.\n\n0:43:14\tSPEAKER_09\n That the PLP and the reason PLP has been advantageous in slightly noisy situations is because PLP does the smoothing at the end by an aggressive model.\n\n0:43:27\tSPEAKER_09\n And Melcafstrom does it by just computing the lower test row coefficients.\n\n0:43:32\tSPEAKER_07\n Okay, so one thing I haven't done yet is to actually do all of this with a much larger with our full train set.\n\n0:43:41\tSPEAKER_07\n So right now we're using a...\n\n0:43:44\tSPEAKER_07\n...40E.\n\n0:43:48\tSPEAKER_07\n It's a train set that's about...\n\n0:43:53\tSPEAKER_07\n...my effective force model that we want to use when we train the fault system.\n\n0:43:59\tSPEAKER_07\n So some of these moving issues are overfitting for that matter.\n\n0:44:02\tSPEAKER_07\n And the long route should be much less of a factor if you go full-hog.\n\n0:44:08\tSPEAKER_07\n Good to be, yeah.\n\n0:44:10\tSPEAKER_07\n So the strategy is to first treat things with fast train around on the smoothing set.\n\n0:44:17\tSPEAKER_07\n And then when you've narrowed down, you've tried on a larger train set.\n\n0:44:22\tSPEAKER_07\n So we haven't done that yet.\n\n0:44:23\tSPEAKER_09\n Now the other great related question though is, is what's the boot models for these things?\n\n0:44:29\tSPEAKER_07\n The boot models are trained from scratch.\n\n0:44:32\tSPEAKER_07\n So we compute...\n\n0:44:34\tSPEAKER_07\n So we start with a...\n\n0:44:38\tSPEAKER_07\n...alignment that we computed with sort of the best system we have.\n\n0:44:44\tSPEAKER_07\n And then we train from scratch.\n\n0:44:47\tSPEAKER_07\n We do...you know... we collect the...\n\n0:44:53\tSPEAKER_07\n...observations from those linings under each of the future sets that we train.\n\n0:44:59\tSPEAKER_07\n And then from there we do...\n\n0:45:02\tSPEAKER_07\n There's a lot of actually the way it works.\n\n0:45:04\tSPEAKER_07\n The first train, the phonetically tight mixture model.\n\n0:45:08\tSPEAKER_07\n You do a total of...\n\n0:45:10\tSPEAKER_07\n First you do a context independence PTN model.\n\n0:45:13\tSPEAKER_07\n Then you switch to context...\n\n0:45:15\tSPEAKER_07\n...and then you do two iterations of that.\n\n0:45:18\tSPEAKER_07\n Then you do two iterations of the context dependent, but actually the packet mixtures.\n\n0:45:22\tSPEAKER_07\n And then from that you go to a state custom model.\n\n0:45:26\tSPEAKER_07\n And you do four iterations of that.\n\n0:45:28\tSPEAKER_07\n So there's a lot of iterations overall between your original boot models and the final models.\n\n0:45:33\tSPEAKER_07\n I don't think that we have never seen big differences.\n\n0:45:37\tSPEAKER_07\n Once I thought, oh, I can...\n\n0:45:39\tSPEAKER_07\n Now I have these much better models.\n\n0:45:41\tSPEAKER_07\n I'll regenerate my initial alignments and I'll get much better models at the end.\n\n0:45:44\tSPEAKER_07\n That's what's right.\n\n0:45:45\tSPEAKER_07\n Right.\n\n0:45:46\tSPEAKER_09\n Well, making things better, yeah, but this...\n\n0:45:49\tSPEAKER_09\n...for making things worse, that is possible.\n\n0:45:53\tSPEAKER_09\n Another possible partial cause is if the boot models use a different feature set.\n\n0:46:00\tSPEAKER_07\n But there are some boot models in fact.\n\n0:46:02\tSPEAKER_07\n You're not booting from initial models, you're booting from initial alignments.\n\n0:46:05\tSPEAKER_09\n What you got from a different feature set.\n\n0:46:08\tSPEAKER_07\n That's correct.\n\n0:46:09\tSPEAKER_09\n So those features look at the data differently actually.\n\n0:46:12\tSPEAKER_09\n I mean, you know, they will find boundaries a little differently.\n\n0:46:15\tSPEAKER_09\n You know, all that sort of thing is actually slightly different.\n\n0:46:18\tSPEAKER_09\n I'd expect it to be a minor effect.\n\n0:46:21\tSPEAKER_07\n So for a long time we had used boot alignments that had been trained with a same front end.\n\n0:46:32\tSPEAKER_07\n But with acoustic models that were like 15% worse than what we used now.\n\n0:46:38\tSPEAKER_07\n And with a different dictionary, with a considerably different dictionary, which was much less detailed and much less suited.\n\n0:46:45\tSPEAKER_07\n And so then we switched to new boot alignments, which now had the benefit of all these improvements that we've made over two years in the system.\n\n0:46:53\tSPEAKER_07\n Right.\n\n0:46:54\tSPEAKER_07\n And the result at the end was no different.\n\n0:46:57\tSPEAKER_07\n What I'm saying is the exact nature of these boot alignments is probably not a big factor in the quality of the final model.\n\n0:47:05\tSPEAKER_09\n Yeah, maybe not. But it's still see it as, I mean, there's a history of this too.\n\n0:47:11\tSPEAKER_09\n But I don't want to go into it.\n\n0:47:13\tSPEAKER_09\n But I think it could be the things that the data is being viewed in a certain way.\n\n0:47:19\tSPEAKER_09\n That a beginning is here rather than there and so forth because the actual signal processing is doing a slightly different.\n\n0:47:26\tSPEAKER_09\n But it's probably not it.\n\n0:47:28\tSPEAKER_07\n I should really reserve any conclusions until we've met it on the live trains and until we've seen results with the BTO training.\n\n0:47:39\tSPEAKER_09\n Yeah, at some point you also might want to take the same thing and try it on some broadcast news data or something else that actually has some noisy, noisy components.\n\n0:47:48\tSPEAKER_09\n So we can see if any conclusions would come to a halt across different data.\n\n0:47:54\tSPEAKER_09\n So something quick about absent.\n\n0:47:59\tSPEAKER_04\n Just what we were talking about before, which is that I hoarded a blast library to absent and then got it working with fast forward and got a speed up roughly proportional to the number of processors times the clock cycle.\n\n0:48:11\tSPEAKER_04\n So that's pretty good.\n\n0:48:13\tSPEAKER_04\n I mean, the process of doing it for quick net, but there's something going wrong and it's about half the speed that I was estimating it should be.\n\n0:48:19\tSPEAKER_04\n And I'm not sure why, but I'll keep working on it. But what it means is it's likely that for net training and forward passes will absent will be a good machine, especially if we get a few more processors and upgrade the processors.\n\n0:48:33\tSPEAKER_04\n There are five now. It can hold eight.\n\n0:48:37\tSPEAKER_04\n Yeah, we'll just go by and it's also 550 megahertz and you can get a gigahertz.\n\n0:48:42\tSPEAKER_07\n Can you fix the processors with different?\n\n0:48:44\tSPEAKER_04\n I don't think so. I think we'd have to do all.\n\n0:48:46\tSPEAKER_09\n Yeah, thank you for the box.\n\n0:48:51\tSPEAKER_07\n We can press.\n\n0:48:54\tSPEAKER_04\n We'd have to get a almost certainly have to get a netfinity server.\n\n0:48:58\tSPEAKER_04\n They're pretty, pretty specialized.\n\n0:49:02\tSPEAKER_09\n Okay. Is this going back?\n\n0:49:05\tSPEAKER_09\n Yeah. How are you doing?\n\n0:49:08\tSPEAKER_09\n All right.\n\n0:49:12\tSPEAKER_09\n All right. See you.\n\n0:49:19\tSPEAKER_09\n All right. So they're having T out there.\n\n0:49:22\tSPEAKER_09\n So I guess the other thing that we were going to talk about is demo.\n\n0:49:26\tSPEAKER_09\n And so these are the demos for the July meeting and July what?\n\n0:49:37\tSPEAKER_09\n Early July, late July? Oh, I think it's July 15.\n\n0:49:42\tSPEAKER_09\n 16, 13. Yeah. So we talked about getting something together for that.\n\n0:49:46\tSPEAKER_09\n But maybe we'll just put that off for now given that.\n\n0:49:51\tSPEAKER_09\n But I think we should have a sub meeting.\n\n0:49:54\tSPEAKER_09\n I think probably Adam and Chuck and me should talk about.\n\n0:50:00\tSPEAKER_09\n Should get together and talk about that sometimes.\n\n0:50:02\tSPEAKER_09\n Over at Captain Chinatumar.\n\n0:50:03\tSPEAKER_09\n Yeah, something like that. Maybe we'll involve Daniel and some of us as well.\n\n0:50:12\tSPEAKER_09\n Okay. The T is going.\n\n0:50:15\tSPEAKER_09\n So I see just we do a unison.\n\n0:50:20\tSPEAKER_09\n A unison digit. Yeah.\n\n0:50:21\tSPEAKER_04\n Which is going to be a little hard for a couple people because we have different digit forms.\n\n0:50:25\tSPEAKER_04\n I found a couple of old ones.\n\n0:50:30\tSPEAKER_09\n Interesting. So have you done digits before?\n\n0:50:33\tSPEAKER_09\n No. I haven't done it.\n\n0:50:35\tSPEAKER_04\n Okay. So the idea is just to read each line with a short pause between lines.\n\n0:50:40\tSPEAKER_04\n Not between. And since we're in a hurry, we were just going to read everyone all at once.\n\n0:50:44\tSPEAKER_04\n So if you sort of plug your ears and read.\n\n0:50:46\tSPEAKER_04\n Okay. So first read the transcript number and then start reading the digits.\n\n0:50:50\tSPEAKER_04\n Okay. One, two, three.\n\n0:50:54\tSPEAKER_12\n L1154 Bazinai Stars.\n\n0:51:01\tSPEAKER_11\n 0 is 333 Codos,\n\n0:51:12\tSPEAKER_02\n m \u00ea\u00b0\u0099as, j Eins,\n\n0:51:20\tSPEAKER_03\n 510-610-165-4-6367-277-5-8659-6978-248-617145-2258-31469-566\n\n0:51:44\tSPEAKER_09\n Okay, we're done\n\n0:51:46\tSPEAKER_02\n And\n\n", "summary": [{"summary_text": "Morgan wanted to talk about the ARPA demo. Chuck added an item to the agenda. Andreas will be 10 to 15 minutes late. They will talk about segmentation and recognition, IBM transcription, SmartCom, files and directories and reorganization status. Speaker wants to focus on segmentation recognition when Andreas is here."}]}