{"filename": "./data/Bmr028.txt", "transcript": "0:00:00\tSPEAKER_03\n And we're going.\n\n0:00:05\tSPEAKER_03\n So the only status item, well, first of all, we haven't decided whether we're meeting recorded data issues or recognition this week.\n\n0:00:14\tSPEAKER_03\n I think we were recognition.\n\n0:00:17\tSPEAKER_05\n What was on the list?\n\n0:00:18\tSPEAKER_05\n I mean, I sent you a couple things.\n\n0:00:20\tSPEAKER_03\n You only sent me one thing, which was demo status.\n\n0:00:24\tSPEAKER_03\n And asking which one we were on this week.\n\n0:00:27\tSPEAKER_03\n That was the second thing, right?\n\n0:00:31\tSPEAKER_03\n So should we simply assert that this week we are recognition and next week data issues?\n\n0:00:35\tSPEAKER_03\n I think that's correct.\n\n0:00:36\tSPEAKER_01\n I think so too.\n\n0:00:37\tSPEAKER_03\n And so I think what we should probably do is any quick, small stuff we can do every week.\n\n0:00:43\tSPEAKER_03\n So like Morgan asked about the demo status, we can go ahead and talk about that a little bit, and then alternate in more depth.\n\n0:00:53\tSPEAKER_05\n By the way, I won't be here next Thursday.\n\n0:00:55\tSPEAKER_05\n I'll be out of town.\n\n0:00:57\tSPEAKER_03\n But actually, I may not be here either.\n\n0:01:01\tSPEAKER_03\n So I've got to double check the dates.\n\n0:01:03\tSPEAKER_03\n But anyway, so demo status, first of all, I did a little thing for Liz with the transcriber tool that, first of all, it uses the forced alignments so that the words appear in their own segments, rather than in long chunks.\n\n0:01:22\tSPEAKER_03\n She said that that.\n\n0:01:23\tSPEAKER_03\n She thought that was a much better idea for the other stuff she's working on.\n\n0:01:29\tSPEAKER_03\n And that works fine, except it's even slower to load.\n\n0:01:31\tSPEAKER_03\n It's already pretty slow.\n\n0:01:33\tSPEAKER_09\n Is that because the transcripts go longer?\n\n0:01:35\tSPEAKER_03\n Yeah.\n\n0:01:36\tSPEAKER_03\n Yeah.\n\n0:01:37\tSPEAKER_03\n And the transcriber tool is just not very good at.\n\n0:01:42\tSPEAKER_09\n But that's, you didn't have to change the software for that, yet, right?\n\n0:01:46\tSPEAKER_09\n It's just formatting, they're writing kind of.\n\n0:01:48\tSPEAKER_03\n Yeah, it's just writing conversion tools from the format that the aligner actually did a SRT file for it.\n\n0:01:57\tSPEAKER_03\n And then just back into transcriber format.\n\n0:02:00\tSPEAKER_03\n Yeah, so my decision was for the first pass for this demo that Liz was talking about.\n\n0:02:05\tSPEAKER_03\n I decided that I would do only enough to get it working as opposed to any coding.\n\n0:02:12\tSPEAKER_03\n And so the other thing, she wanted to display the stylized F0s, I think they're cold.\n\n0:02:17\tSPEAKER_03\n Is that right?\n\n0:02:17\tSPEAKER_03\n Yeah, the linear fit.\n\n0:02:19\tSPEAKER_03\n So what I did is I just took the file with those and it converted it so that it looks like an audio file.\n\n0:02:24\tSPEAKER_03\n And so it shows that instead of the way file.\n\n0:02:27\tSPEAKER_03\n And so that's working.\n\n0:02:28\tSPEAKER_03\n And I think it actually looks pretty good.\n\n0:02:30\tSPEAKER_03\n I'd like someone who's more familiar with it to look at it, because when I was looking at it, we seem to have lots of stuff going on when no one's saying anything.\n\n0:02:38\tSPEAKER_06\n That's just background speech.\n\n0:02:41\tSPEAKER_04\n Yeah.\n\n0:02:42\tSPEAKER_04\n So you have to pad that out so that it looks like it's an eight-killer-heard sample thing.\n\n0:02:48\tSPEAKER_03\n You know, the audio file, you can specify any sampling rate.\n\n0:02:52\tSPEAKER_03\n And so I specified, instead of 16,000 or 8,000, I specified 100.\n\n0:02:58\tSPEAKER_03\n And the only problem with that is that there's a bug in transcriber that if the sample rate is too low, when it tries to compute the shape file, it fails and crashes.\n\n0:03:10\tSPEAKER_03\n But the solution to that is just set the option so it doesn't compute the shape file.\n\n0:03:14\tSPEAKER_03\n And it will work.\n\n0:03:15\tSPEAKER_03\n And the only problem with that is you can't zoom out on it.\n\n0:03:19\tSPEAKER_03\n You can zoom in, but not out.\n\n0:03:20\tSPEAKER_05\n That's a shape file.\n\n0:03:22\tSPEAKER_03\n The shape file is, if you think about a wave file, 16,000 samples per second is way too many to display on the screen.\n\n0:03:29\tSPEAKER_03\n So a transcriber does is it computes another thing to display based on the wave form.\n\n0:03:34\tSPEAKER_03\n And it displays it up.\n\n0:03:36\tSPEAKER_03\n And it allows you to show many different resolutions.\n\n0:03:38\tSPEAKER_03\n So there's a little user interface component that lets you select the resolution.\n\n0:03:43\tSPEAKER_03\n And if you don't compute the wave file, you can't zoom out.\n\n0:03:48\tSPEAKER_03\n You can't get a larger view of it, but you can zoom in.\n\n0:03:53\tSPEAKER_03\n And that's all right, because I had 100 samples.\n\n0:03:55\tSPEAKER_03\n That's already pretty far out.\n\n0:03:58\tSPEAKER_03\n And so I think it looks pretty good that all that lives.\n\n0:04:01\tSPEAKER_03\n Look at it and see what you get.\n\n0:04:02\tSPEAKER_02\n Sorry.\n\n0:04:03\tSPEAKER_02\n I got the wave file, but I couldn't get the words yet.\n\n0:04:05\tSPEAKER_02\n But the wave file part looks good.\n\n0:04:08\tSPEAKER_03\n OK.\n\n0:04:10\tSPEAKER_03\n We should, if you are having problems with the words, you should take your out why.\n\n0:04:15\tSPEAKER_02\n I'll have done.\n\n0:04:16\tSPEAKER_02\n I'm probably doing something wrong.\n\n0:04:18\tSPEAKER_02\n Sorry, the microphones moving around.\n\n0:04:25\tSPEAKER_03\n You put that part over your ear.\n\n0:04:27\tSPEAKER_02\n I can do that, but there's no orientation where there is.\n\n0:04:36\tSPEAKER_03\n I'll watch this with the mic.\n\n0:04:38\tSPEAKER_01\n Is it really easy to go in here here?\n\n0:04:40\tSPEAKER_01\n That bud doesn't have to go in here, right?\n\n0:04:42\tSPEAKER_03\n No, it doesn't have to, but I find that's the only way to wear it.\n\n0:04:46\tSPEAKER_03\n That the bud's in the ear and that the link is over it.\n\n0:04:51\tSPEAKER_03\n So anyway, I think that looks pretty good.\n\n0:04:53\tSPEAKER_03\n The only other thing we might want to do with that is be able to display more than one waveform.\n\n0:04:58\tSPEAKER_03\n And that actually shouldn't be too slow, because it's much lower resolution than a full waveform.\n\n0:05:03\tSPEAKER_03\n The problem with it is just it does require coding.\n\n0:05:06\tSPEAKER_03\n And so it would be much better to get Dave Galvard to do that than me, because he's familiar with the code, and is more likely to be able to get it to work quickly.\n\n0:05:13\tSPEAKER_06\n I mean, I think we can do like a quick hack just so we can play the audio file too.\n\n0:05:17\tSPEAKER_06\n Right.\n\n0:05:18\tSPEAKER_06\n With the display, like even if we, I think that even if we didn't display the waveform, it might be better to rather play the waveform than display.\n\n0:05:27\tSPEAKER_06\n I mean, like we were to choose, I don't know if I were to choose between one or the other.\n\n0:05:30\tSPEAKER_06\n I'd rather have it played than display.\n\n0:05:33\tSPEAKER_03\n Right.\n\n0:05:35\tSPEAKER_03\n But for the demo, maybe it doesn't matter.\n\n0:05:37\tSPEAKER_03\n I'm not sure whether you want to do the demo live anyway, or just screenshots of what we have.\n\n0:05:41\tSPEAKER_03\n The problem with doing it live is it takes so long to load that.\n\n0:05:46\tSPEAKER_09\n So this slide is not loading.\n\n0:05:50\tSPEAKER_09\n Is all due to the parsing of the XML?\n\n0:05:54\tSPEAKER_03\n I was talking to Dave Galvard about that.\n\n0:05:55\tSPEAKER_03\n And apparently, it's not actually the parsing of the XML raw that going from the XML to an internal tree structure is pretty fast.\n\n0:06:03\tSPEAKER_03\n But then it walks the tree to assemble its date internal data structures, and that's slow.\n\n0:06:08\tSPEAKER_04\n It seems like you should be able to spawn that off into a background process, because not everything is displayed in that tree at once.\n\n0:06:15\tSPEAKER_03\n No, but what it does is it actually assembles all the user interface components then, and then displays all the user interface.\n\n0:06:22\tSPEAKER_05\n I'm confused.\n\n0:06:24\tSPEAKER_05\n Is this downloading something that happens once?\n\n0:06:27\tSPEAKER_05\n Yes.\n\n0:06:28\tSPEAKER_05\n And then when you display different things, it's fine.\n\n0:06:32\tSPEAKER_05\n So in that case, a new transcript.\n\n0:06:35\tSPEAKER_05\n Well, no meeting, transcript, right?\n\n0:06:37\tSPEAKER_05\n But for audio files.\n\n0:06:38\tSPEAKER_03\n Well, actually, audio files are pretty fast, too.\n\n0:06:40\tSPEAKER_05\n For presentation.\n\n0:06:43\tSPEAKER_05\n You just have to have something running.\n\n0:06:46\tSPEAKER_03\n Right.\n\n0:06:46\tSPEAKER_03\n The only problem with that is if anything goes wrong, or if you want to switch from one thing to another.\n\n0:06:50\tSPEAKER_03\n Go wrong?\n\n0:06:52\tSPEAKER_02\n I think, yeah.\n\n0:06:54\tSPEAKER_02\n I guess for the demo, you can always play, just store the pieces that you're going to display and play those as separate files if we can't actually do it.\n\n0:07:02\tSPEAKER_02\n They do older files.\n\n0:07:03\tSPEAKER_02\n That's true.\n\n0:07:03\tSPEAKER_02\n We can just subset it.\n\n0:07:04\tSPEAKER_02\n Yeah.\n\n0:07:05\tSPEAKER_03\n That's a good idea.\n\n0:07:05\tSPEAKER_03\n That's actually probably the right thing to do.\n\n0:07:07\tSPEAKER_03\n Yeah, just take 10 minutes.\n\n0:07:09\tSPEAKER_05\n That's what I did for my truck.\n\n0:07:11\tSPEAKER_05\n Oh, you're downloading a whole meeting.\n\n0:07:13\tSPEAKER_05\n Yeah.\n\n0:07:13\tSPEAKER_05\n Oh, yeah.\n\n0:07:15\tSPEAKER_03\n Yeah, so that's actually the definitely the way to do it.\n\n0:07:17\tSPEAKER_03\n That's a good idea.\n\n0:07:20\tSPEAKER_05\n And then still do it ahead of time.\n\n0:07:21\tSPEAKER_05\n But then at least you're covered if there are any problems.\n\n0:07:25\tSPEAKER_03\n There's problem.\n\n0:07:26\tSPEAKER_03\n Yeah, I mean, even five minutes is probably enough.\n\n0:07:29\tSPEAKER_02\n Right.\n\n0:07:30\tSPEAKER_02\n So what happened?\n\n0:07:31\tSPEAKER_02\n Is it possible at all to display the words in their aligned location?\n\n0:07:35\tSPEAKER_02\n That's what I did.\n\n0:07:36\tSPEAKER_02\n OK.\n\n0:07:36\tSPEAKER_02\n So I'm sorry.\n\n0:07:37\tSPEAKER_02\n I missed.\n\n0:07:38\tSPEAKER_02\n OK.\n\n0:07:38\tSPEAKER_02\n Great.\n\n0:07:39\tSPEAKER_02\n But OK.\n\n0:07:40\tSPEAKER_02\n I couldn't get the words and the way from it at the same time for some reason.\n\n0:07:43\tSPEAKER_02\n And there must be some work on it with Don and see what I'm doing wrong.\n\n0:07:48\tSPEAKER_03\n Yeah, just ask.\n\n0:07:49\tSPEAKER_03\n Just come by my office.\n\n0:07:49\tSPEAKER_03\n I can show you as well.\n\n0:07:50\tSPEAKER_02\n Great.\n\n0:07:51\tSPEAKER_02\n Oh, thanks a lot.\n\n0:07:52\tSPEAKER_03\n It's really great.\n\n0:07:53\tSPEAKER_03\n And for the information retrieval, Don has been working on that.\n\n0:07:57\tSPEAKER_06\n So yeah, so it's coming along.\n\n0:08:00\tSPEAKER_06\n Just hacking, dance code, stepping through it.\n\n0:08:03\tSPEAKER_06\n But I think it's close.\n\n0:08:07\tSPEAKER_06\n Should be there pretty soon.\n\n0:08:08\tSPEAKER_06\n But at least with being able to search over a certain amount of meetings, just like really basic stuff, just asking for a word and looking through a bunch of different meetings.\n\n0:08:21\tSPEAKER_06\n And if we have time, we'll also add choosing which speakers you want to include and stuff.\n\n0:08:26\tSPEAKER_06\n But OK.\n\n0:08:27\tSPEAKER_05\n I'm going to start working on this week after.\n\n0:08:29\tSPEAKER_05\n So that's the point I'll need to look more carefully at what you guys have.\n\n0:08:33\tSPEAKER_06\n So is the end of the month still?\n\n0:08:36\tSPEAKER_05\n Right.\n\n0:08:37\tSPEAKER_05\n The Monday that we get to next is July 2nd, which is the first day I get back.\n\n0:08:41\tSPEAKER_00\n OK.\n\n0:08:43\tSPEAKER_03\n Yeah, so I think for the stuff Liz was talking about, we have something that'll work now.\n\n0:08:47\tSPEAKER_03\n And Liz can look at it and see if she wants anything else.\n\n0:08:51\tSPEAKER_03\n Maybe we can work on doing displaying multiple.\n\n0:08:53\tSPEAKER_03\n We're displaying one and playing back the other.\n\n0:08:55\tSPEAKER_02\n So do you think it's reasonable to display more than one before the demo?\n\n0:09:00\tSPEAKER_03\n I think I'd have to ask Dave.\n\n0:09:02\tSPEAKER_03\n I did it once before, and it was just so slow to scroll that I gave up.\n\n0:09:07\tSPEAKER_03\n But the advantages that these things are much lower sampling rate, so it might be all right.\n\n0:09:12\tSPEAKER_02\n OK.\n\n0:09:13\tSPEAKER_02\n Let me know.\n\n0:09:14\tSPEAKER_06\n Morgan, when's the demo?\n\n0:09:16\tSPEAKER_05\n Well, I'm giving a talk on July 16th, so Monday in four weeks.\n\n0:09:27\tSPEAKER_09\n So it was three weeks.\n\n0:09:29\tSPEAKER_09\n If Ross beat us the problem, this thing is written in tickle.\n\n0:09:34\tSPEAKER_09\n I mean, John AustroHouth started his own company based on tickle stuff, and maybe they have a native code compiled error or something.\n\n0:09:43\tSPEAKER_03\n I mean, we could check.\n\n0:09:43\tSPEAKER_03\n I don't think they do.\n\n0:09:46\tSPEAKER_03\n There was actually a Java backend that apparently is actually a little faster, a generate byte code.\n\n0:09:52\tSPEAKER_03\n But.\n\n0:09:54\tSPEAKER_05\n I was excited to hear that Java's faster than something.\n\n0:09:57\tSPEAKER_05\n Yeah.\n\n0:09:58\tSPEAKER_03\n Well, everything is faster than tickle TK.\n\n0:10:00\tSPEAKER_03\n It's a string substitution language, basically.\n\n0:10:03\tSPEAKER_03\n I should probably beat that out.\n\n0:10:04\tSPEAKER_03\n And John AustroHouth ever listens.\n\n0:10:06\tSPEAKER_01\n But tickle is wonderful.\n\n0:10:08\tSPEAKER_01\n It is wonderful.\n\n0:10:09\tSPEAKER_03\n It is for prototyping and user interface.\n\n0:10:11\tSPEAKER_03\n It's just really the language is awful.\n\n0:10:13\tSPEAKER_00\n Oh.\n\n0:10:14\tSPEAKER_00\n Beep.\n\n0:10:15\tSPEAKER_00\n Beep.\n\n0:10:19\tSPEAKER_03\n But let me tell you how I really feel.\n\n0:10:22\tSPEAKER_05\n I'll entitle to our opinion, too.\n\n0:10:24\tSPEAKER_01\n Yeah.\n\n0:10:24\tSPEAKER_05\n I like it.\n\n0:10:25\tSPEAKER_05\n Yeah.\n\n0:10:28\tSPEAKER_05\n Because the meeting is July 16, 18.\n\n0:10:33\tSPEAKER_05\n And I talk to the first day.\n\n0:10:35\tSPEAKER_05\n So I'm flying out there this Sunday before.\n\n0:10:38\tSPEAKER_05\n So I guess it would be desirable if a week ahead of that.\n\n0:10:48\tSPEAKER_05\n We basically thought we had it, which would allow a week.\n\n0:10:53\tSPEAKER_06\n For realizing we don't.\n\n0:10:55\tSPEAKER_03\n Yeah.\n\n0:10:56\tSPEAKER_03\n Then the other issue related to that is data release.\n\n0:11:00\tSPEAKER_03\n If we want to show this in public, it should be released.\n\n0:11:03\tSPEAKER_03\n So I haven't gotten any other replies from the original email asking for approval.\n\n0:11:08\tSPEAKER_03\n So I sent out another set this morning.\n\n0:11:10\tSPEAKER_03\n I saw that.\n\n0:11:11\tSPEAKER_03\n And now we'll see if we get any responses.\n\n0:11:13\tSPEAKER_02\n But it is.\n\n0:11:14\tSPEAKER_02\n I did want to say that.\n\n0:11:16\tSPEAKER_03\n Did you notice I put it in the filter?\n\n0:11:19\tSPEAKER_02\n No.\n\n0:11:20\tSPEAKER_02\n No.\n\n0:11:21\tSPEAKER_02\n No.\n\n0:11:22\tSPEAKER_02\n I just figured you.\n\n0:11:23\tSPEAKER_03\n There's a link there that now says, if you want to search by filter by regular expression, you can.\n\n0:11:30\tSPEAKER_02\n Perfect.\n\n0:11:31\tSPEAKER_02\n I didn't just for you.\n\n0:11:32\tSPEAKER_02\n Well, since you didn't answer the question, I had asked Adam whether it's possible to search only for your own name, your own utterances, so that you don't have to go through the whole meeting.\n\n0:11:41\tSPEAKER_02\n And I didn't hear back.\n\n0:11:42\tSPEAKER_02\n I thought, OK, it's probably too hard.\n\n0:11:44\tSPEAKER_02\n He's overloaded.\n\n0:11:44\tSPEAKER_02\n I won't say anything.\n\n0:11:45\tSPEAKER_02\n I'll just do it.\n\n0:11:47\tSPEAKER_02\n Great.\n\n0:11:48\tSPEAKER_02\n OK.\n\n0:11:48\tSPEAKER_03\n So anyway, it's actually an arbitrary regular expression.\n\n0:11:52\tSPEAKER_03\n If you search your name, you'll get all the things you said and any time anyone said your name.\n\n0:11:57\tSPEAKER_05\n That's great.\n\n0:11:58\tSPEAKER_05\n It's case in sensitive.\n\n0:11:59\tSPEAKER_05\n Correct.\n\n0:11:59\tSPEAKER_05\n Yeah.\n\n0:12:00\tSPEAKER_05\n That's great.\n\n0:12:02\tSPEAKER_04\n Did you actually look through your transcripts, or you just approved them all?\n\n0:12:05\tSPEAKER_04\n Well.\n\n0:12:06\tSPEAKER_04\n I just approved them.\n\n0:12:07\tSPEAKER_04\n I didn't look at it.\n\n0:12:08\tSPEAKER_02\n I started a spot check.\n\n0:12:09\tSPEAKER_02\n I was trying to remember.\n\n0:12:11\tSPEAKER_02\n I couldn't find the keywords for things that I thought I had said wrong.\n\n0:12:16\tSPEAKER_03\n It's hard to find.\n\n0:12:18\tSPEAKER_04\n That's a compliment to you.\n\n0:12:20\tSPEAKER_04\n He said, it's hard to find things you say wrong.\n\n0:12:22\tSPEAKER_02\n It's hard to find anything that you say.\n\n0:12:25\tSPEAKER_00\n Great.\n\n0:12:26\tSPEAKER_02\n Well, thank you for the filter.\n\n0:12:27\tSPEAKER_02\n It's really useful, because if you're only at part of a meeting or something.\n\n0:12:31\tSPEAKER_05\n So we have our first information retrieval example.\n\n0:12:33\tSPEAKER_05\n It's a great expression.\n\n0:12:36\tSPEAKER_02\n Yeah, that's actually, well, it's useful.\n\n0:12:38\tSPEAKER_03\n And it demonstrates why it doesn't work, because you really want to go more than one meeting.\n\n0:12:42\tSPEAKER_03\n And you need a better user interface for displaying the results.\n\n0:12:45\tSPEAKER_02\n But this helps a lot.\n\n0:12:47\tSPEAKER_05\n You want to say, we're, we're, we're, we'll find all the contentious things I said.\n\n0:12:52\tSPEAKER_04\n Find everything that should be bleeped.\n\n0:12:54\tSPEAKER_03\n That's right.\n\n0:12:55\tSPEAKER_03\n We do have that.\n\n0:12:56\tSPEAKER_03\n It nice marker is that, because we all know we're being recorded whenever anyone says anything like that, we then have a conversation about bleeping it out.\n\n0:13:03\tSPEAKER_02\n Yeah, you can search for beep or bleep.\n\n0:13:04\tSPEAKER_02\n Yeah.\n\n0:13:05\tSPEAKER_02\n Yeah.\n\n0:13:06\tSPEAKER_02\n And somebody else's turn.\n\n0:13:12\tSPEAKER_03\n Oh, and also we actually have a few people who have still not filled out speaker forms, specifically in the NSA ones.\n\n0:13:18\tSPEAKER_03\n And I noticed that when I tried to generate the transcripts for NSA, that there are a few with no speaker forms.\n\n0:13:27\tSPEAKER_03\n And so I have, I said out yet another this morning, which I think makes six totally males that I've sent to these people.\n\n0:13:34\tSPEAKER_03\n And so I think we need to escalate to some other method of trying to contact them.\n\n0:13:44\tSPEAKER_05\n Right.\n\n0:13:44\tSPEAKER_05\n It's a talk.\n\n0:13:46\tSPEAKER_05\n Has, has, has, has your social reply?\n\n0:13:48\tSPEAKER_05\n No.\n\n0:13:49\tSPEAKER_01\n It will work.\n\n0:13:49\tSPEAKER_01\n Maybe talk to him first in person.\n\n0:13:51\tSPEAKER_01\n That's what I would think.\n\n0:13:52\tSPEAKER_05\n He's not around to see any problems.\n\n0:13:54\tSPEAKER_01\n Always, right?\n\n0:13:56\tSPEAKER_05\n I saw him on Tuesday.\n\n0:13:58\tSPEAKER_05\n Yeah, he popped in.\n\n0:13:59\tSPEAKER_05\n He's basically like John.\n\n0:14:00\tSPEAKER_09\n A thinner time, I mean.\n\n0:14:02\tSPEAKER_03\n Well, if I could find phone numbers, that would certainly work.\n\n0:14:04\tSPEAKER_01\n What did you ask, why not?\n\n0:14:06\tSPEAKER_01\n Because I bet she has this information.\n\n0:14:07\tSPEAKER_03\n Yeah, that's a good idea.\n\n0:14:08\tSPEAKER_03\n Well, that's curfew.\n\n0:14:08\tSPEAKER_03\n She can catch up some of them down.\n\n0:14:09\tSPEAKER_05\n And tell her, tell your specific problem.\n\n0:14:13\tSPEAKER_01\n She picks.\n\n0:14:14\tSPEAKER_01\n And then there's still, Miguel is still an active member with a group.\n\n0:14:18\tSPEAKER_01\n And he's, what I mean is he's an active member.\n\n0:14:19\tSPEAKER_01\n And he's still here.\n\n0:14:20\tSPEAKER_03\n He's right there, yeah.\n\n0:14:21\tSPEAKER_03\n Very helpful.\n\n0:14:22\tSPEAKER_03\n Yeah, I didn't actually see who they all were.\n\n0:14:25\tSPEAKER_03\n A couple of them were like people at IBM who were here for one of the IBM meetings.\n\n0:14:29\tSPEAKER_03\n And a guy from SRI, who was at one of the SRI meetings.\n\n0:14:32\tSPEAKER_03\n And so those might be harder to track down.\n\n0:14:35\tSPEAKER_01\n Most of them though, really, we're visitors here.\n\n0:14:37\tSPEAKER_01\n And Lila should have all kinds of nice meetings, by the way.\n\n0:14:39\tSPEAKER_01\n Yeah.\n\n0:14:41\tSPEAKER_03\n They were people who didn't have accounts at XC.\n\n0:14:43\tSPEAKER_03\n So they're, they're harder to find.\n\n0:14:44\tSPEAKER_01\n Well, not the ones that, are you?\n\n0:14:47\tSPEAKER_01\n Are you sure?\n\n0:14:48\tSPEAKER_01\n I'm not sure about what.\n\n0:14:49\tSPEAKER_01\n Yeah, NSA 1 and NSA 3.\n\n0:14:50\tSPEAKER_01\n There were other people also.\n\n0:14:51\tSPEAKER_03\n There were other people also who didn't have to fill out speaker for us in addition to that.\n\n0:14:55\tSPEAKER_05\n In other meetings.\n\n0:14:56\tSPEAKER_01\n Yeah.\n\n0:14:57\tSPEAKER_05\n Oh, I see.\n\n0:14:58\tSPEAKER_05\n Well, SRI people is either blind.\n\n0:15:00\tSPEAKER_05\n And IBM people also just let us know.\n\n0:15:04\tSPEAKER_05\n Certainly have an email.\n\n0:15:06\tSPEAKER_01\n But I knew everybody in the NSA meetings.\n\n0:15:08\tSPEAKER_01\n So I'm sure that we have a fresh information on them.\n\n0:15:13\tSPEAKER_03\n Yeah, none of the emails bounced.\n\n0:15:15\tSPEAKER_03\n So I know they're going somewhere.\n\n0:15:16\tSPEAKER_00\n Good.\n\n0:15:17\tSPEAKER_03\n OK.\n\n0:15:18\tSPEAKER_03\n That's all I have.\n\n0:15:21\tSPEAKER_03\n You want to talk about recognition?\n\n0:15:23\tSPEAKER_03\n I have done anything.\n\n0:15:24\tNone\n I want to talk about recognition.\n\n0:15:25\tSPEAKER_09\n I haven't done anything.\n\n0:15:26\tSPEAKER_09\n I want to talk about recognition.\n\n0:15:27\tSPEAKER_09\n I've done a couple of days.\n\n0:15:28\tSPEAKER_04\n So I haven't done anything.\n\n0:15:29\tSPEAKER_02\n We're sort of in a stage where we're, uh, Don's going through getting some of the next meetings that Jay has.\n\n0:15:39\tSPEAKER_02\n And, uh, you know, creating a second database.\n\n0:15:43\tSPEAKER_02\n So we haven't actually run anything yet.\n\n0:15:46\tSPEAKER_02\n We need to get a critical mass for that.\n\n0:15:47\tSPEAKER_09\n However, we just got an email from Tilo saying that we are ready to run.\n\n0:15:52\tSPEAKER_09\n I mean, we have segmentation.\n\n0:15:53\tSPEAKER_09\n Check the segmentation.\n\n0:15:54\tSPEAKER_02\n Yeah.\n\n0:15:55\tSPEAKER_09\n Yeah.\n\n0:15:56\tSPEAKER_09\n From his segment.\n\n0:15:57\tSPEAKER_09\n So great.\n\n0:15:58\tSPEAKER_09\n You had three different versions, different like the last thresholds between the segments.\n\n0:16:03\tSPEAKER_08\n Yeah, just, yeah, just move the output of the.\n\n0:16:07\tSPEAKER_08\n Right.\n\n0:16:08\tSPEAKER_09\n And you recommended using the one with two, two, two seconds.\n\n0:16:11\tSPEAKER_02\n What do you mean a different pass?\n\n0:16:13\tSPEAKER_08\n You can use the one with one second or whatever.\n\n0:16:17\tSPEAKER_08\n There's not much difference between the one second and the two second one.\n\n0:16:21\tSPEAKER_09\n I mean, the only advantage to using the longer threshold would be that you run less risk of missing some.\n\n0:16:27\tSPEAKER_09\n Act some speed.\n\n0:16:28\tSPEAKER_08\n And I think wouldn't it be better to have a little longer sequences for recognize?\n\n0:16:34\tSPEAKER_08\n Because the language model has sometimes it happens that it struts off within us.\n\n0:16:39\tSPEAKER_08\n Yeah, but we can be sure that is or we can be not not totally sure, but we can be somehow sure that there is nothing, not no speech between those.\n\n0:16:49\tSPEAKER_04\n Yeah.\n\n0:16:50\tSPEAKER_04\n So it is the two second thresholds.\n\n0:16:51\tSPEAKER_08\n I think that's the same as in the this move for the IBM thing.\n\n0:16:56\tSPEAKER_03\n It combines them if the pause is no more than six words.\n\n0:17:00\tSPEAKER_02\n So roughly on average, that's pretty good.\n\n0:17:04\tSPEAKER_02\n Right.\n\n0:17:05\tSPEAKER_03\n So the tradeoff as you get longer utterances, but you miss fewer utterances.\n\n0:17:08\tSPEAKER_08\n Yeah, but the trunks are really in general are short.\n\n0:17:12\tSPEAKER_08\n So I think it would be better to have more of them concernated together in order to have better language model language modeling.\n\n0:17:20\tSPEAKER_08\n I think two seconds.\n\n0:17:22\tSPEAKER_09\n I would maybe go with one second.\n\n0:17:24\tSPEAKER_09\n Well, take a look.\n\n0:17:25\tSPEAKER_09\n Do that.\n\n0:17:26\tSPEAKER_09\n Yeah.\n\n0:17:27\tSPEAKER_08\n Yeah, but there's really not much difference between the one second and so on.\n\n0:17:31\tSPEAKER_04\n I wouldn't think just the language model would continue across two seconds.\n\n0:17:35\tSPEAKER_09\n Well, yeah, you do.\n\n0:17:38\tSPEAKER_09\n You get false recognition.\n\n0:17:39\tSPEAKER_09\n So you've got to, yeah, you've got to hurt yourself occasionally by having missing the language model context, but you might hurt yourself more by having missed recognition due to background speech or.\n\n0:17:53\tSPEAKER_08\n I'm not too afraid about that as when there would be something, some background speed or something that would be a chunk in another.\n\n0:18:02\tSPEAKER_08\n Yeah, I think there's something in between.\n\n0:18:05\tSPEAKER_08\n I can't I do not come.\n\n0:18:06\tSPEAKER_08\n The longer it's better.\n\n0:18:07\tSPEAKER_08\n It's just when there is when there is sequentially and so I would I would use it.\n\n0:18:11\tSPEAKER_02\n There's a lot of these cases just like now where people say, and they're trying to talk and there's about a half second pause to a second in between and then another word.\n\n0:18:21\tSPEAKER_02\n And it's much better if we can keep those together, I think.\n\n0:18:24\tSPEAKER_03\n It's funny looking at some of the transcripts I was filtering by person and in one of the one of the early meetings, one particular person, almost the only thing they said the entire meeting was yeah, it was just a whole list of them.\n\n0:18:38\tSPEAKER_09\n I can't even know that was.\n\n0:18:39\tSPEAKER_09\n So we need to split the waveforms.\n\n0:18:41\tSPEAKER_09\n Or do you already have them split up?\n\n0:18:43\tSPEAKER_09\n No, you don't, right?\n\n0:18:44\tSPEAKER_09\n No.\n\n0:18:45\tSPEAKER_09\n So I guess Dawn would need your help to create a new set of split meetings.\n\n0:18:51\tSPEAKER_09\n Sure.\n\n0:18:52\tSPEAKER_02\n So you just fake the format that you take as input with the same times to a new set of same time.\n\n0:18:57\tSPEAKER_03\n Do we know about disk?\n\n0:18:58\tSPEAKER_03\n Yeah, there's that.\n\n0:19:01\tSPEAKER_03\n Abbott disk.\n\n0:19:02\tSPEAKER_05\n I know they're in.\n\n0:19:03\tSPEAKER_05\n Okay.\n\n0:19:04\tSPEAKER_05\n And but I don't know.\n\n0:19:06\tSPEAKER_04\n He was wasn't he asking a problem, right?\n\n0:19:08\tSPEAKER_05\n Yeah.\n\n0:19:09\tSPEAKER_05\n Well, there was an issue he wanted to take it down and then he did and then it didn't work.\n\n0:19:14\tSPEAKER_03\n I didn't hear any of the masking as you're going to need space to split them up.\n\n0:19:18\tSPEAKER_06\n And so I wanted to make sure I still have like probably six, seven eight gig on my desk.\n\n0:19:27\tSPEAKER_03\n I still have another couple days.\n\n0:19:29\tSPEAKER_02\n I have another six gig which Jeremy, if you're not using, is a couple weeks.\n\n0:19:34\tSPEAKER_05\n He probably needs us to prove another time to take things down, right?\n\n0:19:38\tSPEAKER_04\n Yeah, he didn't say anything to me about it.\n\n0:19:41\tSPEAKER_05\n I thought he said in that mail that he would need to take it down another time.\n\n0:19:45\tSPEAKER_05\n Yeah, he just didn't say when.\n\n0:19:47\tSPEAKER_05\n Well, no, I think he wanted us to tell him.\n\n0:19:49\tSPEAKER_02\n How about during the picnic?\n\n0:19:51\tSPEAKER_05\n Yeah, that's pretty good.\n\n0:19:53\tSPEAKER_03\n Yeah, I'm sure he thought it was.\n\n0:19:55\tSPEAKER_05\n I'm feeling about that.\n\n0:19:57\tSPEAKER_03\n Well, that's the point.\n\n0:20:00\tSPEAKER_03\n So it's Jane.\n\n0:20:01\tSPEAKER_03\n We have to coordinate that through.\n\n0:20:03\tSPEAKER_03\n What I was going to say is as soon as possible and I'm willing to not work for an hour to get it done.\n\n0:20:09\tSPEAKER_03\n But.\n\n0:20:12\tSPEAKER_05\n I think the people with disrupts the most are the transcribers.\n\n0:20:19\tSPEAKER_02\n Well, you know, all I need to do is mail, send them a mail like two days in advance so they can schedule their time.\n\n0:20:26\tSPEAKER_03\n I get what the last outage.\n\n0:20:28\tSPEAKER_01\n I wrote to them letting them know that this.\n\n0:20:31\tSPEAKER_01\n So early on, I can't make sure to almost decide when to do it.\n\n0:20:35\tSPEAKER_01\n I'm going to do it.\n\n0:20:37\tSPEAKER_05\n And just as long as we have a little warning.\n\n0:20:45\tSPEAKER_02\n So that means we can't save meeting data either, right?\n\n0:20:49\tSPEAKER_03\n Just not during that time when it's down, but that it should only be down for an hour.\n\n0:20:53\tSPEAKER_02\n So we can't have two meetings in a row or the first meetings during that hour.\n\n0:20:57\tSPEAKER_03\n Right.\n\n0:20:58\tSPEAKER_03\n Well, we can store them here.\n\n0:21:00\tSPEAKER_03\n We can store them here.\n\n0:21:02\tSPEAKER_03\n We just run the risk that if you have a crash, we lose the data.\n\n0:21:05\tSPEAKER_02\n There's no, I mean, the, oh, just, yeah, this is some popcorn or something.\n\n0:21:09\tSPEAKER_07\n Yep.\n\n0:21:10\tNone\n Okay.\n\n0:21:15\tSPEAKER_05\n Yeah.\n\n0:21:16\tSPEAKER_05\n We store our data on popcorn.\n\n0:21:18\tSPEAKER_05\n That's really great.\n\n0:21:19\tSPEAKER_05\n It's just making we store our data on popcorn.\n\n0:21:22\tSPEAKER_05\n I'm making the students.\n\n0:21:23\tSPEAKER_05\n Can you?\n\n0:21:24\tSPEAKER_05\n So they do that.\n\n0:21:25\tSPEAKER_05\n Okay.\n\n0:21:26\tSPEAKER_05\n Megabytes and mega many megabytes too.\n\n0:21:30\tSPEAKER_05\n What?\n\n0:21:31\tSPEAKER_05\n What?\n\n0:21:32\tSPEAKER_03\n We have a kernel log popcorn too.\n\n0:21:35\tSPEAKER_05\n So what's on your queue for recognition experiments?\n\n0:21:44\tSPEAKER_05\n Let's talk about that for a second.\n\n0:21:46\tSPEAKER_05\n What was the question?\n\n0:21:47\tSPEAKER_05\n What was on his queue for recognition experiments?\n\n0:21:50\tSPEAKER_04\n I'm rebuilding the net that we're going to use for the tandem stuff.\n\n0:21:54\tSPEAKER_04\n And so what I'm doing is putting in the stream reader into the quick-knit libraries.\n\n0:22:01\tSPEAKER_04\n For the SRI feature files, which is the right way to do it.\n\n0:22:05\tSPEAKER_04\n I mean, when we did our first experiments and I was creating SRI feature files from the XC front end, I just had Perl scripts, you know, and hacked a bunch of stuff together just to get it going.\n\n0:22:16\tSPEAKER_04\n But the right way to do it is to integrate it in with the XC tools.\n\n0:22:21\tSPEAKER_04\n And so that's what I'm doing now.\n\n0:22:23\tSPEAKER_04\n And so once I get that done, then I'll generate the P files I need.\n\n0:22:26\tSPEAKER_04\n Because we already have the feature files in the SRI form.\n\n0:22:30\tSPEAKER_04\n And the SRI format, so what I need to do is make it so that the quick-knit stuff can read those.\n\n0:22:36\tSPEAKER_09\n Is that independent or related to also being able to write out the feature file in the SRI format?\n\n0:22:44\tSPEAKER_09\n There's an input stream in an output stream.\n\n0:22:47\tSPEAKER_09\n So then you could use, like, a fecalc and just specify as an output format.\n\n0:22:56\tSPEAKER_09\n Yeah, that's the point.\n\n0:22:57\tSPEAKER_09\n I'm just thinking about it.\n\n0:23:00\tSPEAKER_03\n If you- Right, quick-knit is a very nice stream-based library.\n\n0:23:04\tSPEAKER_03\n So without too much effort, once he has the classes written, we can incorporate it into all the standard tools.\n\n0:23:13\tSPEAKER_04\n So then it's tandem experiments.\n\n0:23:15\tSPEAKER_03\n And at some point, I'd like to get back to porting quick-knit to the multi-process or Linux box.\n\n0:23:23\tSPEAKER_03\n I have forward passes working, but I haven't done training yet.\n\n0:23:28\tSPEAKER_09\n So speaking of Linux, so there's some impetus at SRI to actually build support Linux as a platform.\n\n0:23:40\tSPEAKER_09\n So that means once we have everything running on Linux, we can also run all our jobs on your machines.\n\n0:23:48\tSPEAKER_02\n Yeah, exactly.\n\n0:23:49\tSPEAKER_04\n We don't have too many.\n\n0:23:50\tSPEAKER_04\n We just have that.\n\n0:23:51\tSPEAKER_04\n Just have a few.\n\n0:23:53\tSPEAKER_09\n I mean, if you can't use all the processors on whatever machine.\n\n0:23:56\tSPEAKER_03\n Well, that's a nice thing about it, since it's course parallelism, you don't have to do anything special.\n\n0:24:01\tSPEAKER_03\n I'd expect it.\n\n0:24:02\tSPEAKER_03\n So, I mean, that would be a fine use for before that machine.\n\n0:24:05\tSPEAKER_03\n So it's just five more processors.\n\n0:24:09\tSPEAKER_09\n Yeah.\n\n0:24:11\tSPEAKER_09\n So- And in the future, if Linux machines become way cheaper than Solaris machines, then that wouldn't be a reason not to use Linux anymore.\n\n0:24:23\tSPEAKER_07\n Yeah.\n\n0:24:24\tSPEAKER_05\n Yeah.\n\n0:24:25\tSPEAKER_05\n I think it would be neat at some point in this to do a recognition pass on one of the PCM mics for these same meetings that you're getting.\n\n0:24:40\tSPEAKER_05\n I mean, it's going to be terrible, but we just don't know how terrible.\n\n0:24:45\tSPEAKER_02\n It's also an interesting problem to come up with the reference.\n\n0:24:50\tSPEAKER_02\n So the reference file for the relative time that-\n\n0:24:55\tSPEAKER_00\n Oh, it's a good one.\n\n0:24:56\tSPEAKER_02\n So, well, it's an interesting question because I was thinking, well, you can force a line, the transcriber transcripts, and then, of course, you try to merge them in time. But how do you score?\n\n0:25:08\tSPEAKER_03\n I think the first pass is throw out words which are overlapped.\n\n0:25:12\tSPEAKER_03\n That would be a good first pass.\n\n0:25:14\tSPEAKER_03\n Just ignore everything that hasn't been done.\n\n0:25:16\tSPEAKER_05\n Yeah, because you have a set of scores about that.\n\n0:25:18\tSPEAKER_02\n Right.\n\n0:25:19\tSPEAKER_02\n Some of you then that wouldn't be so bad.\n\n0:25:20\tSPEAKER_02\n But there's a whole interesting discussion because, of course, the alignments are not perfect either.\n\n0:25:24\tSPEAKER_02\n Right.\n\n0:25:25\tSPEAKER_02\n So, in fact, we actually don't have a-\n\n0:25:28\tSPEAKER_05\n I mean, it's a little bit better than what we do with just these. Right.\n\n0:25:32\tSPEAKER_05\n And again, if you rule out the overlapped, you have some numbers for that, because that's yet another- I'm just concerned, of course, about that.\n\n0:25:38\tSPEAKER_02\n Oh, I see you mean one only one person is talking-\n\n0:25:40\tSPEAKER_00\n Yep. Yes.\n\n0:25:42\tSPEAKER_00\n Because you have scores for that.\n\n0:25:43\tSPEAKER_00\n We can try that.\n\n0:25:44\tSPEAKER_00\n Right.\n\n0:25:45\tSPEAKER_05\n Right, exactly.\n\n0:25:46\tSPEAKER_05\n Yeah, we should try.\n\n0:25:47\tSPEAKER_05\n That will be- I mean, one of the things that Dave was noticing we're talking this morning is that it seems like we don't know this in detail, but it seems like you're getting a lot from the channel adaptation, the speaker adaptation, and so forth.\n\n0:26:00\tSPEAKER_05\n So, you are already, and I recognize you're doing something that is likely to affect the far-fielk microphone performance.\n\n0:26:11\tSPEAKER_05\n So, it may not- I mean, it's going to be bad, but it may not be like, won't decode kind of bad.\n\n0:26:18\tSPEAKER_05\n It might only be that it- It may be 40%- Maybe, or something like that.\n\n0:26:23\tSPEAKER_02\n Do you assume you know the speaker when you do this?\n\n0:26:26\tSPEAKER_05\n I want us to assume the exact- whatever it was you assumed when you did the other-\n\n0:26:31\tSPEAKER_02\n The close mic. Well, there's only one person who it can be because they own that microphone.\n\n0:26:37\tSPEAKER_02\n I'm just wondering- That comes another far- I wonder when you're the gendered person.\n\n0:26:40\tSPEAKER_02\n That's for scoring.\n\n0:26:41\tSPEAKER_02\n That's for scoring.\n\n0:26:42\tSPEAKER_02\n You can do it or not do it as you choose.\n\n0:26:43\tSPEAKER_02\n Right.\n\n0:26:44\tSPEAKER_02\n You're saying for this- For the adaptation- Well, for everything first.\n\n0:26:47\tSPEAKER_02\n You know, you do a supervised adaptation.\n\n0:26:50\tSPEAKER_02\n Right.\n\n0:26:51\tSPEAKER_02\n All of these adaptations-\n\n0:26:53\tSPEAKER_09\n All of these assume you know-\n\n0:26:56\tSPEAKER_02\n Assume that the same person-\n\n0:26:57\tSPEAKER_09\n You would have to do the speaker segmentation first on the five field mic.\n\n0:27:00\tSPEAKER_03\n Well, but you can use the- When you're doing the scoring, since you're- You're going to be scoring against transcript, you can use-\n\n0:27:06\tSPEAKER_09\n When you want to cheat.\n\n0:27:07\tSPEAKER_03\n Well, you're doing that anyway. Well, I don't-\n\n0:27:10\tSPEAKER_01\n So, should she-\n\n0:27:11\tSPEAKER_03\n Try to cheat in the same way that you're doing with the close talk.\n\n0:27:13\tSPEAKER_01\n Actually, I don't like that- I don't like that too.\n\n0:27:15\tSPEAKER_05\n I- I have a suggestion.\n\n0:27:17\tSPEAKER_05\n Do the simplest thing first.\n\n0:27:18\tSPEAKER_05\n Yeah, right.\n\n0:27:19\tSPEAKER_05\n Because we're going to want to know that anyway.\n\n0:27:21\tSPEAKER_05\n So, the simplest thing is you cheat, saying- No, it's- no, it's even simpler thing than that is just that you don't know.\n\n0:27:27\tSPEAKER_09\n You mean you don't- You don't do all those numbers, right?\n\n0:27:30\tSPEAKER_09\n Yeah.\n\n0:27:31\tSPEAKER_02\n Oh, you- You can totally unwrap it.\n\n0:27:33\tSPEAKER_05\n Yeah, because you can get a number for that with the other as well, right?\n\n0:27:36\tSPEAKER_05\n You can turn those things off, right?\n\n0:27:38\tSPEAKER_09\n Yeah.\n\n0:27:39\tSPEAKER_09\n Actually, we don't have any models.\n\n0:27:42\tSPEAKER_02\n Oh, you can-\n\n0:27:43\tSPEAKER_09\n You can-\n\n0:27:44\tSPEAKER_02\n You can use a speaker- What about gender defects?\n\n0:27:46\tSPEAKER_09\n Actually, we would have to retrain models that are not- That have none of that stuff in it.\n\n0:27:53\tSPEAKER_09\n But actually, we could- We can just run it, assuming that it's all one speaker, basically.\n\n0:28:01\tSPEAKER_09\n Yeah.\n\n0:28:02\tSPEAKER_09\n And see what happens.\n\n0:28:03\tSPEAKER_05\n Yeah.\n\n0:28:04\tSPEAKER_05\n Yeah, and then put it in correctly and see how much that helps.\n\n0:28:06\tSPEAKER_05\n Yeah.\n\n0:28:07\tSPEAKER_05\n I mean, I was just thinking to do the one that's easiest first.\n\n0:28:09\tSPEAKER_05\n Because you want to know how much that's helping you in the right cases anyhow.\n\n0:28:12\tSPEAKER_05\n So, you have gender- Gender-depend models?\n\n0:28:14\tSPEAKER_08\n So, I- All the models gender-depend?\n\n0:28:16\tSPEAKER_08\n Yeah.\n\n0:28:17\tSPEAKER_02\n And then also-\n\n0:28:18\tNone\n Yeah, so- So, you could do that- No, you could run both.\n\n0:28:21\tSPEAKER_09\n And pick whichever is better.\n\n0:28:22\tSPEAKER_09\n Here's what we would usually do on the least circumstances.\n\n0:28:25\tSPEAKER_09\n We would actually- We would run some sort of segmentation.\n\n0:28:28\tSPEAKER_09\n Tilosus is good at saying it probably.\n\n0:28:31\tSPEAKER_09\n And then we would do an answer- Provised clustering of the segments to- And put the similar ones into bins that would be sort of pseudo speakers.\n\n0:28:43\tSPEAKER_09\n And then we would do our standard processing on these pseudo speakers.\n\n0:28:46\tSPEAKER_09\n And that turns out to work very well on broadcast news, spy on those types of tasks where you don't have the speaker segmentation given to you.\n\n0:28:55\tSPEAKER_03\n Does the clustering do you give it sort of a target number of clusters or is it-\n\n0:28:59\tSPEAKER_09\n And that means- Either by target number or by some measure of the similarity that you've been using.\n\n0:29:05\tSPEAKER_03\n Yes, I'm just thinking one of the big differences with broadcast news in these meetings is we have many fewer participants.\n\n0:29:11\tSPEAKER_02\n The other thing is that you actually have direction here.\n\n0:29:16\tSPEAKER_02\n So unlike these corpora that are recorded with other microphones, like the right way to do this, I guess, you know, in the future would be- Speak on it, yeah.\n\n0:29:25\tSPEAKER_02\n In general, Tilo sitting there and this PCM is gonna- Well, there are different ways of taking that.\n\n0:29:29\tSPEAKER_03\n I mean, that would be true if you had a meeting situation with multiple mics.\n\n0:29:33\tSPEAKER_03\n But if you only had your PDA sitting in front of you.\n\n0:29:36\tSPEAKER_02\n Well, any case where the people are not all sitting at the same place and they're not moving around too much.\n\n0:29:41\tSPEAKER_03\n And you have more than one mic.\n\n0:29:43\tSPEAKER_05\n Yeah, if you don't have one more than one mic, you don't have a very good handle on location.\n\n0:29:48\tSPEAKER_02\n Well, you have distance and you have-\n\n0:29:50\tSPEAKER_05\n distance not enough.\n\n0:29:53\tSPEAKER_02\n I mean that James, the pickup of Adam on this mic is gonna be different than me in terms of energy and so forth over the whole meeting.\n\n0:30:01\tSPEAKER_03\n So just from clustering, you might be able to cluster a little bit.\n\n0:30:03\tSPEAKER_02\n You might get some clustering from the speaker and some of it from characteristics of the distance.\n\n0:30:09\tSPEAKER_05\n But say if you had a- Transcript, right.\n\n0:30:12\tSPEAKER_05\n Carried with micracing.\n\n0:30:13\tSPEAKER_05\n Sitting someplace, then sitting there, then it's- It's a response to him would be- Well, I think there are lots of- They're both picked up in the clustering.\n\n0:30:20\tSPEAKER_09\n You can send your normalizations like, you know, gain control before you do the clustering to rule out those types of things.\n\n0:30:26\tSPEAKER_02\n Or to just do the clustering knowing that you're capturing both.\n\n0:30:30\tSPEAKER_02\n It's just that the kind of clustering we've done before hasn't had that distance factor or-\n\n0:30:36\tNone\n Yeah. or location factor in it in the same way.\n\n0:30:38\tSPEAKER_02\n And so we're not really modeling it directly if somebody does.\n\n0:30:41\tSPEAKER_02\n Yeah, that's an interesting- Maybe we had that because I think it would be a pretty big difference.\n\n0:30:45\tSPEAKER_02\n When you listen, you can sort of tell where people are, not which, you know, side.\n\n0:30:50\tSPEAKER_03\n Well, humans are really good at that transfer function through the head.\n\n0:30:53\tSPEAKER_03\n Right.\n\n0:30:54\tSPEAKER_02\n Things like that.\n\n0:30:55\tSPEAKER_03\n Even with one- You only have one ear.\n\n0:30:57\tSPEAKER_03\n You can still get good transfer.\n\n0:30:58\tSPEAKER_02\n So our clustering is not going to be intelligent that way.\n\n0:31:01\tSPEAKER_02\n It's just going to pick up whatever energy difference or whatever.\n\n0:31:04\tSPEAKER_05\n But anyway, I'd be neat to have that because we've been at this for a little while.\n\n0:31:09\tSPEAKER_05\n We don't have any results yet with conversational speech at a distance.\n\n0:31:14\tSPEAKER_05\n So we should at least get a first one.\n\n0:31:17\tSPEAKER_05\n Something, yeah.\n\n0:31:18\tSPEAKER_05\n And the other thing, this would kind of be a hail Mary.\n\n0:31:21\tSPEAKER_05\n But Dave does have this stuff that is helping on digits.\n\n0:31:26\tSPEAKER_05\n Yeah, so it would be cool to see if it helped.\n\n0:31:28\tSPEAKER_03\n You know, just throw that in.\n\n0:31:29\tSPEAKER_09\n Yeah.\n\n0:31:30\tSPEAKER_09\n Throw it to the whole training site.\n\n0:31:31\tSPEAKER_09\n Do you retreat?\n\n0:31:32\tSPEAKER_09\n Yeah.\n\n0:31:33\tSPEAKER_03\n That would be quick.\n\n0:31:35\tSPEAKER_03\n Since I think you did it in MATLAB.\n\n0:31:38\tSPEAKER_05\n Well, you can do it in something else.\n\n0:31:41\tSPEAKER_05\n But I mean, you know, it's-\n\n0:31:43\tSPEAKER_03\n Can you export C from MATLAB?\n\n0:31:45\tSPEAKER_05\n Actually, we're experimenting with FACE stuff now. And the first result he got was really great.\n\n0:31:51\tSPEAKER_05\n It actually didn't exactly eliminate the reverberation, but it completely got rid of the speech.\n\n0:31:57\tSPEAKER_05\n That would be a lot of fun.\n\n0:32:00\tSPEAKER_09\n Yeah, well, I was just taking the inputs and you're fine.\n\n0:32:03\tSPEAKER_05\n You think I didn't know that?\n\n0:32:05\tSPEAKER_05\n No, I got pretty excited because it completely got rid of the speech.\n\n0:32:08\tSPEAKER_05\n So I was thinking- So it's a speech detector, that's great.\n\n0:32:11\tSPEAKER_05\n That's interesting.\n\n0:32:12\tSPEAKER_05\n Could be useful for lots of things.\n\n0:32:13\tSPEAKER_01\n Take your rid of other stuff too, though.\n\n0:32:14\tSPEAKER_01\n You could get rid of other stuff besides the speech.\n\n0:32:16\tSPEAKER_03\n Well, yeah, sort of check that out.\n\n0:32:17\tSPEAKER_03\n Subtract that from the original signal and your set.\n\n0:32:19\tSPEAKER_01\n Wow, interesting.\n\n0:32:20\tSPEAKER_09\n Right then, you can estimate the- Noise estimate.\n\n0:32:24\tSPEAKER_09\n Signal to noise, that's great.\n\n0:32:27\tSPEAKER_05\n It reminds me of an AirVay and I were first playing with context dependent things for NETS.\n\n0:32:33\tSPEAKER_05\n And at one point, we took out the speech input, so we only had priors and our performance went up.\n\n0:32:39\tSPEAKER_03\n I guess that's why AirVay always talks about using the priors as one of the mixers in his always combats.\n\n0:32:47\tSPEAKER_03\n Well, of course it was a bug, but I mean it was-\n\n0:32:50\tSPEAKER_05\n That's still, but it was pretty. Wow, interesting.\n\n0:32:52\tSPEAKER_05\n It was pretty funny anyway.\n\n0:32:54\tSPEAKER_03\n So if you run your recognizer with all probabilities equal, what do you get at?\n\n0:33:00\tSPEAKER_03\n Probably garbage.\n\n0:33:02\tSPEAKER_03\n Whatever the learning model is.\n\n0:33:03\tSPEAKER_03\n The learning probably prints everything.\n\n0:33:05\tSPEAKER_03\n You got a switch, but we had to make it.\n\n0:33:07\tSPEAKER_05\n That's how it's generating.\n\n0:33:10\tSPEAKER_09\n Yes, so we have this new speaker adaptation.\n\n0:33:13\tSPEAKER_09\n It was a sort of feature normalization, like speaker adaptation, which I wrote about in the last set of support, which seems to be helping not percent of the half of the five.\n\n0:33:27\tSPEAKER_09\n So we haven't tried that yet on the meetings, but hopefully we'll help there too.\n\n0:33:32\tSPEAKER_09\n I want to ask-\n\n0:33:33\tSPEAKER_01\n So you know that the data, I've upgraded it considerably, so I've probably made- I probably corrected something like, well, it's really substantial amount of things that have caught changed added to it, including a lot of back channels.\n\n0:33:46\tSPEAKER_01\n So when you're running things, if you run it on the old- so if you run it on the new version, then the numbers will be- And you compare it to the- to runs on the old version, then you're going to end up with more of an improvement than would actually be the case.\n\n0:34:01\tSPEAKER_09\n We do all our experiments with the frozen version of the transcripts, as of- I don't know.\n\n0:34:07\tSPEAKER_09\n As of February?\n\n0:34:08\tSPEAKER_09\n I don't know when did we- So- Like the ACLT paper?\n\n0:34:14\tSPEAKER_01\n Sorry.\n\n0:34:15\tSPEAKER_09\n For these meetings?\n\n0:34:16\tSPEAKER_09\n We're talking about which version we're using for evaluating the recognition, which version of the transcripts?\n\n0:34:22\tSPEAKER_02\n Right.\n\n0:34:23\tSPEAKER_02\n There's somewhere in between January and late March or something like that.\n\n0:34:27\tSPEAKER_02\n Yeah, so long as you have the baseline, then you'll be able to tell.\n\n0:34:31\tSPEAKER_01\n Obviously, yeah.\n\n0:34:32\tSPEAKER_01\n So long as the same base are now being able to tell, but I'm just saying that if you would compare that with running that on the old version, it would be more of the same outcome.\n\n0:34:40\tSPEAKER_09\n It takes only a minute to restore all the old outputs with if you had new transcripts than which is- Right, because you haven't done any training.\n\n0:34:51\tSPEAKER_03\n Sorry?\n\n0:34:52\tSPEAKER_02\n Right, because we're not doing a training.\n\n0:34:54\tSPEAKER_02\n Yeah, we haven't modified the recognizer at all.\n\n0:34:56\tSPEAKER_02\n Right, so it's really- It would be easy to redo it.\n\n0:34:58\tSPEAKER_02\n At some point, we should update and restore everything with, you know, the practice and practice.\n\n0:35:02\tSPEAKER_02\n It'd be interesting just to see how much it changes.\n\n0:35:04\tSPEAKER_03\n It's a bit-\n\n0:35:05\tSPEAKER_02\n What are the changes we get as the changes? Sometimes the changes are cases where the recognizer would get it wrong anyway, because it was somewhere that we didn't have in the vocabulary.\n\n0:35:15\tSPEAKER_02\n But it does help to get the back tunnels back in and things like that.\n\n0:35:19\tSPEAKER_09\n So whenever the- Right now, the scoring is based on segments, which is not great because for instance, so the other way to do the scoring is using a list format called STM, so segment type- Yep, we know where.\n\n0:35:36\tSPEAKER_09\n So I have to convert the transcripts into this format, and then the scoring program actually looks at the times.\n\n0:35:45\tSPEAKER_09\n And, you know, you can have a different segmentation and you recognize the output and your references.\n\n0:35:50\tSPEAKER_09\n So that's what we need to-\n\n0:35:54\tSPEAKER_03\n Transcriber will export STM in case you care.\n\n0:35:59\tSPEAKER_09\n Well, but then there's other changes, so I mean, there's other- We strip away a lot of the markup and the transcripts, which, you know, isn't a trend on the template of the speech I can show up.\n\n0:36:12\tSPEAKER_02\n But that doesn't only change the scoring if a word has moved into a different segment.\n\n0:36:17\tSPEAKER_02\n I mean, I don't think that's- I hardly ever see that.\n\n0:36:20\tSPEAKER_02\n I think most of them are pretty good.\n\n0:36:23\tSPEAKER_09\n Well, I mean, if support- I assume you also changed some of that.\n\n0:36:27\tSPEAKER_09\n I did.\n\n0:36:28\tSPEAKER_09\n So if we want to use new transcripts with a different segmentation, then we can't use them in a current way we use score.\n\n0:36:35\tSPEAKER_09\n We have to-\n\n0:36:37\tSPEAKER_02\n Oh, you mean you need to rerun the recognition?\n\n0:36:39\tSPEAKER_09\n No, we have to-\n\n0:36:41\tSPEAKER_02\n I mean, if you rerun the recognition, then you just run it. I see, if you want to use the old- You can actually never, though, really infer what you would get with a different, you know.\n\n0:36:50\tSPEAKER_02\n It's probably more fair to rerun that.\n\n0:36:53\tSPEAKER_02\n In other words, it's not really a scoring script problem.\n\n0:36:57\tSPEAKER_09\n No, but if you just want to see what- Like, suppose you fix some type, or you're going to fix some typos, and you want to see what effect does it have on the word error.\n\n0:37:08\tSPEAKER_03\n Right, but-\n\n0:37:09\tSPEAKER_02\n Yeah.\n\n0:37:10\tSPEAKER_03\n If the segments change, that won't work.\n\n0:37:11\tSPEAKER_02\n It'll sort of work, but it's not exactly what you would maybe get from recognition.\n\n0:37:15\tSPEAKER_03\n Well, I mean, what happens if you break one segment into two? Suddenly, they don't match at all, and you can't line them up anymore.\n\n0:37:21\tSPEAKER_09\n Well, you can line them up in the top.\n\n0:37:25\tSPEAKER_09\n So the scoring program, if you give it an STM reference file, it will actually compare the words based on their timelapse.\n\n0:37:34\tSPEAKER_09\n So therefore, you can-\n\n0:37:36\tSPEAKER_03\n Does STM do per word or per utterance?\n\n0:37:39\tSPEAKER_09\n It's per utterance, but it allows- As long as you hypothesize the word in the right segment in a reference, it gives you credit for that.\n\n0:37:47\tSPEAKER_09\n So it does a word alignment, like you have to do for scoring.\n\n0:37:51\tSPEAKER_09\n And it does also- It constrains the words to lie within the segment.\n\n0:37:55\tSPEAKER_03\n Within the segment, yeah.\n\n0:37:56\tSPEAKER_09\n The reference, I see.\n\n0:37:57\tSPEAKER_09\n And for you to get credit for that, so-\n\n0:38:00\tSPEAKER_01\n That sounds great.\n\n0:38:02\tSPEAKER_09\n So it should be just a straightforward reforming issue of the right-\n\n0:38:06\tSPEAKER_01\n Yeah, I mean, I was thinking the other day that this- It's not just conversational speech, the fact that it has so much technological jargon in it.\n\n0:38:15\tSPEAKER_01\n It makes it considerably harder to- To transcribe and to double check and all those things.\n\n0:38:23\tSPEAKER_01\n So I think you're going to find a substantial gain in terms of the word accuracy.\n\n0:38:28\tSPEAKER_01\n As long as those words are in your vocabulary.\n\n0:38:31\tSPEAKER_01\n Well, it definitely helps with-\n\n0:38:32\tSPEAKER_02\n What percent? Forced alignment, too, because, you know, when we know the true words, and we're adding them to the vocabulary and training a language model, and so forth for future meetings, especially the front end meetings or meetings with a lot of jargon in them that- It's not represented in switchboard or call home, but it-\n\n0:38:51\tSPEAKER_01\n For all of our meetings. For all of our meetings have a lot of jargon in them.\n\n0:38:54\tSPEAKER_01\n But we know what those words are.\n\n0:38:56\tSPEAKER_01\n I mean, I don't know how you get them into the vocabulary, but it would seem- Now, I have to- I really need to raise a question about the term cheating.\n\n0:39:04\tSPEAKER_01\n Okay.\n\n0:39:05\tSPEAKER_01\n And the reason is, if I understand that cheating is a term which is used to apply for basically what- All of linguistics, corpus linguistics does and what- What my transcribers are doing and what I do, which is a methodology where by you actually physically mark things in the data.\n\n0:39:21\tSPEAKER_01\n Like the transcription, like the words-\n\n0:39:23\tSPEAKER_03\n All we need by that is that we're giving the recognizer more information than it would have if you were running it raw. Over a meeting that no person has ever listened to or transcribed.\n\n0:39:33\tSPEAKER_03\n Okay.\n\n0:39:34\tSPEAKER_01\n I mean, that- that part is okay, but I- But I do wonder sometimes if it might be possible to use a term that's a little bit less evaluative, like- The cheating is-\n\n0:39:44\tSPEAKER_05\n The cheating is pretty commonly used to me-\n\n0:39:48\tSPEAKER_02\n I guess it is. It's a long time and it's sort of- Because it's so strong or word, people don't take it that seriously.\n\n0:39:56\tSPEAKER_02\n Yeah.\n\n0:39:57\tSPEAKER_02\n And it's not negatively viewed, it just really means-\n\n0:39:59\tSPEAKER_05\n It's even more than that. I think it really gives a very strong perspective that you know that what you were doing is not an unbiased experiment.\n\n0:40:10\tSPEAKER_05\n If you don't say that, then people think, oh, they did that and they threw that, but that doesn't represent what would happen in the real world.\n\n0:40:16\tSPEAKER_05\n If you say, we did a cheating experiment, which is really the standard way you'd say it.\n\n0:40:21\tSPEAKER_05\n It says you deliberately put in a piece of the information that you would not have in the real world so that you can learn something.\n\n0:40:27\tSPEAKER_05\n This is part of your process.\n\n0:40:29\tSPEAKER_05\n So it's- I don't like-\n\n0:40:31\tSPEAKER_01\n Okay. I guess what I'm thinking is just in- When these are presented in an interdisciplinary context, it might be nice to add that explanation.\n\n0:40:40\tSPEAKER_01\n Otherwise, it sounds like a pejorative statement on an alternative methodology.\n\n0:40:44\tSPEAKER_01\n Because it sounds like it sort of devalues the other approach which is to put those distinctions in-\n\n0:40:51\tSPEAKER_05\n I mean, I've heard this at ICS, I hope you're years and years and years now. Yeah, it's pretty, pretty clear.\n\n0:40:56\tSPEAKER_09\n Well, through a broader audience you could call it a diagnostic experiment.\n\n0:41:00\tSPEAKER_02\n Actually, Jane is right like in conversation analysis, I've never heard people use this because they're not using an automatic system.\n\n0:41:07\tSPEAKER_02\n So it really- Right, well, you can do experiments, but the- It's cheating relative to what we call a system where we can completely control this black box.\n\n0:41:19\tSPEAKER_02\n And it's not a very smart system.\n\n0:41:21\tSPEAKER_02\n It only knows what we give it.\n\n0:41:23\tSPEAKER_02\n And if it knows more than we would really give it when it runs, we call it cheating.\n\n0:41:27\tSPEAKER_02\n But it's- yeah, it's only used in a community that does some type of computational modeling, I think.\n\n0:41:34\tSPEAKER_02\n It's really not used in any kind of community doing experiments on human perception or so.\n\n0:41:41\tSPEAKER_02\n Yeah, it's machine learning.\n\n0:41:42\tSPEAKER_05\n Certainly experiments.\n\n0:41:44\tSPEAKER_05\n I mean, when the neural net wave hit in the mid-80s and by the late-80s, we were reviewing thousands of papers that were coming out neural nets.\n\n0:41:57\tSPEAKER_05\n It was really hot and everybody thought it would do everything.\n\n0:42:00\tSPEAKER_05\n And a really common error that people were making was they were just reporting their classification results on the data that they were training on.\n\n0:42:11\tSPEAKER_05\n And so I think it was very important for people then who were doing something diagnostic to say, hey, I know I'm doing something that isn't kosher and to make it really clear that they knew it.\n\n0:42:22\tSPEAKER_05\n So that was, I think, why it became a popular experiment.\n\n0:42:25\tSPEAKER_01\n It just seems like, you know, if it were bootstrapping or if it were, I mean, there are other ways to maybe get the point of time.\n\n0:42:30\tSPEAKER_05\n But it is a bootstrapping.\n\n0:42:31\tSPEAKER_05\n It's really- It's using information you wouldn't normally have.\n\n0:42:35\tSPEAKER_05\n But it's cheating in a way that's- it's announcing to everybody, hey, I'm cheating by doing this.\n\n0:42:40\tSPEAKER_05\n It's saying so. It's all above the table.\n\n0:42:42\tSPEAKER_05\n I'm actually using this other thing.\n\n0:42:44\tSPEAKER_05\n Okay.\n\n0:42:45\tSPEAKER_05\n Bootstrapping would imply it was actually legitimate in some kind of way.\n\n0:42:49\tSPEAKER_05\n Well, I think-\n\n0:42:50\tSPEAKER_03\n But we're not de-legionizing the data, we're de-legionimizing the experiment. We're not saying that the data is cheating data.\n\n0:42:57\tSPEAKER_03\n We're saying we are cheating by using this data.\n\n0:43:00\tSPEAKER_03\n Okay.\n\n0:43:01\tSPEAKER_03\n Because normally you wouldn't have that data available.\n\n0:43:03\tSPEAKER_01\n Okay.\n\n0:43:04\tSPEAKER_01\n It does seem to me that it carries over some baggage with it that- that I can understand it in context as you described it.\n\n0:43:11\tSPEAKER_01\n But it seems to me that it does import some negative evaluation that would- Maybe not be good.\n\n0:43:20\tSPEAKER_01\n It has shock value and to the wrong audience, I think that that might be a negative shock.\n\n0:43:25\tSPEAKER_01\n Yeah.\n\n0:43:26\tSPEAKER_01\n To the wrong audience, I agree that-\n\n0:43:28\tSPEAKER_02\n Like a disclaimer. To the wrong audience, we should just explain what it means.\n\n0:43:32\tSPEAKER_01\n Yeah. We started with hand-marked data or with, you know, hand-transcribed data or- Shoot.\n\n0:43:37\tSPEAKER_01\n Yeah. Did you bring the microphone?\n\n0:43:39\tSPEAKER_01\n Just the clip.\n\n0:43:40\tSPEAKER_01\n Okay.\n\n0:43:41\tSPEAKER_01\n Okay.\n\n0:43:42\tSPEAKER_01\n Well, I feel better now.\n\n0:43:43\tSPEAKER_01\n Thank you very much.\n\n0:43:44\tSPEAKER_01\n The first time I had-\n\n0:43:45\tSPEAKER_02\n Thank you, I'm good. I thought, you know, the same thing and I guess you just after a while it becomes- It really is part of the jargon.\n\n0:43:52\tSPEAKER_02\n It's a bit of- It's also- A humblings when somebody says that if they get good results but we were cheating on this feature because we took it for granted even though we can't really assume that, then it's actually the opposite.\n\n0:44:04\tSPEAKER_01\n The trouble is that, you know, I understand it in that context, but it is almost resentful.\n\n0:44:10\tSPEAKER_01\n It's almost like, you know, resentful of the data, resentful of the- The hard work that's going into preparing the data.\n\n0:44:16\tSPEAKER_01\n No, no, I don't think you're saying the data is cheating.\n\n0:44:19\tSPEAKER_05\n I think you're saying- That's the same.\n\n0:44:21\tSPEAKER_05\n In my experiment, I cheated in this way.\n\n0:44:23\tSPEAKER_05\n I mean, another thing is what- This was talking about how in the switchboard test, in all the switchboard tests we've been doing, we've been making the same standard- Using the same standard way of getting the data to test on, which means that we weren't actually running it on data that had no speech.\n\n0:44:43\tSPEAKER_05\n And in a sense that was cheating.\n\n0:44:45\tSPEAKER_05\n Okay.\n\n0:44:46\tSPEAKER_05\n So it's a good wake-up call of people, well, we have this performance, but you have to keep in mind we're doing the whole real task in this way and this way and this way.\n\n0:44:57\tSPEAKER_05\n But I'll convince you that it's still important for you to listen to what I have say next because of this and this.\n\n0:45:03\tNone\n Okay.\n\n0:45:03\tSPEAKER_05\n And so it's just a way of putting it all out on the table.\n\n0:45:05\tSPEAKER_03\n And it's used for a lot of different types of data.\n\n0:45:08\tSPEAKER_03\n So whether you have segmentation or not, is it male or female or not?\n\n0:45:12\tSPEAKER_03\n Do you know the signal to noise?\n\n0:45:14\tSPEAKER_03\n Like that's another one I see all the time where you assume it's known.\n\n0:45:17\tSPEAKER_03\n No, I just- And you say it's cheating because you don't actually compute it.\n\n0:45:20\tSPEAKER_05\n In the multi-band experiments, in the first one, we really wanted to find out what if you knew which band was really noisy?\n\n0:45:26\tSPEAKER_05\n Right.\n\n0:45:27\tSPEAKER_05\n I mean, suppose you just know that.\n\n0:45:29\tSPEAKER_05\n And then even if you know that, can that help you?\n\n0:45:32\tSPEAKER_05\n I mean, what strategy can you do to do well without that particular band in the spectrum?\n\n0:45:37\tSPEAKER_05\n And so that was important to know as a baseline.\n\n0:45:40\tSPEAKER_05\n And then once you knew that, then you go, well, now how do I know that that's noisy?\n\n0:45:44\tSPEAKER_05\n Okay.\n\n0:45:45\tSPEAKER_05\n But you know, I should also say that there's a lot of- It's not just we're cheating, but there's lots of other things that we talk about, which as soon as you go outside of a few narrow little group, it gets very, very confusing to people.\n\n0:45:57\tSPEAKER_01\n Oh, sure. Terminalogy is always context dependent. No question about it.\n\n0:46:00\tSPEAKER_01\n It's just that it seems like the point without the negative evaluation would be, however, you know, I understand your point.\n\n0:46:07\tSPEAKER_01\n That it has a long tradition in this field that he's not realized and is used.\n\n0:46:10\tSPEAKER_01\n This is interesting what Adam said about it being used also for a bunch of other-\n\n0:46:14\tSPEAKER_05\n Well, the example I was thinking of also was this thing that, that are they, and T.M.I. made about increasing the error rate?\n\n0:46:20\tSPEAKER_05\n And so we did a number of papers and talks and so forth about the virtues of increasing the- Oh.\n\n0:46:27\tSPEAKER_05\n Okay. I mean, and the whole point of it was not that it was good to increase the error rate, but it was good to be willing to risk increasing the error rate by trying risky things and trying, because there's this notion of a local minimum that if you just have some system that's very complex, then you turn some knobs to try to make it better and better, you'll never get out of this local minimum.\n\n0:46:50\tSPEAKER_05\n You have to be willing to jump to something that's quite different.\n\n0:46:53\tSPEAKER_05\n And the first time you jump to something quite different, or maybe the first ten times, or hundred times you do, it's going to be much, much worse because you've optimized the other system.\n\n0:47:01\tSPEAKER_05\n So the effect, immediate effect, is going to be to increase your error rate.\n\n0:47:04\tSPEAKER_05\n Interesting.\n\n0:47:05\tSPEAKER_05\n And so we had a couple of papers like towards increasing the error rate and speech and so on.\n\n0:47:09\tSPEAKER_05\n And we really did get feedback from a few people, some of whom were fairly senior, that well, you know, you're really concerned about you misleading people into the thinking they should be increasing the error.\n\n0:47:24\tSPEAKER_05\n And we saw that, but did you read the paper?\n\n0:47:26\tSPEAKER_05\n Did you read the paper?\n\n0:47:27\tSPEAKER_05\n Yeah, it was actually a little experiment.\n\n0:47:30\tSPEAKER_05\n We weren't, that's why we increased the error rate.\n\n0:47:33\tSPEAKER_02\n Actually, I think of cheating as a way to do some work where you can't address all of the computational tasks, like if we want to study speaker habits, but we can't do speaker detection.\n\n0:47:47\tSPEAKER_02\n But we want to assume, let's say we know this is Jane and we know this is Chuck, even though automatically to look at the habits, we would need to also first figure that out.\n\n0:47:55\tSPEAKER_02\n But we can sort of cheat on that factor because it's somebody else's research.\n\n0:47:59\tSPEAKER_02\n And then we just, so then we want to make a process concept for her.\n\n0:48:03\tSPEAKER_02\n What would this be like if we're perfect?\n\n0:48:05\tSPEAKER_02\n If someone else.\n\n0:48:06\tSPEAKER_02\n If this component were perfect.\n\n0:48:07\tSPEAKER_02\n Right. But we really can't work on that problem.\n\n0:48:09\tSPEAKER_02\n We don't have time when I'm interested or whatever.\n\n0:48:12\tSPEAKER_02\n It's too hard.\n\n0:48:13\tSPEAKER_00\n Usually.\n\n0:48:14\tSPEAKER_02\n But I assume it's given because you want to go forward with your research and assume that you have that information.\n\n0:48:21\tSPEAKER_02\n So I guess I don't ever think of it as negative, more like it's something we're not building.\n\n0:48:26\tSPEAKER_01\n The term itself is, you know.\n\n0:48:28\tSPEAKER_01\n But it's not matured towards the decision.\n\n0:48:30\tSPEAKER_01\n It's matured towards the decision.\n\n0:48:31\tSPEAKER_01\n It's matured towards a certain purpose.\n\n0:48:32\tSPEAKER_01\n I understand.\n\n0:48:33\tSPEAKER_03\n It's matured towards herself, right?\n\n0:48:34\tSPEAKER_03\n To say I am cheating in this experiment.\n\n0:48:36\tSPEAKER_03\n Yeah.\n\n0:48:37\tSPEAKER_03\n It's not saying that the data is bad.\n\n0:48:38\tSPEAKER_03\n It's saying that my experiment is bad.\n\n0:48:40\tSPEAKER_05\n Anyway, it's cloned, and it's interesting to hear that someone comes from a different direction.\n\n0:48:46\tSPEAKER_05\n It sounds the way it sounds to you.\n\n0:48:48\tSPEAKER_05\n But I'd never heard that before.\n\n0:48:50\tSPEAKER_05\n Yeah.\n\n0:48:51\tSPEAKER_01\n That's interesting.\n\n0:48:52\tSPEAKER_01\n Well, I wanted to raise the issue and I appreciate the discussion.\n\n0:48:56\tSPEAKER_01\n I wanted to ask one other question, which is a different matter, which is with respect to this thing that you've been working on for the recording monitoring script.\n\n0:49:05\tSPEAKER_01\n So the idea, you had the script that you're working on to be sure that the microphone will reser in the agenda.\n\n0:49:11\tSPEAKER_03\n I haven't got it back to that recently.\n\n0:49:13\tSPEAKER_03\n Okay.\n\n0:49:14\tSPEAKER_03\n I assume you're saying you want me to get back to it.\n\n0:49:17\tSPEAKER_01\n Well, I'm just wondering.\n\n0:49:19\tSPEAKER_01\n Because I am finding that in double checking, I run across one data set where the microphone was off early on, and then two other speakers, their microphones went off later, and this is how like seven speakers.\n\n0:49:35\tSPEAKER_01\n So out of seven speakers, four microphones basically, three microphones basically, which makes it hard for the data to be used for all possible purposes.\n\n0:49:43\tSPEAKER_01\n Do you think the battery ran out of there?\n\n0:49:45\tSPEAKER_01\n That's what I think.\n\n0:49:46\tSPEAKER_01\n I think the two that flaked late, I think it was a battery.\n\n0:49:48\tSPEAKER_01\n But if the script could alert the recording person to that, I mean, I don't know if there's a way to replace the battery.\n\n0:49:54\tSPEAKER_01\n If it happens in the middle of a meeting, maybe that's hopeless anyway.\n\n0:49:56\tSPEAKER_03\n Well, you can, but you'll lose a lot of data.\n\n0:49:58\tSPEAKER_03\n But I mean, that doesn't really help because often the recording person isn't in the room.\n\n0:50:02\tSPEAKER_03\n Oh, I see.\n\n0:50:03\tSPEAKER_03\n So what are you going to do?\n\n0:50:05\tSPEAKER_03\n I mean, well, if you're looking up at the board and I disable the screen saver, you will see that the mic is off, but that doesn't necessarily help.\n\n0:50:11\tSPEAKER_03\n Okay.\n\n0:50:12\tSPEAKER_01\n Then I guess that raises the question of whether we should screen the data before they get transcribed.\n\n0:50:17\tSPEAKER_01\n Because although I think that the data are still useful in terms of providing content, and that, I know that having three out of seven microphones out of commission during some part of the meeting restricts the usefulness of the data for other purposes.\n\n0:50:34\tSPEAKER_01\n I think that's a good way.\n\n0:50:35\tSPEAKER_02\n And maybe you don't want to have it.\n\n0:50:36\tSPEAKER_02\n I think that's a good idea.\n\n0:50:37\tSPEAKER_02\n Because for all kinds of studies, we don't really enjoy meetings where the signal's going off at times.\n\n0:50:42\tSPEAKER_02\n It just makes it hard to study any kind of parameters.\n\n0:50:45\tSPEAKER_02\n So if there's a way to check the signal quality before transcribing it, and you find any problem at all, it'd be much better to go to another meeting, I think.\n\n0:50:53\tSPEAKER_01\n I actually think that Tilos, and when you do the pre-segment or any run across travel, see he runs across some of these.\n\n0:51:00\tSPEAKER_01\n We have some part of that.\n\n0:51:02\tSPEAKER_08\n We have some part of that.\n\n0:51:03\tSPEAKER_08\n We mix them in whatever you find in the channels.\n\n0:51:05\tSPEAKER_03\n It's just hard to tell between that and just someone not talking.\n\n0:51:08\tSPEAKER_03\n Yeah.\n\n0:51:09\tSPEAKER_01\n And the other aspect of it is that when the microphone is not well adjusted, then even if it's not a little pelmike, you can get lapel mic type behaviors.\n\n0:51:19\tSPEAKER_01\n I'm expecting, for example, with this, that you're going to end up picking up high-speed signals and notes here.\n\n0:51:25\tSPEAKER_01\n Yeah, I mean, it's just a microphone is intentional.\n\n0:51:28\tSPEAKER_03\n Well, we should be getting new equipment in, so we don't have to use the earplugs anymore.\n\n0:51:32\tSPEAKER_02\n That's my ear.\n\n0:51:33\tSPEAKER_02\n I'm sure it's something wrong with my head.\n\n0:51:34\tSPEAKER_02\n But actually, is there a way to use whatever you're using for background noise to check post-talk that a microphone was constantly on?\n\n0:51:43\tSPEAKER_03\n I mean, you can do sort of a check, but it will be very hard to tell the difference between that and someone not talking.\n\n0:51:50\tSPEAKER_05\n So the microphone's dead, doesn't put out zeros?\n\n0:51:53\tSPEAKER_05\n No.\n\n0:51:54\tSPEAKER_05\n Really?\n\n0:51:55\tSPEAKER_02\n But then how are you detecting during a mic?\n\n0:51:58\tSPEAKER_02\n I use a threshold.\n\n0:51:59\tSPEAKER_03\n It's below a particular killer value.\n\n0:52:01\tSPEAKER_03\n It flashes yellow, so it's not perfect.\n\n0:52:04\tSPEAKER_02\n But is it better than nothing?\n\n0:52:05\tSPEAKER_02\n Yeah, probably.\n\n0:52:06\tSPEAKER_02\n Because it would really be easier.\n\n0:52:07\tSPEAKER_03\n I mean, this is the reason why I haven't gotten back to it, is because my first pass at it didn't really work because all the mics have different noise levels.\n\n0:52:13\tSPEAKER_03\n And so I have to do something a little more clever.\n\n0:52:15\tSPEAKER_06\n It's just the noise from the connections and the...\n\n0:52:17\tSPEAKER_06\n Yep.\n\n0:52:18\tSPEAKER_02\n...everything.\n\n0:52:19\tSPEAKER_02\n So you could run that post-talk on an already recorded meeting in the sense that, you know, not everyone, as you just said, you won't be there.\n\n0:52:25\tSPEAKER_02\n And then if we find any problems, have transcribers listen, and I really think it's better not to transcribe a meeting that's going to have problems once you've spent all this effort.\n\n0:52:33\tSPEAKER_01\n The only argument for doing so would be with reference to the content.\n\n0:52:37\tSPEAKER_01\n Yes.\n\n0:52:38\tSPEAKER_01\n But maybe then it should be done in the old original way, instead of channelizing and having the...\n\n0:52:44\tSPEAKER_03\n Yeah, there's the standard deviation of the signal gives you a good clue.\n\n0:52:48\tSPEAKER_03\n I mean, if that is too low, then you can be pretty sure that it's empty.\n\n0:52:52\tSPEAKER_08\n Sometimes you capture that when you mix it together.\n\n0:52:56\tSPEAKER_08\n Right, exactly.\n\n0:52:57\tSPEAKER_01\n And actually, an alternative to even doing that level of transcription would be to have a transcriber listen and, you know, maybe just...\n\n0:53:04\tSPEAKER_01\n Oh, I don't know if a trans...\n\n0:53:06\tSPEAKER_01\n Someone who's associated with the meeting could have like a summary of points handled in the meeting.\n\n0:53:11\tSPEAKER_01\n You know, maybe if we could pay one person who knows that subject matter to do an outline of the meeting's content, instead of losing the...\n\n0:53:18\tSPEAKER_01\n Well, is there a...\n\n0:53:19\tSPEAKER_09\n If you could still transcribe the words based on the...\n\n0:53:23\tNone\n...f I guess the trout table in my mind is that it's not a very neat corpus.\n\n0:53:33\tSPEAKER_01\n If you say these data are available, but these are imperfect because of the bad guys' flake.\n\n0:53:37\tSPEAKER_01\n We'll just have to note this.\n\n0:53:38\tSPEAKER_02\n A much rather have, you know, meetings that have all the channel, even if we had to skip a meeting or something, just for all these other purposes.\n\n0:53:45\tSPEAKER_02\n We can't sway the meeting because otherwise we'll end up with very few meetings.\n\n0:53:49\tSPEAKER_05\n But we have to be able to get through the backlog of the good meetings.\n\n0:54:17\tSPEAKER_07\n We have to be able to get through the backlog of the good guys' flake.\n\n0:54:45\tSPEAKER_06\n We have to be able to get through the backlog of the good guys' flake.\n\n", "summary": [{"summary_text": "This week they are meeting recorded data issues and recognition this week. Next week they will talk about the demo status and then alternate in more depth. The transcriber tool is not very good and it takes a long time to load. Speaker will not be here next Thursday as he will be out of town."}]}