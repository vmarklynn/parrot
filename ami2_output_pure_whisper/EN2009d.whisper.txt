 data man, you know, yeah, I want everything and then I'll decide what I want. So this was that face-to-face meeting. Okay. But it doesn't, there isn't, so there are things in the iTRECKREK that we definitely don't want in the GDF format like the frame rate i movement. You know, we're expecting the GDF format to be sort of a parsed version of events and you know, there's just too much raw frame frame rate stuff coming out of this. You wouldn't, you wouldn't want it in this kind of format for translation data. We always get back to it. We're not actually throwing anything away. We're not throwing anything away. We decide to just dig this at some finer method. We'll still have the original end, a method of filtering. But the way to think of this is this is the data that we want to be able to analyze against the other tracks of data. So the data that we want to compare with the language or with whatever. And so as long as the format in which we pick it up is a format which could be generalized to a finer take because the worst thing that can ever happen to you is you discover that you've done huge amounts of analysis and you actually had the data but you threw it away because you treated it so grossly. Yeah. Okay. So in essence what you would then do is- Whatever we should be able to, you know, backtrack and say okay instead of every second, every tenth of a second or some such thing. Well, we're not doing frame rate at any frame for, well, maybe we are. I don't know. Well, the- I had thought we were- Yeah, the eye tracker does. Right. Well, the kinds of events that we had before talked about putting into the record for that use in Alana and NXT isn't based on saying every X seconds something, you know, give me what's happening every X seconds. It's more like, you know, give me the fixations and the- What needs to know the duration of these things, right? Yeah, oh, yeah. There's a difference between saying that something that's in a particular state every frame, whatever the frame rate is, you know, ten seconds a minute, you know, that's one kind of way of looking at data and a parsed version of the data which isn't at any particular length. It relies on this really close frame rate. Well, so there's no real time. There's only- There's only events. What I'm trying to figure out is whether we throw time away. No, no. The time is still in there but you'll get what you want is to figure out what are the concepts behind that data that you want represented. So rather than saying the eye was at this particular place, you know, here and then a tenth of a second later here and then a tenth of a second later here, you say there was a fixation from this time to that time and there was blank from this time to that time. Okay, so one of the formats in which our tracker data is analyzed is percentage of time spent on some target as opposed to some competitor over the first second after some event. Okay, so you actually have to have to show at some time slice rate where the eye was on the same target as the other guy, a similar target, what we've both been dealing, you know, so we have to we have all the parts, the interesting parts of the screen identified and be able to show distribution of gaze over time. All right, now we could be really unlucky and somebody would expect us to do that at the real frame rate. But I think that's really unlucky but but my point is that we mustn't throw away or lose the capacity of being able to deliver that data. So there's two issues here, we're not throwing anything away but the question is what tool would you use to get that information out of the data? Would you be? So the more you can plan... So typically the eye will move, right? So over any one second the eye is actually fixing on a bunch of different things and you and so when you say the eye was on this from here to here, what's going to happen is it is that if you use the real frame rate it's going to jiggle all over the place, it's going to be on this landmark, it's on this object, that object, this fixed thing, that fixed thing, okay? You've got to get lots and lots of stuff and it's percentage distribution that you're going to want. It's not... I went here, you know, it's not like person walking, I went here, I stayed here. It's more like fly hovering. So you need to know the percentage of time it was on during that fixation? Because if you if you take them as separate events you get thousands of separate events. Yeah, but they sort of start in any times but give you that and then you just major against, you know, against bigger frames. Yeah, the cumulative total timer. Okay, so the percentage is... it's not something you're using for measurement, it's a cutoff for whether or not it counts as a fixation? Well, that's the problem. There are two ways of doing it. One is that there's always a cutoff, right? But the other is that there will be a time span, a kind of reaction to some event span. Yeah, so I'll lag in some of it to... I suppose there's the the saccadic movement itself. And so I mean there are really two ways of looking at this. One would like to know, for example, the percentage of time overall in which two people are looking at the same thing. Okay, and one would like to know sequences of they didn't look at the same thing and then they broke it, or they did look at the same thing and then they did or didn't break, you know, one could imagine those two categories. That's a kind of testing of our hypotheses. But there's a certain amount of dues you pay to the way they do things in the literature to get your papers published. And one of the things they will want to know is an event series after some critical event, right? What percentage of time is given to looking where the other guy is looking? And what percentage of time? Over some, you know, reasonable time span of a couple of seconds. All right, so they'll be... They'll want to see essentially the gays settling on particular incidents on particular places. So we have to be able to deliver those two things and they're rather different demands. Right. It should still come out. The little sketch I asked this for last week about NXT and whether it would have that sort of tiered effect. So you can see the overlap of where one person is looking compared to the other and their mouse movements and things. Yeah. That should... Because all you want to know is whether they were looking at the same object in the period after. But because it's also based on the the time course of the procedure, you'll be able to basically get the scan path of the pattern of events from that. Okay. Can we try to make sure that that this is satisfying elements of the search? Well, there's a whiteboard, right? We love this thing. See if the pens work. So this is A's eyes, right? And B's eyes. And I think what you're saying, you should probably draw this, right? Is that they... You know, if from this time to this time, they're looking at triangle one. What you're saying is that you want to know in the critical... You want to know after they're looking at triangle one, what's happening in this period with the sky, right? Or how... Let's imagine a typical construction event. Okay. There's some part... There are separate movable parts on the screen ready for use, right? There may be or not a construction already begun. Somebody makes the first move. There's some kind of communication, either gestural imaginary or verbal, that plans how we're gonna do it, right? Before that happens, the person who speaks is going to do some kind of visual scanning. While they're speaking or communicating in some way, the other person may or may not be looking where they're looking. Okay. They may be overlapping gaze at particular objects which are of interest. Let's call it the construct, existing construct, which could be zero, right? Or the addendum, the thing which is next going to be added. Next piece. Okay. Now in neither case, when you draw this, he's looking at triangle one, what you're actually drawing, you know, for the period of time in which he's steadily looking at triangle one is going to be very, very short, right? Because staring fixatively without interruption, blink or saccade is an extremely short event. At that point they're lumped all the individual fixations as long as it doesn't move off that triangle together is a total of gaze time. So it's in a region. It's in a region. That's a target. But even so, you're likely to get bouncing in and out of the region, right? So even so you want to look at if we're interested in how long before the construction move takes place, how much of the time they spend looking at the same thing. Let's call that our measure of alignment. So they're going to be, yeah, that's right, A is going to be on triangle one and various other places. That's right. And B, okay. And we're going to look at the percentage of that time where they're both in the same region. So what I want to make sure is that we don't simplify, do you know what I mean, temporarily simplify too much? So that, yeah, I mean as long as we're... Because then you lose percentages. There shouldn't be anything to be. Right. And so B has some periods of looking at one and which will also be intermittent. Yeah. Because... So you know, he might get triangle one there and now maybe this one's going to overlook quite a bit. So what you want to do is be able to define bigger periods, which is the period when they're sort of interested in triangle one overall, right? When they should be. We have an event that, yeah, the second lane then for the second before it and then we can just take that chonk out and do something with it. Yeah. But that's... That should be... Okay. That's not something that you can do in the NXT career language but you can't do that in any... You know, this is such a special purpose but it's easy enough, given the data format for any of these things to do that. So you can do it on... Because it's just a matter of... The heart barter is deciding how close together these have to be before you decide this is an event that you want to pull out. Because, you know, algorithmically, you're already putting together. I mean, this is essentially already, you know, these fixations with stuff in between. And, you know, we've got an algorithm for deciding when that's a look, I guess. You already have that or no? Well, it's just based on a stable fixation result or something crossing into that region. Oh, yeah, yeah. So it's all fixations. These are all fixations and saccades but within the... Yeah. So that's easy enough. So the hard thing is they could be moving their eye arbitrarily here, right? And, you know, maybe even having fixations on other things? Yes. Yeah. Because, for example, for part of that time, both B and A are probably looking at the construct. Okay. If your intention is to move the red triangle to sit on top of the thing already constructed, you would tend to look back forward. Back forward. Yep. So... This is... This is... Yeah. But what you need to do is... We can already build into this GDF format, these regions, if you can give a definition of what you think that is. But I think the right way to do this is to be able to inspect the data in some tool and play around with the definitions because you won't get it right the first time. Yeah, sure. So the question would be under what tool should we be looking at these events? And Elan's a reasonable choice for that, right? What you need is something... Well, no, because you need to... You need to be able to see the effects of this. So I guess this is a case of Craig writing some scripts. So Robin having some ideas about what the relationship is and saying, you know, add this data automatically. I mean, it's not that hard, right? It's just there'll be a bunch of these. You'll have some rules about how maybe how long you spend on other objects and whether the other object is the existing construction or not, right? So essentially there's this AE is divided into TR1 and C and other stuff, okay, where C is the construct of the existing thing. Right. So if they had a fixation on C, you wouldn't be worried. But if they had a fixation on C, well, I mean, we take a separate... We'd look at the percentage time. I mean, I have no idea because I don't know how people look when they're building things together, okay? So there's the addendum and the existing construct and I don't know whether they're going to spend more time looking at one or the other. But if they're... Whatever it is that one is looking at the other's looking the same place, they're in good shape. But, you know, they're gonna look at the clock. Yeah, sure. And that's what the other stuff is with the... That's what the diagonal stripes are for. That's true. But we can... One of the things we'll be doing is categorizing people I take it or interactions by the amount of time people spend looking at the clock. We expect that we put people under time pressure. They'll look at the clock a lot more. But that's like a separate analysis, right? Sure. It's a separate analysis, but you don't want to throw it away. No. So... So... You need to find if all of these things are actually categorized by the eye tracker as to where the eye is, right, you should be able to pull out any interesting category and say, all right, for this phase it's TR1 or C. For this phase it's SQ1 or C. But what we find... What we can get out of the data easily at the moment is at this kind of level, right? And then it's a case of defining algorithmically all these other transformations that you want. So this is one... We hadn't thought of adding before, but we should, right? Which is... Well, how would you decide whether something was the current addendum that you have to actually transcribe the thing or watch the film for a while? So that's a human decision. Yeah, absolutely. Yeah. Yeah, so once you've got that some information, you've got the GDF format, you then filter it to say, right, between time X and time Y, they're constructing it, they're adding triangle one to the construct, and then you just say, in that time period, what essentially they're looking at triangle one, what essentially they're looking at the construct. So that's unreasonable. Yeah, that's the addendum in the construct should be, you know, kind of... Yeah. They change their true identity, but they're categories of stuff. Yeah, cool. My kind of assumption was that this was JP land, that's what he was really interested in, was the kind of coding which would define the building sequence. Right. So, and maybe he wants to think about that more and say, well, there were several candidates for the addendum. All right, and it was the negotiation of which candidate was going to be the right candidate. That's actually the interesting stuff. So I should talk to him about this. He's actually emailed me with a list of things he wants to discuss at length. But we believe JP had to be defining that maybe. Well, this is my question for him. Is he going to define this kind of building sequence in a way that we can get out or see? So, I mean, you know, they've been working on construction there for a while, so maybe that they have a coding system that's ready to go, and we should just apply it. Yeah. Okay. They do a lot of subassembly. The tasks they've been doing, so they may well have a... I could believe them, you know, taking an interest in that. Well, that's fine. I mean, the general division was a language here and other stuff there, right? Right. I understood it. Right. Well, we have the actions might mostly be theirs, right? But since we have the eye tracker, we're going to have to answer their questions. Oh, yeah, eye tracker here. Yeah, we know that. But so they'll tell us something about that, but presumably what you piously hope happens here is what happened with transactions, right? That the verbal analysis and the visual analysis give you the same breaking points, the same chunking points. Well, yeah, but I mean, with transaction coding and something like this, you wouldn't consider it verbal analysis exactly. It'd be verbal plus action. Well, I mean, it's a task breakdown. It is a task breakdown, but for the verbal version, there are ways of announcing. But now we're doing a new one, right? Yeah, but you wouldn't have... You wouldn't do two codings for task level one. No, you wouldn't. You would do transaction coding and then... One of the things you'd like to establish as an outcome of this is that you could analyze either end and you'd get the same chunking of the material. I don't think that's realistic because I think what you'd actually do is use the full record of what you have and do a segmentation. I think it'd be hard to understand what was going on if you used just the language without which in the video to decide whether we're breaking down the task. It's a hypothesis. Oh, you don't want it to be coding based on that, though, and then that seems a strange way to go about things. Well... I mean, the language events are multi-modal, right? They're doing all these things together. They are doing these things together, but one of the things that you one could imagine doing is having the transcription there and just play it back to a bunch of captive undergraduates and say... Why do you care whether they stop the start? Just based on the language. Because essentially you're looking at cycling sequences and discourse and if the discourse tells you what's going on, that's information. I mean, one of the questions is how the information is going to be shared across these media. And if you can get it all out of the speech, if all of the chunking is available when there is speech, then it's carrying a lot of the burden. Well, it seems to me much less important than the other things one could get out of this data. But I... But this is... It's a possibility. We have a look at data like this with our old-fashioned analyses. And it would be really nice to know that that much information, that chunking of the task information, is being carried by the language. Because JP's question, the overriding question, is so what's language for? You know, people are busy interacting all the time, and all of our colleagues don't even bother to control for whether people are talking to one another when they're doing these joint tasks. Because it seems to them to be irrelevant, because language is irrelevant. It would actually be nice to demonstrate that in a place where we're controlling whether you have language or not, you could get the entire chunking of the task out of the language. Yeah, well, I can see maybe wanting to know whether you can do the chunking just based on the actions without the language. In cases where they use both. It's more... I can't quite see why it's important to know that they can do it just based on the language because you know it's a self-contained system as opposed to a system which can't be interpreted without the other system. Uh-huh, well, I think that was just bound to fail. Almost all studies on language claim that language is a self-contained system, which will give you everything you need to know. Really? That's the claim. Okay. All right. Anyway. I didn't say it was true. That's the claim, and so it's worth testing. So back to this main problem, which is the record that we are getting in the first instance is about these... you know, they're looking at some region of the screen to find dynamically. And then we need some way of knowing what the... you can see adding these other analyses about, you know, they're jointly focused on this region and trying to figure out what percentage of time they're looking at it. As adding new tiers of information to either the Elan track or NXT, they're both sort of track-based in this way. But the hard part is knowing how you want to do that. And I think in the first instance, what we're trying to get into the GDF format is just this, and then we've got no option but to figure out a way for, like, to look at this, just explore this data, and suggest ways about doing it, and be able to play them back and see when we think we've got these things right. I don't think we even know what the set of these things are that we want much less how to get in there. And we will... So establishing the full set will, you know, take as much of the project. Yeah, that's right. So this is not... you know, this is something we're aiming for, but this isn't something that affects what Craig programs for the initial GDF translation. My only concern, as I said when I barged in, was just to make sure that we didn't lose the things that we might need to pick up later. Yeah. So let's just return to this question of frame rate, because this is the thing we were not planning to transfer into this format. So again, you know, a frame-wide kind of coding is, can again be seen as a track, but it says... Everything will be... It's coding like this, right? Where you say it's... Well, state A, state B, state C, state A. Okay, but since the definitions of the thing we're looking at are the ones which get rid of the lower level, like jiggling around in the area of a particular object, right? So if we're moving the green triangle, we've defined a region which is dynamically the green triangle wherever it is. We will jiggle around in there, but it doesn't matter where we are in there. That's the neither level of analysis. Right, so I'm just... You're happy that it's not going to have frame rate like this. It's going to have an interpretation like this. Well, that interpretation is definable to frame rate by the only way we're going to use frame rate. What does that mean? Sorry. Well, I mean, because I can say for how many frames this fixation is officially defined. So that as long as it's not an untimed event. Okay. So it's all events have a start time and the day time. So it's fine. I can say it's a long one or it's a short one or it's 20 milliseconds more than that one. It seems to me that Alan's concerns might mean we need to add more information to these tags because this thing in itself is... You need to detect a... A bunch of fixations, right? With the cards. So things like fixation, the number of fixations. Fixations and the percentage of time those fixations cover, you might want. Yeah, with some measure of the... so we could work out the number of fixations that made and the average fixation duration as well. Because having long steady fixations can be informative. And so, okay. So, number of fixations as percentage of... This isn't the leading question. This is a question question. Why would that be informative particularly? If they're holding their... if there's less dancing around, the cognitive focus tends to be in one sort of part. So there is a difference between if they... even though they're still looking the same part, if they're looking around it. Rather than just holding their gaze, steady or... On it. So you think that, for example, if they're looking at one or another apex of triangle, it would just... It would make a difference. We're exploring the thing. Yes, it would certainly... As opposed to they were simply... All right, there it is. Okay. So... So that really means that we're not throwing away absolute fixations. No, I wouldn't... Screen location of absolute fixations. But the actual... No, no, this is still summary data. We're talking about just adding attributes to these things that say the number of fixations that counted as that looking at triangle one. Right? So it's possible out of it. So you... so I thought I understood you to mean exploring the figure because, you know, your fixation is a point. And the figures are bigger than points. So you could be exploring the figure or you could be just somewhere in the region defined as the figure, but not on... Well, yes, but that probably isn't going to be easy to get out of it because they have to break up the part. So you just want to know the variability of the fixation. And wouldn't that differ from person to person? Yes, it can do, but it's also looking at it within their own behavior. Okay, so it's the number of different spots within that region where the eye aspect... I would say just the number of fixations. The number of different... Yeah, the spots will be different anyway. So it's too great, okay. You're not going to have the same pixel. Yeah, exactly. So we have the option that we can put in an affixation thing here, right, as well. If you want the smaller... if you want the smaller coding in here so that it's not just parsed into this idea of which object, but you also have the raw fixation data. We can put that in as another track. If you think that that's something that you might want to look at in one of these tools that shows you the tracks against each other. Well, all I understood you to ask for was the duration. Yeah, that's all he asked for. Yeah. Well, I think... If we've got everything, then I suppose it's... You can come back. You can always... yes, it's... you're not throwing anything away then. Yeah, and in NXT there's no cost right because... you just don't choose to load those. All we're doing is dumping it as output that you can load if you choose to. So if the things that you just know are crazy and you're not going to want, then we don't do it. But otherwise we go ahead and dump them because it's easy to dump up the fixations. Yes. Yeah. Number of different fixations. Okay, so it's the number of fixations. Well, actually, do you want the average duration? Did you want the number of different ones? The duration thing as well, somehow, whether it's the average one or... Duration of each fixation in the region. Not each? Well, if it's each, you have to break it down into another tier, right? You can say there were three fixations and they averaged at a certain time, but you don't want to... The average should be all right to work. Well, what about the overall sum of the durations? Is that... Well, you've already got that number of fixations in the average time... Yeah, then that's the way you want it that way around? Yeah. So you had some measure of jiggle in the region, roughly. And did you want the percentage of time fixated as opposed to... Which is sort of another view of this number? You can have as many of these... That should be... You should be able to derive that presumably from... Yeah. Well, it's not... The extra cost of having these as attributes is not high. So, you know, it saves you having to do... Write scripts to do arithmetic on that later. If you know that these are numbers that are going to be useful to you. What's our error of measurement on location on the screen? So, to what degree do we actually know whether the two little eyes, little circles, are exactly in the same place, or just somewhere in the same region? It can vary a bit depending on the calibration, but we're building in a sort of error margin. We based on pixels around, but there will also be a minimum one, because I'm trying to think of probably the small, virtual mouse icon is so small, it'll need a slightly larger... It's... Yeah, okay. So, a larger error margin around it. Okay, so my question was going to be... The mouse is a dynamic object, right? The eye track is a dynamic object, or is it only the piece that the other person's eye track is on? That's an object in this definition. No, the other person's gaze position is a... Is an object. Okay, with some... With plus or minus something or other. Yeah. Around it. Some circular area. Yes. Okay. And... So, you can be on the object, but not on the other person's gaze. So, there can be a triangle, which has... So, if there... A's gaze in the center, and your gaze actually happens to be here. Yes. You're in the triangle region. Does this... But not looking at their individual. But they probably will avoid looking directly. If they're looking directly at it, it's obscuring the part. But it's directly at it when these two... In this situation, when these two overlap. Right, like this. Yeah. So, I think that's going to cut that. Because the... Don't worry about this, just in... They're only looking at one thing at times, or whether it's a triangle, or whatever else. So, what you suggest in there is they can be looking at the triangle and maybe a mouse pointer, and maybe an eye at the same time. Okay. Well, it would come up... It would say yes. Right, I mean, because they would be in the same place. So, if you... You're going to have dynamic regions which overlap one another by definition. If the mouse is on... The mouse is on the... The construct. Yeah. Yeah. Right. Well, well, those are different tracks of information. So, what you want is one track of information about which object it's on. What about whether or not it's on the other guy's gaze? And what about whether it's on one of the mouse's... We... Treat those as other objects. But the difference between them and the parts of the thing to be constructed is that they're allowed to overlap with other things. Nothing breaks. Okay. Yeah, but in the analysis, you should treat those as completely separate tracks of information. Because they can be looking at... They could look simultaneously at somebody's mouse, somebody's gaze, and some object. Right? Yes. As opposed to simply looking at somebody's gaze when the mouse isn't also there. Right. And you want to know those things. So, these are independent. Right. They're independent dynamic objects. So, what we want is whether they're looking at the other person's gaze, right? And say they are in this period. Well, I mean... Okay. So, a definition of we're all looking at it and touching the same thing. So, imagine that we've just added a piece to the construct. All right? So, now that's the construct. And both mouse symbols are on it. Right? And both gazes are on it. Yep. Right? So, at that point, you should have a lineup of A is on the construct, A is on the mouse, A is on... A is on A's mouse, A is on B's mouse, A is on B's gaze, and B likewise. Yeah. Okay. So, there's a lot of tracks here, right? Because what we just did is this fixation track. And there's A's mouse, not their eyes, is on an object, right? And the mouse might be on it. Yeah, but the mouse is also trying a one dynamic object. But it doesn't matter. That's fine. Okay. The mouse, which thing? Where is the mouse? You know, it's on this object. And then A's eye is on... Well, A's mouse, I guess, right? A's eye might be looking at A's mouse here. Right? I mean, these are all the different ways of taking cross products, the things that could be collocated. So, you just treat them as independent. And I guess it from what you say... And then you look for combinations of them. Yeah. I'm guessing from what you're saying, you want all these tracks. I think we need to. Yeah. Which is a measurable line. And it's looking where the other guy is directing attention. And there are two measures of where the other guy is directing attention. That you get from the visual track. One is where the mouse is. The other is where the gaze is. So... So, you know, I think that's a good idea. Yeah. Yeah. Yeah. So, yeah. So, yeah. So, it's just a matter of adding the two mice pointless and the two gazes as extra objects. So, yeah. As long as I've got an ID in there, we can just say, right, at this... Between these times, they're looking at that object or the look at the mouse, the look at whatever. But the important thing is you don't treat that entire set as mutually exclusive and exhaustive. It's just... Yeah. The... The objects is like a separate level of analysis. It's just one of the looking at the objects, then one of the looking at the gaze. But it's also going to be the case that whatever region you define as the region of the dynamic object of the red triangle may get to the point where it overlaps the region of the dynamic object of the green square. Okay. What do we do about that? Does that happen? Yeah. Because if you have them close together, there's always some fuzz factor around there. Oh, right. And so, if they're left lying close together, or in fact in the model, in the... Not in the model, in the supplies set, they're actually neatly packed into a little space. Okay. So, what you're saying is like a new problem for us, which is... I'm going to change... Two objects close together. Your eye gaze can actually be looking at the left edge of one and the right edge of the other. And they're therefore looking at two objects at once. Yeah. So, you're saying... Speak, speak, okay. Can you write on my pen pad? Just say... Yeah, pens. Pen. Whiteboard pens. So, you're saying, you know, they could be looking at square one at this point. Because they... Because the two are so close together that their regions overlap. Okay. That's a problem for the data models and either the things that we're using. That's a problem. Unless we just define it as... There's only... they are exclusive. And whichever area has the greatest overlap is what they're actually looking at. What do you mean by greatest? Well, if you've got your sort of eye position and it's unlikely to be exactly 50% in one object and 50% in the other. Draw it. My special reasoning is no good. I think it's really important. I think it's really information. I'm the one that uses the whiteboard because I actually put the marker on. Yeah. Well, I'm thinking is if you've got, say, one object there and... Yeah, so this is... Yeah, this is the better pen. Thank you. Part one and part two. And you've got their sort of... they're looking... They're... Then that overlap means they're looking at two pieces simultaneously. Yeah. But you had a way of choosing which one, right? Yeah, but maybe a bad idea. This is more of it. It may be a bad idea. You've just thrown data away. Yeah, that's a decision. Well, the thing is that... I'm saying is if they're looking... if most of what their overlap is here, then we stick with that one. So, what do you mean, which... is it closer to the... is the circle... I mean, what is the circle? They're looking at a pixel or something, right? No, that... because the gaze position will be a sort of fuzzy area. It won't just be a pixel. It will be a natural... like a circle. Why is it wobble? The gaze will wobble. So that's... that's going to be... So that's very... it's a sort of lump target. So there'll be a bit of a... some sort of overlap. Two objects. Or indeed, they might be looking from one to another. Yeah, they're deciding which one to choose or thinking. So you don't want to decide it's only one. The only GDS force is working at the moment. It's actually got a separate track for each part. Okay, well, that's fine. I was going to say that's the obvious. Oh, but what? And that's going to be analytically. Because it's going to... Well... Which one is yes or no? How many parts of it? Well, it depends on what you're building. There's different parts. There's different parts, whether you're doing the 10 gram, whether you're doing an airplane or whatever. Six, two, a dozen. Okay. I know ways of getting around the center. We can easily analyze it down later on. I mean, I think it's very likely that... If the other ones are oscillating, then that's presumably going to change the width. So you're actually going to see them flipping between... Well, not if the regions overlap. If they're really close to the region, it's going to get boxed. It's really close. Yeah. Right. And if you define the regions so neatly that there's... You know, that we're losing gaze because of jiggle outside this closely defined region when it's in the middle of space, then... I mean, I actually like the solution. However, ugly, it looks in terms of the data format of having a track for every... Yeah, well, the last format I'm worried about, it's the way you do the analysis because you don't want to have to say... You know, did they jointly look at triangle one? Okay. Did they jointly look at square one? Okay. Did they jointly look at... You know, you need some way of... It's a thing. Going over the whole thing. But we can find ways around that. I think for now we do it this way and then we think about what we need out of it in the end. It's just, you know, in a lawn that has the side effect, that if you go for the naturalistic way of up translating to a lawn, there'll be a zillion tracks and it'll probably ruin their viewer because you'll get very sparse data on each track. It'll be like the old referring expression general visualization in the map task, you know, when they talk about one object, one landmark, and then another one. That was brilliant. Well, it's big, right? Yeah, it is big and you do have to scroll through it to see what's going on, but it gives you a very clear picture of what's going on. Well, we'll see if a lawn likes it or not. Yeah. Well, okay. So we better do a test one. Yeah. And we better also like have in the representational list of part, like even in the NXT of translational list of parts. Yeah. It affects the way we do the NXT. Yeah. Yeah. But there's only list of parts in the GDF. So, yeah, that's not a problem. There's a base basically what we've got is, well, there's three places where you've got the ID there. So you've got an ID for a part, you've got an ID for a location on the screen. So that's just the target config, the clock, whatever else. And then we can easily add IDs for the two mouse points and the two gazes. And from that, basically all the tracks that are doing is saying, between this time there's a look at this object, yeah, this ID. So, so it's effectively a track for each ID. Okay. So what about the point where a part becomes the construct? You still are unified as a part. But not much should lose that. Well, what happens there is that the two, the existing parts basically cease to exist. And a new part with a new ID starts existing at the point where they're joining. So every time a part is added to the construct, it becomes a new part. So the construct actually has, say, it has six things that are added to some initial thing. Okay. So if there's just the initial thing you've put in the middle of the screen, that's just the initial object. Yeah. As soon as you put a part, there's a construct. But it's construct one because when you add another part, construct one ceases to exist. And you get construct two. Yeah. Right. So actually defining all of those as the construct is going to be the trickiest thing. It's also going to be a problem because you're going to have one part to construct forming in the middle of a fixation. Right. So it's not going to be quite as clear. Right. So you're looking at triangle one, right? All of a sudden it's something else. And it becomes construct or assembly, whatever. Yeah. And there could be more than one construct at a time, right? There is no construct. And then you can start again. Also when you build some sort of assembly, then you can screw that and link the. Yeah. But why does it, why does construct one become construct two when you add something to it? Because the. Yeah, that's always working the moment because it's generating a new idea when you create a new part. Oh, and this is because we don't want it to stay triangle one. When you start with a construct, it's not a construct at all. It's just a one thing. And we don't want to triangle one to suddenly have. Yeah. Well, the problem is that all of these things are popping out of existence. So do we know the difference between we broke it and it went away? And it's now part of the construct. Yeah, but there's join events. So if a join event, if there's a join event linked to linked to item, then you know, it's become part of a construct. Or can we tag the constructs with what's in them? Yeah, the contracts are already tagged with it. So there's actually a separate part of the data format which says for each construct, which two parts made that. Okay. So we could essentially, well, then we could cumulative or it is a new construct because it has a new listed, a new cumulative listed parts. Yeah. But you can still track what parts went into it. Right. So you can still find triangle one, whatever. Some fancy programming is going to have to be done to say, I was looking at triangle one and I'm looking at triangle one in construct one. Because the first construct was triangle one and square one. Yeah. But that's easy to me because the, the, the, each construct has the IDs for the, the things that construct it. So now we have to ask whether. So let's imagine this. We've made a construct of two parts and we're a triangle and a square and we're considering now adding something on to the side of the square that isn't attached to the triangle. Okay. Are we looking at the square? Are we looking at the construct? Yeah. That was the next question I had. Yeah. You're really looking at the construct. Because I said in this definition, I should be looking at the construct. Yeah. The reason to figure out that you're looking at the square rather than the triangle. Well, yeah. The thing is that we used to have the x, the x, y traces from the ASCII format. So if you want, if you want to be able to save on looking at the square instead of on the construct. So it is possible to get that data out. Yes. It's not doing it. It's not doing it in the jazz sandwich at the moment, but I can easily add it to give that information if you want. Because I mean, that's the example presumably that's the best example of overlapping areas. Because if the two things are now about it, of course, there's an area which is coming into both of them. Okay. So what I'm trying to run through in my head is that we can always tell the difference between something going out of existence. Because it's trying to construct something going out of existence because we threw it away. Right. Suppose we pick up and we screwed up the first time we put the triangle with the square and we threw it away. We decided we didn't like it. And we took another one. Is it triangle one? Is it triangle one prime or something like that? It's the replacement triangle. Yeah. If you create a new part, it gets a new ID. So if you get your dragon new part, how do I know what it replaces? You don't because that's, you'd have to have human coding to do that. Yeah. You want to know which one they're planning on using. This is true. But if I have triangles one, two, three, right, and I throw them away. Any triangles I take out are to replace one, two, three. Well, you know which mold they come from. And so you know which shape they match, but you can't possibly know which one of the ones they're meant to replace. Yeah. You don't know which one they're meant to replace, but you know they're not meant to replace any better all better. They haven't been thrown away. They can't replace the new parts when they appear when the previous one's broken. Right. So the new parts are replacing those which have disappeared from the screen. Yes. And if there's no more TR1 track, the TR1 track is gone. Oh, so there's no two parts with the same shape? Oh, there are many. Same shape, but not the same shape and color. Same identity. Oh, same shape and color. Right. Okay. Oh, is that true? You've decided not to make all the triangles written, squares written. That's what they're at the moment. Okay. So you can't tell what is meant to replace that because it's the same. It's just the case of the mold, right? Yes. That's the way it works at the moment. I assume that's how nine Negan had set up a lot. Okay. So that's back to Tim's. Yeah. So shape plus color. They are individual. They're unique. Yep. All the parts are unique. So we hang on, that makes the task a little bit easier. Yes. Right. Tim, 10 grams are much easier and you can see all the lines. Yeah. So it is just a construction task rather than a puzzle. Indeed. Which kind of leaves you with an obvious way of making the same task harder and easier, doesn't it? Yeah. Yeah. But this also, that's hard to code. I mean, that's really a thing we might do. Okay. So now let's make sure that the coding would survive that. It's just, it's a beautifully controlled situation. The construction task is essentially the same. It's the figuring out stuff that gets harder if everything is purple. For just to choose a color at random here. Yeah. Yeah. So I think the ending is probably a little bit, then two triangles, isn't there? There's two identical triangles in the tangram. Yes. At the moment, there are two, I think, two small ones and two large triangles. They're actually the same physical size and shape. At the moment, they're in different colors. That also means in the new parts list, they're therefore, you know, two large triangles and two small ones. Small ones. Whereas in the revised edition, if they were all just plaque, they'd only be one, uh, mold in the new parts. Yeah. Well, in, when you specify these things, do you specify the molds or does it figure out what the molds are based on? So is this hard word into Tim's program or is it just an artifact? An artifact is the way we- It's hard word. It just- Yeah. Yeah. When you specify the molds in the- in the- in the- the file that generates the parts, we've got a list of parts. The molds are based just taken out of the- the file that generates the- the first place apart. Right. Okay. So- So how many parts- How many parts are in the file? That's how many parts appear in the- in the parts box. So if you have five black triangles, they're going to be five black triangles in the parts box or one. If you have five black triangles, there's going to be five- five parts in the part- five black triangles in the parts box. But- So minor- But what you can do, in the initial configuration, you can reuse a triangle. So if you only want one black triangle, you just create one black triangle in the parts box and then reuse that black triangle five times in the configuration. Mm-hmm. Okay. As long as this is possible. So I mean, that just is a kind of thing which is so simple. So much like a single. Yep. Seem. One zero variable change that it did. But what would- Doesn't matter, because I'm trying to kind of map this onto biofix. And biofix has multiple, you know, all the- The nuts are red or all the flat things or- No, they can't have different nuts there. Well, it's not very different- The same part is different colors. Yeah. Yeah, but they don't have enough to make unique. No, I mean, there's more than- There are multiple pieces of the same. Mm-hmm. So when you say a red nut or a green bolt or a long green bolt, then there'll be lots of them lying around. Yeah. I think that's how the robot is set up too. Mm-hmm. So five green bolts. Here is one. I think we've gotten to the point where, you know, to try to summarize, we think Tim's program can do both of these conditions. Okay. But I'm still worried about what the effects are for analysis, because you were aiming at something in the GDF format, and I wasn't quite sure what. Okay. So all I'm doing is kind of worrying out loud about all the things that will happen that will miss by a simple view of, for example, regions and looking at triangle one. Yes. When it's triangle one, not triangle one anymore. So, okay, so I'll summarize what we said about that part, that every time you cast up a new part from a mold or, you know, every black triangle has a different idea. And you know it's a black triangle, because you know which mold it came from. Yeah. But you don't know which part it was intended to replace on the screen, because you can't mind read. That's true. So how can we define the shapes that people build? What do you mean define? If, assuming I was, for a moment I was JP and I wanted to know how they actually went about building the thing. Okay. And I wanted to look at the strategy. And I wanted to see if the strategy was different when we could talk about it, and when we just picked up whatever. I mean, suppose I can't talk to you and I'm doing this task with you and I can't talk to you. The thing which is going to be hardest for me is making elaborate plans with you. I can reach for the next thing and you can go where I reach. But if I have some sub goal, some long term sub goal of doing something clever with putting these together because it's hard and putting these together because it's hard. It's going to be almost impossible to convey that to you. And the difference in the history of construction is an important thing. And I wonder how we can get that information back. I think that this is a human coding that is part of the action in coding because I don't see how anybody but a person watching this can guess why they cast off this thing at this time. Why is not, that's not the question I'm asking. The question I'm asking is what's the history of the construct. So you have the names of the things in there. And you have two constructs. Suppose we have two sub constructs. And whichever one had two pieces put together first is the earlier number of those constructs. How do you tell the difference between adding a piece to this first construct and creating a second construct? When the file construct, the way the constructs are defined in the file, you've got your parent construct and the parts that it was constructed out of. And the other thing is it's a parent-child relationship. Yeah, so you've got a parent-child relationship and the child can be a part or it can be another construct. So construct two, construct one is a red triangle and green square. Construct two is two green squares. Construct three is a red triangle, a green square and another red triangle. Construct four. Yeah, but that's okay because they all have different underlying part numbers. And when you say what a construct is. So how are we going to tell when, for example, you think we're going to have to do human coding on when two sub constructs are put together? No, no, no, no. No, that's definition where a construct has construct as children. Yeah, yeah, because there's a joint action. The result, what you need to do is to do a construct in the part, two parts, whatever you think together. And then the result there is a construct. You've got time when that happens. You can see that construct appeared at that time. And you can still track the children of that construct. We can zip through this and look at all the interactions in which people built construct construct, construct first, which we expect them to do as a wild hypothesis more when they have verbal communication than when they don't. Okay, and we can do that by simply searching for any constructs that have construct as children. Yeah. Yeah, so we can easily look at things like that automatically. It's just the why they get new parts that's the problem for us. We can't, if they suddenly, if they decide to get a part of a mold, we don't know. We can't know why until they do something with it. We haven't actually made a rule that you can't collect extra parts, right? Extra parts don't appear, so you can't click. Oh, yeah, you said that. Yeah, there are a couple of minutes like grayed out there. Yeah, but you can see the mold is there, but they don't come filled. No, no, I mean, you have to break one to get one. Yes. You can, but you can break one. When you break one, you don't cast off the mold yourself. It happens automatically. Yes. Okay. Never mind that. It appears. And then you like it. So they just have to use it. Yeah. The new part lights up sort of thing. Oh, but they have to drag it up past the mold line. Yes, you have to bring it into play. And you can't just bring extras in case you screw up. You have to screw up first and then you bring it. That is one thing unlike the, say the bow fix or anything. Yeah, with this extra part. There aren't any extra parts. And at the moment, the software doesn't. But it does have replacement. Yes. Replacement, but no superfluous. So you can't have a standard stock of extra parts that will never use. Okay. So this is why question doesn't even arise. So you appreciate, you appreciate the cost. Because you know what they're going to do with it. When they decide to move it past the mold line, they're doing something with it probably. And you'll know what they're going to do with it because. Yeah, but by the time both of them are doing that, they must have already broken something. So you don't love what they were facing. So they rejected something. Okay. Is there a way of telling the difference between intentional and intentional breakages? How would you do that? Intentional. In the sense that they break deliberately when they bring them into the new parts. Yeah, it's like the trash can idea. They both put their hands on a construct because they don't like it. Yeah, but there'd be no way of coding that automatically. Right. How could you possibly do that? You have to hope that there's language in one of them say something. But that's a human coding. Right. So there's no way you could tell that just from the role movement. So not generically. Because if they're going to do it by gesture, they'll build up a convention. So that's going to be a problem for JP. Remember all the things we're looking at are with language and without language. And it's going to be very difficult to tell whether they broke something intentionally without the language. Which means it's probably not. They develop a convention. Suppose they start off with language and then they say. Yeah. Okay. This is probably part of the action coding. Sure. I just want to make sure that they're not. Wishlist. Right. Wishlist. As a side effect. Yes. I'm trying to remember if the people deliberately break things by moving two pieces together. They don't break. They do. If one person is dragging a part to a part that isn't that the part that's just sitting on the screen does not be in touch. They both break. So the intentional thing is when they actually both click on the same object. For sure you know that's. Well, it's not necessarily intentional. They could just screw up. They could discuss to send it a break something. Yeah. I don't know what's very good. No, we'll never get away with that. We'll get a bad score. Let's just throw that away and start again. Yeah. Okay. Wish reminds me we have fixed the score problem. Have we? Yeah. Yeah. It was through the rotation. Oh, yes. The percentage score. Yes. So rather than the number of penalties or something like no, the score. It was the percentage overlap. And that made the score. That's that's the way it's worked out. But the problem was to do with the. Which they had relative and absolute piece and. It's all to symmetry. But it wasn't a bug. It was a. Don't tell me it was a feature. No, it was them just forgetting to. To find something that had to be. And the. Yeah. Okay. Which is probably a documentation fault. It's in the documentation, but it's like. It's like. It's quite. It's like. Well, one past things or anything else you want to tell us about the prior part of this, which is the. You know, what else is holding you up from. Well, yes, we should go back to the beginning. The Camtasia was tested last week and initially we were a bit worried because. In the old version, it seemed to interfere with it. But when you when Craig recompiled it and it is new version, it's like. Seems to work fine. Yeah. Right. So it doesn't slow down the eye tracker. It doesn't do anything nasty. So we can tell. So we pay for it. There's very small graphical bugs, but it's not. It's not a big thing. It's like a couple of white pixels in the course of a. Of course, with a task. So it's not the distract. Nothing important. Nothing big enough. They're going to look at it. Right. So the last, I think I'm sorry, you know, I had a sort of emails from you and I probably didn't catch everything. The problem was that there are two Camtasia records. Yes. There will now have to be two Camtasia records because. Each person actually sees a different screen because of. They don't see their own gaze. They see the only other gaze. So there will need to be two separate Camtasia. Yeah. Oh, do you need to come to Camtasia to do that? Hopefully. Officially or. Yeah. The question is the license for Camtasia. You just need one editing thing and two recording things because. Yeah, the recording. The recording program is just quite a small program that just generates the video. So don't forget the licensing for that just to see. So you're going to look into this, right? Yeah, I hadn't thought about it. I just assume we just get one and one license code run a lot further. So it was technically she had to look at the license conditions. It might not. I suspect that it will be a per machine. I think. I never prejudge licenses in plugred. Okay. I'll have a look at the actual Camtasia license. The other thing we. Well, and hold on before we get going further. So this has implications for data storage, right? Because we've got, well, no, this is three times right because we've got. Oh, no, we're going to build. We're going to use Joe's script to build the videos on the fly, right? Because it's fast. So the permanent storage is just the Camtasia stuff. So. Is that a problem? Where are we putting things? Is there? Is there such a thing as dual track video? Because you can certainly mix things. What ideally one wants, one doesn't really want to have these things. Because we're using them for backup and for coding. We don't really want to play them independently. We almost always want to use them in exactly in parallel time aligned. You can dump them into one video frame if you don't mind losing resolution. But that's maybe a problem, right? Well, the other problem is Camtasia has to be manually launched in both machines separately. So the synchronization is going to be a problem? Yeah. What are we doing for synchronization otherwise? During the task, there's a flash and a bleep. Not during the task. Before. Yeah, before we. Okay, so that we'd have to realign them and couldn't. Yes. Dumps them from their start points. Well, maybe you could. The thing that you're dumping them onto just starts running with flash and a bleep. You turn on the two copies whenever at different times, but they're still. No, what are they? I don't really understand the parts that are operating here. Camtasia's are turning on. There's no time stamp that comes from some common source. No. They're on the two separate machines and you start and end them separately. They're not talking to each other. They're just recording. You start it recording and it starts recording once in one screen and you start the other recording and the other machine. So. They don't know. Okay. These are backups. Right. So the flash allows you to hand synchronize them later if you need to buy stripping extra video off the front. As long as you make sure you start them before the flash, then you're fine. But there's a cost of having to go to backup, which is synchronizing them. So they'll include things like the eye tracker calibration. Yes. Which is not bad thing actually. Because sometimes you want to go back and find out if this was just a particularly duff subject. Yes. See how long it took them actually. That's true. How long did it take them to calibrate? Every time we calibrated the damping slip. How many days before the validation worked or something? So you should start the Camtasia really early then. Well, at the moment that's why I was assuming. Right. Okay. No, that actually saves you hours trying to make somebody's data smooth out when it won't. Because. You go back and actually, yes, they were crap. That's a technical term. It's a technical categorization and psychological research. The other thing we were getting started was the microphones. Because only one of the Camtasia videos will actually have the same track. And that's because. We're just getting one people to the two mics. It's supposed to be worse. We need real sound recording. Right. That's two tracks. Yes. At the moment it's in what we've finally just. At 12 o'clock today, looks like we've got it. Sust. Is to get one channel, one microphone being the left channel and one being the right channel to merge into a stereo. Go. File. Unfortunately. On what? Sorry. On one machine. On one of the. The display piece easier, the Camtasia video. It's. That's not what you're putting it. I mean, that's our only sound record. Yes. Well, okay. You've got the proper sound record, but you're not dumping it through Camtasia to record it. Right. Yeah. Camtasia is recording. Well, before we were going to use Camtasia at all, what we were going to do, what were we going to do with the sound? Mm-hmm. Yeah. So, is there any sound degradation that comes about from putting this through Camtasia rather than running it out straight? No, you got. Yeah. You got exactly the same access to sound quality as you got from anything else on the windows. Yeah. You can decide whatever quality you want. So, whatever. Okay. So, what you're planning on doing is bunging it on one of the Camtasia tracks and then splicing it off the Camtasia track. It's an easy bit of. Yeah. And then you're going to bung it out of the other Camtasia track too if you need it, right? But we're going to store all three separately. Then. And the sound is going to start at the same time as one of the arbitrary one of the Camtasia videos, but you'll know when the real experiment. You'll know the relationship between that and the eye tracker timings. Yeah, because the synchronization, the audio and visual synchronization comes at a specific point in the eye track file. Yeah. No human intervention required. It's time stamped. No, it's stamped into it. So, it's just after just after it prints the line, styling experiment. Yeah. I'm pretty sure it's. Yeah. Hold on. Do we need that? I mean, I thought the way that Tim had the setup originally, the audio, the timestamps used, there would be joint timestamps between the audio and the eye tracker. So that, you know, the audio record. Ten seconds in was the same as ten seconds into the eye tracker record so that we didn't have to do any extra handwork. You know, any chopping the starts of audio signals to get. There was nothing. Okay. So we're relying on your MATLAB script to get us the chopped version of the audio, right? The MATLAB script just says, yeah, it gives you the timing of the audio beep in the end signal. Right. So we can either adjust the eye track data or we can actually chop the audio signal. Yeah. Take off the first, whatever, 70 seconds. There's going to be a way to sooner or later to align the eye track, Camtasia 1, Camtasia 2 with two sound channels. Yeah. Yeah, but, but, um, lining up the Camtasia 2 is going to take, he's working on a MATLAB script for the sound, but not for. So the one that's got the sound on it, that'll also tell you where to chop the video to get it to line up. The one that doesn't have the sound on it, it won't. Oh, the beep will fall. Oh, so it's just the beep's. Oh, okay. So no hand synchronization required at all. As long as the scripts work. Right. Yeah. Okay. Okay. How confident are you about the finding these things? Break off. I mean, you've seen the bit was it was. Yeah. So we just have to hope we don't have any subjects with odd vocalizations. Yeah, I don't see it on a technical that's what we know. They also tend to have a funny, funny shape. So, yeah. Okay. Yeah, because this is the dropout test. Yep. Okay. Is there an end signal? When you decide it's all over, does it? Yeah. There's a signal at the start and the end of every trial. Right. So when you when you've pressed, we're finished. Yeah. It's just that all kinds of crazy things happen when you're writing things. So saving a percentage of a trial, sometimes a good idea. Okay. Yeah. Oh, yeah. Yeah. It's a stereo jack. It's a stereo jack, but it's a mono microphone. You got a solution for that then? Line in. It's going through a line. So it's quieter because it's not powered, but it's still. Yeah. We still pick up the signal. Because, you know, people might want to use this for speech recognition or something. You never know if the date is there. Yeah. I mean, it's crazy we're in an anacolic room, which we specially built in anacolic room. Yeah. It's not dead in the room, which we specially built for this. And you're going to want for some line answers. We shouldn't screw it up more than we have to. Is there anything we can do to improve this? Oh, no. No, no. Better to collect it sort of. Do you have a powered microphone or something? Well, when they're out there, they're out there. So they have batteries in them, but it's not. It doesn't seem to be powered because of the line in it. Inputs are low. Wait, wait. I thought a solution was fixing this problem with a model microphone socket. Sound card? So you said the problem was the. The sound of the sound is. The sound is. The input is mono. Right. Yeah. The jack that is plugged into is stereo. But when it's recording from microphone, it records in mono. So is that fixable? Like is there any way we're in the sound card? Yeah. And these sound cards are better solutions than monkeying about with trying to filter white knives out. I think we remember the out front ten. Well, that's what one thing you do is record the speech signal separately for each person. But then you have to pull the two sounds together. Which isn't hard. But if each machine recorded the sound, we recorded the recording. So you have to line the videos anyway. Right. Yeah. Yeah. Yeah. Yeah. And then it's the. It's easy. I'm not the technical person. It's not. It's not. I was thinking in a MATLAB script, you just read for one read felt T. And then. So is there any reason why we don't do that? Yeah. But then the math script will tell you how far apart there. You can just measure the drift between the two of them. You get a list of where the beeps are. And then you say, right, this stream is like, I don't know, 0.25 seconds behind the other one. Says Robin thinking about cutting and splicing. Yeah. Yeah. Well, it's in the old days, we probably would have. If they'd been in the same room, we would have read a little stereo thing in the background as backup as well, just to make sure because it's slightly dicier. You know, if his scripts don't work. Yeah. I want to see. I want to see one of them look really nice before we start running subjects. Can we do that? It doesn't have to be a real trial. It just has to be two guys talking in the two bits. And then I just want to know it works the way you expect it to work. This is not a gesture of mistrust. This is just experience that if anything can screw up, it will. We've both been so badly picked in the past. I'm trying to choose my language carefully because we're being recorded. We're here more choice language at the point when we've all done a lot of work and then we discover we can't use the session because of something we didn't think about. Yeah. Yeah. But this sounds reasonable to me. So I think. Yeah. Do they both have the same sound card problem? I wouldn't count on it. They've both got the same sound card. Okay. Yeah. Yeah. Yeah. Yeah. It's probably worth mentioning this to the guys in the garage in Toronto, right? To say. Yes. Yes. Yeah. So the external version has got plugs that size. And that is stereo microphones. Right. But yeah, the other one is like the smaller size and that isn't stereo. So the card can do it. It's just that the connectors on the back of the computer can't. Well, yeah. I think tell the guys that's a, if the documentation said it could record in stereo, then I think we should talk to them about how they've done this. Is you not sure from the documentation what it says it can do? That's quite a trouble. It's finding it. It's a concern. And what's your work with the size? Yeah. Yeah. Yeah. But as far as we can do and find the website of the, yeah, the creative labs website and the review of it. And they weren't entirely clear, but they both suggested that it, that it was a mono, that it was a mono microphone. Yeah. And it's not the people that are interested in other things, but I'm more interested in the other things. Yeah. It's just the way they're wired it. So it's getting late and I've got a two o'clock and I've got a nice lunch. So I want to eat my lunch today. What did you want to get through today? I mean, I think it was useful going through your expectations about this because that's quite a bit clearer in my head at least. Yeah. But I think mostly we leave you to go away and redesign the GDF or add new bits to the GDF along these lines. Yeah. So basically the output of the GDF is just going to be a whole series of events. Yeah. With starting in time and the event's going to have whatever, whatever the object is that's been looked at and things. And then, yeah, and then it's a matter of we can put whatever filters we need after that so you can say, right? I just want to say from the time where they picked up triangle one to the part time it became part of the assembly, find out how much how much percentage of time they were looking at it or whatever. Okay. So given that there are these events recorded, we can use any of them as the beginning of any of them as a start point, for example, right? There are also motions being recorded of objects. Yep. So there's movements, there's look events. There's fixations of blinks in there at the moment as well. And yeah, and see, looks at objects and looks wherever else. But I think the thing to do is for you to go away and think about it this way with the different tracks, the different objects and the kinds of things we've added about whether they're looking at the other person's gaze and what have you. And try to change the spec so it reflects this and maybe by that point there will be some sample data or something. And the right thing to do is for us to look at the spec the way you understand it now and some data. And then Alan will have new ideas about what's needed or about these post analyses. Yeah. And then we can add them in. But it's going to emerge over time. That's clear. That's great. Before we break up for lunch, I just want to make sure that I know how long it's going to be before we run mode. Okay. So the sound thing is stands in our way. We need to be recording sound online. Okay. So that's the thing that has to be solved. The shape thing is solved. Yeah. That's solved now. We think. Yeah. Test. We believe. We have to test. So that's that should be done this week. In fact, like tomorrow, for example, the shape, all the shape problems are solved. Generating shapes, no problem. Scoring shape overlap, no problem. Nothing is a problem. There are no visual display. You don't have your models, how do you? What is, how do you know that the model is a different from frame? Yeah, they had their inspection last week. JP staggered away from it. Yeah. Yeah. Well, anything you actually need fixed. Yeah. Joe doesn't live here anymore, right? Well, but he wasn't going to be booking any time to us after the 31st of October. So that means that any bugs that need fixed in our correct responsibility, right? You don't know any change on that, right? That's what he said to us originally. So I would assume, you know, no more contact with Joe. It's not fair to get work out of somebody for free. So, you know, ask Craig instead. Well, he's physically here. We want to pay him for some more time. You can do that. Would that be a just better use of our time and get? Yeah. Well, he wasn't paid in advance. He was being paid in a rear, so it doesn't matter. I think he is around, and I believe. I think it's better to have all the software. I mean, it's not big things. It's just maintenance of this program at this point. But if everybody has a lot to do and, you know, Joe could give it a couple of hours, which is what it might take just to fix it, then let's do it because starting run time is not getting to be. Yeah. You know, like, because the problem is you've got to have it immediately when you discover a bug in that. And we can make Craig shift all his other priorities to do this because we bought him. Right. But we can't. We can't make Joe do this. Yeah. So it's kind of between availability and speed from start to finish, given that this is somebody else's code. But it sounds like you don't think there's anything that actually needs fixed at the moment because we only need this to work well enough that you can use it for something. We've got more products. We're building models. Right. And how many models do you need to completion and how long does that take? You have the design and some. And you got. Well, and you know about complexity. Well, that's what I'm waiting for. You're waiting on Marlous. You can cold call her today this afternoon. Yeah. I think so. I have to check back with JP fairly soon. Okay. You wanted to. The next 18 month plan. Great. Deliberables. Great progress with the experiment. Well, that's what we're doing now. Okay. So what do we think if you have a fairly hectic week, are we looking for subjects next week? Okay. Ads go up. Yeah, I do. I do. But I think ads should probably go up this week. We want people for next week. Is that okay? Is anybody now terrified at the thought that we're live next week? There are people coming in here. One after another or two after two more likely. Okay. Is this generalized is this generalized anxiety Robin or do you have a specific thing that. Okay. So aside from the usual angst which we all suffer when we go live. So we want to do some piloting at the end of the week. Yep. Yeah. So we'll get the audio stuff tested. Yeah. Single mic friends. Yeah. Get that test in a couple days. I assume that's something you need me for in terms of that. Right. Oh yeah. But she's actually relaxed that somewhat. Okay. Yeah. Yeah. Yeah. Mm-hmm. Mm-hmm. Mm-hmm. Mm-hmm. Mm-hmm. Mm-hmm. Mm-hmm. Mm-hmm. Mm-hmm. Mm-hmm. Mm-hmm. Mm-hmm. Mm-hmm. Oh, stensive blue book time, which isn't. So you can dash in there for half an hour at a time. Doesn't sound very useful for you. It's... Uh-huh. Okay. Well, you guys started out. We have a solid booking for all the mornings anyway. Right? Except by permission of us. Right. We own it. So we can change that. I mean, everybody acknowledged the other week that we... Right. But it would be kind to tell her ahead of time, which of your morning sessions you're booking. Oh, yeah, yeah, yeah. Oh, yeah, yeah. Don't worry. There's a booking system. Right? So it's public. What's booked and what is it? Mm-hmm. I thought that was a problem that your mornings weren't sliced up on the booking system. Yeah. Mm-hmm. All right. Maybe you should get on there and book mornings as far as the eye can see. Does, you know, if you're told, use the booking system. We think we spoke to all the people who used those facilities the other day, but we could be wrong. So... Yeah. And one of the people upstairs, downstairs, have, you know, as rules about who you hand the keys to. Well, there's a key goal to do. Because, you know, we like people to know to ground the... Oh, I thought the lending for the booking system. Caroline. From Caroline? Oh, the general office. The general office. See, because you're supposed to have training in... But no, they need an account on this machine to actually use it. They need an account on these machines. Oh, okay. So that's the same thing. So that they could book. They couldn't actually... And you control those accounts. Oh, okay. That's fair enough. Okay. Okay. We're also working on a way of making sure that the machines return to zero state when they're... Uh-huh. Yeah. When you come off. That's safe. Because then they learn the first time. Well, people have been leaving various bits of who knows what around them, right? Which we think is what's critical. Yeah, yeah. Okay. I really have to get out of here. So, what else is important before you run? Nothing, right? Piloting, piloting, piloting. You have to build the things you have to try the machines. The machines, things we have to check them with Marlos and JP that they like the representation of the variables, right? How about... Do you have any time on Friday? Oh, I don't think I brought my diary up. But maybe... Why? Maybe you and I should be the pilot subjects. First pilot subjects, the ones who know which questions we want to ask. And then we should get another pair who are naive to the whole thing. Okay. So... Yeah. This is generalized floating anxiety. No, no. It's wisdom, but yeah. Well, because actually we can... We make comments. They keep backing a vote into the development. So, do you know what time of day you might want? Because I should check that. Okay. You don't need me involved in the pilot there. Well... You all have to be there. You all have to be there too. I'll be around, but yeah, I'll be sure. Hopefully it all runs smoothly. I can relax. Okay. So that all sounds good fun. Okay. Well, I can just leave you guys here. Why not? Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay.