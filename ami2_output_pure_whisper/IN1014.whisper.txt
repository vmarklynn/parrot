 a I told the controller, well, I don't know. So, I think we organized this meeting just to discuss... I don't have my presentation. To discuss the project that is on the web, I shall mark proposed about capturing audio, video and slides in a synchronized way. So, we will start with an introduction, I think we will give you a few slides about reviewing Q&A systems. And then even if we don't have many things to talk about, just to start discussing about clearly the project and also dealing with our kind of timing constraints. And... The USB card doesn't work. And you didn't put on the... Maybe you can access through the network if it's on your H, or it's on your D machine. So, maybe we will be able to... Keep going. So, we had like five slides presenting different systems. And maybe we can do that at the whiteboard, it's a bit stupid, but I think you remember well the different parts and I am sure we can do that at the whiteboard. I really do something like that. It would be great to use the whiteboard. Okay, so I would like just to review the different project regarding acquisition system. So, basically there are five systems. The first one is called SMACK IDECO, which is developed by Fribor and CERN. The second one is your system, I would like to say the cheap meeting room system. The third one, yeah maybe I can share that. So the first one is a SMACK? The SMACK, yeah. Should I write? Yeah, maybe. Okay. Just a review of the... Yeah, yeah, sure, that's interesting. The first one is, yeah, I will call that a. SMACK, which is developed by Fribor and CERN. The second one is B, which is Arizona, I would like to say cheap meeting room or... I don't know. It's okay, cheap meeting room. Well, cheap meeting room is the, you know... Okay. But for the moment, I listen to the loved ones. For the moment, it's just to understand each other so we know... I thought it was called PAS. Yeah, for PAS. PAS, yeah, good idea. Okay, PAS. The third one is... That sounds like a rezandropa. Yeah, that's not the... Okay, the third one is called... This is the SMACK meeting room developed by Fribor, which is called... SMACK, smart minute, but... DIVA and SMACK, yeah. SMACK, yeah, smart minute is all the process of capturing the minutes automatically, but... DIVA. DIVA. D-I-V-A, something like that. The third one is called... The third one is the project that I have to improve the current smart meeting room at ADAP. For that, we will use... DIVA. Yeah, tape three. Okay, let's call that... DIVA. Free. And the last one, I would like just to mention, just for the meeting, this is the firewire. I don't know if you saw my presentation during my time. Did you... Okay. E, which is firewire. Okay. So, I will start just with the SMACK. So maybe I draw a line here. So the SMACK... The SMACK project is a project which aims to do the acquisition of audio, video and slide for presentation. Yeah, this project is done with free-boor and sound, but I'm just going to make a very short graphic. In fact, they use a card, a video card, which is called... I-VC... Yeah. I just write I-VC. In fact, this is a video card with four inputs. On these four inputs, you can have only video, but they want to make also the slide acquisition. So on one input, they put a conversion box, a converter, which converts from slide to video. So that means that we decrease the quality. We have a high quality in slide, and we go to lower quality, to lower quality with video. So this one is just for the SMACK. Now I will just move... The three others are the video. Yeah, these ones are just for video and audio. You can use them, and this board does the dVx compression on the file. This is the box that we have on the table, the card that we have on the table. And I'd like to add that this... I think it's quite ambitious project because it's with the SON, and they already worked on a European project called Indico, where they have released a full kind of conference software to manage all the conference aspects we have in the conference automatically. And I know that Alfredo already installed in a big amphitheater for students. And I guess it's currently working. And just in balance with this, we didn't choose that solution because they had no... The slides were not captured in a very precise way. That's the point. Otherwise it's fully automatic. Are you disgusted with them? Did you discuss that? Is it fully automatic? You don't know? I don't know. Okay. Well, I suppose, I suppose like a capture of things, right? I mean, I don't see why you could not capture the videos. I mean, we can't like this. But is it all synchronized and is it doing all what we want, but without the slide precision? I don't know. Let me cover this one important point. The technical aspect, so the way you acquire things should be driven by the kind of processing you want to have. So in our case, we need to have a good processing of slides. That in our case it means to transcribe with an OCR and then make indexing. We need to have a high resolution image. I guess that's what you mean by precision. Yeah. Right? So in a sense, that's the point. For us, we need to have this sufficient resolution image of slides to do what we want to do. So that's why I guess we don't follow the solution. And we are sure that in that context of SMAC project with the free brew working on document analysis, there were not enough precision and enough resolution in the slides. As far as I know so far, they did similar works on meetings, document center meetings. They always worked on manual transcriptions of documents. So they never really took into account a possibility of actually performing processing on the document they talk about during the meeting and during in this case the talk, the conference, the presentation. As far as they published them, I know the results they published so far. So essentially they never took into account. So I mean, they work at the eye level, which means basically we have the information coming from here and there. And we create the techniques that allow to start from the text there and the things that are saved and we find contacts. I mean, they make some kind of processing. But as they don't work on the low level, so low level means basically, okay, I take the speech and I start the transcription. I take the image of the document and I take the transcription. They basically don't really care of the aspect as far as I understand. As far as I know. As far as I know, I mean, they do, of course, they can do slide detection, slide change detection, which of course what I understood is also they try to recover the layout somehow. I mean, given the slides, but in no case they are extracting the text from the slides. So this in all the cases what I've seen, in all the cases I've seen, they assume that at least they have like a PDF version of the document. And basically they try to match what is displayed to the document. So first they need to extract information from the document, which does not seem to be so trivial at least for, because they're also working with maybe more complex documents with images and text and so on. Maybe with slides it's easier to extract the information. I assume it's easier indeed. But they assume basically that they have this document, which is something somehow we would like to relax because people are like in an affiliate, they're like, you may not want each time to ask the person, maybe the person has a point point, not a PDF version or maybe it's using Excel to do a demonstration or something like this. That's it, it makes less automatic in the sense that at a point you need someone giving the file and putting the file uploaded somewhere, etc. And it is a different kind of process. In some ways it's always driven by what you're able to do. They work a lot on layout analysis. I know they match the layout into XML files, etc. So it's a different way of approaching the problem, which means a different way of capturing different exigencies in capturing different documents. But most of the points for us would be valid. Slide transition, we would use slide, we need to do slide transition. To some extent we would like to extract some elements of the layout to this thing, to have a more higher analysis. But we would like to do this more automatically and in particular for the text recognition to be able to do retrieval of slides or points of presentation. We would like not to have to rely yet to a first PDF version or any version of the document. Okay, so the solution to that low quality is solved by you project, the past project. Make a tick here and I clean up. This is just to solve that problem regarding the slide and the slide resolution. So we remove that part and we call that the pass. And in that case we use a frame grabber here and we go with the slide here. And of course these two cards will be on the same machine and we have to develop a solution here. The main critical point is here the synchronization between these two cards. With that, this is the card that we use in the smart meeting room and this is the card. So you have both these cards, right? No, no, this one is the video card and this one, this is the card that we have already at EDAB for the... But I mean this one is the... It's the same list. Okay, so what I want to say is that on this card there are four inputs, right? Yeah. Yeah, so... So no, well, yeah. I was thinking to some extent nothing would prevent us from also occurring the slide but it is a slide stream from this card indeed, right? Okay, yeah, yeah. So we can have both. We can have the slide from the slide capture and we can just use a video signal to capture that also. Do you want to have two quality, high quality and all of that? Well, I mean just because we cannot... something we cannot do with the high quality capture device is to have a stream, I mean the stream, right? The full stream. Yeah, we can just take some snapshots. So we can take snapshots. So basically it may be interesting to have still the slide stream so that, for instance, if we detect there is any video that is displayed or so on, to some extent we could just cut these videos to keep it and to be able to replay it later on and so on. Yeah. And maybe indeed if, for instance, the slide stream on the right is automatically synchronized with the other parts of the video. Yeah. It may be easier to synchronize directly by some matching process. The slide, the high quality images we have here. With this one. Yeah, you won't. Yeah. So you would... Yeah. Something like... Is this something like that? Yeah, exactly. Yeah. So at least this is not at the electronic level but you would say at the content level, doing an alignment from the slide stream and from the snapshots we would have on the other side with something that might be possible. Of course if we have some constraints given by the electronic, I mean that's better. Because of course first the process is going to be easier and it might be just a few seconds that we have to align on the other parts but I think I could see, I could imagine that this could be a reasonable process to do especially because this would solve some of the issues regarding, I mean, the possibility of displaying videos after, from what we recall. Definitely. Okay. So I was just talking about the past project. Maybe I would like just now to talk about the DIVA project. So I clean up. Yeah. Yeah. Yeah. Did you rate something regarding the DIVA project? Well, this is more or less what we just discussed. Yeah, we just remember that here we still have only one machine to do the slide video and audio acquisition. In the DIVA it was something different. In fact we have a master machine. We have a master machine here and we have some slaves machine here. We have some connection and here we have some inputs. We have audio usually we have audio and the same for this one. And basically on the slave machine we have two cards, one for audio and one for video. So they develop something to synchronize these two cards together and this is something which is more a product which is called a direct show which allows you to synchronize these two cards together. But of course you want these two streams to be synchronized but you want also these two streams to be synchronized. So they have a synchronization between two slaves which is done by the master. Here we just use the ethernet network to synchronize these two devices. I just find it's not something like that. And they do only audio and video or they don't do any slide. So it was for the DIVA. I would like to talk regarding the fire free smart meeting room to have an equation. Tape free. Tape free. Tape free. Sorry. Tape free smart meeting room. So for that. So like the DIVA project is a tape free smart. Yeah. It's a tape free but also video. The acquisition is done in raw video. So the file is huge and they really need a long processing to convert raw file to a DIVA XOR to R and files. Okay. But this can be done automatically right. Yeah but it takes time. It's just a mention. So I'm really right. And that's what they use more less in TNOs. They don't have dapes. But with different cards. Yeah. They had something. Okay. Maybe first I will just describe the smart meeting room that we have at T DIVA. In fact we have also a master slave architecture. I clean a little bit. And which takes care about the audio. I clean that. And we have the slave PC which takes care about the whiteboard and the slides. Now if we look at the video. In fact, maybe first I should mention that between the master and the slave. We have the synchronization signal which is called MIDI time code. I just write MIDI. And for the video we have the video input here. We reuse the MIDI signal with to insert the time code on each frame. And we save that to dv recorder. Okay. We know the problem of that. Somebody has to take care of the dv tapes and convert them into dv eggs. So my idea is to do something like that. It's to develop a video slave machine. I say something like that. We have a video slave machine which use the MIDI time code. Sorry. I'm doing something. We have the video here. We just have the time code inserted. So we take that signal here and we move to this machine here. Which is in fact just the IBC video call. This is just an acquisition call. And we convert file directly to dv eggs. And so we will have here video. And also because we want to control that machine we use also the MIDI time code. The MIDI time code to start and to stop the machine. This is just something like that. This is just to remove the dv recordings. But just this is just an improvement of the smart material. Okay. Do you have any questions regarding that? Currently because there is a time code, video time code. You don't care about frame dropping. I mean because anyway you need to frame in the video signal. It is encoded time. Yeah. We don't have to care about the synchronization in that case because the time code is inserted here. And we take after the time code insertion we take the video signal and we pass through the machine. So this is a simple solution but where we don't have to care about the synchronization. Okay. Because the synchronization problem comes from the grabbing from the dv tape. Yeah. The synchronization is in dvicks so it is afterwards. Well but you don't, I mean at this point you don't really care because I mean in the signal you can extract the time. I mean the time stamp is in the signal. So if you drop some frame which happens sometimes when you do compression or acquisition. Yeah. You will automatically find this in the signal. Right. I mean it is encoded in the image so you can do it otherwise. If there is some frame dropping you have to rely on the number of frames you are counting or else as it goes to us. It is impossible. Yeah. So you have some problems. Okay. Okay. So the last one is the firewire acquisition. I just. Which was more or less TNO. It is a problem. Okay. Respect to frame dropping. Right. They didn't have too much frame dropping. The problem was it was not synchronized. So the time code was wrong for the different videos. They had at the beginning of the video you saw the time code. It was 6 hours and 50 minutes and there were 4 hours and 32 minutes. So it was a problem with the time code. I think if it was not a problem of frame dropping the alignment would have been quite easy to do. Well that is what they did manually afterwards. But they didn't have too much frame drops. In fact. No really. Yeah. It was not a difficult process. Well it is manual to synchronize. Yeah but if it is only to find one offset. Yeah that is what they did. Some examples. But I had the feeling that there are also some frame dropping. That was. No no because we did the software here and it did not. Okay. Okay. In fact the major problem regarding acquisition system is always the synchronization and for that firewire is good. I mean firewire was a project. Now the project is standby. We don't move to that project but I am just going to talk about this one. So with acquisition systems the major problem is the synchronization and firewire gives you some way to be synchronized. In fact this is I just want to describe here the bus. Yeah this is the bus where you can send some package. Any device we which wants to send a package. A package sorry. Should ask there is a manager of that bus. This is just the bus. Any device which wants to send a package has to require some bandwidth. So after that he will have that bandwidth and he will always have that bandwidth. So yeah he will always have that bandwidth and so we are sure that we will have a synchronized application with firewire and so that means that. Yeah sorry sorry. No problem. This is done at the libraries etc. To true well all you are saying about asking about bandwidth etc. It's done by hardware. So we don't have to code or communication. And in fact yeah as I mentioned before we have a bus manager and the bus manager send just a flag to say now it's time to give me your data and all devices which have required some bandwidth will send the data. So I am just drawing something like that. This is this kind of signal that the bus manager is sending and just after that bus just after that signal all device will send the data. So we will have the data from A from B and from C and so on. And after the next one we will have again the data from A, B and C and so on and so on. With firewire we are sure to have an acquisition system. Now the major problem with firewire is that firewire is just an kind of intelligent smart pipe, a synchronized pipe. We can put what we want inside. So we can put raw data or we can send a devics data or we can send also what I was presenting in my time presentation was H.264. But in that case we need something hardware here to encode raw data to a given former. Of course the idea is to reduce the bandwidth on the bus also. And all data are sent to the master. Do you have any questions? Now basically we have all this kind of general view about all the systems. Maybe we can take this opportunity to come back to our system because we have a long discussion and finally we decided for one approach and maybe take the opportunity to look just a moment at what point we are and when we plan basically to get something done working. I can add to that list of projects something that Shamaar can meet. And in the future we have a little bit of a background in the literature. There is FXPAL that is doing something very similar to what we do here basically. A capture through the projector signal of the slides and for the moment they just plan to use the slides as a way to index the presentations. But roughly it is an idea that is very similar to our idea. And this is up to you to tell us roughly what do you think. We will have something working. So we will be done together to try to divide the time. What do we do? We do not want today to put deadlines. But what we have, what we can do and how we will be able to do. I was thinking for instance in what we have because I do not know a lot about using like GLL, MFC, Microsoft software. But I am very happy to do that. So what we have until now is the software that Darren did for the frame grabbing. And actually I can start playing and looking at this in detail. So Darren software about frame grabbing. Not MFC. MFC. And GLL etc. All the windows are programming. So this is one step. Then the audio video card. So first we need to look at this, to look at the demos that are with what they call the SDK software development kit. And the demos testing the card with only one audio for instance and only one video. And even testing with only the slides to capture all the videos stream. In fact the slide card, sorry the slide card and the video card are both SDK. So you mean the frame grabbing card? Yeah. Both are SDK. They have SDK software development kit that is based on MFC libraries. Yeah. C++ libraries. Yeah. This is for that. I do not remember by half now. So once you have tested individually the card we can test to synchronize the audio and the video together. Usually audio and video should be synchronized. Okay. Because this just an audio video channel. Okay. So they are synchronized. So we can play with the video, we can play with the slide. And after that the major point is to combine both. Okay. And now as you said, the next point will be to use that card with the other card and to merge the slide signal with the, well, the synchronization signal coming from the frame grabbing card. It is not a synchronization signal. It is a slide with that. We do not have synchronization. We have to find a solution. And for that, maybe we can use a direct show, which is a thing. Which is a technique to synchronize different device. And is it external to this card? It is external? No, this is just an application. So it is external. It is not in this card. No, no, no. It is not on the card, it is just an application that runs on the machine. And we do not have to buy that. Or at least at least the base. I think, Rachel, you can download for free. I am not sure. I should check. Okay. And that will help us to synchronize this from grabbing card and this video card. Yeah. We need to do some tests. Reading. Yeah. Okay. And then when we have, okay. Where do we do that? We do not know yet with Frank if we installed this card. Maybe he. I think the best thing to do is to have a machine which is only dedicated to that. Because our... Okay. If you use a machine which has been already used for something else, sometimes you have plenty of libraries and so you don't know exactly. Maybe it would be better to have just a dedicated machine just for that. Be careful because I listen to Frank and apparently don't want to buy a new machine. Just for which we show that this works. Okay. So we have to use material that is already available. Okay. Yeah. And then we need to do some machines. Maybe there are some free machines. Well, my machine, his machine, no, this machine. Okay. So it is possible to use other machines? Yeah. I mean just that, you know, if of course you don't want to have a library that might conflict with the one you are trying to use at the same time if you crash a machine, I mean, because you are doing some tests you may not want. Do you have what's on your machine? I mean, it's too good to be erased or what's weather. So I think this is true. So maybe there is a machine, I don't know whether for this you need, you know, a very powerful machine and so on. But maybe there is a possibility to use a current machine. Yeah, yeah. With some other machine, yeah. Because we've drawn from the network. Because I think the video is done. The video compression is done on that car. And I'm not 100% sure. But I think the GPAC conversion for the slide capture is done also on the car. So we don't need. Yeah, but still I mean even if it's done on the car, the basic thing you need to check is the best, right? I mean the best way to speed up. But I mean, I was just thinking about the speed of the computer could be lower. Yeah, yeah, yeah. CPU itself may not be so good. Access. So in terms of time, what we can think, what we can expect to see. Can we expect a Christmas gift? Christmas gift. So early Christmas to early summer. Yeah, Christmas gift. Yeah, that's a good question. Maybe the first solution will be just to start with, because we need to start with something. We have the slide capture from Darren. We have, I will work on the video acquisition for the tape free smart fitting room. So I will start with that to develop some knowledge regarding that board, that video board. And after that we can combine both. The way of course, I don't know exactly what the work in course is. But it's not that I don't care, but I don't understand. I think the real point is when. Okay, I said at the beginning of the meeting that we're not roughly in it. I don't say, well no, no, I don't want to put the deadline. But given the current material we have, even your activities, because I know that you both are involved in many other things. So it's something that you, as Mr. Mark said, it's Christmas and so we are happy with the Christmas gift. Or it's something that you say is Christmas 2006. So I definitely just want to know something very rough. And when you expect to finish this. I mean, the test of looking at there, if we go point by point. So looking at there and score. So you said you would look at this, right? We would look both at this because we are also both quite busy with other projects. Of course, what I just feel is the base. That's the problem. Do you think it's something for the very next month? Do you think it's not for? No, no, it's not for end of next year. It's too long. So it's too long? So half next year? For my session, I would like to say that up real may we should have results. Results, what does it mean? The end of this? I don't know. I mean, the... It's not for the ready that we use. Almost the complete application. Maybe some minor change will appear. For me, what is important is when it is ready to be used, when I can say start collecting data. I start using, I start playing with this. Basically, the process is ready and we can start having our demo. Also because there is a risk that we submitted a project, maybe it will be rejected with a no. But potentially, we are going to have a student supposed to work in this. It will be no before April 2006 anyway. But, you know, some way we cannot tell students and make them wait one year before he has the material to work. So my point is when, reasonably, roughly, I don't know, and it's not that it lines away. But when do you expect to have the system ready to work working? Because, I mean, the IVC system, I mean, my feeling is that, I mean, people have expertise in this, like in free-bours. Yeah, they have. I don't think it should take a lot of time. I mean, just to look at this, right? I mean, at least one month seems to be... Yeah, but we start with the IVC. We start with the data path, the slide, Frank Grabber. And after that, the question is, how to synchronize, how to make both car working together. Together. So this seems to be the main problem as far as I understand. So, yeah, let's see. For checking down in the code, et cetera, we can expect it until... Yeah, for one month or so, then the IVC... The people at free will have... IVC should go faster. So, because anyway, we see what you are working on, right? We have the IVC, but using the signals that are coming... I mean, basically it's... Yeah, I'm not currently working on it. I will start to work on January on that point. Okay, and then... But I think... Okay, so currently you are not working on this. No, no, I'm not working. Okay, then... I scheduled to work on that. So we can say we try to make something for April. Yeah. But I have... You think something you are using, very vague expression or result... Well, I want this to work for the time. Just tell me when it is ready. And if you think it's not before... But must be reasonable, I mean... If you think it will be not before December 2006, say December 2006, so don't try to tell me March or April... If you already know that it is unrealistic to say that, it must be realistic, if you say June 2006, we know it is June 2006... But I would like to say there is many unknown in that project. I know. I would like to say we can make a schedule for that project... Of course. To just to see if we track the timetable. If we don't, we ask for more people, maybe HEVS people, to be slightly involved in that project... Once you don't... To respect the date. Yeah. There is no date to respect this. I don't know. I mean, if you can have early warnings in the Senate, if you see that there is a major problem somewhere. But it's just to know, in the sense that really... This thing has been stopped now for quite a long time. It took a long time to decide what kind of material. Now we have it. It's something that is a pretty good idea. We see that other people are working, etc. We are going to lose it some way. That's one of the issues. And very honestly... I don't know whether you realize this. But of course, if we have this in two years, maybe okay, it's good, we have it. But of course, it's on a different level of research. In terms of research, maybe even in terms of innovation. I mean, if you think about this, which is what they said, I mean, speaking about innovation, this is probably one innovation. We see quite well why FxPAL is working on this, right? But in two years, if we want to build a CTI or transfer technology and something like this, maybe of course, okay, people will say, yeah, but there is already something that people have started to put on the market and so on. So maybe it's too late to do it. So I think this is really one of the points with respect to research. Of course, I think it's going to appear more and more and more. In a sense, I never tried, for example, eventually to ask for one person dedicated to this, because I always said the feeling that you are very interested, you wanted to do it. It's something new, something that is interesting to you. But if you have no time and the possibility that you are both involved in many other things, we can eventually try to ask to have one person, to involve one person that will be dedicated strictly to this. We can try, I mean, we can ask in the sense that if it is a priority for idiots, so far we will get very good signals from that point of view. I don't know. But please, if you think you don't have the time or the energy to do it, it involves too many things that you cannot keep under control, given the other things you have to do. Don't think that, okay, something nice, we can wait, or sooner or later it's going to happen. No, no, we just can't wait. We were here one year ago, I don't know, also when it was... So I think it's the moment for you to really realize, try to have a realistic date. And if you think there are too many things that you risk to lose control, tell it now, and we can try to say, well, we want to do it, but basically in my head, and all of you... Okay, that's not only I want to be involved in that project. But you can be involved in a different way. I mean, you can eventually have a supervision role, and the sad that you think, I know how to do it, I like to do it, but I have no time, because at a certain point is a matter of time, we can try to ask. But please just don't keep this as a kind of thing, I like to do it, I like it, it's nice, etc. Because when you say here now, okay, no, I'm not going to start working on this before January, for me it surprises me to some extent, you know. I thought, I mean, you would be working on this, so if you say... Yeah, but at the same time I have some other project, I want to finish those projects first. But here you have to take responsibility, you can say I like to do it, but then I will do it when I can... But the point is that Olivier, you have, I mean, since one year, you have always been saying that you want to be involved in this and so on, so it seems that it has never been a priority, so that's the point. So if you have no time to put priority at some point, and this seems to have been the case during one year on this project, I mean, you need to say now. But for example, I received some new project, I said that I have no time yet, I say I have no time, now currently, I say for some project you say that you don't have time, but people will continue to say, no, no, you will find time, just to do with that project. Okay, so now is your responsibility to say I cannot find time. If you can't find time, you have to say it now, this is possible. At least it's obvious to us, and we see it's not an accusation, we are all in the same condition. Again, and this is a question. How are you saying you have no time? So now you say it to us, so now we understand, and maybe after, if we discuss with Frank, Frank, from us, and we'll see, okay, and go, and try to see, okay, apparently he has no time to work on this, so we think it's important and we'd like to do something. So what kind of solution has that essential momentum? Do we need to take somebody, do we want to take some intern to work on this, and so on and so on? Do we take to have somebody contract, even if it's not an intern, but take somebody for six months to work on this? I mean, but so this is a point, I mean, I don't know about the other projects you have to do, I don't know if you are discussing about the time you can spend on each of the projects, but if, because now you are just telling us you have no time, indeed, to work on this, right? Yeah, okay. So, so... Currently, but... Yeah, but I mean... Up to December, I don't have time to work on it, but I plan already, I... With IM2, I... With IM2, I did, I mentioned that I will have from January 2006, I will have time for that. I have a... It was on IM2, I see. Now, I will work fully on that, on this point, from January 2006. I wish... It was 50%, no, on IM2, IP1, okay, maybe an 50% on that. So, let me post a question very brutally. Do you think that to have a person that does this will help you? We can ask, we can try to ask, maybe have some person for six months, so that your role is simply to help and advise. Well, this was... I don't want to talk too much, maybe, with Sebastian, so this was maybe his concern. Yeah, Sebastian is busy with annotations, all kind of things. Maybe we can... I think... In the process, we can ask for... Someone more? Maybe a good thing will be to make a plan, to say. Well, that's what I... We answer the deadline here, we are here, we split that part in different seconds. That's what I was trying to do, and I, before coming here, I just tried to make a... I'm sorry, but you still don't answer to my question. But I don't answer, yeah. You are not answering my question. Let's say April, 06, and we do our best with trying to keep you informed about the advancements. And if we see early, that clearly... Let me pause again the question very clearly. If I go to Erve, I can try and say, we are in this situation, apparently. Why don't we take one person, three months, six months, four months, that directly advise by earlier, and we can speak up. And we can speak with experience in C++ MFC. Consider that it can be difficult, of course, to find an acceptor. Do you think it's an option? You have people that are aware of MFC, I mean, people that suppose that it's UV, or something else. A teacher, you think there are people? Why wasn't it a mind, the UV? I mean, there would be, obviously, some students that would be aware of, and that could be able to handle this. I mean, you're working with software and both of us, software and our way. Do you think it's a reasonable option? Do you think it's something that can help you? Because that's just a matter of responsibility for you guys to... There is nothing bad if you say have other things to do, because we are all full of work. This is something that is added on the top. If you don't have time, you don't have time, guys. But please, just tell me, we will find the time, however, so April 6, you will have your system. Or, no, we are not sure. We don't really know. It can happen that we don't. We don't know what we are going to find on the way. Maybe we think it takes one week and then it takes one month, we don't know. Maybe we will not able to be continuous, because one of the longest thing is to work one week, then one month, no, etc. It's something that breaks, it's difficult. That's a point. So, which doesn't mean you are excluded from the thing. In the sense that in the case someone will have to advise the person eventually. It can't be him, it can't be me, it can be you that basically follow, advise, help, but at least the mass of the work will be done by someone else that can spend 100% of time on that. Now, it's not even guaranteed in the sense that I can ask this. I can say that this is the situation and you are. Or eventually, yes, someone can say, okay, now this become your priority, forget about everything else and go with that. I don't know. Or we'll tell you, okay, January 2006, but from January 2006 you do not understand this. We can find the time, whether it is your time, whether it is the time of someone else. But I really would like to stop with this because this has been for several months that you say we like, we want, and I'm sure, I believe you. But then it is always something that must be done outside the normal activity. Which is really bad. I understand exactly. Otherwise, I mean, as I say, to do it in two years. Yeah. So what do you think? You like to try to solve this problem and try to say that there is a time problem and you don't have the time to do it? Because so Olivier says it's not before January on his side, so I'm not sure about it on your side. What I would like to work on part-time one day a week. Yeah. And one full day a week. Okay, maybe you want my own server, but I would say that we start, but we really have to start working, reading all the code from Davin. And then we try this card with the code, IVC card to try this. Then we try a little bit direct show to see to have an idea of how long that could be. And then at the moment we can say, okay, we need someone to help us. Okay. That's going to be. I think that would be good just to have a plan and to have some deadline in that plan. As soon as we are not in time, we will have several issues. I would say like if there would be a machine like this with the two cards separated as I mentioned. I mean, if we record the flow of the video, for instance, and the snapshots from the slides to some extent, there is some possibility of doing some automatic alignment without having a special synchronous. So this means that to some extent we could have a device which would not yet be fully synchronized. And I don't know if we've very well done code in terms of signing signals and so on. But that might be sufficient because it's synchronized up to five seconds. And you would say five seconds, my sim a lot for you and video, but maybe with respect to slides and the rest is something that might be terrible. So still we would be able to start doing some recordings and maybe doing even the automatic alignment or at least we would have an idea about what are the problems in terms of alignments. Because it's not like with microphone arrays where you need microsecond alignments, of course. Or even maybe we will have video where it might be one or two frames. I don't know. So this is really somehow, I mean, the issue. I mean, I'm sure that there are plenty of possibilities to do things. And the goal would be that indeed we could start doing some of the recordings of the time. So that we would have something where we could start getting the data. Because after, I mean, even if it's there, we cannot put all the times in one week. So I mean, this is one of the issues as well, which is to have it so that we can play and we can make a nice demo and so on with the full thing and something. So the other part is to have a system from which we can already record data and with some approximations. And I have the feeling, given the descriptions that you made, that to have such a system wouldn't require six months of work. Because basically, there are not codes in there to some extent. And the IVC is something quite standard from which we could ask, I mean, even we could even pay maybe pro. Some people from Fribbo, I don't know, I have to come here and to help us with installation on a computer. And to get the, so I have more of the feelings that we see, something that could be done almost in one month. Again, I'm not speaking about the synchronization, I mean, without the actual, you mean, the functional and time alignment? Yeah, yeah. That would be done in like in common software that we have. Yeah, for instance, after all, a simple question, maybe can, are we sure that it can work on a single computer? I don't know. Okay, I mean, this is about testing and services. Yeah, okay. So it doesn't require, it's more testing, it does not require so for this, I mean, if you put the two cards on the computer, you put the two, then you, basically, you say play on both sides, and you look whether at the end, you have a record of signals, which is a time that it should not be. And, or whether I mean the fact that whenever I mean the slides is doing some processing, it is some burden, there is some frame drops. So you could say, okay, let's for Christmas, let's try this, without the, all the synchronization with the actual issue. Okay, oh yeah, you cannot, oh, by doing one day a week, you know, just testing the cards. It seems to me clear, until January, if I, if I say, in January, this is just to finish, I want to have the deadline at, and of December to finish all my projects, I want to finish all this project when everything is finished. So, just to conclude, I can move to another one. But I don't want to. So you can't work. Yeah, it's not really, can't work until January. So I try my best. It's up to you. Until January. And, and I try to do what Jamak described, to give you a first feedback on the different cards. And, and from there, yeah. And then we make a decision in a sense, whether you continue working or we try to find a time in a different way, or we try to eliminate your other priorities. So we're under. I'm wondering whether or still we could ask for to get an intern for this. Yeah. I don't know regarding HEVS. I don't know if this is still in time, but you can have, you can ask for students. Deeplma work. Yeah, this is still even, even the non-diploma work. I mean, I think that's different. That's different, but it's really up to you guys, whether you think it's good to have one person try to have it, because I can say we have tried to have. I would say, yeah, let's try to have one student to help us on that. That is very, well, we have to choose whether the students, it's a bit, but the student should have knowledge about MFC. Better not person, then a bad person anyway. Okay. It doesn't mean that we have to. The recording is finished. That's your idea, as a result.