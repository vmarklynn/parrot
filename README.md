# PARROT SUMMARIZATION FOR MEETINGS
#### Project for Data Science Capstone @ Seattle University
#### Team Members: Vincent Marklynn, Long Yong Tan, Anjali Sebastian
#### Sponsor and Guide: Dr. Wan Bae and Dr.Sada Narayanappa

### Information on all Modules
1. data: contains all the full transcripts generated from the audio files of AMI and ICSI corpus using both whisper and pyannote.
2. formatted_data: contains the data after preprocess. We are trying to make appropriate for input to the BART model
3. baseline_sum: Baselne summaries generated by using vanilla BART model
4. reference_txt:  Human made summaries for reference purposes  
5. templates: all Django template files
6. mini_samples: small audio samples to test the Django UI
7. notebooks: all code files are here. Detailed info on each code file **TBDL**
8. Environment Files: requirement.txt (for Django Environment), whisper_django.yml (conda environment exported from AWS)


### 1.Project Objectives
- Analyze and summarize audio data in conversations with more than two speakers in a meeting environment.
- Speaker Diarization - Identifying how many speakers are there in teh converstion and when each speaker spoke.  
- Summarization – there are two approaches - Extractive vs. Abstractive. We use the abstractive method as there are not many people doing this. 

### 2. Related Work
BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension 

BART is pretrained by corrupting the input text using some noise schemes and learning a model to reconstruct the original input. It reads the corrupted input in both directions, left to right or vice versa. The bidirectional encoder produces a set of hidden states that capture the meaning and context of our input text. Then, this collection of hidden states will get pushed to the autoregressive decoder. The decoder is another component that generates the output text one element at a time, where each element is conditioned on the previously generated elements.

### 3. Tools Used
- Whisper -  https://github.com/openai/whisper  
- Pyannote - Partitioning speakers (diarization) - Amazon Transcribe 
- Summarization Algorithm – BART 
- NLTK - https://www.nltk.org/
- Django Framework  

### 4. Datasets Used
- AMI Meeting Corpus - https://groups.inf.ed.ac.uk/ami/corpus/ 
- ICSI Meeting Corpus - https://groups.inf.ed.ac.uk/ami/icsi/ 

BART hasn’t been trained on any long conversation dataset that includes multiple speakers. We plan to feed some of the AMI and ICIS corpus to BART and utilize another portion of the data to validate the outcome. 

### 5. Metrics for assessing performance
- Our main evaluation metric will be ROUGE (Recall-Oriented Understudy for Gisting Evaluations). 
- It compares automatically produced summaries against reference summaries which are human produced. 
- For example, if a machine summary produced “the cat was found under the bed,” it would be compared against “the cat was under the bed.” 
- ROUGE measures the following: **Recall:** how much of the reference summary is recovered from the reference? **Precision:** how much of the system summary was relevant? 
- ROUGE needs reference summarries. For reference summary we are using previous human summaries created for the data set.
